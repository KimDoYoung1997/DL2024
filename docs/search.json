[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2024)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n카카오톡: http://pf.kakao.com/_txeIFG/chat\n\n수업빼먹음\n\n06wk-2: (1시간)\n08wk-1,2:(1시간)\n09wk-1: (2시간)\n10wk-1: (2시간)\n\n수업보충\n\n10wk-2: (1시간)\n11wk-2: (1시간30분)\n13wk-2: (30분)\n14wk-2: (1시간)\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nJun 13, 2024\n\n\n15wk-2: 기말고사\n\n\n최규빈 \n\n\n\n\nJun 10, 2024\n\n\n15wk-1: 강화학습 (4) – LunarLander, A1, A2\n\n\n최규빈 \n\n\n\n\nJun 6, 2024\n\n\n14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)\n\n\n최규빈 \n\n\n\n\nJun 3, 2024\n\n\n14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)\n\n\n최규빈 \n\n\n\n\nMay 29, 2024\n\n\n13wk-2: 강화학습 (1) – Bandit\n\n\n최규빈 \n\n\n\n\nMay 27, 2024\n\n\n13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?\n\n\n최규빈 \n\n\n\n\nMay 22, 2024\n\n\n12wk-2: 순환신경망 (3) – RNN, LSTM\n\n\n최규빈 \n\n\n\n\nMay 20, 2024\n\n\n12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell\n\n\n최규빈 \n\n\n\n\nMay 15, 2024\n\n\n11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해\n\n\n최규빈 \n\n\n\n\nMay 13, 2024\n\n\n11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2\n\n\n최규빈 \n\n\n\n\nMay 8, 2024\n\n\n10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템\n\n\n최규빈 \n\n\n\n\nMay 1, 2024\n\n\n09wk-2: 중간고사\n\n\n최규빈 \n\n\n\n\nApr 22, 2024\n\n\n08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)\n\n\n최규빈 \n\n\n\n\nApr 15, 2024\n\n\n07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM\n\n\n최규빈 \n\n\n\n\nApr 8, 2024\n\n\n06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10\n\n\n최규빈 \n\n\n\n\nApr 3, 2024\n\n\n05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석\n\n\n최규빈 \n\n\n\n\nApr 1, 2024\n\n\n05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy\n\n\n최규빈 \n\n\n\n\nMar 27, 2024\n\n\n04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현\n\n\n최규빈 \n\n\n\n\nMar 25, 2024\n\n\n04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\n최규빈 \n\n\n\n\nMar 20, 2024\n\n\n03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복\n\n\n최규빈 \n\n\n\n\nMar 18, 2024\n\n\n03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계\n\n\n최규빈 \n\n\n\n\nMar 13, 2024\n\n\n02wk-2: 회귀분석 (3) – Step1,2,4 의 변형\n\n\n최규빈 \n\n\n\n\nMar 11, 2024\n\n\n02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분\n\n\n최규빈 \n\n\n\n\nMar 6, 2024\n\n\n01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법\n\n\n최규빈 \n\n\n\n\nMar 4, 2024\n\n\n01wk-1: 이미지 자료 분석 (겉핥기)\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/11wk-2.html#a.-data",
    "href": "posts/11wk-2.html#a.-data",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "A. Data",
    "text": "A. Data\n\ntxt = list('abc'*100)\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'c', 'a', 'b', 'c', 'a']\n\n\n\ndf_train = pd.DataFrame({'x': txt[:-1], 'y': txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\na\n\n\n3\na\nb\n\n\n4\nb\nc\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'a':0,'b':1,'c':2}))\ny = torch.tensor(df_train.y.map({'a':0,'b':1,'c':2}))"
  },
  {
    "objectID": "posts/11wk-2.html#b.-mlp-하나의-은닉노드",
    "href": "posts/11wk-2.html#b.-mlp-하나의-은닉노드",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "B. MLP – 하나의 은닉노드",
    "text": "B. MLP – 하나의 은닉노드\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=1),\n    torch.nn.Tanh(), # 이거를 씁니다. 왜 이걸 쓰는지 설명하면 너무 길어요. 외우세여. \n    torch.nn.Linear(in_features=1, out_features=3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n\n\nfor epoc in range(50):\n    ## 1 \n    netout = net(x) \n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nyhat = soft(netout)\nyhat.argmax(axis=1),y\n\n(tensor([1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]),\n tensor([1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2, 0,\n         1, 2, 0, 1, 2, 0, 1, 2, 0, 1, 2]))"
  },
  {
    "objectID": "posts/11wk-2.html#c.-적합결과의-해석-star",
    "href": "posts/11wk-2.html#c.-적합결과의-해석-star",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "C. 적합결과의 해석 (\\(\\star\\))",
    "text": "C. 적합결과의 해석 (\\(\\star\\))\n- 네트워크 분해\n\nebdd, tanh, linr = net \n\n- ebdd 레이어 통과직후\n\nebdd_x = ebdd(x).data[:9]\nebdd_x\n\ntensor([[ 0.0287],\n        [ 1.8616],\n        [-2.8092],\n        [ 0.0287],\n        [ 1.8616],\n        [-2.8092],\n        [ 0.0287],\n        [ 1.8616],\n        [-2.8092]])\n\n\n\nplt.plot(ebdd_x, '--o', color='gray')\nplt.title(r\"$ebdd({\\bf x})$\")\nplt.title(r\"$ebdd({\\bf x})$\")\nplt.xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3);\n\n\n\n\n\n\n\n\n- (ebdd -&gt; tanh) 레이어 통과직후\n\nebdd_x = ebdd(x).data[:9]\nh = tanh(ebdd(x)).data[:9]\ntorch.concat([ebdd_x,h],axis=1)\n\ntensor([[ 0.0287,  0.0287],\n        [ 1.8616,  0.9528],\n        [-2.8092, -0.9928],\n        [ 0.0287,  0.0287],\n        [ 1.8616,  0.9528],\n        [-2.8092, -0.9928],\n        [ 0.0287,  0.0287],\n        [ 1.8616,  0.9528],\n        [-2.8092, -0.9928]])\n\n\n\nfig,ax = plt.subplots(2,1,figsize=(8,8))\nax[0].plot(ebdd_x, '--o', color='gray')\nax[0].set_title(r\"$ebdd({\\bf x})$\")\nax[0].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[1].plot(h, '--o', color='gray')\nax[1].set_title(r\"${\\bf h}:=(tanh \\circ ebdd)({\\bf x})$\")\nax[1].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3);\n\n\n\n\n\n\n\n\n\n여기까지 2개는 세트로 봐도 무방할듯\n결과를 \\({\\boldsymbol h}\\)로 생각하자.\n\n- (임베딩 -&gt; tanh -&gt; linr) 통과직후 – 여기에서 차원이 3차원으로 된다.\n\nebdd_x = ebdd(x).data[:9]\nh = tanh(ebdd(x)).data[:9]\nnetout = linr(tanh(ebdd(x))).data[:9]\n#netout = net(x).data[:9]\ntorch.concat([ebdd_x,h,netout],axis=1)\n\ntensor([[ 0.0287,  0.0287, -1.3637,  0.8247, -1.3384],\n        [ 1.8616,  0.9528, -4.9139,  1.2273,  2.9339],\n        [-2.8092, -0.9928,  2.5602,  0.3797, -6.0603],\n        [ 0.0287,  0.0287, -1.3637,  0.8247, -1.3384],\n        [ 1.8616,  0.9528, -4.9139,  1.2273,  2.9339],\n        [-2.8092, -0.9928,  2.5602,  0.3797, -6.0603],\n        [ 0.0287,  0.0287, -1.3637,  0.8247, -1.3384],\n        [ 1.8616,  0.9528, -4.9139,  1.2273,  2.9339],\n        [-2.8092, -0.9928,  2.5602,  0.3797, -6.0603]])\n\n\n\nnetout_a = netout[:,[0]]\nnetout_b = netout[:,[1]]\nnetout_c = netout[:,[2]]\n\n\nlinr.weight, linr.bias\n\n(Parameter containing:\n tensor([[-3.8416],\n         [ 0.4357],\n         [ 4.6228]], requires_grad=True),\n Parameter containing:\n tensor([-1.2536,  0.8122, -1.4709], requires_grad=True))\n\n\n\nnetout_a, h*(-3.8416) + (-1.2536)\n\n(tensor([[-1.3637],\n         [-4.9139],\n         [ 2.5602],\n         [-1.3637],\n         [-4.9139],\n         [ 2.5602],\n         [-1.3637],\n         [-4.9139],\n         [ 2.5602]]),\n tensor([[-1.3637],\n         [-4.9140],\n         [ 2.5602],\n         [-1.3637],\n         [-4.9140],\n         [ 2.5602],\n         [-1.3637],\n         [-4.9140],\n         [ 2.5602]]))\n\n\n\n값이 살짝 다른이유는 Appendix 참고\n여기서는 그냥 “똑같은 결과가 나왔다” 라고 생각하고 넘어가자\n\n\nfig,ax = plt.subplots(2,1,figsize=(8,8))\nax[0].plot(h, '--o', color='gray')\nax[0].set_title(r\"${\\bf h}:=(tanh \\circ ebdd)({\\bf x})$\")\nax[0].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3);\nax[1].plot(netout_a, '--o', label=r\"$netout_a =  (-3.8416)\\times {\\bf h} + (-1.2536)$\")\nax[1].plot(netout_b, '--o', label=r\"$netout_b =  ( 0.4357)\\times {\\bf h} + (0.8122)$\")\nax[1].plot(netout_c, '--o', label=r\"$netout_c =  (4.6228)\\times {\\bf h} + (-1.4709)$\")\nax[1].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3);\nax[1].legend()\n\n\n\n\n\n\n\n\n\n파란색: 의사표현 확실\n초록색: 의사표현 확실\n주황색: 약간 회색분자느낌, 사실상 얘가 결정하는건 없음.\n\n- 이 네트워크는 b-&gt;c 인 맵핑과 c-&gt;a인 맵핑은 확실히 학습한듯 보이지만 a-&gt;b인 맵핑은 그다지 잘 학습한 느낌이 들지 않는다.\n\n마치 y=b를 맞추는 방식은 y=c 도 아닌것 같고 y=a 도 아닌것 같으니까 y=b 아닐까?” 같은 느낌\n\n- 전체과정 시각화\n\nonehot_x = ohot(x).data[:9]\nonehot_a = onehot_x[:,[0]]\nonehot_b = onehot_x[:,[1]]\nonehot_c = onehot_x[:,[2]]\n#--#\nebdd_x = ebdd(x).data[:9]\n#--#\nh = tanh(ebdd(x)).data[:9]\n#--#\nnetout = linr(tanh(ebdd(x))).data[:9]\nnetout_a = netout[:,[0]]\nnetout_b = netout[:,[1]]\nnetout_c = netout[:,[2]]\n#--#\nyhat = soft(net(x)).data[:9]\nyhat_a = yhat[:,[0]]\nyhat_b = yhat[:,[1]]\nyhat_c = yhat[:,[2]]\n#--#\ntorch.concat([ebdd_x,h,netout,yhat],axis=1).numpy().round(2)\n\narray([[ 0.03,  0.03, -1.36,  0.82, -1.34,  0.09,  0.81,  0.09],\n       [ 1.86,  0.95, -4.91,  1.23,  2.93,  0.  ,  0.15,  0.85],\n       [-2.81, -0.99,  2.56,  0.38, -6.06,  0.9 ,  0.1 ,  0.  ],\n       [ 0.03,  0.03, -1.36,  0.82, -1.34,  0.09,  0.81,  0.09],\n       [ 1.86,  0.95, -4.91,  1.23,  2.93,  0.  ,  0.15,  0.85],\n       [-2.81, -0.99,  2.56,  0.38, -6.06,  0.9 ,  0.1 ,  0.  ],\n       [ 0.03,  0.03, -1.36,  0.82, -1.34,  0.09,  0.81,  0.09],\n       [ 1.86,  0.95, -4.91,  1.23,  2.93,  0.  ,  0.15,  0.85],\n       [-2.81, -0.99,  2.56,  0.38, -6.06,  0.9 ,  0.1 ,  0.  ]],\n      dtype=float32)\n\n\n\nfig, ax = plt.subplots(5,1,figsize=(8,16))\nax[0].set_title(r\"$onehot({\\bf x})$\")\nax[0].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[0].plot(onehot_a,'--o',label=\"a\")\nax[0].plot(onehot_b,'--o',label=\"b\")\nax[0].plot(onehot_c,'--o',label=\"c\")\nax[0].legend()\n#--#\nax[1].set_title(r\"$ebdd({\\bf x}):=(linr_{3 \\to 1} \\circ onehot)({\\bf x})$\")\nax[1].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[1].plot(ebdd_x, '--o', color='gray')\n#--#\nax[2].set_title(r\"${\\bf h}:=(tanh \\circ ebdd)({\\bf x})$\")\nax[2].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[2].plot(h, '--o', color='gray')\n#--#\nax[3].set_title(r\"$net({\\bf x})=(linr_{1 \\to 3} \\circ tanh \\circ ebdd)({\\bf x})$\")\nax[3].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[3].plot(netout_a,'--o',label=r\"$netout_a =  (-3.8416)\\times {\\bf h} + (-1.2536)$\")\nax[3].plot(netout_b,'--o',label=r\"$netout_b =  ( 0.4357)\\times {\\bf h} + (0.8122)$\")\nax[3].plot(netout_c,'--o',label=r\"$netout_c =  (4.6228)\\times {\\bf h} + (-1.4709)$\")\nax[3].legend()\n#--#\nax[4].set_title(r\"$\\hat{\\bf y} = soft(net({\\bf x}))$\")\nax[4].set_xticks(range(9),[r'$a\\to b$', r'$b\\to c$', r'$c\\to a$']*3)\nax[4].plot(yhat_a,'--o',label=r\"$P_a$\")\nax[4].plot(yhat_b,'--o',label=r\"$P_b$\")\nax[4].plot(yhat_c,'--o',label=r\"$P_c$\")\nax[4].legend()\nplt.tight_layout()\n\n\n\n\n\n\n\n\n- 다른방식의 시각화\n\nh = tanh(ebdd(x)).data[:9]\nnetout = linr(tanh(ebdd(x))).data[:9]\nyhat = soft(net(x)).data[:9]\nmat = torch.concat([h,netout,yhat],axis=1)\n#---#\nplt.matshow(mat,cmap=\"bwr\",vmin=-6,vmax=6)\nplt.colorbar()\nplt.axvline(0.5,color=\"lime\")\nplt.axvline(3.5,color=\"lime\")\nplt.xticks(ticks=[0,1,2,3,4,5,6],labels=[r\"$h$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\"]);\n\n\n\n\n\n\n\n\n\nnetout 을 보는 요령: 가장 빨간부분이 예측값이 된다.\n역시 \\(out_b\\)의 경우 애매한 색깔만 있음. (가장 빨갛다기 보다 다른게 파란색이 나와줘서 정답을 맞추는 느낌)\n그런데 \\(out_b\\)의 경우에 대응하는 \\({\\boldsymbol h}\\)를 살펴보니 흰색임. 이것은 값이 0이라는 의미인데 이때는 \\({\\boldsymbol h}\\) 에 걸리는 선형변환 \\(linr_{1 \\to 3}\\) 의 weight 가 의미없고 bias만 의미있기 때문에 특징을 잡기에 불리하다.\n따라서 \\({\\boldsymbol h}\\)가 확실한 색을 가지고 있는것이 유리함. 그렇지만 확실한 색인 빨강 파랑은 이미 차지된 상태라서 어쩔수 없이 0이 선택된 것.."
  },
  {
    "objectID": "posts/11wk-2.html#d.-mlp-두개의-은닉노드",
    "href": "posts/11wk-2.html#d.-mlp-두개의-은닉노드",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "D. MLP – 두개의 은닉노드",
    "text": "D. MLP – 두개의 은닉노드\n- 적합\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=3,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=3),\n    #torch.nn.Softmax(),\n)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n\n\nfor epoc in range(50):\n    ## 1 \n    netout = net(x)\n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nebdd,tanh,linr = net\nh = tanh(ebdd(x)).data[:9]\nnetout = linr(tanh(ebdd(x))).data[:9]\nyhat = soft(net(x)).data[:9]\nmat = torch.concat([h,netout,yhat],axis=1)\n#---#\nplt.matshow(mat,cmap=\"bwr\",vmin=-6,vmax=6)\nplt.colorbar()\nplt.axvline(1.5,color=\"lime\")\nplt.axvline(4.5,color=\"lime\")\nplt.xticks(ticks=[0,1,2,3,4,5,6,7],labels=[r\"$h_1$\",r\"$h_2$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\"]);\n\n\n\n\n\n\n\n\n- 시각화결과해석: 깔끔함. netout의 가장 빨간부분도 너무 명확함. \\({\\boldsymbol h}\\)가 0이 아닌 값으로 학습되어있음\n\nx=a \\(\\Rightarrow\\) h=(파,빨) \\(\\Rightarrow\\) y=b\nx=b \\(\\Rightarrow\\) h=(빨,파) \\(\\Rightarrow\\) y=c\nx=c \\(\\Rightarrow\\) h=(빨,빨) \\(\\Rightarrow\\) y=a\nh = (파,파) 는 사용하지 않음. –&gt; 문자열 d를 하나 더 쓸수 있는 공간이 \\(h\\)에 있다고 해석할 수 있음.."
  },
  {
    "objectID": "posts/11wk-2.html#a.-data-1",
    "href": "posts/11wk-2.html#a.-data-1",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "A. Data",
    "text": "A. Data\n\ntxt = list('abcd'*100)\ntxt[:10]\n\n['a', 'b', 'c', 'd', 'a', 'b', 'c', 'd', 'a', 'b']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\nd\n\n\n3\nd\na\n\n\n4\na\nb\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'a':0, 'b':1, 'c':2, 'd':3}))\ny = torch.tensor(df_train.y.map({'a':0, 'b':1, 'c':2, 'd':3}))"
  },
  {
    "objectID": "posts/11wk-2.html#b.-mlp-하나의-은닉노드-1",
    "href": "posts/11wk-2.html#b.-mlp-하나의-은닉노드-1",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "B. MLP – 하나의 은닉노드",
    "text": "B. MLP – 하나의 은닉노드\n- 학습\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=1),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=1,out_features=4)\n)\nebdd,tanh,linr = net \nebdd.weight.data = torch.tensor([[-0.3333],[-2.5000],[5.0000],[0.3333]])\nlinr.weight.data = torch.tensor([[1.5000],[-6.0000],[-2.0000],[6.0000]])\nlinr.bias.data = torch.tensor([0.1500, -2.0000,  0.1500, -2.000])\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n\n\nfor epoc in range(50):\n    ## 1 \n    netout = net(x)\n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화1\n\nonehot_x = ohot(x).data[:8]\nonehot_a = onehot_x[:,[0]]\nonehot_b = onehot_x[:,[1]]\nonehot_c = onehot_x[:,[2]]\nonehot_d = onehot_x[:,[3]]\n#--#\nebdd_x = ebdd(x).data[:8]\n#--#\nh = tanh(ebdd(x)).data[:8]\n#--#\nnetout = linr(tanh(ebdd(x))).data[:8]\nnetout_a = netout[:,[0]]\nnetout_b = netout[:,[1]]\nnetout_c = netout[:,[2]]\nnetout_d = netout[:,[3]]\n#--#\nyhat = soft(net(x)).data[:8]\nyhat_a = yhat[:,[0]]\nyhat_b = yhat[:,[1]]\nyhat_c = yhat[:,[2]]\nyhat_d = yhat[:,[3]]\n#--#\n\n\nfig, ax = plt.subplots(5,1,figsize=(8,16))\nax[0].set_title(r\"$onehot({\\bf x})$\")\nax[0].set_xticks(range(8),[r'$a\\to b$', r'$b\\to c$', r'$c\\to d$', r'$d\\to a$']*2)\nax[0].plot(onehot_a,'--o',label=\"a\")\nax[0].plot(onehot_b,'--o',label=\"b\")\nax[0].plot(onehot_c,'--o',label=\"c\")\nax[0].plot(onehot_d,'--o',label=\"d\")\nax[0].legend()\n#--#\nax[1].set_title(r\"$ebdd({\\bf x})$\")\nax[1].set_xticks(range(8),[r'$a\\to b$', r'$b\\to c$', r'$c\\to d$', r'$d\\to a$']*2)\nax[1].plot(ebdd_x, '--o', color='gray')\n#--#\nax[2].set_title(r\"${\\bf h}:=(tanh \\circ ebdd)({\\bf x})$\")\nax[2].set_xticks(range(8),[r'$a\\to b$', r'$b\\to c$', r'$c\\to d$', r'$d\\to a$']*2)\nax[2].plot(h, '--o', color='gray')\n#--#\nax[3].set_title(r\"$net({\\bf x})=(linr \\circ tanh \\circ ebdd)({\\bf x})$\")\nax[3].set_xticks(range(8),[r'$a\\to b$', r'$b\\to c$', r'$c\\to d$', r'$d\\to a$']*2)\nax[3].plot(netout_a,'--o',label=r\"$netout_a$\")\nax[3].plot(netout_b,'--o',label=r\"$netout_b$\")\nax[3].plot(netout_c,'--o',label=r\"$netout_c$\")\nax[3].plot(netout_d,'--o',label=r\"$netout_d$\")\nax[3].legend()\n#--#\nax[4].set_title(r\"$\\hat{\\bf y} = soft(net({\\bf x}))$\")\nax[4].set_xticks(range(8),[r'$a\\to b$', r'$b\\to c$', r'$c\\to d$', r'$d\\to a$']*2)\nax[4].plot(yhat_a,'--o',label=r\"$P_a$\")\nax[4].plot(yhat_b,'--o',label=r\"$P_b$\")\nax[4].plot(yhat_c,'--o',label=r\"$P_c$\")\nax[4].plot(yhat_d,'--o',label=r\"$P_d$\")\nax[4].legend()\nplt.tight_layout()\n\n\n\n\n\n\n\n\n- 결과시각화2\n\nebdd,tanh,linr = net\nh = tanh(ebdd(x)).data[:8]\nnetout = linr(tanh(ebdd(x))).data[:8]\nyhat = soft(net(x)).data[:8]\nmat = torch.concat([h,netout,yhat],axis=1)\n#---#\nplt.matshow(mat,cmap=\"bwr\",vmin=-6,vmax=6)\nplt.colorbar()\nplt.axvline(0.5,color=\"lime\")\nplt.axvline(4.5,color=\"lime\")\nplt.xticks(ticks=[0,1,2,3,4,5,6,7,8],labels=[r\"$h$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$out_d$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_d$\"]);\n\n\n\n\n\n\n\n\n\nout에서 제일 빨간색.. -&gt; 찾기 어렵죠??"
  },
  {
    "objectID": "posts/11wk-2.html#c.-mlp-두개의-은닉노드",
    "href": "posts/11wk-2.html#c.-mlp-두개의-은닉노드",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "C. MLP – 두개의 은닉노드",
    "text": "C. MLP – 두개의 은닉노드\n- 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(num_embeddings=4,embedding_dim=2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(in_features=2,out_features=4)\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n\n\nfor epoc in range(50):\n    ## 1 \n    netout = net(x)\n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화\n\nebdd,tanh,linr = net\nh = tanh(ebdd(x)).data[:8]\nnetout = linr(tanh(ebdd(x))).data[:8]\nyhat = soft(net(x)).data[:8]\nmat = torch.concat([h,netout,yhat],axis=1)\n#---#\nplt.matshow(mat,cmap=\"bwr\",vmin=-6,vmax=6)\nplt.colorbar()\nplt.axvline(1.5,color=\"lime\")\nplt.axvline(5.5,color=\"lime\")\nplt.xticks(ticks=range(10),labels=[r\"$h_1$\",r\"$h_2$\",r\"$out_a$\",r\"$out_b$\",r\"$out_c$\",r\"$out_d$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_d$\"]);"
  },
  {
    "objectID": "posts/11wk-2.html#d.-비교실험",
    "href": "posts/11wk-2.html#d.-비교실험",
    "title": "11wk-2: 순환신경망 (1) – 임베딩 공간(Embedding Space)의 이해",
    "section": "D. 비교실험",
    "text": "D. 비교실험\n\nclass Net1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.ebdd = torch.nn.Embedding(4,1)\n        self.tanh = torch.nn.Tanh()\n        self.linr = torch.nn.Linear(1,4)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        ebdd_x = self.ebdd(x)\n        h = self.tanh(ebdd_x)\n        netout = self.linr(h)\n        ## 정의 끝\n        return netout\n\n\nclass Net2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.ebdd = torch.nn.Embedding(4,2)\n        self.tanh = torch.nn.Tanh()\n        self.linr = torch.nn.Linear(2,4)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        ebdd_x = self.ebdd(x)\n        h = self.tanh(ebdd_x)\n        netout = self.linr(h)\n        ## 정의 끝\n        return netout\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Net1()\n        optimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        for epoc in range(50):\n            ## 1 \n            netout = net(x)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = net.tanh(net.ebdd(x)).data[:6]\n        yhat = soft(net(x)).data[:6]\n        mat = torch.concat([h,yhat],axis=1)\n        ax[i][j].matshow(mat,cmap='bwr',vmin=-1,vmax=1)\n        ax[i][j].axvline(0.5,color='lime')\n        ax[i][j].set_xticks(ticks=[0,1,2,3,4],labels=[r\"$h$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_d$\"])\nfig.suptitle(\"# of hidden nodes = 1\", size=20)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        net = Net2()\n        optimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n        loss_fn = torch.nn.CrossEntropyLoss()\n        for epoc in range(50):\n            ## 1 \n            netout = net(x)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = net.tanh(net.ebdd(x)).data[:6]\n        yhat = soft(net(x)).data[:6]\n        mat = torch.concat([h,yhat],axis=1)\n        ax[i][j].matshow(mat,cmap='bwr',vmin=-1,vmax=1)\n        ax[i][j].axvline(1.5,color='lime')\n        ax[i][j].set_xticks(ticks=[0,1,2,3,4,5],labels=[r\"$h_1$\",r\"$h_2$\",r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_d$\"])\nfig.suptitle(\"# of hidden nodes = 2\", size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/13wk-2.html#a.-게임설명-및-원시코드",
    "href": "posts/13wk-2.html#a.-게임설명-및-원시코드",
    "title": "13wk-2: 강화학습 (1) – Bandit",
    "section": "A. 게임설명 및 원시코드",
    "text": "A. 게임설명 및 원시코드\n- 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을 누르면 10의 보상을 준다고 가정\n- 처음에 어떤 행동을 해야 하는가?\n\n처음에는 아는게 없음\n일단 “아무거나” 눌러보자.\n\n- 버튼을 아무거나 누르는 코드를 작성해보자.\n\naction_space = ['버튼0','버튼1']\naction = np.random.choice(action_space,p=[0.5,0.5])\naction\n\n'버튼0'\n\n\n\naction_space 와 action 이라는 용어를 기억할 것\n\n- 버튼을 누른 행위에 따른 보상을 구현하자.\n\nreward = 1 if action == \"버튼0\" else 10 \nreward\n\n1\n\n\n\nreward라는 용어를 기억할 것\n\n- 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자.\n\naction_space = ['버튼0','버튼1']\nfor _ in range(10):\n    action = np.random.choice(action_space)\n    reward = 1 if action == \"버튼0\" else 10\n    print(action,reward)\n\n버튼1 10\n버튼1 10\n버튼1 10\n버튼0 1\n버튼1 10\n버튼1 10\n버튼0 1\n버튼0 1\n버튼1 10\n버튼0 1\n\n\n- 깨달았음: 버튼0을 누르면 1점을 받고, 버튼1을 누르면 10점을 받는 “환경(environment)”이구나? \\(\\to\\) 버튼1을 누르는 “동작(=action)”을 해야하는 상황이구나?\n\n여기에서 \\(\\to\\)의 과정을 체계화 시킨 학문이 강화학습\n\n\nenvironment라는 용어를 기억할 것\n\n\naction_space = ['버튼0','버튼1']\nfor _ in range(10):\n    action = '버튼1'\n    reward = 1 if action == \"버튼0\" else 10\n    print(action,reward)\n\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n버튼1 10\n\n\n\n게임 클리어\n\n- 강화학습: 환경(environment)을 이해 \\(\\to\\) 에이전트(agent)가 행동(action)을 결정\n\nagent라는 용어를 기억할 것\n\n위의 과정이 잘 되었다는 의미로 사용하는 문장들\n\n강화학습이 성공적으로 잘 되었다.\n에이전트가 환경의 과제를 완료했다.\n에이전트가 환경에서 성공적으로 학습했다.\n에이전트가 올바른 행동을 학습했다.\n게임 클리어 (비공식)\n\n- 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다.\n\n첫 생각: 버튼1을 누르는 순간 게임클리어로 보면 되지 않나?\n두번째 생각: 아니지? 우연히 누를수도 있잖아?\n게임클리어조건: (1) 20번은 그냥 진행 (2) 최근 20번의 보상의 평균이 9.5점 이상이면 게임이 클리어 되었다고 생각하자.1\n\n1 버튼1을 눌러야 하는건 맞지만 몇번의 실수는 눈감아 주자는 의미- 원시코드1: 환경을 이해하지 못한 에이전트 – 게임을 클리어할 수 없다.\n\naction_space = [0,1]\nactions = []\nrewards = []\nfor t in range(1,51):\n    action = np.random.choice(action_space)\n    reward = 1 if action == 0 else 10\n    actions.append(action)\n    rewards.append(reward)\n    #--#\n    print(\n        f\"시도:{t}\\t\"\n        f\"행동:{action}\\t\"\n        f\"보상:{reward}\\t\"\n        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n    )\n    if t&lt;20:\n        pass \n    elif t==20:\n        print(\"--\")\n    else: \n        if np.mean(rewards[-20:]) &gt; 9.5:\n            print(\"Game Clear\")\n            break\n\n시도:1    행동:0    보상:1    최근20번보상평균:1.0000    \n시도:2    행동:0    보상:1    최근20번보상평균:1.0000    \n시도:3    행동:0    보상:1    최근20번보상평균:1.0000    \n시도:4    행동:1    보상:10   최근20번보상평균:3.2500    \n시도:5    행동:0    보상:1    최근20번보상평균:2.8000    \n시도:6    행동:1    보상:10   최근20번보상평균:4.0000    \n시도:7    행동:0    보상:1    최근20번보상평균:3.5714    \n시도:8    행동:1    보상:10   최근20번보상평균:4.3750    \n시도:9    행동:0    보상:1    최근20번보상평균:4.0000    \n시도:10   행동:0    보상:1    최근20번보상평균:3.7000    \n시도:11   행동:1    보상:10   최근20번보상평균:4.2727    \n시도:12   행동:0    보상:1    최근20번보상평균:4.0000    \n시도:13   행동:1    보상:10   최근20번보상평균:4.4615    \n시도:14   행동:1    보상:10   최근20번보상평균:4.8571    \n시도:15   행동:1    보상:10   최근20번보상평균:5.2000    \n시도:16   행동:0    보상:1    최근20번보상평균:4.9375    \n시도:17   행동:0    보상:1    최근20번보상평균:4.7059    \n시도:18   행동:0    보상:1    최근20번보상평균:4.5000    \n시도:19   행동:1    보상:10   최근20번보상평균:4.7895    \n시도:20   행동:0    보상:1    최근20번보상평균:4.6000    \n--\n시도:21   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:22   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:23   행동:1    보상:10   최근20번보상평균:5.5000    \n시도:24   행동:1    보상:10   최근20번보상평균:5.5000    \n시도:25   행동:0    보상:1    최근20번보상평균:5.5000    \n시도:26   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:27   행동:1    보상:10   최근20번보상평균:5.5000    \n시도:28   행동:1    보상:10   최근20번보상평균:5.5000    \n시도:29   행동:1    보상:10   최근20번보상평균:5.9500    \n시도:30   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:31   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:32   행동:1    보상:10   최근20번보상평균:6.8500    \n시도:33   행동:1    보상:10   최근20번보상평균:6.8500    \n시도:34   행동:1    보상:10   최근20번보상평균:6.8500    \n시도:35   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:36   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:37   행동:1    보상:10   최근20번보상평균:6.8500    \n시도:38   행동:1    보상:10   최근20번보상평균:7.3000    \n시도:39   행동:1    보상:10   최근20번보상평균:7.3000    \n시도:40   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:41   행동:0    보상:1    최근20번보상평균:7.3000    \n시도:42   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:43   행동:0    보상:1    최근20번보상평균:7.3000    \n시도:44   행동:0    보상:1    최근20번보상평균:6.8500    \n시도:45   행동:0    보상:1    최근20번보상평균:6.8500    \n시도:46   행동:1    보상:10   최근20번보상평균:7.3000    \n시도:47   행동:1    보상:10   최근20번보상평균:7.3000    \n시도:48   행동:0    보상:1    최근20번보상평균:6.8500    \n시도:49   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:50   행동:1    보상:10   최근20번보상평균:6.4000    \n\n\n- 원시코드2: 환경을 깨달은 에이전트 – 게임클리어\n\naction_space = [0,1]\nactions = []\nrewards = []\nfor t in range(1,51):\n    action = 1\n    reward = 1 if action == 0 else 10\n    actions.append(action)\n    rewards.append(reward)\n    #--#\n    print(\n        f\"시도:{t}\\t\"\n        f\"행동:{action}\\t\"\n        f\"보상:{reward}\\t\"\n        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n    )\n    if t&lt;20:\n        pass \n    elif t==20:\n        print(\"--\")\n    else: \n        if np.mean(rewards[-20:]) &gt; 9.5:\n            print(\"Game Clear\")\n            break\n\n시도:1    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:2    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:3    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:4    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:5    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:6    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:7    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:8    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:9    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:10   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:11   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:12   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:13   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:14   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:15   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:16   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:17   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:18   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:19   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:20   행동:1    보상:10   최근20번보상평균:10.0000   \n--\n시도:21   행동:1    보상:10   최근20번보상평균:10.0000   \nGame Clear"
  },
  {
    "objectID": "posts/13wk-2.html#b.-수정1-env-구현",
    "href": "posts/13wk-2.html#b.-수정1-env-구현",
    "title": "13wk-2: 강화학습 (1) – Bandit",
    "section": "B. 수정1: Env 구현",
    "text": "B. 수정1: Env 구현\n- Bandit 클래스 선언 + .step() 구현\n\nclass Bandit:\n    def step(self,agent_action):\n        reward = 1 if agent_action == 0 else 10\n        return reward\n\n\nenv = Bandit()\naction_space = [0,1]\nactions = []\nrewards = []\nfor t in range(1,51):\n    action = np.random.choice(action_space)\n    reward = env.step(action)\n    actions.append(action)\n    rewards.append(reward)\n    #--#\n    print(\n        f\"시도:{t}\\t\"\n        f\"행동:{action}\\t\"\n        f\"보상:{reward}\\t\"\n        f\"최근20번보상평균:{np.mean(rewards[-20:]):.4f}\\t\"\n    )\n    if t&lt;20:\n        pass \n    elif t==20:\n        print(\"--\")\n    else: \n        if np.mean(rewards[-20:]) &gt; 9.5:\n            print(\"Game Clear\")\n            break\n\n시도:1    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:2    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:3    행동:0    보상:1    최근20번보상평균:7.0000    \n시도:4    행동:0    보상:1    최근20번보상평균:5.5000    \n시도:5    행동:0    보상:1    최근20번보상평균:4.6000    \n시도:6    행동:1    보상:10   최근20번보상평균:5.5000    \n시도:7    행동:0    보상:1    최근20번보상평균:4.8571    \n시도:8    행동:1    보상:10   최근20번보상평균:5.5000    \n시도:9    행동:1    보상:10   최근20번보상평균:6.0000    \n시도:10   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:11   행동:1    보상:10   최근20번보상평균:6.7273    \n시도:12   행동:0    보상:1    최근20번보상평균:6.2500    \n시도:13   행동:1    보상:10   최근20번보상평균:6.5385    \n시도:14   행동:1    보상:10   최근20번보상평균:6.7857    \n시도:15   행동:1    보상:10   최근20번보상평균:7.0000    \n시도:16   행동:1    보상:10   최근20번보상평균:7.1875    \n시도:17   행동:0    보상:1    최근20번보상평균:6.8235    \n시도:18   행동:1    보상:10   최근20번보상평균:7.0000    \n시도:19   행동:0    보상:1    최근20번보상평균:6.6842    \n시도:20   행동:1    보상:10   최근20번보상평균:6.8500    \n--\n시도:21   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:22   행동:0    보상:1    최근20번보상평균:5.9500    \n시도:23   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:24   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:25   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:26   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:27   행동:0    보상:1    최근20번보상평균:6.4000    \n시도:28   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:29   행동:1    보상:10   최근20번보상평균:6.4000    \n시도:30   행동:0    보상:1    최근20번보상평균:5.9500    \n시도:31   행동:1    보상:10   최근20번보상평균:5.9500    \n시도:32   행동:0    보상:1    최근20번보상평균:5.9500    \n시도:33   행동:0    보상:1    최근20번보상평균:5.5000    \n시도:34   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:35   행동:0    보상:1    최근20번보상평균:4.6000    \n시도:36   행동:0    보상:1    최근20번보상평균:4.1500    \n시도:37   행동:1    보상:10   최근20번보상평균:4.6000    \n시도:38   행동:1    보상:10   최근20번보상평균:4.6000    \n시도:39   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:40   행동:0    보상:1    최근20번보상평균:4.6000    \n시도:41   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:42   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:43   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:44   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:45   행동:0    보상:1    최근20번보상평균:5.0500    \n시도:46   행동:0    보상:1    최근20번보상평균:4.6000    \n시도:47   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:48   행동:1    보상:10   최근20번보상평균:5.0500    \n시도:49   행동:0    보상:1    최근20번보상평균:4.6000    \n시도:50   행동:0    보상:1    최근20번보상평균:4.6000"
  },
  {
    "objectID": "posts/13wk-2.html#c.-수정2-agent-구현-인간지능",
    "href": "posts/13wk-2.html#c.-수정2-agent-구현-인간지능",
    "title": "13wk-2: 강화학습 (1) – Bandit",
    "section": "C. 수정2: Agent 구현 (인간지능)",
    "text": "C. 수정2: Agent 구현 (인간지능)\n- Agent 클래스 설계\n\n액션을 하고, 본인의 행동과 환경에서 받은 reward를 기억\n.act()함수와 .save_experience()함수 구현\n\n\nclass Agent:\n    def __init__(self):\n        self.action_space = [0,1]\n        self.action = None \n        self.reward = None\n        self.actions = []\n        self.rewards = [] \n    def act(self):\n        prob = [0.5, 0.5]\n        self.action = 1 #np.random.choice(self.action_space,p=prob)\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n\n— 대충 아래와 같은 느낌으로 코드가 돌아가요 —\n시점0: init\n\nagent = Agent()\nenv = Bandit()\n\n\nagent.action, agent.reward, agent.actions, agent.rewards\n\n(None, None, [], [])\n\n\n시점1: agent 가 acition을 선택\n\nagent.act()\n\n\nagent.action, agent.reward, agent.actions, agent.rewards\n\n(1, None, [], [])\n\n\n시점2: env가 agent에게 보상을 줌\n\nagent.reward = env.step(agent.action)\n\n\nagent.action, agent.reward, agent.actions, agent.rewards\n\n(1, 10, [], [])\n\n\n시점3: 경험을 저장\n\nagent.save_experience()\n\n\nagent.action, agent.reward, agent.actions, agent.rewards\n\n(1, 10, [1], [10])\n\n\n– 전체코드 –\n\nenv = Bandit()\nagent = Agent()\nfor t in range(1,51):\n    agent.act()\n    agent.reward = env.step(agent.action)\n    agent.save_experience()\n    #--#\n    print(\n        f\"시도:{t}\\t\"\n        f\"행동:{agent.action}\\t\"\n        f\"보상:{agent.reward}\\t\"\n        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n    )\n    if t&lt;20:\n        pass \n    elif t==20:\n        print(\"--\")\n    else: \n        if np.mean(agent.rewards[-20:]) &gt; 9.5:\n            print(\"Game Clear\")\n            break    \n\n시도:1    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:2    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:3    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:4    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:5    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:6    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:7    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:8    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:9    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:10   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:11   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:12   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:13   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:14   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:15   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:16   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:17   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:18   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:19   행동:1    보상:10   최근20번보상평균:10.0000   \n시도:20   행동:1    보상:10   최근20번보상평균:10.0000   \n--\n시도:21   행동:1    보상:10   최근20번보상평균:10.0000   \nGame Clear"
  },
  {
    "objectID": "posts/13wk-2.html#d.-수정3-agent-구현-인공지능",
    "href": "posts/13wk-2.html#d.-수정3-agent-구현-인공지능",
    "title": "13wk-2: 강화학습 (1) – Bandit",
    "section": "D. 수정3: Agent 구현 (인공지능)",
    "text": "D. 수정3: Agent 구현 (인공지능)\n- 지금까지 풀이의 한계\n\n사실 강화학습은 “환경을 이해 \\(\\to\\) 행동을 결정” 의 과정에서 “\\(\\to\\)”의 과정을 수식화 한 것이다.\n그런데 지금까지 했던 코드는 환경(environment)를 이해하는 순간 에이전트(agent)가 최적의 행동(action)2을 “직관적으로” 결정하였으므로 기계가 스스로 학습을 했다고 볼 수 없다.\n\n2 버튼1을 누른다- 에이전트가 데이터를 보고 스스로 학습할 수 있도록 설계 – 부제: agent.learn()을 설계하자.\n\n데이터를 모아서 q_table 를 만든다. q_table은 아래와 같은 내용을 포함한다.\n\n\n\n\n행동\n보상(추정값)\n\n\n\n\n버튼0 (\\(=a_0\\))\n1 (\\(=q_0\\))\n\n\n버튼1 (\\(=a_1\\))\n10 (\\(=q_1\\))\n\n\n\n\nq_table을 바탕으로 적절한 정책(=policy)을 설정한다.\n\n\n이 예제에서는 버튼0과 버튼1을 각각 \\(\\big(\\frac{q_0}{q_0+q_1},\\frac{q_1}{q_0+q_1}\\big)\\) 의 확률로 선택하는 “정책”을 이용하면 충분할 듯\n처음부터 이러한 확률로 선택하기보다 처음 20번정도는 데이터를 쌓기 위해서 행동을 랜덤하게 선택하고, 그 이후에 위에서 제시한 확률값으로 행동을 선택하는게 합리적인듯.\n\n\n여기에서 q_table, policy라는 용어를 기억하세요.\n\n- q_table을 계산하는 코드 예시\n\nagent.actions = [0, 1, 1,  0, 1,   0, 0] \nagent.rewards = [1, 9, 10, 1, 9.5, 1, 1.2] \nactions = np.array(agent.actions)\nrewards = np.array(agent.rewards)\n\n\nq0,q1 = rewards[actions==0].mean(), rewards[actions==1].mean()\n\n\nq_table = np.array([q0,q1])\nq_table\n\narray([1.05, 9.5 ])\n\n\n\nq_table/ q_table.sum()\n\narray([0.09952607, 0.90047393])\n\n\n\nprob = q_table/ q_table.sum()\nagent.action = np.random.choice(agent.action_space,p = prob )\nagent.action\n\n1\n\n\n- 최종코드정리\n\nclass Agent:\n    def __init__(self):\n        self.action_space = [0,1]\n        self.action = None \n        self.reward = None\n        self.actions = []\n        self.rewards = []\n        self.q_table = np.array([0.001,0.001])\n        self.n_experience = 0 \n    def act(self):\n        if self.n_experience &lt;= 20:\n            self.action = np.random.choice(self.action_space)\n        else: \n            prob = self.q_table/ self.q_table.sum()            \n            self.action = np.random.choice(self.action_space,p = prob )\n    def save_experience(self):\n        self.actions.append(self.action)\n        self.rewards.append(self.reward)\n        self.n_experience = self.n_experience + 1 \n    def learn(self):\n        if self.n_experience &lt; 20:\n            pass \n        else: \n            actions = np.array(self.actions)\n            rewards = np.array(self.rewards)      \n            q0,q1 = rewards[actions==0].mean(), rewards[actions==1].mean()\n            self.q_table = np.array([q0,q1])\n\n\nenv = Bandit()\nagent = Agent()\nfor t in range(1,51):\n    # step1: 행동\n    agent.act()\n    # step2: 보상\n    agent.reward = env.step(agent.action)\n    # step3: 저장 & 학습\n    agent.save_experience()\n    agent.learn()    \n    #--#\n    print(\n        f\"시도:{t}\\t\"\n        f\"행동:{agent.action}\\t\"\n        f\"보상:{agent.reward}\\t\"\n        f\"최근20번보상평균:{np.mean(agent.rewards[-20:]):.4f}\\t\"\n    )\n    if t&lt;20:\n        pass \n    elif t==20:\n        print(\"--\")\n    else: \n        if np.mean(agent.rewards[-20:]) &gt; 9.5:\n            print(\"Game Clear\")\n            break    \n\n시도:1    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:2    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:3    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:4    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:5    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:6    행동:1    보상:10   최근20번보상평균:10.0000   \n시도:7    행동:0    보상:1    최근20번보상평균:8.7143    \n시도:8    행동:1    보상:10   최근20번보상평균:8.8750    \n시도:9    행동:1    보상:10   최근20번보상평균:9.0000    \n시도:10   행동:1    보상:10   최근20번보상평균:9.1000    \n시도:11   행동:1    보상:10   최근20번보상평균:9.1818    \n시도:12   행동:1    보상:10   최근20번보상평균:9.2500    \n시도:13   행동:0    보상:1    최근20번보상평균:8.6154    \n시도:14   행동:1    보상:10   최근20번보상평균:8.7143    \n시도:15   행동:0    보상:1    최근20번보상평균:8.2000    \n시도:16   행동:1    보상:10   최근20번보상평균:8.3125    \n시도:17   행동:1    보상:10   최근20번보상평균:8.4118    \n시도:18   행동:1    보상:10   최근20번보상평균:8.5000    \n시도:19   행동:0    보상:1    최근20번보상평균:8.1053    \n시도:20   행동:1    보상:10   최근20번보상평균:8.2000    \n--\n시도:21   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:22   행동:0    보상:1    최근20번보상평균:7.7500    \n시도:23   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:24   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:25   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:26   행동:1    보상:10   최근20번보상평균:7.7500    \n시도:27   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:28   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:29   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:30   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:31   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:32   행동:1    보상:10   최근20번보상평균:8.2000    \n시도:33   행동:1    보상:10   최근20번보상평균:8.6500    \n시도:34   행동:1    보상:10   최근20번보상평균:8.6500    \n시도:35   행동:1    보상:10   최근20번보상평균:9.1000    \n시도:36   행동:1    보상:10   최근20번보상평균:9.1000    \n시도:37   행동:1    보상:10   최근20번보상평균:9.1000    \n시도:38   행동:1    보상:10   최근20번보상평균:9.1000    \n시도:39   행동:1    보상:10   최근20번보상평균:9.5500    \nGame Clear"
  },
  {
    "objectID": "posts/11wk-1.html#a.-임베딩레이어",
    "href": "posts/11wk-1.html#a.-임베딩레이어",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "A. 임베딩레이어",
    "text": "A. 임베딩레이어\n- 모티브: torch.nn.functional.one_hot + torch.nn.Linear 를 매번 쓰는건 너무 귀찮지 않어?\n\ntorch.manual_seed(43052)\n#x = ['옥순','영숙','하니','옥순','영숙']\nx = torch.tensor([0,1,2,0,1])\nE = torch.nn.functional.one_hot(x).float()\nlinr = torch.nn.Linear(3,1,bias=False) \nlf = linr(E)\nlf\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n- 코드를 뜯어보면..\n\nlinr.weight\n\nParameter containing:\ntensor([[-0.2002, -0.4890,  0.2081]], requires_grad=True)\n\n\n\nE @ linr.weight.T\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\n\\({\\boldsymbol x}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\Longrightarrow {\\bf E}= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\)\n\\(\\text{linr}({\\bf E})= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n\n- torch.nn.functional.one_hot + torch.nn.Linear 를 함께처리해주는 레이어 torch.nn.Embedding 존재\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(3,1) \nebdd.weight.data = linr.weight.data.T\nebdd(x)\n\ntensor([[-0.2002],\n        [-0.4890],\n        [ 0.2081],\n        [-0.2002],\n        [-0.4890]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n\n\\(\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}\\)\n우리가 이전에 구현했던 코드 “onehot + linr” 와 “ebdd”는 정확하게 동일한 동작을 수행함.\n\n- 결론: 아래의 두개의 코드는 같다.\nX = torch.tensor([0,1,2,0,1])\n\n## 코드1 \nlinr = torch.nn.Linear(3,1) \nlinr(torch.nn.functional.one_hot(X))\n\n## 코드2 \nebdd = torch.nn.Embedding(3,1)\nebdd(X) \n# 의문: 그냥 원핫인코딩없이 바로 선형변환하면 안되나? (= 꼭 임베딩레이어를 써야하나?)\n\nx = torch.tensor([0,1,2,0,1])\nX = x.reshape(-1,1).float()\nx,X\n\n(tensor([0, 1, 2, 0, 1]),\n tensor([[0.],\n         [1.],\n         [2.],\n         [0.],\n         [1.]]))\n\n\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(1,1)\nl1(X)\n\ntensor([[-0.8470],\n        [-1.1937],\n        [-1.5404],\n        [-0.8470],\n        [-1.1937]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ntorch.manual_seed(43052)\nebdd = torch.nn.Embedding(3,1) \nebdd(x)\n\ntensor([[-0.8178],\n        [-0.7052],\n        [-0.5843],\n        [-0.8178],\n        [-0.7052]], grad_fn=&lt;EmbeddingBackward0&gt;)\n\n\n결과적으로 0,1,2 를 다른숫자들로 맵핑한건 비슷해보이는데?\n- 수식의 차이: 비슷해보이지만 계산방식이 조금 다름\n\nl1.weight, l1.bias\n\n(Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\n\\(l_1({\\bf X}) = \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}\\)\n\\(\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix} = \\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052 \\end{bmatrix}\\)\n\n- 데이터를 읽으며 해석: 사실상 0,1,2에 대한 의미는 “옥순”,“영숙”,“하니” 같은 자료였고, 임베딩의 결과는 “옥순”,“영숙”,“하니”가 가지는 어떠한 특징이었음 (예를들면 매력같은). 데이터를 상상하며 위의 결과를 다시 해석해보자.\n옥순이 가지는 어떠한 특징 (-0.8470 혹은 -0.8178) 을 바꾸고 싶다면?\n\nebdd의 경우: ebdd.weigth에 있는 -0.8178 이라는 숫자를 조정하면 된다. 이 조정은 옥순의 특징만 바꾸며 영숙과 하니의 특징은 바꾸지 않는다. (개별조정이 쉬움)\nlinr의 경우: linr.weight에 있는 -0.3467 혹은 linr.bias에 있는 -0.8470 을 조정하면 되는데, 이를 조정하면 옥순의 특징을 바꿈과 동시에 영숙/하니의 특징까지 같이 바뀌게 된다. (개별조정이 어려움)\n\n만약에 출연자가 1000명이라면??\n\nlinr의 경우: 1000명의 특징을 단 2개의 파라메터로 조정해야한다. (그리고 한명의 특징을 바꾸면 999명의 특징이 같이 바뀐다, 개별조정은 애초에 가능하지 않음.)\nebdd의 경우: 1000개의 특징을 조정할 수 있는 1000개의 파라메터를 확보할 수 있게 된다.\n\n- 결론: ebdd가 더 파라메터 미세조정을 통하여 특징을 학습하기 용이하다. (독립적으로 특징값을 줄 수 있으니까!)\n\n만약에 문자열이 “최우수(A)”, “우수(B)”, “보통(C)”, “미흡(D)”, “매우미흡(F)” 이었다면 특징을 뽑아낼때 linr 가 더 적절했겠죠?"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \nX2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \ny = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector\n\n임베딩레이어를 활용하여 MF-based 추천시스템을 설계하라.\n(풀이)\n\ntorch.manual_seed(43052)\nebdd1 = torch.nn.Embedding(9,2)\nb1 = torch.nn.Embedding(9,1)\nebdd2 = torch.nn.Embedding(8,2)\nb2 = torch.nn.Embedding(8,1)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.MSELoss()\nparams = list(ebdd1.parameters())+list(b1.parameters())+list(ebdd2.parameters())+list(b2.parameters()) \noptimizr = torch.optim.Adam(params, lr=0.1) \n#--#\nfor epoc in range(100):\n    # 1\n    W_feature = ebdd1(X1)\n    W_bias = b1(X1)\n    M_feature = ebdd2(X2)\n    M_bias = b2(X2)\n    score = (W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias\n    yhat = sig(score)*5 \n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat,y],axis=1)[::4]\n\ntensor([[4.1083, 4.0200],\n        [0.9388, 1.1200],\n        [4.0483, 3.9900],\n        [0.9707, 0.9600],\n        [4.2264, 4.0500],\n        [0.9518, 0.9900],\n        [0.5124, 0.5600],\n        [1.1198, 1.1200],\n        [4.0588, 4.1600],\n        [1.0596, 1.0500],\n        [3.9666, 3.7800],\n        [0.9472, 0.8800],\n        [3.9194, 4.0400],\n        [1.0346, 1.0300],\n        [4.8851, 4.8500],\n        [4.5387, 4.3900]], grad_fn=&lt;SliceBackward0&gt;)"
  },
  {
    "objectID": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "href": "posts/11wk-1.html#a.-사용자정의-네트워크-사용법",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "A. 사용자정의 네트워크 사용법",
    "text": "A. 사용자정의 네트워크 사용법\n# 예비학습1: net(x)와 사실 net.forward(x)는 같다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\n\n\nX = torch.randn(5,1)\nX\n\ntensor([[ 0.3837],\n        [ 0.7194],\n        [-0.2655],\n        [-1.2488],\n        [ 0.5538]])\n\n\n\nnet(X)\n\ntensor([[0.3901],\n        [0.3808],\n        [0.4083],\n        [0.4362],\n        [0.3854]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet.forward(X)\n\ntensor([[0.3901],\n        [0.3808],\n        [0.4083],\n        [0.4362],\n        [0.3854]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n\nnet.forward = lambda x: '메롱'\n\n\nlambda x: '메롱' 은 입력이 x 출력이 ’메롱’인 함수를 의미 (즉 입력값에 상관없이 항상 ’메롱’을 출력하는 함수)\nnet.forward = lambda x:1 이라고 새롭게 선언하였므로 앞으론 net.forward(x), net(x) 도 입력값에 상관없이 항상 ’메롱’을 출력하게 될것임\n\n\nnet.forward(X)\n\n'메롱'\n\n\n\nnet(X)\n\n'메롱'\n\n\n#\n# 예비학습2: torch.nn.Module을 상속받아서 네트워크를 만들면 (= “class XXX(torch.nn.Module):” 와 같은 방식으로 클래스를 선언하면) 약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n(예시1)\n\nclass Mynet1(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.Sigmoid()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet1()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n(예시2)\n\nclass Mynet2(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.a1 = torch.nn.ReLU()\n        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n    def forward(self,x):\n        yhat = self.l2(self.a1(self.l1(x)))\n        return yhat\n\n이제\nnet = Mynet2()\n는 아래와 같은 효과를 가진다.\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n    torch.nn.RuLU(),\n    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n)\n클래스에 대한 이해가 부족한 학생을 위한 암기방법\nstep1: 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX 자리는 원하는 이름을 넣는다)\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        \n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\n\nforward의 입력: X는 net(X)에 사용하는 X임\nforward의 출력: yhat은 net.forward(X) 함수의 리턴값임\n사실, X/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output 이라든지, netin/netout 이라든지) 설명의 편의상 X와 yhat을 고정한다.\n\nstep2: def __init__(self):에 yhat을 구하기 위해 필요한 재료를 레이어를 정의하고 이름을 붙인다. 이름은 항상 self.xxx 와 같은 식으로 정의한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        \n        ## 정의 끝\n        return yhat\nstep3: def forward:에 “X –&gt; yhat” 으로 가는 과정을 묘사한 코드를 작성하고 yhat을 리턴하도록 한다.\nclass XXXX(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        self.xxx2 = torch.nn.Sigmoid()\n        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        u = self.xxx1(X) \n        v = self.xxx2(u)\n        yhat = self.xxx3(v) \n        ## 정의 끝\n        return yhat\n#\n# 실습: 사용자정의 네트워크를 사용하여 아래의 자료를 학습해보자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n(풀이)\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        ## 우리가 yhat을 구할때 사용할 레어어를 정의\n        self.linr = torch.nn.Linear(1,1)\n        ## 정의 끝\n    def forward(self,X):\n        ## yhat을 어떻게 구할것인지 정의 \n        yhat = self.linr(X)\n        ## 정의 끝\n        return yhat\n\n\nnet = Net()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--') # 최초의 직선\n\n\n\n\n\n\n\n\n\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # 1\n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o')\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n#"
  },
  {
    "objectID": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "href": "posts/11wk-1.html#b.-mf-based-추천시스템-재설계-1",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "B. MF-based 추천시스템 재설계",
    "text": "B. MF-based 추천시스템 재설계\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \nX2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \ny = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector\n\n사용자정의 네트워크를 이용하여 MF-based 추천시스템을 설계하라.\n(풀이1) – net(X1,X2)\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n    def forward(self,X1,X2):\n        W_feature = self.ebdd1(X1)\n        W_bias = self.b1(X1)\n        M_feature = self.ebdd2(X2)\n        M_bias = self.b2(X2)\n        score = (W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias \n        yhat = sig(score) * 5 \n        return yhat\n\n\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(100):\n    # 1\n    yhat = net(X1,X2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat.data,y],axis=1)[::5]\n\ntensor([[3.9088, 4.0200],\n        [0.6968, 0.4300],\n        [3.4267, 3.4300],\n        [3.5181, 3.4200],\n        [0.9098, 0.9900],\n        [0.7797, 0.5200],\n        [0.5975, 0.4300],\n        [0.9656, 0.9400],\n        [3.8616, 3.7800],\n        [0.8109, 0.8900],\n        [0.4865, 0.4800],\n        [3.9685, 3.8200],\n        [4.6336, 4.3900]])\n\n\n(풀이2) – net(X)\n\nX = torch.stack([X1,X2],axis=1)\nX[:5]\n\ntensor([[0, 1],\n        [0, 2],\n        [0, 3],\n        [0, 4],\n        [0, 5]])\n\n\n\nX[:,0], X[:,1]\n\n(tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3,\n         3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n         6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8]),\n tensor([1, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 6, 0, 1, 2, 3, 4, 6, 7, 0, 1, 3,\n         4, 5, 6, 7, 0, 2, 3, 4, 5, 6, 7, 0, 1, 2, 3, 4, 5, 7, 0, 1, 2, 3, 4, 5,\n         6, 7, 0, 1, 2, 4, 5, 6, 0, 1, 3, 4, 5, 6, 7]))\n\n\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.sig = torch.nn.Sigmoid()\n    def forward(self,X):\n        X1,X2 = X[:,0],X[:,1]\n        W_feature = self.ebdd1(X1)\n        W_bias = self.b1(X1)\n        M_feature = self.ebdd2(X2)\n        M_bias = self.b2(X2)\n        score = (W_feature * M_feature).sum(axis=1).reshape(-1,1) + W_bias + M_bias \n        yhat = sig(score) * 5 \n        return yhat\n\n\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(100):\n    # 1\n    yhat = net(X) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat.data,y],axis=1)[::5]\n\ntensor([[4.1003, 4.0200],\n        [0.5432, 0.4300],\n        [3.5055, 3.4300],\n        [3.3474, 3.4200],\n        [0.9624, 0.9900],\n        [0.6404, 0.5200],\n        [0.4905, 0.4300],\n        [0.7304, 0.9400],\n        [4.0403, 3.7800],\n        [0.8519, 0.8900],\n        [0.6959, 0.4800],\n        [3.8667, 3.8200],\n        [4.4733, 4.3900]])"
  },
  {
    "objectID": "posts/11wk-1.html#a.-nn-based-방식",
    "href": "posts/11wk-1.html#a.-nn-based-방식",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "A. NN-based 방식",
    "text": "A. NN-based 방식\n아래의 자료를 활용하여 추천시스템을 설계하고자한다.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \nX2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \ny = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector\n\nNN-based 추천시스템을 설계하라.\n(풀이1) – 실패\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,1),\n            torch.nn.Sigmoid()\n        )   \n    def forward(self,X1,X2):\n        W_feature = self.ebdd1(X1)\n        M_feature = self.ebdd2(X2)\n        W_bias = self.b1(X1)\n        M_bias = self.b2(X2)\n        Z = torch.concat([W_feature,M_feature,W_bias,M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(1000):\n    # 1\n    yhat = net(X1,X2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat.data,y],axis=1)[::5]\n\ntensor([[2.1566, 4.0200],\n        [1.6908, 0.4300],\n        [2.6466, 3.4300],\n        [2.7759, 3.4200],\n        [2.5815, 0.9900],\n        [2.3104, 0.5200],\n        [2.6402, 0.4300],\n        [1.7232, 0.9400],\n        [2.3892, 3.7800],\n        [2.4107, 0.8900],\n        [1.9775, 0.4800],\n        [2.0164, 3.8200],\n        [4.7447, 4.3900]])\n\n\n\n못하겠네?\n\n(풀이2) – 에라 모르겠다 깊은신경망..\n\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        self.ebdd1 = torch.nn.Embedding(9,2)\n        self.ebdd2 = torch.nn.Embedding(8,2)\n        self.b1 = torch.nn.Embedding(9,1)\n        self.b2 = torch.nn.Embedding(8,1)\n        self.mlp = torch.nn.Sequential(\n            torch.nn.Linear(6,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,15),\n            torch.nn.ReLU(),\n            torch.nn.Linear(15,1),\n            torch.nn.Sigmoid()\n        )   \n    def forward(self,X1,X2):\n        W_feature = self.ebdd1(X1)\n        M_feature = self.ebdd2(X2)\n        W_bias = self.b1(X1)\n        M_bias = self.b2(X2)\n        Z = torch.concat([W_feature,M_feature,W_bias,M_bias],axis=1)\n        yhat = self.mlp(Z) * 5 \n        return yhat\n\n\ntorch.manual_seed(43052)\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1) # 이게 편해요!!\n#--# \nfor epoc in range(1000):\n    # 1\n    yhat = net(X1,X2) \n    # 2\n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat.data,y],axis=1)[::5]\n\ntensor([[4.0276, 4.0200],\n        [0.4426, 0.4300],\n        [3.4343, 3.4300],\n        [3.4210, 3.4200],\n        [0.9852, 0.9900],\n        [0.5153, 0.5200],\n        [0.4402, 0.4300],\n        [0.9483, 0.9400],\n        [3.8077, 3.7800],\n        [0.8960, 0.8900],\n        [0.4833, 0.4800],\n        [3.8466, 3.8200],\n        [4.3930, 4.3900]])\n\n\n\n잘 맞추긴했는데 불안함\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n(옥순-영식), (영자-다호), (하니-영호) 를 예측해보자.\n\nXX1 = torch.tensor([0,1,8])\nXX2 = torch.tensor([1,7,2])\n\n\nnet(XX1,XX2)\n\ntensor([[4.0114],\n        [0.5262],\n        [4.9767]], grad_fn=&lt;MulBackward0&gt;)\n\n\n그럴싸함.. (오버피팅 아닌듯)"
  },
  {
    "objectID": "posts/11wk-1.html#b.-ncf-he2017neural",
    "href": "posts/11wk-1.html#b.-ncf-he2017neural",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "B. NCF (He et al. 2017)",
    "text": "B. NCF (He et al. 2017)\n\nHe, Xiangnan, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and Tat-Seng Chua. 2017. “Neural Collaborative Filtering.” In Proceedings of the 26th International Conference on World Wide Web, 173–82."
  },
  {
    "objectID": "posts/11wk-1.html#a.-지도학습",
    "href": "posts/11wk-1.html#a.-지도학습",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "A. 지도학습",
    "text": "A. 지도학습\n- 우리가 수업에서 다루는 데이터는 주로 아래와 같은 느낌이다.\n\n데이터는 \\((X,y)\\)의 형태로 정리되어 있다.\n\\(y\\)는 우리가 관심이 있는 변수이다. 즉 우리는 \\(y\\)를 적절하게 추정하는 것에 관심이 있다.\n\\(X\\)는 \\(y\\)를 추정하기 위해 필요한 정보이다.\n\n\n\n\n\n\n\n\n\n\n\n\\(X\\) = 설명변수 = 독립변수\n\\(y\\) = 반응변수 = 종속변수\n비고\n순서\n예시\n\n\n\n\n이미지\n카테고리\n합성곱신경망\n상관없음\n개/고양이 이미지 구분\n\n\n유저,아이템\n평점\n추천시스템\n상관없음\n넷플릭스 영화추천\n\n\n과거~오늘까지의주가\n내일주가\n순환신경망\n순서상관있음\n주가예측\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n이후 1개의 단어(혹은 문장)\n순환신경망\n순서상관있음\n챗봇, 텍스트생성\n\n\n처음 \\(m\\)개의 단어(혹은 문장)\n카테고리\n순환신경망\n순서상관있음\n영화리뷰 텍스트 감정분류\n\n\n\n- 이러한 문제상황, 즉 \\((X,y)\\)가 주어졌을때 \\(X \\to y\\)를 추정하는 문제를 supervised learning 이라한다."
  },
  {
    "objectID": "posts/11wk-1.html#b.-모델이란",
    "href": "posts/11wk-1.html#b.-모델이란",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "B. 모델이란?",
    "text": "B. 모델이란?\n\n모델이란 단어는 제 발작버튼이었어요..\n\n- 통계학에서 모델은 y와 x의 관계를 의미하며 오차항의 설계를 포함하는 개념이다. 이는 통계학이 “데이터 = 정보 + 오차”의 관점을 유지하기 때문이다. 따라서 통계학에서 모델링이란\n\\[y_i = net(x_i) + \\epsilon_i\\]\n에서 (1) 적절한 함수 \\(net\\)를 선택하는 일 (2) 적절한 오차항 \\(\\epsilon_i\\) 을 설계하는일 모두를 포함한다.\n- 딥러닝 혹은 머신러닝에서 모델은 단순히\n\\[y_i \\approx net(x_i)\\]\n를 의미하는 경우가 많다. 즉 “model=net”라고 생각해도 무방하다. 이 경우 “모델링”이란 단순히 적절한 \\(net\\)을 설계하는 것만을 의미할 경우가 많다.\n- 그래서 생긴일\n\n통계학교재 특: 분류문제와 회귀문제를 엄밀하게 구분하지 않는다. 사실 오차항만 다를뿐이지 크게보면 같은 회귀모형이라는 관점이다. 그래서 일반화선형모형(GLM)이라는 용어를 쓴다.\n머신러닝/딥러닝교재 특: 회귀문제와 분류문제를 구분해서 설명한다. (표도 만듦) 이는 오차항에 대한 기술을 모호하게 하여 생기는 현상이다."
  },
  {
    "objectID": "posts/11wk-1.html#c.-학습이란",
    "href": "posts/11wk-1.html#c.-학습이란",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "C. 학습이란?",
    "text": "C. 학습이란?\n- 학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “규칙” 혹은 “원리”를 찾는 것이다.\n\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “맵핑”을 찾는 것이다.\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “함수”을 찾는 것이다. 즉 \\(y\\approx f(X)\\)가 되도록 만드는 \\(f\\)를 잘 찾는 것이다. (이 경우 “함수를 추정한다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “모델” 혹은 “모형”을 찾는 것이다. 즉 \\(y\\approx model(X)\\)가 되도록 만드는 \\(model\\)을 잘 찾는 것이다. (이 경우 “모형을 학습시킨다”라고 표현)\n학습이란 주어진 자료 \\((X,y)\\)를 잘 분석하여 \\(X\\)에서 \\(y\\)로 가는 어떠한 “네트워크”을 찾는 것이다. 즉 \\(y\\approx net(X)\\)가 되도록 만드는 \\(net\\)을 잘 찾는 것이다. (이 경우 “네트워크를 학습시킨다”라고 표현)\n\n- prediction이란 학습과정에서 찾은 “규칙” 혹은 “원리”를 \\(X\\)에 적용하여 \\(\\hat{y}\\)을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는 \\(f\\),\\(model\\),\\(net\\) 으로 생각가능한데 이에 따르면 아래가 성립한다.\n\n\\(\\hat{y} = f(X)\\)\n\\(\\hat{y} = model(X)\\)\n\\(\\hat{y} = net(X)\\)"
  },
  {
    "objectID": "posts/11wk-1.html#d.-haty를-부르는-다양한-이름",
    "href": "posts/11wk-1.html#d.-haty를-부르는-다양한-이름",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "D. \\(\\hat{y}\\)를 부르는 다양한 이름",
    "text": "D. \\(\\hat{y}\\)를 부르는 다양한 이름\n- \\(\\hat{y}\\)는 \\(X\\)가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에 따라 지칭하는 이름이 미묘하게 다르다.\n\n\\(X \\in data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, fitted value 라고 부른다.\n\\(X \\notin data\\): \\(\\hat{y}=net(X)\\) 는 predicted value, predicted value with new data 라고 부른다."
  },
  {
    "objectID": "posts/11wk-1.html#e.-다양한-코드들",
    "href": "posts/11wk-1.html#e.-다양한-코드들",
    "title": "11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크, NN-based 추천시스템, A1-A2",
    "section": "E. 다양한 코드들",
    "text": "E. 다양한 코드들\n- 파이썬 코드..\n#Python\npredictor.fit(X,y) # autogluon 에서 \"학습\"을 의미하는 과정\nmodel.fit(X,y) # sklearn 에서 \"학습\"을 의미하는 과정\nlearner.learn() # fastai 에서 \"학습\"을 의미하는 과정\nlearner.fine_tune(1) # fastai 에서 \"부분학습\"을 의미하는 과정\nlearner.predict(cat1) # fastai 에서 \"예측\"을 의미하는 과정 \nmodel.fit(x, y, batch_size=32, epochs=10) # keras에서 \"학습\"을 의미하는 과정\nmodel.predict(test_img) # keras에서 \"예측\"을 의미하는 과정 \n- R 코드..\n# R\nols &lt;- lm(y~x) # 선형회귀분석에서 학습을 의미하는 함수\nols$fitted.values # 선형회귀분석에서 yhat을 출력 \npredict(ols, newdata=test) # 선형회귀분석에서 test에 대한 예측값을 출력하는 함수\nols$coef # 선형회귀분석에서 weight를 확인하는 방법"
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅",
    "href": "posts/04wk-2.html#a.-오버피팅",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”.\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/04wk-2.html#b.-오버피팅-예시",
    "href": "posts/04wk-2.html#b.-오버피팅-예시",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\nmodel: \\(y_i = (0\\times x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0,0.01^2)\\)\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ny는 그냥 정규분포에서 생성한 오차이므로 \\(X \\to y\\) 로 향하는 규칙따위는 없음\n\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat=net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    net.zero_grad() \n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 \\(\\to\\) 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)"
  },
  {
    "objectID": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain에서는 잘 맞추는듯이 보인다.\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.plot(xx,net(xx).data,label=\"predicted values, predicted values with new data\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain은 그럭저럭 따라가지만 test에서는 엉망이다. \\(\\to\\) overfit"
  },
  {
    "objectID": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\n시벤코정리의 항변(?) (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다 (즉 마음만 먹으면 loss를 0에 가깝도록 만들 수 있다는 의다) 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times p}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 즉\n\\[{\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 근사시킨 네트워크라고 할지라도\n\\[{\\bf XX}_{m \\times p} \\to {\\bf yy}_{m\\times q}\\]\n는 엉터리로 나올 수 있다. 시벤코는 넓은 신경망이 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다. 넓은 신경망이 우수한 신경망1이라는 주장을 한적은 없다.\n\n\n1 여기에서 우수하다는 말은 여러의미가 있어요, 오버피팅이 없는 신경망이라든가, 경제적인 신경망이라든가..\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅의-해결",
    "href": "posts/04wk-2.html#a.-오버피팅의-해결",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터 – 재활용\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(net(x),y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = True')\n\n\n\n\n\n\n\n\n\n\nnet에 드랍아웃이 포함되어 있다면, net.training  == True 일때 결과가 엉망으로 나옴.\n왜??\n\n- 결과시각화 (올바른 사용)\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.plot(xx,net(xx).data,'--',color='C1') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = False')\n\n\n\n\n\n\n\n\n\n\n이게 제대로 된 결과시각화임!"
  },
  {
    "objectID": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "href": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n\nu = torch.randn(20).reshape(10,2)\nu\n\ntensor([[ 1.2686, -0.8109],\n        [-1.0100,  0.1346],\n        [-1.9911, -0.9007],\n        [ 0.7675, -0.7510],\n        [ 2.1963, -0.4903],\n        [-1.5218,  0.7236],\n        [-0.4238,  0.0079],\n        [ 1.5566,  1.6662],\n        [ 1.4546,  0.2123],\n        [-1.5117,  0.9293]])\n\n\n\nd = torch.nn.Dropout(0.9)\nd(u)\n\ntensor([[12.6862, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [-0.0000,  0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리\n\n구조: 입력 -&gt; 드랍아웃레이어 -&gt; 출력\n역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정\n효과: 오버피팅을 억제하는 효과가 있음 (왜??) &lt;– 이거 너무 시간이 없어서 대충 설명했는데요.. 잘 이해가 안되시면 2023-기계학습활용-11wk-43, 2023-기계학습활용-12wk-44 참고하시면 될 겁니다. 그래도 이해가 안되면 일단은 외우세요. (진짜 궁금하시면 따로 물어보세요.. 제가 이걸 설명할 시간이 없을것 같아요.. 죄송합니다)\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n\n\n오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n- ReLU + dropout의 특이한 성질\n\ndef my_dropout(x):\n    x[:5,[0]] = torch.zeros(5).reshape(-1,1)\n    x[5:,[1]] = torch.zeros(5).reshape(-1,1)\n    return 2*x\n\nrelu = torch.nn.ReLU()\nsig = torch.nn.Sigmoid()\n\n\nrelu(my_dropout(u)), my_dropout(relu(u))\n\n(tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]),\n tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]))\n\n\n\nsig(my_dropout(u)), my_dropout(sig(u))\n\n(tensor([[0.5000, 0.1650],\n         [0.5000, 0.5669],\n         [0.5000, 0.1417],\n         [0.5000, 0.1821],\n         [0.5000, 0.2728],\n         [0.0455, 0.5000],\n         [0.2999, 0.5000],\n         [0.9574, 0.5000],\n         [0.9483, 0.5000],\n         [0.0464, 0.5000]]),\n tensor([[0.0000, 0.6154],\n         [0.0000, 1.0672],\n         [0.0000, 0.5778],\n         [0.0000, 0.6412],\n         [0.0000, 0.7597],\n         [0.3584, 0.0000],\n         [0.7912, 0.0000],\n         [1.6517, 0.0000],\n         [1.6214, 0.0000],\n         [0.3614, 0.0000]]))\n\n\n\n드랍아웃은 히든레이어사이, 즉 활성화 함수 바로 뒤에 오는게 맞음. 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 03kw-2에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\nRosenblatt, Frank et al. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. Vol. 55. Spartan books Washington, DC.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "posts/02wk-1.html#a.-소설",
    "href": "posts/02wk-1.html#a.-소설",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 소설",
    "text": "A. 소설\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 박혜원씨는\n\n일기예보를 보고 오늘의 평균 기온을 입력하면, 오늘의 아이스아메리카노 판매량을 미리 예측할 수 있지 않을까? 그 예측량만큼 아이스아메리카노를 준비하면 장사에 도움이 되지 않을까???\n\n라는 생각을 하게 되었고 이를 위하여 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다.1 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n1 판매량이 소수점이고 심지어 음수인것은 그냥 그려러니 하자..\nplt.plot(temp,sales,'o')"
  },
  {
    "objectID": "posts/02wk-1.html#b.-모델링",
    "href": "posts/02wk-1.html#b.-모델링",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 모델링",
    "text": "B. 모델링\n- 산점도를 살펴본 박혜원씨는 평균기온이 올라갈수록 아이스아메리카노 판매량이 “선형적”으로 증가한다는 사실을 캐치했다. 물론 약간의 오차는 있어보였다. 오차까지 고려하여 평균기온과 아이스판매량의 관계를 추정하면 아래와 같이 생각할 수 있다.\n\n아이스아메리카노 판매량 \\(\\approx\\) \\(w_0\\) \\(+\\) \\(w_1\\) \\(\\times\\) 평균기온\n\n위의 수식에서 만약에 \\(w_0\\)와 \\(w_1\\)의 값을 적절히 추정한다면, 평균기온량을 입력으로 하였을때 아이스아메리카노 판매량을 예측할 수 있을 것이다.\n- 아이스크림 판매량을 \\(y_i\\)로, 평균기온을 \\(x_i\\)로 변수화한뒤 박혜원의 수식을 좀 더 수학적으로 표현하면\n\\[y_i \\approx w_0 + w_1 x_i,\\quad i=1,2,\\dots,100\\]\n와 같이 쓸 수 있다. 오차항을 포함하여 좀 더 엄밀하게 쓰면\n\\[y_i = w_0 + w_1 x_i + \\epsilon_i,\\quad i=1,2,\\dots,100\\]\n와 같이 나타낼 수 있어보인다. 여기에서 \\(\\epsilon_i \\sim N(0,\\sigma^2)\\) 로 가정해도 무방할 듯 하다. 그런데 이를 다시 아래와 같이 표현하는 것이 가능하다.\n\\[{\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\]\n단 여기에서\n\\[{\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} {\\bf 1} & {\\bf x} \\end{bmatrix}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\]\n이다."
  },
  {
    "objectID": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "href": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 데이터를 torch.tensor로 변환",
    "text": "C. 데이터를 torch.tensor로 변환\n- 현재까지의 상황을 파이토치로 코딩하면 아래와 같다.\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n#W = ?? 이건 모름.. 추정해야함. \n#ϵ = ?? 이것도 모름!!"
  },
  {
    "objectID": "posts/02wk-1.html#d.-아무렇게나-추정",
    "href": "posts/02wk-1.html#d.-아무렇게나-추정",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 아무렇게나 추정",
    "text": "D. 아무렇게나 추정\n- \\({\\bf W}\\) 에 대한 추정값을 \\(\\hat{\\bf W}\\)라고 할때\n\\[\\hat{\\bf W}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix} =\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n으로 추정한 상황이라면 커피판매량의 예측값은\n\\[\\hat{\\bf y} = {\\bf X}\\hat{\\bf W}\\]\n이라고 표현할 수 있다. 이 의미는 아래의 그림에서 주황색 점선으로 커피판매량을 예측한다는 의미이다.\n\nWhat = torch.tensor([[-5.0],\n                     [10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')"
  },
  {
    "objectID": "posts/02wk-1.html#e.-추정의-방법",
    "href": "posts/02wk-1.html#e.-추정의-방법",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 추정의 방법",
    "text": "E. 추정의 방법\n- 방법1: 이론적으로 추론 &lt;- 회귀분석시간에 배운것\n\ntorch.linalg.inv((X.T @ X)) @ X.T @ y # 공식~\n\ntensor([[2.4459],\n        [4.0043]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.4459 + 4.0043*x,'--')\n\n\n\n\n\n\n\n\n- 방법2: 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법)\n\n1단계: 아무 점선이나 그어본다..\n2단계: 1단계에서 그은 점선보다 더 좋은 점선으로 바꾼다.\n3단계: 1-2단계를 반복한다."
  },
  {
    "objectID": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "href": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 문제셋팅 다시 복습",
    "text": "A. 문제셋팅 다시 복습\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "href": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 1단계 – 최초의 점선",
    "text": "B. 1단계 – 최초의 점선\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거"
  },
  {
    "objectID": "posts/02wk-1.html#c.-2단계-update",
    "href": "posts/02wk-1.html#c.-2단계-update",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 2단계 – update",
    "text": "C. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6240, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6240)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 발상의 전환: 가만히 보니까 loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수잖아??? 즉 아래와 같이 생각할 수 있음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n- \\(loss({\\bf W})\\)를 최소로 만드는 \\({\\bf W}\\)를 컴퓨터로 구하는 방법, 즉 \\(\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\)를 구하는 방법을 요약하면 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기2의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기3와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n2 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\)3 \\(\\left|\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|\\)\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n- 여기에서 미분을 어떻게…?? 즉 아래를 어떻게 계산해..?\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix} \\]\n\nloss.backward()를 실행하면 What.grad에 미분값이 업데이트 되어요!\n\n(실행전)\n\nprint(What.grad)\n\nNone\n\n\n(실행후)\n\nloss.backward()\n\n\nprint(What.grad)\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 계산결과의 검토 (1)\n\n\\(loss({\\bf W})=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([[-1342.2466],\n        [ 1188.9198]], grad_fn=&lt;AddBackward0&gt;)\n\n\n- 계산결과의 검토 (2)\n\\[\\frac{\\partial}{\\partial {\\bf W} } loss({\\bf W})=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss({\\bf W}) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\]\n를 계산하고 싶은데 벡터미분을 할줄 모른다고 하자. 편미분의 정의를 살펴보면,\n\\[\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\]\n\\[\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\]\n라고 볼 수 있다. 이를 이용하여 근사계산하면\n\ndef l(w0,w1):\n    return torch.sum((y-w0-w1*x)**2)\n\n\nl(-5,10), loss # 로스값일치\n\n(tensor(8587.6240), tensor(8587.6240, grad_fn=&lt;SumBackward0&gt;))\n\n\n\nh=0.001 \n(l(-5+h,10) - l(-5,10))/h\n\ntensor(-1342.7733)\n\n\n\nh=0.001 \n(l(-5,10+h) - l(-5,10))/h\n\ntensor(1189.4531)\n\n\n이 값은 What.grad에 저장된 값과 거의 비슷하다.\n\nWhat.grad\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 이제 아래의 공식에 넣고 업데이트해보자\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.linalg.inv((X.T @ X)) @ X.T @ y} -- 회귀분석으로 구한값\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3422],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6578],\n        [ 8.8111]]) -- 수정후\ntensor([[2.4459],\n        [4.0043]]) -- 회귀분석으로 구한값\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n\nalpha를 잘 잡아야함~\n\n- 1회 수정결과를 시각화\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6578],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o', label = \"ovserved data\")\nplt.plot(x,X@What.data,'--', label = r\"$\\hat{\\bf y}={\\bf X}@\\hat{\\bf W}$ after 30 iterations (=epochs)\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#a.-단순무식한-print",
    "href": "posts/02wk-1.html#a.-단순무식한-print",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 단순무식한 print",
    "text": "A. 단순무식한 print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-0.001 * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.62   업데이트폭 = tensor([ 1.3422, -1.1889])      업데이트결과: tensor([-3.6578,  8.8111])\nloss = 5675.18   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.63   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.33   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.85    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.72    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4453, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.64    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4481])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.94     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.98     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.41     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.58     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3391, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3749, 4.0479])\nloss = 27.01     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.65     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.49     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.45     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.42     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4289, 4.0145])"
  },
  {
    "objectID": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "href": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 반복시각화 – yhat의 관점에서!",
    "text": "B. 반복시각화 – yhat의 관점에서!\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfig = plt.plot(x,y,'o',label = \"observed\")\nplt.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    plt.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None"
  },
  {
    "objectID": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "href": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 반복시각화 – loss의 관점에서!!",
    "text": "C. 반복시각화 – loss의 관점에서!!\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    return fig\n\n\nl(-5,10)\n\ntensor(8587.6240)\n\n\n\nfig = plot_loss()\n\n\n\n\n\n\n\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\n\n\n\n\n\n\n\n\n\nw0,w1 = What.data.reshape(-1)\n\n\nWhat.data\n\ntensor([[2.4289],\n        [4.0145]])\n\n\n\nw0,w1\n\n(tensor(2.4289), tensor(4.0145))\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig"
  },
  {
    "objectID": "posts/02wk-1.html#d.-애니메이션",
    "href": "posts/02wk-1.html#d.-애니메이션",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nepoch = 0 부터 시작하여 시작점에서 출발하도록 애니메이션을 수정했습니당.\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#a.-해결하고-싶은것",
    "href": "posts/02wk-1.html#a.-해결하고-싶은것",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 해결하고 싶은것",
    "text": "A. 해결하고 싶은것\n아래와 같은 선형모형이 있다고 가정하자.\n\\[{\\bf y}={\\bf X}{\\boldsymbol \\beta} + {\\boldsymbol \\epsilon}\\]\n이러한 모형에 대하여 아래와 같이 손실함수를 정의하자.\n\\[loss({\\boldsymbol \\beta}) = ({\\bf y} - {\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y} - {\\bf X}{\\boldsymbol \\beta}) \\]\n이때 손실함수의 미분값을 아래와 같이 주어지고,\n\\[\\frac{\\partial}{\\partial {\\boldsymbol \\beta}}loss({\\boldsymbol \\beta}) = -2{\\bf X}^\\top{\\bf y}+2{\\bf X}^\\top{\\bf X}{\\boldsymbol \\beta}\\]\n따라서 손실함수를 최소화하는 추정량이 아래와 같이 주어짐을 보여라.\n\\[\\hat{\\boldsymbol \\beta} = ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top{\\bf y}\\]"
  },
  {
    "objectID": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "href": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 해설강의 및 보충자료",
    "text": "B. 해설강의 및 보충자료\n\nhttps://github.com/guebin/DL2024/blob/main/posts/02wksupp.pdf"
  },
  {
    "objectID": "posts/09wk-2.html",
    "href": "posts/09wk-2.html",
    "title": "09wk-2: 중간고사",
    "section": "",
    "text": "import torch \nimport torchvision\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport fastai.vision.all\n\n\n1. 크롤링을 통한 이미지 분석 및 CAM – 30점\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것) – 01wk-1 의 HW를 그대로 활용해도 무방\n(2) ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라.\n(3) resnet34를 이용하여 학습하라.\n(4) CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라.\n\n\n2. 생성모형 / GAN – 40점\n아래는 torchvision을 활용하여 MNIST 데이터를 불러오고 DataLoader를 생성하는 코드이다.\n\n# Data preprocessing\nds = dataset = torchvision.datasets.MNIST(\n    root = './data',\n    download=True,\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.Resize(64), # 이미지를 (64,64)로 resize \n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((0.5,), (0.5,))\n    ])\n)\n# Dataloader\ndl = torch.utils.data.DataLoader(\n    ds, \n    batch_size=120,\n    shuffle=True, \n)\n\n(1) iter와 next를 이용하여 데이터로더의 첫번째 배치를 출력하라. 하나의 배치에 몇개의 이미지가 있는가? 이미지는 흑백인가 칼라인가? 이미지의 크기는 얼마인가?\n(풀이)\n\nxi_real, _  = next(iter(dl))\n\n\nxi_real.shape\n\ntorch.Size([120, 1, 64, 64])\n\n\n(2) 아래의 함수를 이용하여 하나의 배치에 포함된 이미지를 출력하라.\n\ndef imshow(xi_real):\n    plt.imshow(torch.einsum('cij-&gt;ijc',torchvision.utils.make_grid(xi_real, padding=2, normalize=True)))\n\n(풀이)\n\nxi_real, _ = next(iter(dl))\n\n\nimshow(xi_real)\n\n\n\n\n\n\n\n\n(3) 아래의 코드를 이용하여 net_police를 생성하라.\n\nnet_police = torch.nn.Sequential(\n    # Layer1\n    torch.nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.LeakyReLU(0.2),\n    # Layer2\n    torch.nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(128),\n    torch.nn.LeakyReLU(0.2),\n    # Layer3\n    torch.nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(256),\n    torch.nn.LeakyReLU(0.2),\n    # Layer4\n    torch.nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(512),\n    torch.nn.LeakyReLU(0.2),\n    # Layer5\n    torch.nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    torch.nn.Sigmoid(),\n    torch.nn.Flatten()\n)\n\nnet_police에 하나의 배치를 넣어보고 각 층별 출력크기를 조사하라.\n(풀이)\n\nxi_real, _ = next(iter(dl))\n\n\nprint(f'xi_real -- {xi_real.shape}')\nprint(f'Layer1 -- {net_police[:2](xi_real).shape}')\nprint(f'Layer2 -- {net_police[:5](xi_real).shape}')\nprint(f'Layer3 -- {net_police[:8](xi_real).shape}')\nprint(f'Layer4 -- {net_police[:11](xi_real).shape}')\nprint(f'Layer5 -- {net_police(xi_real).shape}')\n\nxi_real -- torch.Size([120, 1, 64, 64])\nLayer1 -- torch.Size([120, 64, 32, 32])\nLayer2 -- torch.Size([120, 128, 16, 16])\nLayer3 -- torch.Size([120, 256, 8, 8])\nLayer4 -- torch.Size([120, 512, 4, 4])\nLayer5 -- torch.Size([120, 1])\n\n\n(4) 아래의 코드를 이용하여 net_faker를 생성하라.\n\nnet_faker = torch.nn.Sequential(\n    # Layer1\n    torch.nn.ConvTranspose2d(100, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    torch.nn.BatchNorm2d(512),\n    torch.nn.ReLU(),\n    # Layer2\n    torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(256),\n    torch.nn.ReLU(),\n    # Layer3\n    torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(128),\n    torch.nn.ReLU(),\n    # Layer4\n    torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(64),\n    torch.nn.ReLU(),\n    # Layer5\n    torch.nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.Tanh()\n)\n\nnet_faker에 아래의 noise를 넣어보고 각 층별 출력크기를 조사하라.\nni = torch.randn(batch_size, 100, 1, 1)\n(풀이)\n\nni = torch.randn(120, 100, 1, 1)\n\n\nprint(f'ni -- {ni.shape}')\nprint(f'Layer1 -- {net_faker[:3](ni).shape}')\nprint(f'Layer2 -- {net_faker[:6](ni).shape}')\nprint(f'Layer3 -- {net_faker[:9](ni).shape}')\nprint(f'Layer4 -- {net_faker[:12](ni).shape}')\nprint(f'Layer5 -- {net_faker(ni).shape}')\n\nni -- torch.Size([120, 100, 1, 1])\nLayer1 -- torch.Size([120, 512, 4, 4])\nLayer2 -- torch.Size([120, 256, 8, 8])\nLayer3 -- torch.Size([120, 128, 16, 16])\nLayer4 -- torch.Size([120, 64, 32, 32])\nLayer5 -- torch.Size([120, 1, 64, 64])\n\n\n(5) 아래와 같이 두개의 optimizr 를 선언하라.\n\noptimizr_police = torch.optim.Adam(net_police.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizr_faker = torch.optim.Adam(net_faker.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n아래의 세부지침에 맞추어 net_police 와 net_faker를 학습하라.\n\n5 Epoch을 진행하여 학습할 것\nGPU를 이용하여 학습할 것\n\n(풀이)\n\nbce = torch.nn.BCELoss()\n\n\nnet_faker.to(\"cuda:0\")\nnet_police.to(\"cuda:0\")\nfor epoc in range(5):\n    for xi_real, _ in dl:\n        xi_real = xi_real.to(\"cuda:0\")\n        ni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\n        xi_fake = net_faker(ni).data\n        yi_real = torch.zeros(120).reshape(-1,1).to(\"cuda:0\")\n        yi_fake = torch.ones(120).reshape(-1,1).to(\"cuda:0\")\n        # step1 \n        yi_hat_real = net_police(xi_real)\n        yi_hat_fake = net_police(xi_fake)\n        # step2 \n        loss_police = bce(yi_hat_real, yi_real) + bce(yi_hat_fake, yi_fake)        \n        # step3 \n        loss_police.backward()\n        # step4 \n        optimizr_police.step()\n        optimizr_police.zero_grad()    \n        #--#\n        # step1\n        ni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\n        xi_fake = net_faker(ni)\n        # step2\n        yi_hat_fake = net_police(net_faker(ni))\n        loss_faker = bce(yi_hat_fake, yi_real)\n        # step3 \n        loss_faker.backward()\n        # step4 \n        optimizr_faker.step()\n        optimizr_faker.zero_grad()\n    print(f\"epoch = {epoc+1}/5\")\n\nepoch = 1/5\nepoch = 2/5\nepoch = 3/5\nepoch = 4/5\nepoch = 5/5\n\n\n(6) 학습결과를 (2)의 imshow 함수를 이용하여 시각화하라.\n(풀이)\n\nni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\nxi_fake = net_faker(ni).data.to(\"cpu\")\nimshow(xi_fake)\n\n\n\n\n\n\n\n\n\n\n3. 단순회귀문제 – 10점\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n(1) torch.nn.Linear를 이용하여 아래와 같은 최초의 직선을 생성하는 네트워크를 설계하라. – 1점\n\\[\\hat{y}_i = -5.0 + 10.0 x_i \\]\n(풀이)\n\nl = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nl.weight.data = l.weight.data*0 + 10 \nl.bias.data = l.bias.data*0 - 5 \n\n\nl(x)[:5], (-5+10*x)[:5] \n\n(tensor([[-29.8211],\n         [-28.6215],\n         [-24.9730],\n         [-21.2394],\n         [-19.7919]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[-29.8211],\n         [-28.6215],\n         [-24.9730],\n         [-21.2394],\n         [-19.7919]]))\n\n\n(2) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (1)의 결과로 얻은 값을 사용하라. – 1점\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(풀이)\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(y,l(x))\n\ntensor(85.8769, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n(3) 적당한 matrix \\({\\bf X}_{n\\times 2}\\) 와 \\(\\hat{\\bf W}_{2\\times 1}\\) 을 정의하여 아래와 같이 \\(\\hat{y}_i\\)을 구하라. – 1점\n\\[\\hat{y}_i = -5.0 + 5.0 x_i \\]\n(풀이)\n\nWhat = torch.tensor([[-5.0],[5.0]],requires_grad=True)\nX = torch.concat([torch.ones(100,1),x],axis=1)\n(X@What)[:5], (-5+5*x)[:5] \n\n(tensor([[-17.4106],\n         [-16.8107],\n         [-14.9865],\n         [-13.1197],\n         [-12.3960]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[-17.4106],\n         [-16.8107],\n         [-14.9865],\n         [-13.1197],\n         [-12.3960]]))\n\n\n(4) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (3)의 결과로 얻은 값을 사용하라. – 1점\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(풀이)\n\nloss_fn(y,X@What)\n\ntensor(55.0216, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n(5) (2)에서 얻은 \\(\\hat{y}_i\\) (4)에서 얻은 \\(\\hat{y}_i\\) 중 무엇이 더 적절하다고 생각하는가? 이유는 무엇인가? 손실(=loss)에 근거하여 설명하라. – 2점\n(풀이)\n(4)에서 얻은 \\(\\hat{y}_i\\)이 더 적절하다. 이유는 loss값이 더 작기 때문. (55.0216 &lt; 85.8769)\n(6) .backward() 를 이용하여 (2)와 (4)에 해당하는 미분값을 계산하라. 학습률이 0.01인 경사하강법을 이용하여 (1),(3) 에 대응하는 가중치를 update 하라. – 4점\n(풀이)\n\nloss = loss_fn(y,l(x)) \nloss.backward()\nl.weight.data = l.weight.data - 0.01 * l.weight.grad\nl.bias.data = l.bias.data - 0.01 * l.bias.grad\n\n\nprint(f\"(2)의 update\\nbias = {l.bias.data}\\nweight = {l.weight.data}\")\n\n(2)의 update\nbias = tensor([-4.8658])\nweight = tensor([[9.8811]])\n\n\n\nloss = loss_fn(y,X@What) \nloss.backward()\nWhat = What.data - 0.01 * What.grad\n\n\nprint(f\"(4)의 update\\n{What.data}\")\n\n(4)의 update\ntensor([[-4.8535],\n        [ 4.9955]])\n\n\n(또 다른 풀이)\n\nl = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nl.weight.data = l.weight.data*0 + 10 \nl.bias.data = l.bias.data*0 - 5 \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(l.parameters(),lr=0.01) \n#--# \nyhat = l(x) # step1 \nloss = loss_fn(y,yhat) # step2 \nloss.backward() # step 3 \noptimizr.step() # step 4 \nprint(f\"(2)의 update\\nbias = {l.bias.data}\\nweight = {l.weight.data}\")\n\n(2)의 update\nbias = tensor([-4.8658])\nweight = tensor([[9.8811]])\n\n\n\nWhat = torch.tensor([[-5.0],[5.0]],requires_grad=True)\nX = torch.concat([torch.ones(100,1),x],axis=1)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([What],lr=0.01) # 이건 안알려준 코드임\n#--#\nyhat = X@What # step1 \nloss = loss_fn(y,yhat) # step2  \nloss.backward() # step3 \noptimizr.step() # step4 \nprint(f\"(4)의 update\\n{What.data}\")\n\n(4)의 update\ntensor([[-4.8535],\n        [ 4.9955]])\n\n\n\n\n4. 네트워크 설계 – 10점\n아래는 mnist자료를 분류하는 네트워크의 예시이다. 그림에 대응하는 네트워크를 파이토치로 설계하라.\n\n\n그림에서 n1=6, n2=16, n3=120 으로 설정하고, 드랍아웃비율은 50%로 설정하라.\n인풋이미지의 차원은 (28,28,1) 이 아니라 (n,1,28,28) 로 해석하라. 동일한 논리로 Conv1의 통과결과도 (n,n1,24,24) 로 해석하라.\nvalid padding 의 의미는 padding 을 하지 않는다는 의미이다.\n\n(풀이)\n\nx = torch.zeros(1,1,28,28)\nx.shape\n\ntorch.Size([1, 1, 28, 28])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,6,kernel_size=(5,5)),\n    torch.nn.MaxPool2d(2,2),\n    torch.nn.Conv2d(6,16,kernel_size=(5,5)),\n    torch.nn.MaxPool2d(2,2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(256,120),\n    torch.nn.ReLU(),\n    torch.nn.Linear(120,10),\n    torch.nn.Dropout(0.5),\n    #torch.nn.Softmax()\n)\n\n\nfor i,l in enumerate(net):\n    print(f\"{i}: {net[:i](x).shape} --&gt; {str(l)}\")\n\n0: torch.Size([1, 1, 28, 28]) --&gt; Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n1: torch.Size([1, 6, 24, 24]) --&gt; MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n2: torch.Size([1, 6, 12, 12]) --&gt; Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n3: torch.Size([1, 16, 8, 8]) --&gt; MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n4: torch.Size([1, 16, 4, 4]) --&gt; Flatten(start_dim=1, end_dim=-1)\n5: torch.Size([1, 256]) --&gt; Linear(in_features=256, out_features=120, bias=True)\n6: torch.Size([1, 120]) --&gt; ReLU()\n7: torch.Size([1, 120]) --&gt; Linear(in_features=120, out_features=10, bias=True)\n8: torch.Size([1, 10]) --&gt; Dropout(p=0.5, inplace=False)\n\n\n\n\n5. 신경망의 학습 – 10점\n아래를 이용하여 데이터를 불러오라.\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nu = -1 + 5*x\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n(1) torch.utils.data.TensorDataset, torch.utils.data.DataLoader 를 이용하여 아래의 세부지침을 따르는 적당한 dataloader를 만들라. – 2점\n세부지침\n\nbatch_size = 128 로 설정할 것\nshuffle = False 로 설정할 것\n\n(풀이)\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128,shuffle=False)\n\n(2) 주어진 자료를 해석할 수 있는 적절한 net 및 손실함수를 설정하고 아래의 세부지침에 맞추어 학습하라. – 8점\n세부지침\n\n30 epochs 학습\nGPU를 이용하여 학습 할 것\n옵티마이저로 torch.optim.Adam을 사용하고 학습률은 0.05로 설정할 것\n\n(풀이)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.05)\n\n\nfor epoc in range(30):\n    for xi,yi in dl:\n        ## step0: 싹다 쿠다로..\n        xi = xi.to(\"cuda:0\")\n        yi = yi.to(\"cuda:0\")\n        ## step1 \n        yi_hat = net(xi)\n        ## step2 \n        loss = loss_fn(yi_hat, yi) \n        ## step3 \n        loss.backward()\n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\nnet.to(\"cpu\")\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,net(x).data,'--b',label=r\"prob (estimated)\")\nplt.legend()"
  },
  {
    "objectID": "posts/14wk-1.html#a.-gym.spaces",
    "href": "posts/14wk-1.html#a.-gym.spaces",
    "title": "14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)",
    "section": "A. gym.spaces",
    "text": "A. gym.spaces\n- 예시1\n\naction_space = gym.spaces.Discrete(4) \naction_space \n\nDiscrete(4)\n\n\n\n[action_space.sample() for _ in range(5)]\n\n[1, 1, 2, 1, 2]\n\n\n\n0 in action_space\n\nTrue\n\n\n\n4 in action_space\n\nFalse\n\n\n- 예시2\n\nstate_space = gym.spaces.MultiDiscrete([4,4])\nstate_space\n\nMultiDiscrete([4 4])\n\n\n\n[state_space.sample() for _ in range(5)]\n\n[array([3, 3]), array([3, 0]), array([3, 3]), array([3, 3]), array([2, 0])]\n\n\n\nnp.array([0,1]) in state_space\n\nTrue\n\n\n\nnp.array([3,3]) in state_space\n\nTrue\n\n\n\nnp.array([3,4]) in state_space\n\nFalse"
  },
  {
    "objectID": "posts/14wk-1.html#b.-시각화",
    "href": "posts/14wk-1.html#b.-시각화",
    "title": "14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)",
    "section": "B. 시각화",
    "text": "B. 시각화\n\ndef show(states):\n    fig = plt.Figure()\n    ax = fig.subplots()\n    ax.matshow(np.zeros([4,4]), cmap='bwr',alpha=0.0)\n    sc = ax.scatter(0, 0, color='red', s=500)  \n    ax.text(0, 0, 'start', ha='center', va='center')\n    ax.text(3, 3, 'end', ha='center', va='center')\n    # Adding grid lines to the plot\n    ax.set_xticks(np.arange(-.5, 4, 1), minor=True)\n    ax.set_yticks(np.arange(-.5, 4, 1), minor=True)\n    ax.grid(which='minor', color='black', linestyle='-', linewidth=2)\n    state_space = gym.spaces.MultiDiscrete([4,4])\n    def update(t):\n        if states[t] in state_space:\n            s1,s2 = states[t]\n            states[t] = [s2,s1]\n            sc.set_offsets(states[t])\n        else:\n            s1,s2 = states[t]\n            s1 = s1 + 0.5 if s1 &lt; 0 else (s1 - 0.5 if s1 &gt; 3 else s1)\n            s2 = s2 + 0.5 if s2 &lt; 0 else (s2 - 0.5 if s2 &gt; 3 else s2)\n            states[t] = [s2,s1]       \n            sc.set_offsets(states[t])\n    ani = FuncAnimation(fig,update,frames=len(states))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\n\nshow([[0,0],[1,0],[2,0],[3,0],[4,0]])\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/14wk-1.html#a.-에이전트-클래스-설계",
    "href": "posts/14wk-1.html#a.-에이전트-클래스-설계",
    "title": "14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)",
    "section": "A. 에이전트 클래스 설계",
    "text": "A. 에이전트 클래스 설계\n- 우리가 구현하고 싶은 기능\n\n.act(): 액션을 결정 –&gt; 여기서는 그냥 랜덤액션\n.save_experience(): 데이터를 저장 –&gt; 여기에 일단 초점을 맞추자\n.learn(): 데이터로에서 학습 –&gt; 패스\n\n\nclass AgentRandom: \n    def __init__(self,env):\n        #--# define spaces \n        self.action_space = env.action_space\n        self.state_space = env.state_space\n        #--# replay buffer \n        self.action = None \n        self.actions = [] \n        self.current_state =  None \n        self.current_states = [] \n        self.reward = None \n        self.rewards = [] \n        self.next_state =  None \n        self.next_states = [] \n        self.terminated = None \n        self.terminations = []\n        #--# other information\n        self.n_episodes = 0         \n        self.n_experiences = 0\n        self.score = 0        \n        self.playtimes = [] \n        self.scores = []    \n    def act(self):\n        self.action = self.action_space.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.current_states.append(self.current_state)        \n        self.actions.append(self.action)\n        self.rewards.append(self.reward)  \n        self.next_states.append(self.next_state)\n        self.terminations.append(self.terminated)\n        #--#\n        self.n_experiences = self.n_experiences + 1 \n        self.score = self.score + self.reward"
  },
  {
    "objectID": "posts/14wk-1.html#b.-환경과-상호작용",
    "href": "posts/14wk-1.html#b.-환경과-상호작용",
    "title": "14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)",
    "section": "B. 환경과 상호작용",
    "text": "B. 환경과 상호작용\n\nenv = GridWorld()\nagent = AgentRandom(env)\n#--#\nfor _ in range(50):\n    agent.current_state = env.reset()\n    agent.score = 0 \n    for t in range(100):\n        # step1: 행동\n        agent.act()\n        # step2: 보상\n        agent.next_state, agent.reward, agent.terminated = env.step(agent.action)\n        # step3: 저장 & 학습\n        agent.save_experience()\n        agent.learn()\n        # step4: \n        agent.current_state = agent.next_state\n        if agent.terminated: break\n    agent.scores.append(agent.score) \n    agent.playtimes.append(t+1)\n    agent.n_episodes = agent.n_episodes + 1 \n    #---#\n    print(\n        f\"에피소드: {agent.n_episodes} \\t\"\n        f\"점수(에피소드): {agent.scores[-1]} \\t\" \n        f\"게임시간(에피소드): {agent.playtimes[-1]}\\t\"\n        f\"경험수: {agent.n_experiences}\"\n    )\n\n에피소드: 1     점수(에피소드): -12   게임시간(에피소드): 3   경험수: 3\n에피소드: 2     점수(에피소드): -15   게임시간(에피소드): 6   경험수: 9\n에피소드: 3     점수(에피소드): -11   게임시간(에피소드): 2   경험수: 11\n에피소드: 4     점수(에피소드): -10   게임시간(에피소드): 1   경험수: 12\n에피소드: 5     점수(에피소드): -10   게임시간(에피소드): 1   경험수: 13\n에피소드: 6     점수(에피소드): -12   게임시간(에피소드): 3   경험수: 16\n에피소드: 7     점수(에피소드): -11   게임시간(에피소드): 2   경험수: 18\n에피소드: 8     점수(에피소드): -18   게임시간(에피소드): 9   경험수: 27\n에피소드: 9     점수(에피소드): -10   게임시간(에피소드): 1   경험수: 28\n에피소드: 10    점수(에피소드): 91    게임시간(에피소드): 10  경험수: 38\n에피소드: 11    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 39\n에피소드: 12    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 40\n에피소드: 13    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 42\n에피소드: 14    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 43\n에피소드: 15    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 44\n에피소드: 16    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 45\n에피소드: 17    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 46\n에피소드: 18    점수(에피소드): -15   게임시간(에피소드): 6   경험수: 52\n에피소드: 19    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 54\n에피소드: 20    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 55\n에피소드: 21    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 56\n에피소드: 22    점수(에피소드): -12   게임시간(에피소드): 3   경험수: 59\n에피소드: 23    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 61\n에피소드: 24    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 63\n에피소드: 25    점수(에피소드): -13   게임시간(에피소드): 4   경험수: 67\n에피소드: 26    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 68\n에피소드: 27    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 69\n에피소드: 28    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 71\n에피소드: 29    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 72\n에피소드: 30    점수(에피소드): -13   게임시간(에피소드): 4   경험수: 76\n에피소드: 31    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 77\n에피소드: 32    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 78\n에피소드: 33    점수(에피소드): -18   게임시간(에피소드): 9   경험수: 87\n에피소드: 34    점수(에피소드): -13   게임시간(에피소드): 4   경험수: 91\n에피소드: 35    점수(에피소드): -18   게임시간(에피소드): 9   경험수: 100\n에피소드: 36    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 101\n에피소드: 37    점수(에피소드): -15   게임시간(에피소드): 6   경험수: 107\n에피소드: 38    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 108\n에피소드: 39    점수(에피소드): -13   게임시간(에피소드): 4   경험수: 112\n에피소드: 40    점수(에피소드): -17   게임시간(에피소드): 8   경험수: 120\n에피소드: 41    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 121\n에피소드: 42    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 122\n에피소드: 43    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 123\n에피소드: 44    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 124\n에피소드: 45    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 125\n에피소드: 46    점수(에피소드): -17   게임시간(에피소드): 8   경험수: 133\n에피소드: 47    점수(에피소드): -10   게임시간(에피소드): 1   경험수: 134\n에피소드: 48    점수(에피소드): -13   게임시간(에피소드): 4   경험수: 138\n에피소드: 49    점수(에피소드): -12   게임시간(에피소드): 3   경험수: 141\n에피소드: 50    점수(에피소드): -11   게임시간(에피소드): 2   경험수: 143"
  },
  {
    "objectID": "posts/14wk-1.html#c.-상호작용결과-시각화",
    "href": "posts/14wk-1.html#c.-상호작용결과-시각화",
    "title": "14wk-1: 강화학습 (2) – 4x4 Grid World (AgentRandom)",
    "section": "C. 상호작용결과 시각화",
    "text": "C. 상호작용결과 시각화\n\n[np.array([0,0])] + agent.next_states[28:38] # 에피소드10\n\n[array([0, 0]),\n array([0, 1]),\n array([0, 2]),\n array([0, 3]),\n array([1, 3]),\n array([2, 3]),\n array([2, 2]),\n array([3, 2]),\n array([3, 1]),\n array([3, 2]),\n array([3, 3])]\n\n\n\nshow([np.array([0,0])] + agent.next_states[28:38]) # 에피소드5\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-2.html#a.-방법1",
    "href": "posts/03wk-2.html#a.-방법1",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 방법1",
    "text": "A. 방법1\n\ny = x*0 \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\n\n\nplt.plot(y,'--')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n강의영상에 보셨듯이 아래의 코드실행결과는 다르게 나옵니다.\n## 아래를 실행하면 꺽인선이 나오는데용...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x*0 + x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n## 이걸 실행하면 그냥 직선이 나옵니다...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n다르게 나오는 이유가 너무 궁금하시다면 아래의 링크로 가셔서 깊은복사/얕은복사에 대한 개념을 이해하시면 됩니다. (그렇지만 가능하다면 궁금해하지 마세요…..)\n\n깊은복사 얕은복사 강의들으러 가기"
  },
  {
    "objectID": "posts/03wk-2.html#b.-방법2-렐루이용",
    "href": "posts/03wk-2.html#b.-방법2-렐루이용",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. 방법2 – 렐루이용",
    "text": "B. 방법2 – 렐루이용\n\nrelu = torch.nn.ReLU()\n\n\nplt.plot(relu(x),'--',label=r'$relu(x)$')\nplt.plot(relu(-x),'--',label=r'$relu(-x)$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x),'--',label=r'$-4.5\\times relu(x) + 4.5$')\nplt.plot(-9*relu(-x),'--',label=r'$-9\\times relu(-x) + 4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x)-9*relu(-x),'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)$')\nplt.plot(y,'--',label=r'$y$')\nplt.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)+4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n- 우리의 목표: 저 초록선에서 시그모이드를 태우면된다. 즉 아래의 느낌임\n\nsig = torch.nn.Sigmoid()\n\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('sig(...)');\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-방법2의-다른구현",
    "href": "posts/03wk-2.html#c.-방법2의-다른구현",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "C. 방법2의 다른구현",
    "text": "C. 방법2의 다른구현\n- 렐루이용하여 만드는 방법 정리\n\n벡터 x와 relu함수를 준비한다.\nu = [x,-x] 를 계산한다.\nv = [relu(x), relu(-x)] 를 계산한다.\ny = -4.5 * relu(x) + 9 * relu(-x) +4.5 를 계산한다.\n\n- 1단계\n\nx,relu\n\n(tensor([[-1.0000],\n         [-0.9980],\n         [-0.9960],\n         ...,\n         [ 0.9960],\n         [ 0.9980],\n         [ 1.0000]]),\n ReLU())\n\n\n- 2단계\n\nu = torch.concat([x,-x],axis=1) # u = [x, -x] 같은것\nu\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n- 3단계\n\nv = relu(u) # 각각의 column에 렐루취함\nv\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n- 4단계\n\n-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n\ny\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n- 그런데, 4단계는 아래와 같이 볼 수 있다.\n\n\\({\\boldsymbol v}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} v_{11} & v_{12} \\\\ v_{21} & v_{22} \\\\ \\dots & \\dots \\\\ v_{n1} & v_{n2} \\\\ \\end{bmatrix}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} -4.5 v_{11} - 9.0 v_{12} + 4.5 \\\\ -4.5 v_{21} - 9.0 v_{22} + 4.5 \\\\ \\dots \\\\ -4.5 v_{n1} - 9.0 v_{n2} + 4.5 \\\\ \\end{bmatrix}\\)\n\n위의 수식을 참고하여 매트릭스의 곱 형태로 다시 포현하면 아래와 같다.\n\n#-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\nWhat = torch.tensor([[-4.5],[-9.0]]) \nv @ What + 4.5 \n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n이제 매트릭스의 곱 대신에 torch.nn.Linear()를 이용하면 아래의 코드와 같아진다.\n\nl2 = torch.nn.Linear(\n    in_features=2,\n    out_features=1 \n)\n\n\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(v)\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 사실 2단계도 아래와 같이 볼 수 있다.\n\\[\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\dots \\\\\nx_n\n\\end{bmatrix}\\begin{bmatrix} 1 & -1 \\end{bmatrix} = \\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n \\end{bmatrix}\\]\n\n#u = torch.concat([x,-x],axis=1) # u1 = [x, -x] 같은것\n\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\n\n\nl1(x)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 따라서 torch.nn 에 포함된 레이어를 이용하면 아래와 같이 표현할 할 수 있다.\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(2,1)\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(a1(l1(x))), y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))\n\n\n- 각각의 layer를 torch.nn.Sequential() 로 묶으면 아래와 같이 정리할 수 있다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1)\n)\nl1,a1,l2 = net\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nnet(x),y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))"
  },
  {
    "objectID": "posts/03wk-2.html#d.-수식표현",
    "href": "posts/03wk-2.html#d.-수식표현",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "D. 수식표현",
    "text": "D. 수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(net({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-데이터",
    "href": "posts/03wk-2.html#a.-데이터",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#b.-step-14",
    "href": "posts/03wk-2.html#b.-step-14",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. Step 1~4",
    "text": "B. Step 1~4\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- Step2,3,4 는 너무 뻔해서..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 3000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 6000 epochs\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n- 맞춰봐\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\n#plt.plot(u,alpha=0.2)\nplt.plot(x,y,'.',alpha=0.01,color=\"C0\")\nplt.plot(x[0],y[0],'o',color=\"C0\",label=r\"observed data (with error): $(x_i,y_i)$\")\nplt.plot(x,v,'--',label=r\"prob (true, unknown): $(x_i,\\pi_i)$ or $(x_i,v_i)$\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 저 주황색 구조를 어떻게 표현하지? \\(\\to\\) 선이 많이 꺽이면되는거아냐?\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,1),\n    #torch.nn.Sigmoid()\n)\n#loss_fn = torch.nn.BCELoss()\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig,ax = plt.subplots(1,2)\nax[0].plot(x,u,'--',label=r\"$(x_i,u_i)$\")\nax[0].plot(x,yhat.data,'--',label=r\"$(x_i,\\hat{u}_i)$\")\nax[0].legend()\nax[0].set_title(\"before sig\")\nax[1].plot(x,y,'.',alpha=0.02,color=\"blue\")\nax[1].plot(x,v,'--', color=\"C0\", label=r\"$(x_i,v_i)$ or $(x_i,\\pi_i)$\")\nax[1].plot(x,sig(yhat.data),'--',color=\"C1\",label=r\"$(x_i,\\hat{v}_i)$ or $(x_i,\\hat{\\pi}_i)$\")\nax[1].legend()\nax[1].set_title(\"after sig\")\n\nText(0.5, 1.0, 'after sig')"
  },
  {
    "objectID": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n- 맞춰봐1\n1 2024년 수능 미적30번 문제에 나온 함수응용\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=r\"observed data (with error): $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unknown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 맞춰본다..\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1024)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,1024)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024),\n    torch.nn.ReLU(),\n    torch.nn.Linear(1024,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=r\"observed data: $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unkown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.plot(x,yhat.data,'--',color=\"C1\",label=r\"underlying (esimated): $(x_i,\\hat{y}_i)$\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "href": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코의 정리 소개",
    "text": "A. 시벤코의 정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 심층신경망은 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}\\)는 토익점수, GPA, 공모전참가여부, \\({\\bf y}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\\({\\bf X}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 \\({\\bf y}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 심층신경망 모델의 표현력은 무한대라 볼 수 있다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-1.html#b.-왜-가능한가",
    "href": "posts/04wk-1.html#b.-왜-가능한가",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가?",
    "text": "B. 왜 가능한가?\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자. (스펙올라도 취업못하는 예제에서 썼던 네크워크랑 비슷해요)\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:11: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:11: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/3092854458.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/3092854458.py:11: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\n\n\n\n\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/3368460049.py:7: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/3368460049.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/2330299143.py:7: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/2330299143.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\n\n\n\n\n- 직관3: 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 “m단계-계단함수”와 같은 형태의 네트워크는 아래와 같이 \\(m\\)개의 은닉노드를 써서 항상 표현할 수 있다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- 직관4: 그런데 어떠한 함수형태라도 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?"
  },
  {
    "objectID": "posts/04wk-1.html#c.-h의-위력",
    "href": "posts/04wk-1.html#c.-h의-위력",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v # activation 의 출력\n\n\na1 = MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n- 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- \\(h\\)의 위력\n예제1 – 스펙높아도 취업이 안된다고??\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2, label=\"observed data (with error)\")\nplt.plot(x,prob,'--', label=\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated)\")\nplt.legend()\n\n\n\n\n\n\n\n\n예제2 – 수능에 나왔다던 이상한 곡선..?\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.2,label=\"observed data (with error)\")\nplt.plot(x,fx,'--',label=\"underlying (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"underlying (estimated)\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#d.-의문점",
    "href": "posts/04wk-1.html#d.-의문점",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 표현하는 네크워크는 잘 안쓰지 않나? 은닉층이 많을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 continuous mapping \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-1.html#a.-데이터-다운로드",
    "href": "posts/04wk-1.html#a.-데이터-다운로드",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 데이터 다운로드",
    "text": "A. 데이터 다운로드\n\nimport fastai.data.all\n\n\nfastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:03&lt;00:00]\n    \n    \n\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\n!ls '/root/.fastai/data/mnist_png'\n\ntesting  training\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/'\n\n0  1  2  3  4  5  6  7  8  9\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/3' | head\n\n10.png\n10000.png\n10011.png\n10031.png\n10034.png\n10042.png\n10052.png\n1007.png\n10074.png\n10091.png\nls: write error: Broken pipe\n\n\n\nimport torchvision\n\n\nimg3 = torchvision.io.read_image('/root/.fastai/data/mnist_png/training/3/10.png')\nplt.imshow(img3.reshape(28,28),cmap=\"gray\")"
  },
  {
    "objectID": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "href": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 예비학습 – `plt.imshow()",
    "text": "B. 예비학습 – `plt.imshow()\n- plt.imshow(...) 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n\nplt.imshow([[0,255],[0,255]],cmap='gray')\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = [[0,255],[0,255]]\ng = [[255,0],[0,0]]\nb = [[0,0],[255,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = [[0,1],[0,1]]\ng = [[1,0],[0,0]]\nb = [[0,0],[1,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n\nr = [[0,1.0],[0,1.0]]\ng = [[1.0,0],[0,0]]\nb = [[0,0],[1.0,0]]\nplt.imshow(np.stack([r,g,b],axis=2))"
  },
  {
    "objectID": "posts/04wk-1.html#c.-예비학습-pathlib",
    "href": "posts/04wk-1.html#c.-예비학습-pathlib",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 예비학습 – pathlib",
    "text": "C. 예비학습 – pathlib\n- 오브젝트 생성\n\npath = fastai.imports.Path('.')\npath\n\nPath('.')\n\n\n- 기능1 – .ls()\n\npath.ls()\n\n(#6) [Path('.ipynb_checkpoints'),Path('05wk-2.ipynb'),Path('06wk-1.ipynb'),Path('01wk-1.ipynb'),Path('05wk-1.ipynb'),Path('04wk-1.ipynb')]\n\n\n- 이미지 파일이 저장된 경로로 새로운 path오브젝트를 만들고 기능1 수행\n\npath = fastai.imports.Path('/root/.fastai/data/mnist_png')\npath\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n- 기능2: / 로 새로운 path 생성하기\n\n(path / 'training')\n\nPath('/root/.fastai/data/mnist_png/training')\n\n\n- 기능1,2의 결합\n\n(path / 'training').ls()\n\n(#10) [Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/3'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/8'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/6'),Path('/root/.fastai/data/mnist_png/training/2'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/9')]"
  },
  {
    "objectID": "posts/04wk-1.html#d.-데이터정리",
    "href": "posts/04wk-1.html#d.-데이터정리",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 데이터정리",
    "text": "D. 데이터정리\n- 데이터가 저장된 path 설정\n\npath = fastai.imports.Path('/root/.fastai/data/mnist_png')\n\n- X ,y를 만듦\n\nX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/3').ls()],axis=0)\nX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/7').ls()],axis=0)\n\n\nX3.shape, X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\ny = torch.tensor([0.0]*6131+[1.0]*6265).reshape(-1,1)\n\n\nX = torch.concat([X3,X7],axis=0)\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n\n\n\n\n“y=0.0” 은 숫자3을 의미함, “y=1.0” 은 숫자7을 의미함\n숫자3은 6131개, 숫자7은 6265개 있음\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\nX = torch.concat([X3,X7],axis=0).reshape(-1,28*28).float()\nX.shape, y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-1.html#e.-학습",
    "href": "posts/04wk-1.html#e.-학습",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "E. 학습",
    "text": "E. 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(200):\n    ## step1\n    yhat = net(X)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o',label=r\"$(i,y_i)$ -- training data set\")\nplt.plot(net(X).data,'.',alpha=0.2, label=r\"$(i,\\hat{y}_i$ -- training data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n잘맞추는데?\n믿을수가 없는데..?\n\n\n((yhat.data &gt; 0.5) == y).float().mean() # train_accuracy\n\ntensor(0.9994)"
  },
  {
    "objectID": "posts/04wk-1.html#f.-test",
    "href": "posts/04wk-1.html#f.-test",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "F. Test",
    "text": "F. Test\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n\nXX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/3').ls()],axis=0)\nXX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/7').ls()],axis=0)\n\n\nXX3.shape,XX7.shape\n\n(torch.Size([1010, 1, 28, 28]), torch.Size([1028, 1, 28, 28]))\n\n\n\nXX = torch.concatenate([XX3,XX7],axis=0).reshape(-1,1*28*28).float()\nXX.shape\n\ntorch.Size([2038, 784])\n\n\n\nyy = torch.tensor([0]*1010 + [1]*1028).reshape(-1,1).float()\nyy.shape\n\ntorch.Size([2038, 1])\n\n\n\nplt.plot(yy,'o',label=r\"$(i,y_i)$ -- test data set\")\nplt.plot(net(XX).data,'.',label=r\"$(i,\\hat{y}_i)$ -- test data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n(yy == (net(XX)&gt;0.5)).float().mean() # test accuracy\n\ntensor(0.9897)\n\n\n\ntest 에서도 잘 맞춘다.."
  },
  {
    "objectID": "posts/03wk-1.html#a.-로지스틱-모형",
    "href": "posts/03wk-1.html#a.-로지스틱-모형",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-1.html#b.-데이터",
    "href": "posts/03wk-1.html#b.-데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터",
    "text": "B. 데이터\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n우리의 목적: \\(x_i\\)가 들어가면 빨간곡선 \\(\\hat{y}_i\\)의 값을 만들어주는 mapping을 학습해보자."
  },
  {
    "objectID": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자. (\\(net: x \\to yhat\\) 을 수행하는 네트워크를 설계해보자는 의미)\n\nw0hat = -0.8\nw1hat = -0.3\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = False)로 구현\n\nX = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=2, out_features=1, bias = False)\nl1.weight\n\nParameter containing:\ntensor([[-0.0370, -0.1980]], requires_grad=True)\n\n\n\nl1.weight.data = torch.tensor([[-0.8,  -0.3]])\n\n\nl1(X), w0hat + w1hat*x # 똑같죠\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;MmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = True)로 구현\n\n#X = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=1, out_features=1)\nl1.weight, l1.bias\n\n(Parameter containing:\n tensor([[-0.0153]], requires_grad=True),\n Parameter containing:\n tensor([-0.4743], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\nl1(x), w0hat + w1hat*x # 이것도 똑같죠!\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- 내가만든 sigmoid 대신에 토치에서 제공하는 sigmoid 사용\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 관찰: 지금 아래의 구조이다.\n\\[{\\boldsymbol x} \\overset{l_1}{\\to} {\\boldsymbol u} \\overset{a_1}{\\to} {\\boldsymbol v} = \\hat{\\boldsymbol y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\boldsymbol x}) := net({\\boldsymbol x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(w0hat+ w1hat*x)\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]]))\n\n\n- net 살펴보기: 초보버전 – “파이토치 30일만에 완성하기” 이런책에 보면 내용이 나올지도?\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\n처음에는 선형변환하고, 그담에는 Sigmoid를 수행하라는 의미\n\n- net 살펴보기: 고수버전 – 책 안보고 코딩배우기\n\nset(dir(net)) & {'__call__', '__getitem__'}\n\n{'__call__', '__getitem__'}\n\n\n\n좋은거 가지고 있네 ㅎㅎ\ncallable 이면서 subscriptable 오브젝트..\n\n\nlst = [11,22,33]\nlst.__getitem__(-1) # lst[-1]\n\n33\n\n\n\nsigmoid.__call__(x) # sigmoid(x)\n\ntensor([[0.2689],\n        [0.2691],\n        [0.2693],\n        ...,\n        [0.7307],\n        [0.7309],\n        [0.7311]])\n\n\n\nsigmoid[0] # 난 스크립터블 하지 않은걸? (= 난 리스트처럼 인덱싱 못해요)\n\nTypeError: 'function' object is not subscriptable\n\n\n\nlst(x)# 난 컬러블하지 않은걸? (= 난 함수처럼 입력을 받고 출력을 주는 일은 못해요)\n\nTypeError: 'list' object is not callable\n\n\n\nnet(x) # 컬러블이면서\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet[0],net[1] # 섭스크립터블\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\n_l1, _a1 = net # 언패킹!! (섭스크립터블하니까..)\n\n\n_l1.weight, _l1.bias # 내가 설정한 웨이트도 그대로 들어가있음\n\n(Parameter containing:\n tensor([[-0.3000]], requires_grad=True),\n Parameter containing:\n tensor([-0.8000], requires_grad=True))"
  },
  {
    "objectID": "posts/03wk-1.html#d.-step-14",
    "href": "posts/03wk-1.html#d.-step-14",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step 1~4",
    "text": "D. Step 1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n성공했나?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-좋은-초기값",
    "href": "posts/03wk-1.html#a.-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 좋은 초기값",
    "text": "A. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "href": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가능성 있는 초기값",
    "text": "B. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-최악의-초기값",
    "href": "posts/03wk-1.html#c.-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 최악의 초기값",
    "text": "C. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-1.html#b.-loss-function-시각화",
    "href": "posts/03wk-1.html#b.-loss-function-시각화",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-0.8470])\n# net[0].weight.data = torch.tensor([[-0.3467]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-3.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-10.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-1.html#b.-가짜데이터",
    "href": "posts/03wk-1.html#b.-가짜데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터",
    "text": "B. 가짜데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음.\n\n결국 올라가다가 내려가는 언더라잉을 맞춰야 하는데 현재 모형으로는 이걸 표현할 수 없다.\n모형의 표현력이 낮다."
  },
  {
    "objectID": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "href": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 해결책 (아이디어 수준만)",
    "text": "D. 해결책 (아이디어 수준만)\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/14wk-2.html#a.-환경의-이해",
    "href": "posts/14wk-2.html#a.-환경의-이해",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "A. 환경의 이해",
    "text": "A. 환경의 이해\n- 랜덤에이전트를 이용해 무작위로 10000판을 진행해보자.\n\nenv = GridWorld()\nagent = AgentRandom(env) \nfor _ in range(10000):\n    # Step1: 에피소드 준비 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    # Step2: 에피소드 진행 \n    for t in range(1,51):\n        # step1: 행동\n        agent.act() \n        # step2: 보상 \n        agent.next_state, agent.reward, agent.terminated = env.step(agent.action)\n        # step3: 저장 & 학습 \n        agent.save_experience() \n        agent.learn() # 사실학습하는 함수는 dummy 함수임..\n        # step4: 다음 스텝준비 \n        agent.current_state = agent.next_state \n        if agent.terminated: break \n    # Step3: 다음에피소드 준비 \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t)\n    agent.n_episodes = agent.n_episodes + 1 \n\n\nagent.n_experiences\n\n32507\n\n\n- 데이터관찰\n\nagent.rewards[0], agent.next_states[0]\n\n(-10, array([ 0, -1]))\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[0]} / {agent.actions[0],action_to_direction2[agent.actions[0]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[0]} / {agent.next_states[0]}\")\n\n에이전트: 현재상태/행동 = [0 0] / (3, 'left')\n환경: 보상/다음상태 = -10 / [ 0 -1]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[1]} / {agent.actions[1],action_to_direction2[agent.actions[1]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[1]} / {agent.next_states[1]}\")\n\n에이전트: 현재상태/행동 = [0 0] / (2, 'up')\n환경: 보상/다음상태 = -10 / [-1  0]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[2]} / {agent.actions[2],action_to_direction2[agent.actions[2]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[2]} / {agent.next_states[2]}\")\n\n에이전트: 현재상태/행동 = [0 0] / (2, 'up')\n환경: 보상/다음상태 = -10 / [-1  0]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[3]} / {agent.actions[3],action_to_direction2[agent.actions[3]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[3]} / {agent.next_states[3]}\")\n\n에이전트: 현재상태/행동 = [0 0] / (3, 'left')\n환경: 보상/다음상태 = -10 / [ 0 -1]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[4]} / {agent.actions[4],action_to_direction2[agent.actions[4]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[4]} / {agent.next_states[4]}\")\n\n에이전트: 현재상태/행동 = [0 0] / (1, 'right')\n환경: 보상/다음상태 = -1 / [0 1]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[5]} / {agent.actions[5],action_to_direction2[agent.actions[5]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[5]} / {agent.next_states[5]}\")\n\n에이전트: 현재상태/행동 = [0 1] / (1, 'right')\n환경: 보상/다음상태 = -1 / [0 2]\n\n\n\nprint(f\"에이전트: 현재상태/행동 = {agent.current_states[6]} / {agent.actions[6],action_to_direction2[agent.actions[6]]}\")\nprint(f\"환경: 보상/다음상태 = {agent.rewards[6]} / {agent.next_states[6]}\")\n\n에이전트: 현재상태/행동 = [0 2] / (2, 'up')\n환경: 보상/다음상태 = -10 / [-1  2]\n\n\n- 환경을 이해하기 위한 기록 (1)\n\nq_table = np.zeros([4,4,4]) \ncount = np.zeros([4,4,4])\nfor i in range(agent.n_experiences):\n    s1,s2 = agent.current_states[i]\n    a = agent.actions[i]\n    r = agent.rewards[i]\n    q_table[s1,s2,a] = q_table[s1,s2,a] + r \n    count[s1,s2,a] = count[s1,s2,a] + 1 \n\n\nq_table[0,0,:]\n\narray([ -2983.,  -2960., -29690., -30800.])\n\n\n\ncount[count==0] = 0.01\nq_table = q_table / count \n\n\nfor i in range(4):\n    print(f\"action = {i}/{action_to_direction2[i]}\")\n    print(f\"action-value function = \\n{q_table[:,:,i]}\\n\")\n\naction = 0/down\naction-value function = \n[[ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1. 100.]\n [-10. -10. -10.   0.]]\n\naction = 1/right\naction-value function = \n[[ -1.  -1.  -1. -10.]\n [ -1.  -1.  -1. -10.]\n [ -1.  -1.  -1. -10.]\n [ -1.  -1. 100.   0.]]\n\naction = 2/up\naction-value function = \n[[-10. -10. -10. -10.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.  -1.]\n [ -1.  -1.  -1.   0.]]\n\naction = 3/left\naction-value function = \n[[-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.  -1.]\n [-10.  -1.  -1.   0.]]\n\n\n\n- 환경을 이해하기 위한 기록 (2)\n\nq_table = np.zeros([4,4,4]) \nfor i in range(agent.n_experiences):\n    s1,s2 = agent.current_states[i]\n    a = agent.actions[i]\n    r = agent.rewards[i]\n    q_hat = q_table[s1,s2,a] # 우리가 환경을 이해해서 얻은값, 우리가 풀어낸 답 \n    q = r # 실제답 \n    diff = q - q_hat # 실제답과 풀이한값의 차이 = 오차피드백값\n    q_table[s1,s2,a] = q_hat + 0.05 * diff \n\n\nfor i in range(4):\n    print(f\"action = {i}/{action_to_direction2[i]}\")\n    print(f\"action-value function = \\n{q_table[:,:,i].round(2)}\\n\")\n\naction = 0/down\naction-value function = \n[[ -1.    -1.    -1.    -1.  ]\n [ -1.    -1.    -1.    -1.  ]\n [ -1.    -1.    -1.    98.72]\n [-10.    -9.99  -9.91   0.  ]]\n\naction = 1/right\naction-value function = \n[[-1.   -1.   -1.   -9.99]\n [-1.   -1.   -1.   -9.99]\n [-1.   -1.   -1.   -9.93]\n [-1.   -1.   98.9   0.  ]]\n\naction = 2/up\naction-value function = \n[[-10.   -10.   -10.    -9.97]\n [ -1.    -1.    -1.    -1.  ]\n [ -1.    -1.    -1.    -0.99]\n [ -1.    -1.    -0.99   0.  ]]\n\naction = 3/left\naction-value function = \n[[-10.    -1.    -1.    -1.  ]\n [-10.    -1.    -1.    -1.  ]\n [-10.    -1.    -1.    -0.98]\n [ -9.98  -1.    -0.99   0.  ]]"
  },
  {
    "objectID": "posts/14wk-2.html#b.-환경의-깊은-이해",
    "href": "posts/14wk-2.html#b.-환경의-깊은-이해",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "B. 환경의 깊은 이해",
    "text": "B. 환경의 깊은 이해\n- 분석1: row=3, col=2 상태에서 행동1(right)에 대한 가치\n\nq_table[3,2,1]\n\n98.90433632025939\n\n\n\n상태 (3,2)에서 행동1을 하게되면 100의 보상을 얻으므로 q_table[3,2,1] = 98.904 는 합리적임\n\n- 분석2: row=3, col=1 상태에서 행동1에(right)에 대한 가치\n\nq_table[3,1,1]\n\n-0.9990658635484849\n\n\n\n상태 (3,1)에서 행동1을 하게되면 -1 의 보상을 얻으므로 q_table[3,1,1] = - 0.999 는 합리적인가??\n\n- 비판: 분석2는 합리적인것 처럼 보이지만 data를 분석한 뒤에는 그다지 합리적이지 못함.\n- 상황상상\n\n빈 종이를 줌\n빈 종이에는 0 또는 1을 쓸 수 있음 (action = 0 혹은 1)\n0을 쓸때와 1을 쓸때 보상이 다름\n무수히 많은 데이터를 분석해보니, 0을 쓰면 0원을 주고 1을 쓰면 10만원을 보상을 준다는 것을 “알게 되었음”\n이때 빈 종이의 가치는 5만원인가? 10만원인가? –&gt; 거의 10만원아니야? (9.99만원쯤?)\n\n- 직관: 생각해보니 현재 \\(s=(3,1)\\) \\(a=1\\)에서 추정된(esitated) 값은 q_table[3,1,1] \\(\\approx\\) -1 이지만1, 현실적으로는 “실제보상(-1)과 잠재적보상(100)”을 동시에 고려해야 하는게 합리적임\n1 즉 next_state가 가지는 잠재적값어치는 고려되어있지 않음\nq_hat = q_table[3,1,1]\nq_hat\n\n-0.9990658635484849\n\n\n\nq = (-1) + 0.99 * 100 \nq\n\n98.0\n\n\n\n여기에서 0.99는 “미래에 받을 보상이 현재에 비해 얼마나 중요한지를 결정하는 가중치” 이다.\n1에 가까울수록 미래에 받을 보상을 매우 중시한다는 의미 (즉 빈종이 \\(\\approx\\) 십만원 으로 생각한다는 의미)\n0.99는 보통 \\(\\gamma\\)라는 기호로 표기하며 discount rate이라고 표현한다. (외우세여)\n\n- 즉 \\(q(s,a)\\)는 모든 \\(s\\), \\(a\\)에 대하여\n\\[q(s,a) \\approx \\text{reward}(s,a) + 0.99 \\times \\max_{a}q(s',a)\\]\n가 성립한다면 \\(q(s,a)\\)는 타당하게 추정된 것이라 볼 수 있다. 물론 수식을 좀 더 엄밀하게 쓰면 (terminated, not-terminated 로 나누어 쓰면) 아래와 같다.\n\\[q(s,a) \\approx \\begin{cases}  \\text{reward}(s,a) + 0.99 \\times \\max_{a}q(s',a) & \\text{not terminated} \\\\ \\text{reward}(s,a) & \\text{terminated} \\end{cases}\\]\n\n\n\n\n\n\nNote\n\n\n\n대충 설명하면서 넘어갔지만 이 수식을 벨만방정식이라고 부른다. (외우세여) 위의 식은 강화학습에서 가장 중요한 식이며 원래 버전은 아래와 같다.\n\\[Q^\\star(s,a) = R(s,a) +\\gamma\\sum_{s'}P(s'|s,a)\\max_{a}Q(s',a)\\]\n여기에서 \\(P(s'|s,a)\\) 는 상태 \\(s \\in {\\cal S}\\)에서 행동 \\(a \\in {\\cal A}\\)를 했을때 \\(s'\\)에 있을 확률이다. 이러한 확률은 “바람,소용돌이” 등의 외부의 확률적인 요소가 있는 환경에서 의미가 있으며 우리의 예제에서는 의미가 없다.\n\n\n\nq_table = np.zeros([4,4,4]) \nfor i in range(agent.n_experiences):\n    s1,s2 = agent.current_states[i]\n    ss1,ss2 = agent.next_states[i]\n    a = agent.actions[i]\n    r = agent.rewards[i]\n    q_hat = q_table[s1,s2,a] # 우리가 환경을 이해해서 얻은값, 우리가 풀어낸 답 \n    if agent.terminations[i]:\n        q = r \n    else:\n        future_reward = q_table[ss1,ss2,:].max()\n        q = r + 0.99 * future_reward \n    diff = q - q_hat # 실제답과 풀이한값의 차이 = 오차피드백값\n    q_table[s1,s2,a] = q_hat + 0.05 * diff \n\n\nfor i in range(4):\n    print(f\"action = {i}/{action_to_direction2[i]}\")\n    print(f\"action-value function = \\n{q_table[:,:,i].round(2)}\\n\")\n\naction = 0/down\naction-value function = \n[[ 87.57  89.5   91.05  89.46]\n [ 89.25  91.56  93.71  95.09]\n [ 84.44  91.63  96.13  98.72]\n [-10.    -9.99  -9.91   0.  ]]\n\naction = 1/right\naction-value function = \n[[87.55 88.89 86.05 -9.99]\n [89.51 91.48 92.34 -9.99]\n [91.28 93.68 96.   -9.93]\n [87.7  94.52 98.9   0.  ]]\n\naction = 2/up\naction-value function = \n[[-10.   -10.   -10.    -9.97]\n [ 85.52  87.25  88.12  80.83]\n [ 86.99  88.99  90.17  86.96]\n [ 85.85  88.51  89.37   0.  ]]\n\naction = 3/left\naction-value function = \n[[-10.    85.5   86.94  84.25]\n [-10.    87.39  88.97  89.31]\n [-10.    88.83  90.9   86.27]\n [ -9.98  80.23  81.86   0.  ]]\n\n\n\n\nq_table.max(axis=-1)\n\narray([[87.5672123 , 89.49562198, 91.04523609, 89.45787756],\n       [89.50614803, 91.56172927, 93.70863488, 95.08948559],\n       [91.27612012, 93.67916052, 96.1257449 , 98.72207181],\n       [87.70384078, 94.51521902, 98.90433632,  0.        ]])"
  },
  {
    "objectID": "posts/14wk-2.html#c.-행동-전략-수립",
    "href": "posts/14wk-2.html#c.-행동-전략-수립",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "C. 행동 전략 수립",
    "text": "C. 행동 전략 수립\n- 상태 (0,0)에 있다고 가정해보자.\n\nprint(q_table[0,0,:])\nprint(action_to_direction2)\n\n[ 87.5672123   87.54804715 -10.         -10.        ]\n{0: 'down', 1: 'right', 2: 'up', 3: 'left'}\n\n\n\n행동 0 혹은 행동 1을 하는게 유리하다. // 행동 2,3을 하면 망한다.\n\n- 상태 (2,3)에 있다고 가정해보자.\n\nprint(q_table[2,3,:])\nprint(action_to_direction2)\n\n[98.72207181 -9.92731143 86.96434157 86.27101599]\n{0: 'down', 1: 'right', 2: 'up', 3: 'left'}\n\n\n\n행동 0을 하는게 유리함.\n\n- 상태 (3,2)에 있다고 가정해보자.\n\nprint(q_table[3,2,:])\nprint(action_to_direction2)\n\n[-9.90606054 98.90433632 89.37012074 81.86454084]\n{0: 'down', 1: 'right', 2: 'up', 3: 'left'}\n\n\n\n행동1을 하는게 유리함\n\n- 위에서 제시한 각 상태에서 최적은 action은 아래와 같다.\n\nprint(q_table[0,0,:].argmax())\nprint(q_table[2,3,:].argmax())\nprint(q_table[3,2,:].argmax())\n\n0\n0\n1\n\n\n- 전략(=정책)을 정리해보자.\n(ver1)\n\nq_table.argmax(axis=-1)\n\narray([[0, 0, 0, 0],\n       [1, 0, 0, 0],\n       [1, 1, 0, 0],\n       [1, 1, 1, 0]])\n\n\n(ver2)\n\npolicy = np.array([\"?????\"]*16).reshape(4,4)\npolicy\n\narray([['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????'],\n       ['?????', '?????', '?????', '?????']], dtype='&lt;U5')\n\n\n\nfor s1 in range(4):\n    for s2 in range(4):\n        policy[s1,s2] = action_to_direction2[q_table[s1,s2,:].argmax()]\npolicy\n\narray([['down', 'down', 'down', 'down'],\n       ['right', 'down', 'down', 'down'],\n       ['right', 'right', 'down', 'down'],\n       ['right', 'right', 'right', 'down']], dtype='&lt;U5')"
  },
  {
    "objectID": "posts/14wk-2.html#d.-에이전트-클래스-설계",
    "href": "posts/14wk-2.html#d.-에이전트-클래스-설계",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "D. 에이전트 클래스 설계",
    "text": "D. 에이전트 클래스 설계\n\nq_table[0,0,:]\n\narray([ 87.5672123 ,  87.54804715, -10.        , -10.        ])\n\n\n\nclass AgentGreedy(AgentRandom):\n    def __init__(self,env):\n        super().__init__(env)\n        #--#\n        self.q_table = np.zeros([4,4,4])\n    def learn(self): # q_table \n        s1,s2 = self.current_state\n        ss1,ss2 = self.next_state\n        a = self.action\n        r = self.reward\n        q_hat = self.q_table[s1,s2,a] # 우리가 환경을 이해해서 얻은값, 우리가 풀어낸 답 \n        if self.terminated:\n            q = r \n        else:\n            future_reward = self.q_table[ss1,ss2,:].max()\n            q = r + 0.99 * future_reward \n        diff = q - q_hat\n        self.q_table[s1,s2,a] = q_hat + 0.05 * diff         \n    def act(self):\n        if self.n_experiences &lt; 3000:\n            self.action = self.action_space.sample()\n        else: \n            s1,s2 = self.current_state \n            self.action = self.q_table[s1,s2,:].argmax() # 그리디.."
  },
  {
    "objectID": "posts/14wk-2.html#e.-환경과-상호작용",
    "href": "posts/14wk-2.html#e.-환경과-상호작용",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "E. 환경과 상호작용",
    "text": "E. 환경과 상호작용\n\nenv = GridWorld()\nagent = AgentGreedy(env) \nfor _ in range(3000):\n    # Step1: 에피소드 준비 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    # Step2: 에피소드 진행 \n    for t in range(1,51):\n        # step1: 행동\n        agent.act() \n        # step2: 보상 \n        agent.next_state, agent.reward, agent.terminated = env.step(agent.action)\n        # step3: 저장 & 학습 \n        agent.save_experience() \n        agent.learn() \n        # step4: 다음 스텝준비 \n        agent.current_state = agent.next_state \n        if agent.terminated: break \n    # Step3: 다음에피소드 준비 \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t)\n    agent.n_episodes = agent.n_episodes + 1 \n    #---#\n    logfreq = 300\n    if (agent.n_episodes % logfreq) == 0: \n        print(\n            f\"에피소드:{agent.n_episodes}\\t\"\n            f\"점수(에피소드):{np.mean(agent.scores[-logfreq:]):.2f}\\t\"\n            f\"게임시간(에피소드):{np.mean(agent.playtimes[-logfreq:]):.2f}\\t\"\n        )\n\n에피소드:300    점수(에피소드):-7.32  게임시간(에피소드):3.45 \n에피소드:600    점수(에피소드):-9.92  게임시간(에피소드):3.48 \n에피소드:900    점수(에피소드):-0.54  게임시간(에피소드):3.64 \n에피소드:1200   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:1500   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:1800   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:2100   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:2400   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:2700   점수(에피소드):95.00  게임시간(에피소드):6.00 \n에피소드:3000   점수(에피소드):95.00  게임시간(에피소드):6.00"
  },
  {
    "objectID": "posts/14wk-2.html#f.-상호작용결과-시각화",
    "href": "posts/14wk-2.html#f.-상호작용결과-시각화",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "F. 상호작용결과 시각화",
    "text": "F. 상호작용결과 시각화\n\nstates = [np.array([0,0])] + agent.next_states[-agent.playtimes[-1]:]\nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/14wk-2.html#a.-클래스-설계",
    "href": "posts/14wk-2.html#a.-클래스-설계",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "A. 클래스 설계",
    "text": "A. 클래스 설계\n\nclass AgentExplorer(AgentGreedy):\n    def __init__(self,env):\n        super().__init__(env)\n        self.eps = 0 # 이것이 0이라는 의미는 돌발행동을 안한다는 의미. 즉 AgentGreedy 와 같은 행동을 한다는 의미 \n    def act(self):\n        if np.random.rand() &lt; self.eps:\n            self.action = self.action_space.sample()\n        else: \n            super().act()"
  },
  {
    "objectID": "posts/14wk-2.html#b.-환경과-상호작용",
    "href": "posts/14wk-2.html#b.-환경과-상호작용",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "B. 환경과 상호작용",
    "text": "B. 환경과 상호작용\n\nenv = GridWorld()\nagent = AgentExplorer(env) \nagent.eps = 1 # 돌발행동할 확률이 100퍼 \nfor _ in range(3000):\n    # Step1: 에피소드 준비 \n    agent.current_state = env.reset()\n    agent.terminated = False \n    agent.score = 0 \n    # Step2: 에피소드 진행 \n    for t in range(1,51):\n        # step1: 행동\n        agent.act() \n        # step2: 보상 \n        agent.next_state, agent.reward, agent.terminated = env.step(agent.action)\n        # step3: 저장 & 학습 \n        agent.save_experience() \n        agent.learn() \n        # step4: 다음 스텝준비 \n        agent.current_state = agent.next_state \n        if agent.terminated: break \n    # Step3: 다음에피소드 준비 \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t)\n    agent.n_episodes = agent.n_episodes + 1 \n    agent.eps = agent.eps * 0.999\n    #---#\n    logfreq = 300\n    if (agent.n_episodes % logfreq) == 0: \n        print(\n            f\"에피소드:{agent.n_episodes}\\t\"\n            f\"점수(에피소드):{np.mean(agent.scores[-logfreq:]):.2f}\\t\"\n            f\"게임시간(에피소드):{np.mean(agent.playtimes[-logfreq:]):.2f}\\t\"\n            f\"돌발행동(에피소드):{agent.eps:.2f}\"\n        )\n\n에피소드:300    점수(에피소드):-11.40 게임시간(에피소드):3.50 돌발행동(에피소드):0.74\n에피소드:600    점수(에피소드):-9.67  게임시간(에피소드):3.60 돌발행동(에피소드):0.55\n에피소드:900    점수(에피소드):0.70   게임시간(에피소드):4.23 돌발행동(에피소드):0.41\n에피소드:1200   점수(에피소드):51.58  게임시간(에피소드):6.15 돌발행동(에피소드):0.30\n에피소드:1500   점수(에피소드):65.10  게임시간(에피소드):6.20 돌발행동(에피소드):0.22\n에피소드:1800   점수(에피소드):69.62  게임시간(에피소드):6.08 돌발행동(에피소드):0.17\n에피소드:2100   점수(에피소드):78.86  게임시간(에피소드):6.01 돌발행동(에피소드):0.12\n에피소드:2400   점수(에피소드):83.88  게임시간(에피소드):6.12 돌발행동(에피소드):0.09\n에피소드:2700   점수(에피소드):84.49  게임시간(에피소드):5.87 돌발행동(에피소드):0.07\n에피소드:3000   점수(에피소드):88.74  게임시간(에피소드):6.03 돌발행동(에피소드):0.05"
  },
  {
    "objectID": "posts/14wk-2.html#c.-상호작용-결과-시각화",
    "href": "posts/14wk-2.html#c.-상호작용-결과-시각화",
    "title": "14wk-2: 강화학습 (3) – 4x4 Grid World (AgentGreedy,AgentExplorer)",
    "section": "C. 상호작용 결과 시각화",
    "text": "C. 상호작용 결과 시각화\n\nstates = [np.array([0,0])] + agent.next_states[-agent.playtimes[-1]:]\nshow(states)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/12wk-2.html#a.-data",
    "href": "posts/12wk-2.html#a.-data",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "A. Data",
    "text": "A. Data\n- 데이터 정리\n\ntxt = list('AbAcAd'*50)\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\nA\nb\n\n\n1\nb\nA\n\n\n2\nA\nc\n\n\n3\nc\nA\n\n\n4\nA\nd"
  },
  {
    "objectID": "posts/12wk-2.html#b.-구현1-rnncell-지난시간",
    "href": "posts/12wk-2.html#b.-구현1-rnncell-지난시간",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "B. 구현1 – RNNCell (지난시간)",
    "text": "B. 구현1 – RNNCell (지난시간)\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n- 데이터정리\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n- Net설계 및 가중치 설정 (구현1과 동일하도록 가중치 초기화)\n\ntorch.manual_seed(4) # 이거를 고정해야함 \nrnncell = torch.nn.RNNCell(4,2)\ncook = torch.nn.Linear(2,4)\n\n- 손실함수 및 옵티마이저 설정\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()),lr=0.1)\n\n\nL = len(X)\nfor epoc in range(200):\n    ## 1~2 \n    loss = 0 \n    ht = torch.zeros(2) # 첫 간장은 맹물 \n    for t in range(L):\n        Xt,yt = X[t],y[t]\n        ht = rnncell(Xt,ht)\n        ot = cook(ht)\n        loss = loss + loss_fn(ot,yt)\n    loss = loss/L\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nh = torch.zeros(L,2)\nwater = torch.zeros(2)\nh[0] = rnncell(X[0],water)\nfor t in range(1,L):\n    h[t] = rnncell(X[t],h[t-1])\nyhat = soft(cook(h))\nyhat\n\ntensor([[2.1032e-03, 7.4842e-01, 2.4849e-01, 9.8890e-04],\n        [9.9601e-01, 6.1446e-05, 3.9266e-03, 2.8410e-09],\n        [5.0120e-05, 2.2370e-02, 9.7758e-01, 2.4300e-07],\n        ...,\n        [5.0229e-05, 2.2415e-02, 9.7753e-01, 2.4398e-07],\n        [9.9858e-01, 9.3154e-05, 1.3903e-08, 1.3301e-03],\n        [2.2350e-05, 1.9198e-02, 1.1779e-07, 9.8078e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmat = torch.concat([h,yhat],axis=1).data[:10]\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1)\nplt.axvline(x=1.5,color='lime')\nplt.xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$']);"
  },
  {
    "objectID": "posts/12wk-2.html#c.-구현2-rnn",
    "href": "posts/12wk-2.html#c.-구현2-rnn",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "C. 구현2 – RNN",
    "text": "C. 구현2 – RNN\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNN.html\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n\ntorch.manual_seed(4) \nrnncell = torch.nn.RNNCell(4,2)\ncook = torch.nn.Linear(2,4)\n\n\nrnn = torch.nn.RNN(4,2)\nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\nrnn.weight_hh_l0.data = rnncell.weight_hh.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()),lr=0.1)\n\n\nWater = torch.zeros(1,2) # 첫 간장은 맹물 \nfor epoc in range(200):\n    ## 1\n    h,hL = rnn(X,Water)\n    netout = cook(h)\n    ## 2 \n    loss = loss_fn(netout, y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nh,_ = rnn(X,Water)\nyhat = soft(cook(h))\nyhat\n\ntensor([[2.1032e-03, 7.4842e-01, 2.4849e-01, 9.8888e-04],\n        [9.9601e-01, 6.1446e-05, 3.9266e-03, 2.8410e-09],\n        [5.0120e-05, 2.2370e-02, 9.7758e-01, 2.4300e-07],\n        ...,\n        [5.0229e-05, 2.2415e-02, 9.7753e-01, 2.4399e-07],\n        [9.9858e-01, 9.3154e-05, 1.3902e-08, 1.3302e-03],\n        [2.2350e-05, 1.9198e-02, 1.1779e-07, 9.8078e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmat = torch.concat([h,yhat],axis=1).data[:10]\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1)\nplt.axvline(x=1.5,color='lime')\nplt.xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$']);"
  },
  {
    "objectID": "posts/12wk-2.html#d.-구현3-rnn-gpu",
    "href": "posts/12wk-2.html#d.-구현3-rnn-gpu",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "D. 구현3 – RNN + GPU",
    "text": "D. 구현3 – RNN + GPU\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n\ntorch.manual_seed(4) \nrnncell = torch.nn.RNNCell(4,2)\ncook = torch.nn.Linear(2,4)\n\n\nrnn = torch.nn.RNN(4,2)\nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\nrnn.weight_hh_l0.data = rnncell.weight_hh.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()),lr=0.1)\n\n\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nrnn.to(\"cuda:0\") \ncook.to(\"cuda:0\")\nWater = torch.zeros(1,2).to(\"cuda:0\")\nfor epoc in range(200):\n    ## 1\n    h,hL = rnn(X,Water)\n    netout = cook(h)\n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nh,hL = rnn(X,Water)\nnetout = cook(h)\nyhat = soft(netout)\nyhat\n\ntensor([[2.1034e-03, 7.4850e-01, 2.4841e-01, 9.8938e-04],\n        [9.9601e-01, 6.1439e-05, 3.9265e-03, 2.8412e-09],\n        [5.0124e-05, 2.2368e-02, 9.7758e-01, 2.4295e-07],\n        ...,\n        [5.0233e-05, 2.2413e-02, 9.7754e-01, 2.4393e-07],\n        [9.9858e-01, 9.3186e-05, 1.3921e-08, 1.3297e-03],\n        [2.2340e-05, 1.9198e-02, 1.1779e-07, 9.8078e-01]], device='cuda:0',\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\n살짝결과다름\n\n\nmat = torch.concat([h,yhat],axis=1).data[:10].to(\"cpu\")\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1)\nplt.axvline(x=1.5,color='lime')\nplt.xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$']);"
  },
  {
    "objectID": "posts/12wk-2.html#e.-구현4-rnn-gpu-맹물x",
    "href": "posts/12wk-2.html#e.-구현4-rnn-gpu-맹물x",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "E. 구현4 – RNN + GPU + 맹물X",
    "text": "E. 구현4 – RNN + GPU + 맹물X\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n\ntorch.manual_seed(4) \nrnncell = torch.nn.RNNCell(4,2)\ncook = torch.nn.Linear(2,4)\n\n\nrnn = torch.nn.RNN(4,2)\nrnn.weight_ih_l0.data = rnncell.weight_ih.data\nrnn.bias_ih_l0.data = rnncell.bias_ih.data\nrnn.weight_hh_l0.data = rnncell.weight_hh.data\nrnn.bias_hh_l0.data = rnncell.bias_hh.data\n\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnn.parameters())+list(cook.parameters()),lr=0.1)\n\n\nX = X.to(\"cuda:0\")\ny = y.to(\"cuda:0\")\nrnn.to(\"cuda:0\") \ncook.to(\"cuda:0\")\nWater = torch.zeros(1,2).to(\"cuda:0\")\nfor epoc in range(200):\n    ## 1\n    h,_ = rnn(X)\n    netout = cook(h)\n    ## 2 \n    loss = loss_fn(netout,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nh,_ = rnn(X)\nnetout = cook(h)\nyhat = soft(netout)\nyhat\n\ntensor([[2.1034e-03, 7.4850e-01, 2.4841e-01, 9.8938e-04],\n        [9.9601e-01, 6.1439e-05, 3.9265e-03, 2.8412e-09],\n        [5.0124e-05, 2.2368e-02, 9.7758e-01, 2.4295e-07],\n        ...,\n        [5.0233e-05, 2.2413e-02, 9.7754e-01, 2.4393e-07],\n        [9.9858e-01, 9.3186e-05, 1.3921e-08, 1.3297e-03],\n        [2.2340e-05, 1.9198e-02, 1.1779e-07, 9.8078e-01]], device='cuda:0',\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmat = torch.concat([h,yhat],axis=1).data[:10].to(\"cpu\")\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1)\nplt.axvline(x=1.5,color='lime')\nplt.xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$']);"
  },
  {
    "objectID": "posts/12wk-2.html#f.-은닉노드-비교실험",
    "href": "posts/12wk-2.html#f.-은닉노드-비교실험",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "F. 은닉노드 비교실험",
    "text": "F. 은닉노드 비교실험\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,2).to(\"cuda:0\")\n        cook = torch.nn.Linear(2,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters()) + list(cook.parameters()), lr=0.1)\n        for epoc in range(200):\n            ## 1\n            h,_ = rnn(X)\n            netout = cook(h)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = rnn(X)[0].data.to(\"cpu\")\n        yhat = soft(cook(rnn(X)[0])).data.to(\"cpu\")\n        mat = torch.concat([h,yhat],axis=1)[:8]\n        ax[i][j].matshow(mat,cmap=\"bwr\")\n        ax[i][j].axvline(x=1.5,color=\"lime\")\n        ax[i][j].set_xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$'])\nfig.suptitle(\"RNN -- # of hidden nodes = 2\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,3).to(\"cuda:0\")\n        cook = torch.nn.Linear(3,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters()) + list(cook.parameters()), lr=0.1)\n        for epoc in range(200):\n            ## 1\n            h,_ = rnn(X)\n            netout = cook(h)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = rnn(X)[0].data.to(\"cpu\")\n        yhat = soft(cook(rnn(X)[0])).data.to(\"cpu\")\n        mat = torch.concat([h,yhat],axis=1)[:8]\n        ax[i][j].matshow(mat,cmap=\"bwr\")\n        ax[i][j].axvline(x=2.5,color=\"lime\")\n        ax[i][j].set_xticks(range(7),[r'$h_1$',r'$h_2$',r'$h_3$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$'])\nfig.suptitle(\"RNN -- # of hidden nodes = 3\",size=20)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,4).to(\"cuda:0\")\n        cook = torch.nn.Linear(4,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters()) + list(cook.parameters()), lr=0.1)\n        for epoc in range(200):\n            ## 1\n            h,_ = rnn(X)\n            netout = cook(h)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = rnn(X)[0].data.to(\"cpu\")\n        yhat = soft(cook(rnn(X)[0])).data.to(\"cpu\")\n        mat = torch.concat([h,yhat],axis=1)[:8]\n        ax[i][j].matshow(mat,cmap=\"bwr\")\n        ax[i][j].axvline(x=3.5,color=\"lime\")\n        ax[i][j].set_xticks(range(8),[r'$h_1$',r'$h_2$',r'$h_3$',r'$h_4$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$'])\nfig.suptitle(\"RNN -- # of hidden nodes = 4\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/12wk-2.html#a.-data-1",
    "href": "posts/12wk-2.html#a.-data-1",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "A. Data",
    "text": "A. Data\n- 데이터 정리\n\ntxt = list('abcabC'*50)\ntxt[:10]\n\n['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b', 'c', 'a']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\na\nb\n\n\n1\nb\nc\n\n\n2\nc\na\n\n\n3\na\nb\n\n\n4\nb\nC"
  },
  {
    "objectID": "posts/12wk-2.html#b.-rnn",
    "href": "posts/12wk-2.html#b.-rnn",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "B. RNN",
    "text": "B. RNN\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n\nx = torch.tensor(df_train.x.map({'a':0,'b':1,'c':2,'C':3}))\ny = torch.tensor(df_train.y.map({'a':0,'b':1,'c':2,'C':3}))\nX = torch.nn.functional.one_hot(x).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        rnn = torch.nn.RNN(4,4).to(\"cuda:0\")\n        cook = torch.nn.Linear(4,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(rnn.parameters()) + list(cook.parameters()), lr=0.1)\n        for epoc in range(500):\n            ## 1\n            h,_ = rnn(X)\n            netout = cook(h)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = rnn(X)[0].data.to(\"cpu\")\n        yhat = soft(cook(rnn(X)[0])).data.to(\"cpu\")\n        mat = torch.concat([h,yhat],axis=1)[:8]\n        ax[i][j].matshow(mat,cmap=\"bwr\")\n        ax[i][j].axvline(x=3.5,color=\"lime\")\n        ax[i][j].set_xticks(range(8),[r'$h_1$',r'$h_2$',r'$h_3$',r'$h_4$',r'$P_a$',r'$P_b$',r'$P_c$',r'$P_C$'])\nfig.suptitle(\"RNN -- # of hidden nodes = 4\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/12wk-2.html#c.-lstm",
    "href": "posts/12wk-2.html#c.-lstm",
    "title": "12wk-2: 순환신경망 (3) – RNN, LSTM",
    "section": "C. LSTM",
    "text": "C. LSTM\n\nx = torch.tensor(df_train.x.map({'a':0,'b':1,'c':2,'C':3}))\ny = torch.tensor(df_train.y.map({'a':0,'b':1,'c':2,'C':3}))\nX = torch.nn.functional.one_hot(x).float().to(\"cuda:0\")\ny = torch.nn.functional.one_hot(y).float().to(\"cuda:0\")\nfig,ax = plt.subplots(5,5,figsize=(10,10))\nfor i in range(5):\n    for j in range(5):\n        lstm = torch.nn.LSTM(4,4).to(\"cuda:0\")\n        cook = torch.nn.Linear(4,4).to(\"cuda:0\")\n        loss_fn = torch.nn.CrossEntropyLoss()\n        optimizr = torch.optim.Adam(list(lstm.parameters()) + list(cook.parameters()), lr=0.1)\n        for epoc in range(500):\n            ## 1\n            h,_ = lstm(X)\n            netout = cook(h)\n            ## 2 \n            loss = loss_fn(netout,y)\n            ## 3 \n            loss.backward()\n            ## 4 \n            optimizr.step()\n            optimizr.zero_grad()\n        h = lstm(X)[0].data.to(\"cpu\")\n        yhat = soft(cook(lstm(X)[0])).data.to(\"cpu\")\n        mat = torch.concat([h,yhat],axis=1)[:8]\n        ax[i][j].matshow(mat,cmap=\"bwr\",vmin=-1,vmax=1)\n        ax[i][j].axvline(x=3.5,color=\"lime\")\n        ax[i][j].set_xticks(range(8),[r'$h_1$',r'$h_2$',r'$h_3$',r'$h_4$',r'$P_a$',r'$P_b$',r'$P_c$',r'$P_C$'])\nfig.suptitle(\"LSTM -- # of hidden nodes = 4\",size=20)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/07wk-1-2.html#a.-dls",
    "href": "posts/07wk-1-2.html#a.-dls",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "A. DLS",
    "text": "A. DLS\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.PETS)\n#path.ls()\n(path/'images').ls()\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/american_bulldog_224.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/chihuahua_133.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Bombay_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/english_setter_153.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_125.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Bombay_156.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/keeshond_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Birman_115.jpg')...]\n\n\n\n(path/'images').ls()[214],(path/'images').ls()[448],(path/'images').ls()[2976]\n\n(Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat'),\n Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat'),\n Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat'))\n\n\n\nfnames = fastai.data.transforms.get_image_files(path/'images')\n#fnames = [l for l in (path/'images').ls() if str(l).split('.')[-1] == 'jpg']\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = fastai.vision.data.ImageDataLoaders.from_name_func(\n    path = path/'images',\n    fnames = fnames,\n    label_func = label_func,\n    item_tfms = fastai.vision.augment.Resize(512),\n    bs = 32 # batch_size = 32 \n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/07wk-1-2.html#b.-이미지-자료-불러오기",
    "href": "posts/07wk-1-2.html#b.-이미지-자료-불러오기",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "B. 이미지 자료 불러오기",
    "text": "B. 이미지 자료 불러오기\n- 원래 우리가 아는 방법: path를 의미하는 string \\(\\to\\) torch.tensor\n\nx = torchvision.io.read_image('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'torch.Tensor'&gt;\nshape: torch.Size([3, 333, 500])\ndtype: torch.uint8\n\n\n- fastai를 이용하는 방법: path를 의미하는 string \\(\\to\\) PILImage \\(\\to\\) fastai.torch_core.TensorImage \\(\\to\\) torch.tensor\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n# print('---')\n# x = torch.tensor(x)\n# print(f\"type: {type(x)}\")\n# print(f\"shape: {x.shape}\")\n# print(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([1, 3, 512, 512])\ndtype: torch.float32\n\n\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0]\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([1, 3, 512, 512])\ndtype: torch.float32\n\n\n- 참고로 아래와 같이 이미지변환할 수도 있음.\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\n#x = next(iter(dls.test_dl([x_pil])))[0]\nx = fastai.torch_core.TensorImage(x_pil)\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([333, 500, 3])\ndtype: torch.uint8"
  },
  {
    "objectID": "posts/07wk-1-2.html#c.-이미지-자료-시각화",
    "href": "posts/07wk-1-2.html#c.-이미지-자료-시각화",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "C. 이미지 자료 시각화",
    "text": "C. 이미지 자료 시각화\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n\n\n\n\n\n\n\n\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))"
  },
  {
    "objectID": "posts/07wk-1-2.html#d.-ap-layer",
    "href": "posts/07wk-1-2.html#d.-ap-layer",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "D. AP layer",
    "text": "D. AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nap\n\nAdaptiveAvgPool2d(output_size=1)\n\n\n\nX = torch.arange(1*3*4*4).reshape(1,3,4,4)*1.0 \nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) # 채널별로 평균을 구해줌. \n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nr,g,b = X[0]\n\n\nr.mean(), g.mean(), b.mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\nap(r), ap(g), ap(b) \n\n(tensor([[7.5000]]), tensor([[23.5000]]), tensor([[39.5000]]))"
  },
  {
    "objectID": "posts/07wk-1-2.html#e.-ap-linear의-교환",
    "href": "posts/07wk-1-2.html#e.-ap-linear의-교환",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "E. AP, Linear의 교환",
    "text": "E. AP, Linear의 교환\n- 신기한 거 보여줄까요??\n\nap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntensor([[17.3000]])\n\n\n\nap(r*0.1 + g*0.2 + b*0.3)\n\ntensor([[17.3000]])\n\n\n\n별로 안 신기함.. 당연한것 아니야?\n\n- torch.nn.Linear() 와 torch.nn.Flatten() 를 이용한 구현\n\nflatten = torch.nn.Flatten()\nl = torch.nn.Linear(3,1,bias=False)\n\n\n# ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\nl.weight.data = torch.tensor([[0.1, 0.2, 0.3]])\nl(flatten(ap(X)))\n\ntensor([[17.3000]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\n#ap(r*0.1 + g*0.2 + b*0.3) ## 각각의 픽셀에 l을 취하고 그 결과에 ap를 취해야함 \nflatten(ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data)))\n\ntensor([[17.3000]])\n\n\n- 정리\n\n# 계산1: x를 ap, flatten, linear 순서로 적용\nprint(f\"{X.shape} -- X\")\nprint(f\"{ap(X).shape} -- ap(X)\")\nprint(f\"{flatten(ap(X)).shape} -- flatten(ap(X))\")\nprint(f\"{l(flatten(ap(X))).shape} -- l(flatten(ap(X)))\")\n\ntorch.Size([1, 3, 4, 4]) -- X\ntorch.Size([1, 3, 1, 1]) -- ap(X)\ntorch.Size([1, 3]) -- flatten(ap(X))\ntorch.Size([1, 1]) -- l(flatten(ap(X)))\n\n\n\n# 계산2: x를 linear, ap, flatten 순서로 적용\nprint(f\"{X.shape} -- X\")\nprint(f\"{torch.einsum('ocij,kc -&gt; okij',X,l.weight.data).shape} -- l(X)\")\nprint(f\"{ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data)).shape} -- ap(l(X))\")\nprint(f\"{flatten(ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data))).shape} -- flatten(ap(l(X)))\")\n\ntorch.Size([1, 3, 4, 4]) -- X\ntorch.Size([1, 1, 4, 4]) -- l(X)\ntorch.Size([1, 1, 1, 1]) -- ap(l(X))\ntorch.Size([1, 1]) -- flatten(ap(l(X)))\n\n\n\\[\\underset{(n,3,4,4)}{\\boldsymbol X} \\overset{ap}{\\to} \\underset{(n,3,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(n,3)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}} = [[17.3],...]\\]\n\\[\\underset{(n,3,4,4)}{\\boldsymbol X} \\overset{linear}{\\to} \\underset{(n,1,4,4)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(n,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}} = [[17.3],...]\\]"
  },
  {
    "objectID": "posts/07wk-1-2.html#a.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "href": "posts/07wk-1-2.html#a.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "A. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습",
    "text": "A. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습\n\nlrnr = fastai.vision.learner.vision_learner(\n    dls = dls,\n    arch = fastai.vision.models.resnet34, \n    metrics = [fastai.metrics.accuracy]\n)    \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.101094\n0.035343\n0.989851\n00:20\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.068278\n0.004763\n0.997970\n00:26"
  },
  {
    "objectID": "posts/07wk-1-2.html#b.-2단계-네트워크의-끝-부분-수정하고-재학습",
    "href": "posts/07wk-1-2.html#b.-2단계-네트워크의-끝-부분-수정하고-재학습",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "B. 2단계– 네트워크의 끝 부분 수정하고 재학습",
    "text": "B. 2단계– 네트워크의 끝 부분 수정하고 재학습\n- 일반적으로 CNN계열은 2D-part와 1D-part로 구분되어있음.\n\nnet1 = lrnr.model[0] # 2d-part \nnet2 = lrnr.model[1] # 1d-part \n\n\n# 하나의 배치를 테스트용으로 임시로 가져옴\n_X, _y = dls.one_batch()\n_X.shape,_y.shape \n\n(torch.Size([32, 3, 512, 512]), torch.Size([32]))\n\n\n\nprint(f\"입력이미지:\\t\\t {_X.shape}\")\nprint(f\"net1통과직후:\\t\\t {net1(_X).shape}\")\nprint(f\"net2의AP까지통과직후:\\t {net2[0](net1(_X)).shape}\")\nprint(f\"net2의Flatten까지통과직후:\\t {net2[1](net2[0](net1(_X))).shape}\")\nprint(f\"net2끝까지통과:\\t\\t {net2(net1(_X)).shape}\")\n\n입력이미지:       torch.Size([32, 3, 512, 512])\nnet1통과직후:        torch.Size([32, 512, 16, 16])\nnet2의AP까지통과직후:   torch.Size([32, 1024, 1, 1])\nnet2의Flatten까지통과직후:  torch.Size([32, 1024])\nnet2끝까지통과:       torch.Size([32, 2])\n\n\n- net2를 아래와 같이 수정하자. (왜??)\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # [n, 512, 16, 16] --&gt; [n, 512, 1, 1]\n    torch.nn.Flatten(), # [n, 512, 1, 1] --&gt;  [n, 512]\n    torch.nn.Linear(512,2,bias=False) # [n,512] --&gt; [n,2] \n)\n\n\nnet = torch.nn.Sequential(\n    net1, # 원래 resnet34에 있던거..\n    net2 # 내가 (CAM을 위해서) 마음대로 바꾼것.. \n)\n\n\nlrnr2 = fastai.learner.Learner(\n    dls = dls, \n    model = net,\n    metrics = [fastai.metrics.accuracy] \n)    \n\n\nlrnr.loss_func, lrnr2.loss_func # loss_fn 은 따로 정의안했는데 알아서 잘 들어가 있음\n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 내마음대로 수정했고, 그것에 대한 패널티로 accuracy가 안좋아짐! 그렇지만 그런대로 쓸만함. \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.323613\n1.646134\n0.705007\n00:26\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.166095\n0.257160\n0.905954\n00:26\n\n\n1\n0.160385\n0.132229\n0.953315\n00:26\n\n\n2\n0.106043\n0.093649\n0.962111\n00:26\n\n\n3\n0.050350\n0.056827\n0.979702\n00:26\n\n\n4\n0.029413\n0.058543\n0.981732\n00:26"
  },
  {
    "objectID": "posts/07wk-1-2.html#c.-3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "href": "posts/07wk-1-2.html#c.-3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "C. 3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈",
    "text": "C. 3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\nx_dec = dls.decode([x])[0]\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n\n\n\n\n\n\n\n\n- 하나의 observation이 yhat까지 나오는 과정\n\n# 계산방식1: 원래계산방식\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\nprint(f\"{x.shape} -- x\")\nprint(f\"{net1(x).shape} -- net1(x)\")\nprint(f\"{ap(net1(x)).shape} -- ap(net1(x))\")\nprint(f\"{fl(ap(net1(x))).shape} -- flatten(ap(net1(x)))\")\nprint(f\"{l(fl(ap(net1(x)))).shape} -- l(flatten(ap(net1(x))))\")\nl(fl(ap(net1(x))))\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- net1(x)\ntorch.Size([1, 512, 1, 1]) -- ap(net1(x))\ntorch.Size([1, 512]) -- flatten(ap(net1(x)))\ntorch.Size([1, 2]) -- l(flatten(ap(net1(x))))\n\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\nnet2의 순서 바꾸기 전 전체 네트워크 \\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [[2.7846, -2.7945]]\\]\n\n# 계산방식2: net2의 순서를 바꾼 계산\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\nWHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\nprint(f\"{x.shape} -- x\")\nprint(f\"{net1(x).shape} -- net1(x)\")\nprint(f\"{WHY.shape} -- l(net1(x)):=WHY\")\nprint(f\"{ap(WHY).shape} -- ap(l(net1(x)))=ap(WHY)\")\nprint(f\"{fl(ap(WHY)).shape} -- flatten(ap(l(net1(x)))))=flatten(ap(WHY))\")\nfl(ap(torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)))\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- net1(x)\ntorch.Size([1, 2, 16, 16]) -- l(net1(x)):=WHY\ntorch.Size([1, 2, 1, 1]) -- ap(l(net1(x)))=ap(WHY)\ntorch.Size([1, 2]) -- flatten(ap(l(net1(x)))))=flatten(ap(WHY))\n\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\nnet2의 순서를 바꾼후 전체 네트워크 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf WHY}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [[2.7846,-2.7945]]\\]\n\n참고: 여기에서 linear는 (1,512,16,16)의 each pixel에 torch.nn.Linear(512,2)를 수행함.\n\n\n\\(\\star\\) 잠깐 멈추고 생각 좀 해보자..\n- 입력이미지\n\nx_pil, x\n\n(PILImage mode=RGB size=500x333,\n TensorImage([[[[ 0.8104,  0.7933,  0.7762,  ..., -0.6794, -0.6794, -0.6794],\n                [ 0.8104,  0.7933,  0.7762,  ..., -0.6965, -0.6965, -0.6965],\n                [ 0.8104,  0.7933,  0.7762,  ..., -0.7137, -0.7137, -0.7137],\n                ...,\n                [-0.6623, -0.2171,  0.3138,  ...,  0.5707,  0.5364,  0.5022],\n                [-0.7650, -0.3541,  0.1597,  ...,  0.5707,  0.5193,  0.4851],\n                [-0.8335, -0.4568,  0.0398,  ...,  0.5707,  0.5193,  0.4679]],\n \n               [[ 0.9930,  0.9755,  0.9580,  ..., -0.5301, -0.5126, -0.4951],\n                [ 0.9930,  0.9755,  0.9580,  ..., -0.5301, -0.5126, -0.4951],\n                [ 1.0105,  0.9930,  0.9580,  ..., -0.5126, -0.4951, -0.4951],\n                ...,\n                [-1.0553, -0.5301,  0.1527,  ..., -0.0399,  0.0126,  0.0476],\n                [-1.1604, -0.6527,  0.0301,  ...,  0.0301,  0.0651,  0.0651],\n                [-1.2479, -0.7402, -0.0574,  ...,  0.0826,  0.0826,  0.0651]],\n \n               [[ 0.9668,  0.9494,  0.9319,  ..., -0.3927, -0.4624, -0.5147],\n                [ 0.9494,  0.9494,  0.9319,  ..., -0.3927, -0.4624, -0.4973],\n                [ 0.9319,  0.9319,  0.9319,  ..., -0.3927, -0.4450, -0.4798],\n                ...,\n                [-0.9156, -0.3578,  0.3393,  ..., -0.0615,  0.0082,  0.0256],\n                [-1.0550, -0.5147,  0.1825,  ...,  0.0431,  0.0082, -0.0267],\n                [-1.1596, -0.6367,  0.0779,  ...,  0.1128,  0.0082, -0.0790]]]],\n             device='cuda:0'))\n\n\n- 원래 net2를 그대로 적용한 결과를 해석\n\nnet2(net1(x))\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n“2.7846 &gt; -2.7945” 이므로, ximg는 높은 확률로 고양이라는 것을 의미함.\n\n- 바뀐 net2를 적용해볼까?\n\nflatten(ap(WHY))\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nWHY[0,0,:,:].mean() # 이 값이 클수록 고양이\n\nTensorImage(2.7846, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nWHY[0,1,:,:].mean() # 이 값이 클수록 강아지 \n\nTensorImage(-2.7945, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n- 좀더 파고들어서 분석해보자.\n\nWHY[0,0,:,:].int() # 이 값들의 평균이 2.7846임. 그리고 이 평균값이 클수록 고양이\n\nTensorImage([[ 0,  0,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  2,  5,  2,  1,  1,  0,  0,  0,  0,  0,  0,  0, -1, -1],\n             [ 0,  0,  1,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -3],\n             [ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0, -1, -3, -2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0, -3, -1,  1,  2,  1,  0,  0, -1,  0,  0,  1],\n             [ 0,  0,  0,  0,  0, -1,  1, 11, 19, 14,  4,  0, -1, -1,  0,  0],\n             [ 0,  0,  0,  0,  0, -1,  6, 24, 40, 28,  9,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  1, 11, 31, 46, 33, 11,  1,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  1,  7, 16, 27, 32, 23,  9,  1,  0,  1,  1,  1],\n             [-1,  0,  0,  0,  4, 14, 22, 20, 17, 11,  5,  2,  2,  3,  4,  3],\n             [-1,  0,  0,  1,  6, 16, 23, 12,  4,  2,  3,  3,  3,  3,  4,  4],\n             [ 0,  0,  1,  1,  5, 11, 13,  7,  2,  1,  2,  1,  1,  2,  1,  1],\n             [ 0,  1,  3,  2,  3,  5,  6,  4,  1,  0,  1,  0,  0,  0,  0,  0],\n             [ 0,  0,  1,  1,  0,  0,  1,  1,  0,  0,  0,  0, -1, -2, -1, -1],\n             [ 0, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0, -1, -2, -2, -2]],\n            device='cuda:0', dtype=torch.int32)\n\n\n\n이 값들의 평균은 2.7846임.\n이 값들이 클수록 이 그림은 고양이라는 의미임 = 이 값이 작을수록 이 그림은 고양이 그림이 아니라는 의미임.\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가지고, 특정 위치에서만 엄청 큰 값이 있어서 2.7846이라는 값이 나온 것임.\n특정위치에 존재하는 엄청 큰 값들은, x가 고양이 이미지라고 판단하는 근거가 된다.\n\n\nWHY[0,1,:,:].int() # 이 값들의 평균이 -2.7945임. 그리고 이 평균값이 클수록 강아지\n\nTensorImage([[  0,   0,  -1,  -1,  -1,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,  -2,  -6,  -2,  -1,  -1,  -1,   0,   0,   0,   0,   0,\n                0,   1,   0],\n             [  0,   0,  -1,  -2,  -2,  -1,   0,   0,   0,   0,   0,  -1,   0,\n                0,   1,   2],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,   2,   1,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   2,   0,  -1,  -2,  -2,   0,   0,   0,\n                0,   0,  -2],\n             [  0,   0,   0,   0,   0,   0,  -1, -11, -18, -15,  -5,   0,   0,\n                1,   0,   0],\n             [  0,   0,   0,   0,   0,   0,  -6, -22, -34, -26,  -9,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  -1, -10, -28, -41, -30, -11,  -1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,  -1,  -6, -15, -27, -31, -22,  -9,  -1,   0,\n               -1,  -1,  -1],\n             [  1,   0,   0,   0,  -4, -12, -20, -19, -17, -10,  -5,  -2,  -1,\n               -2,  -4,  -3],\n             [  1,   0,   0,  -1,  -5, -15, -21, -11,  -4,  -2,  -3,  -4,  -4,\n               -3,  -5,  -4],\n             [  1,   0,   0,  -1,  -5, -11, -12,  -7,  -2,  -1,  -2,  -1,  -1,\n               -2,  -2,  -1],\n             [  0,  -1,  -3,  -2,  -3,  -5,  -6,  -3,  -1,  -1,  -1,   0,   0,\n                0,   0,   0],\n             [  0,   0,  -2,  -1,   0,  -1,  -1,  -1,  -1,   0,   0,   0,   0,\n                1,   1,   0],\n             [  0,   0,   1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   1,\n                2,   2,   2]], device='cuda:0', dtype=torch.int32)\n\n\n\n이 값들의 평균은 -2.7945임.\n이 값들이 클수록 이 그림은 강아지라는 의미임 = 이 값이 작을수록 이 그림은 강아지가 아니라는 의미임.\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가지고, 특정 위치에서만 엄청 큰 작은값이 있어서 -2.7945라는 값이 나온 것임.\n특정위치에 존재하는 엄청 큰 작은값들은, x가 강아지 이미지가 아니라고 판단하는 근거가 된다.\n\n\\[\\underset{(1,2,16,16)}{{\\bf WHY}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [[2.7846,-2.7945]]\\]\n- 시각화1\n\nWHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\nWHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n\n\nfig,ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYCAT,cmap='magma')\nax[2].imshow(WHYDOG,cmap='magma')\n\n\n\n\n\n\n\n\n\nmagma: 검은색 &lt; 보라색 &lt; 빨간색 &lt; 노란색\n가운데 그림의 노란부분은 고양이라는 증거, 오른쪽 그림의 검보라색 부분은 강아지가 아니라는 증거\n\n- 시각화2\n\nWHYCAT.shape\n\ntorch.Size([16, 16])\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n\n\n\n\n\n\n\n\n- 하니를 활용한 시각화\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nWHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\nWHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\nWHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\nsoftmax = torch.nn.Softmax(dim=1)\ncat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[0].set_title(f\"cat prob = {cat_prob:.6f}\")\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[1].set_title(f\"dog prob = {dog_prob:.6f}\")\n\nText(0.5, 1.0, 'dog prob = 0.999991')"
  },
  {
    "objectID": "posts/07wk-1-2.html#d.-4단계-cam-시각화",
    "href": "posts/07wk-1-2.html#d.-4단계-cam-시각화",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "D. 4단계 – CAM 시각화",
    "text": "D. 4단계 – CAM 시각화\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=0\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=25\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout() \n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=50\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=75\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/06wk-1.html#a.-transpose",
    "href": "posts/06wk-1.html#a.-transpose",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. transpose",
    "text": "A. transpose\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntsr.t()\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n\ntorch.einsum('ij-&gt;ji',tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])"
  },
  {
    "objectID": "posts/06wk-1.html#b.-행렬곱",
    "href": "posts/06wk-1.html#b.-행렬곱",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 행렬곱",
    "text": "B. 행렬곱\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1.shape\n\ntorch.Size([4, 3])\n\n\n\ntsr2.shape\n\ntorch.Size([3, 5])\n\n\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -&gt; ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])"
  },
  {
    "objectID": "posts/06wk-1.html#c.-이미지변환",
    "href": "posts/06wk-1.html#c.-이미지변환",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. 이미지변환",
    "text": "C. 이미지변환\n\nr = torch.zeros(16).reshape(4,4) + 1.0\ng = torch.zeros(16).reshape(4,4)\nb = torch.zeros(16).reshape(4,4)\nimg_plt = torch.stack([r,g,b],axis=-1) # matplotlib 를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \nimg_torch = torch.stack([r,g,b],axis=0).reshape(1,3,4,4) # torch를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \n\n\nimg_plt.shape, img_torch.shape\n\n(torch.Size([4, 4, 3]), torch.Size([1, 3, 4, 4]))\n\n\n\nplt.imshow(img_plt)\n\n\n\n\n\n\n\n\n만약에 img_torch를 matplotlib 으로 보고싶다면?\n\n# 잘못된코드\nplt.imshow(img_torch.reshape(4,4,3))\n\n\n\n\n\n\n\n\n\n# 올바른코드\nplt.imshow(torch.einsum('ocij -&gt; ijc',img_torch))"
  },
  {
    "objectID": "posts/06wk-1.html#a.-y-n3-float",
    "href": "posts/06wk-1.html#a.-y-n3-float",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. y: (n,3)-float",
    "text": "A. y: (n,3)-float\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y.argmax(axis=1)).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy.argmax(axis=1)).float().mean():.4f}')\n\ntrain: 0.9851\nval: 0.9898"
  },
  {
    "objectID": "posts/06wk-1.html#b.-y-n-int",
    "href": "posts/06wk-1.html#b.-y-n-int",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. y: (n,)-int",
    "text": "B. y: (n,)-int\n\ny = y.argmax(axis=-1)\nyy = yy.argmax(axis=-1)\ny,yy\n\n(tensor([0, 0, 0,  ..., 2, 2, 2]), tensor([0, 0, 0,  ..., 2, 2, 2]))\n\n\n\nprint(X.shape,'\\t',X.dtype)\nprint(y.shape,'\\t\\t',y.dtype)\nprint(XX.shape,'\\t',XX.dtype)\nprint(yy.shape,'\\t\\t',yy.dtype)\n\ntorch.Size([18623, 1, 28, 28])   torch.float32\ntorch.Size([18623])          torch.int64\ntorch.Size([3147, 1, 28, 28])    torch.float32\ntorch.Size([3147])       torch.int64\n\n\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}') # &lt;-- 여기수정\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}') # &lt;-- 여기수정\n\ntrain: 0.9836\nval: 0.9895"
  },
  {
    "objectID": "posts/06wk-1.html#a.-torch",
    "href": "posts/06wk-1.html#a.-torch",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. torch",
    "text": "A. torch\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\ntrain: 0.9077\nval: 0.8723"
  },
  {
    "objectID": "posts/06wk-1.html#b.-fastai",
    "href": "posts/06wk-1.html#b.-fastai",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. fastai",
    "text": "B. fastai\n\n# Step1: 데이터정리 (dls생성)\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=128) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100) \ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\n#optimizr = torch.optim.Adam(net.parameters())\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3: 적합 \nlrnr.fit(10)\n# Step4: 예측 및 평가 \n\nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.484642\n0.444805\n0.858300\n00:01\n\n\n1\n0.393360\n0.413498\n0.862200\n00:01\n\n\n2\n0.340997\n0.403366\n0.866100\n00:01\n\n\n3\n0.310863\n0.421401\n0.866300\n00:01\n\n\n4\n0.291870\n0.426586\n0.865400\n00:01\n\n\n5\n0.277852\n0.429622\n0.866500\n00:01\n\n\n6\n0.266723\n0.444076\n0.870700\n00:01\n\n\n7\n0.260530\n0.456487\n0.871100\n00:01\n\n\n8\n0.253032\n0.458816\n0.875000\n00:01\n\n\n9\n0.247392\n0.483315\n0.870800\n00:01\n\n\n\n\n\ntrain: 0.9124\nval: 0.8708"
  },
  {
    "objectID": "posts/06wk-1.html#a.-알렉스넷krizhevsky2012imagenet의-의미",
    "href": "posts/06wk-1.html#a.-알렉스넷krizhevsky2012imagenet의-의미",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. 알렉스넷(Krizhevsky, Sutskever, and Hinton 2012)의 의미",
    "text": "A. 알렉스넷(Krizhevsky, Sutskever, and Hinton 2012)의 의미\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. “Imagenet Classification with Deep Convolutional Neural Networks.” Advances in Neural Information Processing Systems 25.\n- 야사로 배우는 인공지능: https://brunch.co.kr/@hvnpoet/109"
  },
  {
    "objectID": "posts/06wk-1.html#b.-알렉스넷의-아키텍처-써보기",
    "href": "posts/06wk-1.html#b.-알렉스넷의-아키텍처-써보기",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 알렉스넷의 아키텍처 써보기",
    "text": "B. 알렉스넷의 아키텍처 써보기\n- 알렉스넷의 아키텍처:\n-ref: https://en.wikipedia.org/wiki/AlexNet#:~:text=AlexNet%20is%20the%20name%20of,at%20the%20University%20of%20Toronto.\n\n- 재미삼아 써보면..\n\nimg = torch.zeros(1,3*227*227).reshape(1,3,227,227)\nimg.shape\n\ntorch.Size([1, 3, 227, 227])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(9216,4096),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),\n    torch.nn.Linear(4096,4096),        \n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),    \n    torch.nn.Linear(4096,1000),\n)\n\n- 참고사항: torchvision.models.alexnet()을 이용하여 네크워크를 선언할 수도 있음.\n\ntorchvision.models.alexnet()\n\nAlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\n직접구현한 알렉스넷과 torchvision.models.alexnet()를 이용한 알렉스넷은 약간다름.\n그 이유는 파이토치에서는 원래 논문에서 구현된 알렉스넷이 아니라 이후 수정된 알렉스넷을 사용하기 때문임. 이 내용은 파이토치 공식홈페이지에서 아래와 같이 명시되어있음.\nAlexNet was originally introduced in the ImageNet Classification with Deep Convolutional Neural Networks paper. Our implementation is based instead on the “One weird trick” paper above.\nref: https://pytorch.org/vision/main/models/generated/torchvision.models.alexnet.html"
  },
  {
    "objectID": "posts/06wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "href": "posts/06wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. 알렉스넷으로 ImageNet 적합",
    "text": "C. 알렉스넷으로 ImageNet 적합\n\npass # 데이터가 너무 커서.. 코랩에서 못할것같아요"
  },
  {
    "objectID": "posts/06wk-1.html#a.-dls-만들자",
    "href": "posts/06wk-1.html#a.-dls-만들자",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. dls 만들자",
    "text": "A. dls 만들자\n- X,y를 얻자.\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.CIFAR)\npath.ls()\n\n\n\n\n\n\n    \n      \n      100.00% [168173568/168168549 00:49&lt;00:00]\n    \n    \n\n\n(#3) [Path('/root/.fastai/data/cifar10/train'),Path('/root/.fastai/data/cifar10/labels.txt'),Path('/root/.fastai/data/cifar10/test')]\n\n\n\nlabels = [str(l).split('/')[-1] for l in (path/'train').ls()]\nlabels\n\n['deer',\n 'airplane',\n 'ship',\n 'dog',\n 'automobile',\n 'truck',\n 'cat',\n 'frog',\n 'horse',\n 'bird']\n\n\n\nX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'train/{l}').ls()],axis=0).float()/255\nXX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'test/{l}').ls()],axis=0).float()/255\ny = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'train/{l}').ls()])\nyy = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'test/{l}').ls()])\n\n\nprint(X.shape,'\\t',X.dtype)\nprint(y.shape,'\\t\\t\\t',y.dtype)\nprint(XX.shape,'\\t',XX.dtype)\nprint(yy.shape,'\\t\\t\\t',yy.dtype)\n\ntorch.Size([50000, 3, 32, 32])   torch.float32\ntorch.Size([50000])              torch.int64\ntorch.Size([10000, 3, 32, 32])   torch.float32\ntorch.Size([10000])              torch.int64\n\n\n- 데이터를 시각화해보자.\n\nylabel = [l for l in labels for fname in (path/f'train/{l}').ls()]\ni = 30002\nplt.imshow(torch.einsum('cij-&gt;ijc',X[i]))\nplt.title(f'{ylabel[i]},{y[i]}')\n\nText(0.5, 1.0, 'cat,6')\n\n\n\n\n\n\n\n\n\n\n그림이 너무 어려운데?\n맞추기 힘들겠는데..\n\n- dls를 만들자.\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n\n- 아래와 같이 쉽게 만들수도있음…\n\n# dls = fastai.vision.data.ImageDataLoaders.from_folder(path,train='train',valid='test')\n# dls.show_batch()"
  },
  {
    "objectID": "posts/06wk-1.html#b.-수제네트워크로-학습",
    "href": "posts/06wk-1.html#b.-수제네트워크로-학습",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 수제네트워크로 학습",
    "text": "B. 수제네트워크로 학습\n- 시도1: 이게 좀 힘들어요 ㅎㅎ\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.429019\n2.301729\n0.121900\n00:00\n\n\n1\n2.867480\n2.297742\n0.121600\n00:00\n\n\n2\n2.798708\n2.350770\n0.099900\n00:00\n\n\n3\n2.378768\n2.292685\n0.116900\n00:00\n\n\n4\n2.436424\n2.289784\n0.126600\n00:00\n\n\n5\n2.972414\n2.361609\n0.122900\n00:01\n\n\n6\n2.285441\n5.540118\n0.100300\n00:00\n\n\n7\n2.908635\n2.349017\n0.131200\n00:00\n\n\n8\n3.101591\n3.855471\n0.103200\n00:00\n\n\n9\n2.130486\n17.543028\n0.100200\n00:00\n\n\n\n\n\ntrain: 0.1000\nval: 0.1002\n\n\n\n????\n\n- 시도2: 셔플!\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.629887\n1.535057\n0.463400\n00:00\n\n\n1\n1.438346\n1.392916\n0.512500\n00:00\n\n\n2\n1.355882\n1.374366\n0.518900\n00:00\n\n\n3\n1.289650\n1.298758\n0.542500\n00:01\n\n\n4\n1.256436\n1.278826\n0.555900\n00:00\n\n\n5\n1.225732\n1.244056\n0.563800\n00:00\n\n\n6\n1.204093\n1.234391\n0.563100\n00:00\n\n\n7\n1.179638\n1.228574\n0.569700\n00:00\n\n\n8\n1.163272\n1.187201\n0.585200\n00:00\n\n\n9\n1.146735\n1.199569\n0.578300\n00:00\n\n\n\n\n\ntrain: 0.6101\nval: 0.5783\n\n\n\n셔플의 차이가 이렇게 크다니??\n\n- 시도3: 복잡하게..\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,256,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(256,64,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(64,16,(5,5)),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(1600,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \n# 코랩사용시 아래는 주석처리할것 (이유: 코랩의 RAM이 충분하지 않음) valiation set의 accuracy는 fastai결과로 확인할것. \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.476197\n1.479258\n0.465500\n00:02\n\n\n1\n1.310572\n1.284226\n0.538200\n00:02\n\n\n2\n1.204503\n1.222977\n0.572300\n00:02\n\n\n3\n1.102717\n1.093513\n0.615500\n00:02\n\n\n4\n1.042015\n1.047397\n0.627400\n00:02\n\n\n5\n0.998049\n1.077097\n0.621600\n00:02\n\n\n6\n0.985487\n0.986339\n0.660600\n00:02\n\n\n7\n0.924648\n0.977845\n0.663900\n00:02\n\n\n8\n0.897980\n0.997572\n0.658000\n00:02\n\n\n9\n0.879995\n0.981113\n0.660500\n00:02\n\n\n\n\n\ntrain: 0.7026\nval: 0.6605"
  },
  {
    "objectID": "posts/06wk-1.html#c.-transferlearning으로-학습",
    "href": "posts/06wk-1.html#c.-transferlearning으로-학습",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. TransferLearning으로 학습",
    "text": "C. TransferLearning으로 학습\n- ResNet18을 다운로드\n\nnet = torchvision.models.resnet18()\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n- 마지막의 레이어만 수정\n\nnet.fc = torch.nn.Linear(512,10)\n\n- 학습해보자.\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=64,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet = torchvision.models.resnet18()\nnet.fc = torch.nn.Linear(512,10)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \n# 코랩사용시 아래는 주석처리할것 (이유: 코랩의 RAM이 충분하지 않음) valiation set의 accuracy는 fastai결과로 확인할것. \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}') # \nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.157889\n1.281547\n0.540200\n00:11\n\n\n1\n0.924410\n1.179057\n0.596200\n00:11\n\n\n2\n0.797667\n0.948804\n0.678700\n00:11\n\n\n3\n0.681159\n0.877607\n0.699700\n00:11\n\n\n4\n0.568150\n0.818889\n0.726400\n00:11\n\n\n5\n0.509804\n0.842927\n0.725800\n00:11\n\n\n6\n0.428966\n0.836546\n0.736100\n00:11\n\n\n7\n0.378433\n0.825805\n0.753200\n00:11\n\n\n8\n0.297282\n0.917828\n0.734000\n00:11\n\n\n9\n0.244396\n0.876090\n0.763200\n00:11\n\n\n\n\n\ntrain: 0.9523\nval: 0.7632\n\n\n\n\n\n\n\n\nCaution\n\n\n\n통계학과서버를 이용하시는 분들은 다른 학생들을 위하여 실습이 끝난이후 커널을 죽여주시기 바랍니다. 그렇지 않으면 GPU메모리 부족으로 다른학생들이 실습하기 어렵습니다.(무슨말인지 모르겠으면 저에게 물어보세요)"
  },
  {
    "objectID": "posts/15wk-2.html",
    "href": "posts/15wk-2.html",
    "title": "15wk-2: 기말고사",
    "section": "",
    "text": "import torch\nimport numpy as np\nimport matplotlib.pyplot as plt\n#--# 문제1\nimport pandas as pd\nimport sklearn.model_selection\n#--# 문제3\nimport gymnasium as gym\nimport IPython\nfrom matplotlib.animation import FuncAnimation\nimport collections\nimport random\n\n\n1. 추천시스템 – 30점\n\n!wget http://files.grouplens.org/datasets/movielens/ml-20m.zip\n!unzip ml-20m.zip\n\n--2024-06-16 15:03:12--  http://files.grouplens.org/datasets/movielens/ml-20m.zip\nResolving files.grouplens.org (files.grouplens.org)... 128.101.65.152\nConnecting to files.grouplens.org (files.grouplens.org)|128.101.65.152|:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 198702078 (189M) [application/zip]\nSaving to: ‘ml-20m.zip’\n\nml-20m.zip          100%[===================&gt;] 189.50M  2.83MB/s    in 65s     \n\n2024-06-16 15:04:17 (2.94 MB/s) - ‘ml-20m.zip’ saved [198702078/198702078]\n\nArchive:  ml-20m.zip\n   creating: ml-20m/\n  inflating: ml-20m/genome-scores.csv  \n  inflating: ml-20m/genome-tags.csv  \n  inflating: ml-20m/links.csv        \n  inflating: ml-20m/movies.csv       \n  inflating: ml-20m/ratings.csv      \n  inflating: ml-20m/README.txt       \n  inflating: ml-20m/tags.csv         \n\n\nMovieLens 20M 데이터셋은 GroupLens Research에서 제공하는 영화 평점 데이터셋으로, 영화 추천 시스템 연구에 널리 사용된다. 이 데이터셋은 약 2천만 개의 영화 평점과 메타데이터를 포함하고 있다. 주요 파일과 그 내용은 다음과 같다:\n1. ratings.csv:\n\nuserId: 사용자의 고유 ID\nmovieId: 영화의 고유 ID\nrating: 사용자가 부여한 평점 (1.0에서 5.0 사이의 값)\ntimestamp: 평점이 부여된 시간 (유닉스 타임스탬프 형식)\n\n2. movies.csv:\n\nmovieId: 영화의 고유 ID\ntitle: 영화 제목\ngenres: 영화 장르 (여러 개의 장르가 ’|’로 구분됨)\n\n3. tags.csv:\n\nuserId: 사용자의 고유 ID\nmovieId: 영화의 고유 ID\ntag: 사용자가 부여한 태그\ntimestamp: 태그가 부여된 시간 (유닉스 타임스탬프 형식)\n\n4. genome-scores.csv:\n\nmovieId: 영화의 고유 ID\ntagId: 태그의 고유 ID\nrelevance: 해당 태그가 영화에 얼마나 관련 있는지 나타내는 점수 (0.0에서 1.0 사이의 값)\n\n5. genome-tags.csv:\n\ntagId: 태그의 고유 ID\ntag: 태그의 이름\n\n6. links.csv:\n\nmovieId: 영화의 고유 ID\nimdbId: IMDB에서의 영화 ID\ntmdbId: TMDB에서의 영화 ID\n\n이중에서 1,2의 데이터만 사용하여 추천시스템을 설계하기로 하자.\n\ndf_ratings = pd.read_csv(\"ml-20m/ratings.csv\")\ndf_movies = pd.read_csv(\"ml-20m/movies.csv\")\ndf_train_all = pd.merge(df_ratings,df_movies)\nuserId_sampled = np.random.choice(df_train_all.userId.unique(),5000)\ndf_train = df_train_all.query(\"userId in @userId_sampled\").reset_index(drop=True)\ndf_train[\"userId\"] = df_train.userId.map({user:i for i,user in enumerate(set(df_train.userId))}) \ndf_train[\"movieId\"] = df_train.movieId.map({movie:i for i,movie in enumerate(set(df_train.movieId))}) \n\n평점정보와 영화정보를 결합하여 df_train을 만들었으며, 위의 코드를 간단히 설명하면 아래와 같다.\n1. df_ratings와 df_movies CSV 파일을 읽어 데이터프레임으로 만든다.\ndf_ratings = pd.read_csv(\"ml-20m/ratings.csv\")\ndf_movies = pd.read_csv(\"ml-20m/movies.csv\")\n2. 평점 데이터와 영화 데이터를 합쳐 하나의 데이터프레임 df_train_all을 만든다.\ndf_train_all = pd.merge(df_ratings, df_movies)\n3. 데이터가 너무 많아 5000명의 유저만 랜덤으로 샘플링한다.\nuserId_sampled = np.random.choice(df_train_all.userId.unique(), 5000)\n4. 샘플링된 5000명의 유저 데이터만 포함하는 새로운 데이터프레임 df_train을 만든다.\ndf_train = df_train_all.query(\"userId in @userId_sampled\").reset_index(drop=True)\n5. 유저 ID를 0부터 시작하는 인덱스로 재조정한다.\ndf_train[\"userId\"] = df_train.userId.map({user: i for i, user in enumerate(set(df_train.userId))})\n6. 영화 ID도 0부터 시작하는 인덱스로 재조정한다.\ndf_train[\"movieId\"] = df_train.movieId.map({movie: i for i, movie in enumerate(set(df_train.movieId))})\n\ndf_train\n\n\n\n\n\n\n\n\nuserId\nmovieId\nrating\ntimestamp\ntitle\ngenres\n\n\n\n\n0\n68\n1\n3.0\n1283448701\nJumanji (1995)\nAdventure|Children|Fantasy\n\n\n1\n256\n1\n3.5\n1105656188\nJumanji (1995)\nAdventure|Children|Fantasy\n\n\n2\n443\n1\n0.5\n1116425348\nJumanji (1995)\nAdventure|Children|Fantasy\n\n\n3\n656\n1\n2.5\n1144777605\nJumanji (1995)\nAdventure|Children|Fantasy\n\n\n4\n869\n1\n4.0\n1399577845\nJumanji (1995)\nAdventure|Children|Fantasy\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n697436\n4655\n11894\n3.0\n1322127039\nMy Flesh My Blood (Moja krew) (2009)\nDrama\n\n\n697437\n4655\n12269\n3.0\n1324485014\nLast Ferry, The (Ostatni prom) (1989)\nDrama\n\n\n697438\n4655\n12591\n0.5\n1326711212\nThis Time Around (2003)\nComedy|Romance\n\n\n697439\n482\n10155\n3.5\n1291904645\nMaster and Margaret, The (Il maestro e Margher...\nDrama|Fantasy|Romance\n\n\n697440\n2143\n8661\n3.5\n1424980356\nMedora (2013)\nDocumentary\n\n\n\n\n697441 rows × 6 columns\n\n\n\n(1) df_train을 아래와 같이 X_train, X_val, y_train, y_val로 나누고 적절한 추천시스템을 설계하고 학습하라. 학습결과를 validation loss로 검증하라.\n\nX1 = torch.tensor(df_train.userId)\nX2 = torch.tensor(df_train.movieId)\nX = torch.stack([X1,X2],axis=1)\ny = torch.tensor(df_train.rating).float().reshape(-1,1)\n\n\nX_train,X_val,y_train,y_val = sklearn.model_selection.train_test_split(X,y,test_size=0.1,random_state=42)\n\n힌트1: 11wk-1, 5-A (풀이2)를 참고하세요\n힌트2: 아래의 코드를 이용하라.\nclass Net(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        #--#\n        ????   \n    def forward(self,X):\n        ???\n        return yhat\n#---#\nnet = Net()\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\nds = torch.utils.data.TensorDataset(X_train,y_train)\ndl = torch.utils.data.DataLoader(ds,batch_size=64,shuffle=True)\n#--# \nfor epoc in range(5):\n    net.to(\"cuda:0\")\n    for xi,yi in dl:\n        xi = xi.to(\"cuda:0\")\n        yi = yi.to(\"cuda:0\")\n        # 1\n        yi_hat = net(xi) \n        # 2\n        loss = loss_fn(yi_hat,yi)\n        # 3 \n        loss.backward()\n        # 4 \n        optimizr.step()\n        optimizr.zero_grad()\n    net.to(\"cpu\")\n    print(f\"epoch: {epoc+1}\\t val_loss: {loss_fn(net(X_val).data,y_val):.4f}\")\n\n# 학습결과\n\nepoch: 1     val_loss: 0.8134\nepoch: 2     val_loss: 0.7696\nepoch: 3     val_loss: 0.7615\nepoch: 4     val_loss: 0.7541\nepoch: 5     val_loss: 0.7517\n\n\n\n# 시각화 \nplt.plot(y_val,net(X_val).data,'.',alpha=0.002)\n\n\n\n\n\n\n\n\n\n전체적으로 우상향 \\(\\to\\) 그럭저럭 잘맞춤\n\n(2) 아래는 유저 2265에 대한 정보이다.\n\ndf_train.query(\"userId == 2265\") # 스릴러 좋아하는듯\n\n\n\n\n\n\n\n\nuserId\nmovieId\nrating\ntimestamp\ntitle\ngenres\n\n\n\n\n5922\n2265\n111\n4.0\n868103611\nRumble in the Bronx (Hont faan kui) (1995)\nAction|Adventure|Comedy|Crime\n\n\n12110\n2265\n295\n5.0\n868103784\nPulp Fiction (1994)\nComedy|Crime|Drama|Thriller\n\n\n119019\n2265\n854\n5.0\n868103861\nGodfather, The (1972)\nCrime|Drama\n\n\n162426\n2265\n5\n5.0\n868103615\nHeat (1995)\nAction|Crime|Thriller\n\n\n173543\n2265\n430\n5.0\n868103965\nCarlito's Way (1993)\nCrime|Drama\n\n\n178248\n2265\n730\n3.0\n868103615\nRock, The (1996)\nAction|Adventure|Thriller\n\n\n195870\n2265\n607\n4.0\n868103615\nFargo (1996)\nComedy|Crime|Drama|Thriller\n\n\n222528\n2265\n1383\n4.0\n868104228\nMars Attacks! (1996)\nAction|Comedy|Sci-Fi\n\n\n224116\n2265\n1458\n5.0\n868103861\nDonnie Brasco (1997)\nCrime|Drama\n\n\n225606\n2265\n1561\n4.0\n868103699\nFace/Off (1997)\nAction|Crime|Drama|Thriller\n\n\n288798\n2265\n1267\n5.0\n868103818\nAkira (1988)\nAction|Adventure|Animation|Sci-Fi\n\n\n340941\n2265\n94\n3.0\n868103425\nBroken Arrow (1996)\nAction|Adventure|Thriller\n\n\n393518\n2265\n774\n5.0\n868103861\nTrainspotting (1996)\nComedy|Crime|Drama\n\n\n407498\n2265\n1540\n4.0\n868104432\nCon Air (1997)\nAction|Adventure|Thriller\n\n\n417165\n2265\n1055\n5.0\n868103985\nWilliam Shakespeare's Romeo + Juliet (1996)\nDrama|Romance\n\n\n421387\n2265\n17\n4.0\n868104228\nFour Rooms (1995)\nComedy\n\n\n425438\n2265\n1057\n4.0\n868104200\nSleepers (1996)\nThriller\n\n\n427183\n2265\n1399\n4.0\n868103699\nScream (1996)\nComedy|Horror|Mystery|Thriller\n\n\n520180\n2265\n795\n4.0\n868103888\nFrighteners, The (1996)\nComedy|Horror|Thriller\n\n\n555155\n2265\n1421\n4.0\n868103699\nFirst Strike (Police Story 4: First Strike) (G...\nAction|Adventure|Comedy|Thriller\n\n\n\n\n\n\n\n유저 2265는 스릴러를 좋아하는 것 같다. (그리고 전체적으로 평점도 잘 주는 편이다) 영화 {49: Usual Suspects, The (1995)} 는 스리럴중에서도 인기가 있는 영화인데, 유저 2265는 아직 이 영화를 시청하지 않은듯 보인다.\n\ndf_train.query(\"movieId == 49\")\n\n\n\n\n\n\n\n\nuserId\nmovieId\nrating\ntimestamp\ntitle\ngenres\n\n\n\n\n4090\n45\n49\n4.0\n1197046172\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n4091\n52\n49\n5.0\n1002381372\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n4092\n69\n49\n4.0\n847049601\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n4093\n74\n49\n4.0\n848457677\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n4094\n97\n49\n5.0\n838483872\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n...\n...\n...\n...\n...\n...\n...\n\n\n5762\n1289\n49\n5.0\n1232821197\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n5763\n1295\n49\n5.0\n844568128\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n5764\n1300\n49\n4.5\n1239957730\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n5765\n1302\n49\n4.0\n1112646316\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n5766\n1314\n49\n4.0\n1194300489\nUsual Suspects, The (1995)\nCrime|Mystery|Thriller\n\n\n\n\n1677 rows × 6 columns\n\n\n\n유저 2265에게 이 영화를 추천하면 어떠한 평점을 줄까? (1)에서 학습한 네트워크로 예측하여 보라.\n\n\n2. hello – 30점\n아래와 같이 hello가 반복되는 자료가 있다고 하자.\n\ntxt = list('hello')*100\ntxt[:10]\n\n['h', 'e', 'l', 'l', 'o', 'h', 'e', 'l', 'l', 'o']\n\n\n(1) torch.nn.RNN()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라. – 12wk-2, 3-C 참고\n(2) torch.nn.RNNCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라. – 12wk-1, hw 참고\n(3) (2)의 결과와 동일한 적합값을 출력하는 신경망을 직접설계한뒤 학습시켜라. (초기값을 적절하게 설정할 것)\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = ????\n        self.h2h = ????\n        self.tanh = ????\n    def forward(self,??,??):\n        ht = ????\n        return ht\n위의 클래스의 ????를 체워 (2)의 결과와 동일한 적합값이 나오도록 하라. – 12wk-1, hw 참고\n\nclass를 이용하지 않으면 점수없음.\ntorch.nn.RNN(), torch.nn.RNNCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.RNN(), torch.nn.RNNCell()을 코드에 포함시키는 것이 가능)\n\n(4) torch.nn.LSTM()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라. – 13wk-1, 4-C 참고\n(5) torch.nn.LSTMCell()을 이용하여 다음문자를 예측하는 신경망을 설계하고 학습하라. – 13wk-1, 4-A 참고\n(6) (5)’의 결과와 동일한 적합값을 출력하는 신경망을 직접설계한 뒤 학습시켜라. (초기값을 적절하게 설정할 것) – 13wk-1, 4-B 참고\n\nclass를 이용하지 않아도 무방함.\ntorch.nn.LSTM(), torch.nn.LSTMCell() 을 이용한 네트워크를 학습시킬시 점수 없음. (초기값을 셋팅하는 용도로는 torch.nn.LSTM(), torch.nn.LSTMCell()을 코드에 포함시키는 것은 가능)\n\n\n이 문제는 전체적으로 https://guebin.github.io/DL2022/posts/2022-11-29-13wk-2-final.html 의 1번과 비슷하니 해당문제 정답을 참고하셔도 됩니다. (근데 뭔가 제가 다시보니까 데이터정리하는 방식등이 미묘하게 좀 바껴있어서요, 올해 강의노트에서 보고 베끼는게 좋을것 같습니다. 이건 뭐 알아서하세요)\n\n\n\n3. FrozenLake\nref: https://www.gymlibrary.dev/environments/toy_text/frozen_lake/\n아래는 OpenAI Gym 라이브러리에서 제공하는 환경 Frozen Lake를 구체화하여 변수 env에 저장하는 코드이다.\n\nenv = gym.make('FrozenLake-v1', desc=None, map_name=\"4x4\", is_slippery=False, render_mode='rgb_array')\n\nFrozen Lake 환경은 강화학습(RL) 실험을 위한 간단한 시뮬레이션 환경으로 에이전트가 얼어붙은 호수 위를 안전하게 건너 목표 지점에 도달하는 것이 목표이다. 주요 특징은 다음과 같다.\n1. 환경 구성:\n\n격자형(grid) 환경으로 이루어져 있으며, 각 격자는 4x4 또는 8x8의 형태를 가질 수 있다. (문제에서는 4x4)\n격자는 시작 지점(Start), 목표 지점(Goal), 얼음(Ice), 그리고 구멍(Hole)으로 구성된다.\n에이전트는 시작 지점에서 목표 지점까지 이동해야 한다.\n\n2. 에이전트의 동작:\n\n에이전트는 상, 하, 좌, 우로 이동할 수 있다.\n얼음 위에서는 자유롭게 이동할 수 있지만, 구멍에 빠지면 에피소드가 종료된다.\n\n3. 보상 체계:\n\n에이전트가 목표 지점에 도달하면 +1의 보상을 받는다.\n그 외에는 보상이 없다(0 보상).\n구멍에 빠지거나 목표 지점에 도달하지 못하면 보상은 없다.\n\n4. 목표:\n\n에이전트는 강화학습 알고리즘을 사용하여 최적의 경로를 학습하고, 가능한 한 구멍에 빠지지 않고 목표 지점에 도달하는 것이다.\n\n아래는 show 함수이며, 이는 env의 현재상태를 렌더링해주는 역할을 한다.\n\ndef show(ims):\n    fig = plt.Figure()\n    ax = fig.subplots()\n    def update(i):\n        ax.imshow(ims[i])\n    ani = FuncAnimation(fig,update,frames=len(ims))\n    display(IPython.display.HTML(ani.to_jshtml()))\n\nshow() 함수의 사용방법은 아래와 같다.\n\nenv.reset()\nplt.imshow(env.render())\n\n\n\n\n\n\n\n\n적당한 위의 환경에 대응하는 Agent를 설계하고 q_net를 이용하여 올바른 행동을 학습하라. 아래는 학습된 결과의 예시이다.\n\n# 학습과정 -- 제가 설정한 게임 클리어 판단 조건은 최근 100번의 score가 0.9 이상일경우입니다. \n\n에피소드:500    경험(t):3048  점수(에피소드):0.08   게임시간(에피소드):6.10 돌발행동(에피소드):0.61\n에피소드:1000   경험(t):5824  점수(에피소드):0.29   게임시간(에피소드):5.55 돌발행동(에피소드):0.37\n에피소드:1500   경험(t):8768  점수(에피소드):0.54   게임시간(에피소드):5.89 돌발행동(에피소드):0.22\n에피소드:2000   경험(t):11134 점수(에피소드):0.41   게임시간(에피소드):4.73 돌발행동(에피소드):0.14\n에피소드:2500   경험(t):14067 점수(에피소드):0.78   게임시간(에피소드):5.87 돌발행동(에피소드):0.08\n---game cleared in 2832 episodes! ---\n\n\n\nshow(imgs)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n힌트1: 14wk-1,2 의 코드가 아닌 15wk-1 의 코드를 참고하세요\n힌트2: 아래의 에이전트를 설계에 이용하라.\n\nclass AgentRandom: \n    def __init__(self,env):\n        #--# define spaces \n        self.action_space = env.action_space\n        self.state_space = env.observation_space\n        #--# replay buffer \n        self.current_state =  None   \n        self.action = None           \n        self.reward = None           \n        self.next_state =  None      \n        self.terminated = None       \n        #-#\n        self.buffer_size = 50000\n        self.current_states = collections.deque(maxlen=self.buffer_size)\n        self.actions = collections.deque(maxlen=self.buffer_size)\n        self.rewards = collections.deque(maxlen=self.buffer_size)\n        self.next_states = collections.deque(maxlen=self.buffer_size)\n        self.terminations = collections.deque(maxlen=self.buffer_size)\n        #--# other information \n        self.n_episodes = 0         \n        self.n_experiences = 0\n        self.playtimes = [] \n        self.score = 0                \n        self.scores = []\n    def act(self):\n        self.action = self.action_space.sample()\n    def learn(self):\n        pass \n    def save_experience(self):\n        self.current_states.append(torch.tensor(self.current_state))\n        self.actions.append(torch.tensor(self.action))\n        self.rewards.append(torch.tensor(self.reward).float())\n        self.next_states.append(torch.tensor(self.next_state))\n        self.terminations.append(torch.tensor(self.terminated))           \n        #--#\n        self.n_experiences = self.n_experiences + 1 \n        self.score = self.score + self.reward\n\n힌트3: q_net의 첫 레이어는 torch.nn.Embedding()을 이용하라.\n\n상태공간(state space)이 0~15일텐데, 상태1 x 2 = 상태2, 상태3 + 상태2 = 상태1 와 같은 관계가 성립한다고 보기 어려우므로 상태공간은 범주형변수로 봐야겠죠?\n\n\n\n4. O/X – 10점\n다음을 읽고 참 거짓을 판단하라.\n(1) Dropout Layer를 추가하면 layer의 추가로 인해 모형이 더 복잡해지며 그 결과 모형이 과적합될 수 있다."
  },
  {
    "objectID": "posts/01wk-2.html#a.-모형소개",
    "href": "posts/01wk-2.html#a.-모형소개",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 모형소개",
    "text": "A. 모형소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "href": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 회귀모형에서 데이터 생성",
    "text": "B. 회귀모형에서 데이터 생성\n\ntorch.manual_seed(43052)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#a.-손실함수",
    "href": "posts/01wk-2.html#a.-손실함수",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 손실함수",
    "text": "A. 손실함수\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (단계2에서 할일은 아님)\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법"
  },
  {
    "objectID": "posts/01wk-2.html#b.-경사하강법",
    "href": "posts/01wk-2.html#b.-경사하강법",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 경사하강법",
    "text": "B. 경사하강법\n- 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(w \\leftarrow w - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 아이디어 (2차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n- 경사하강법 = loss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다."
  },
  {
    "objectID": "posts/13wk-1.html#a.-torch.nn.lstmcell",
    "href": "posts/13wk-1.html#a.-torch.nn.lstmcell",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "A. torch.nn.LSTMCell",
    "text": "A. torch.nn.LSTMCell\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1) \n#---#\nL = len(X)\nfor epoc in range(1):\n    # 1~2 \n    loss = 0 \n    ht = torch.zeros(2)\n    ct = torch.zeros(2)\n    for t in range(L):\n        Xt,yt = X[t],y[t]\n        ht,ct = lstmcell(Xt,(ht,ct))\n        netout_t = cook(ht)\n        loss = loss + loss_fn(netout_t,yt) \n    loss = loss/L\n    # 3\n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([0.0533, 0.2075], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([0.1218, 0.5590], grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/13wk-1.html#b.-직접구현",
    "href": "posts/13wk-1.html#b.-직접구현",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "B. 직접구현",
    "text": "B. 직접구현\n\nt=0 \\(\\to\\) t=1\n- lstmcell을 이용하여 \\(t=0 \\to t=1\\)을 구현해보자. (결과비교용)\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1) \n#---#\nL = len(X)\nfor epoc in range(1):\n    # 1~2 \n    loss = 0 \n    ht = torch.zeros(2)\n    ct = torch.zeros(2)\n    for t in range(1):\n        Xt,yt = X[t],y[t]\n        ht,ct = lstmcell(Xt,(ht,ct))\n        netout_t = cook(ht)\n        loss = loss + loss_fn(netout_t,yt) \n    loss = loss/L\n    # 3\n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([0.1067, 0.1069], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([0.1734, 0.2688], grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n\n이런결과를 어떻게 만드는걸까?\nhttps://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n\n- 직접계산 (\\({\\boldsymbol i}_t, {\\boldsymbol f}_t, {\\boldsymbol g}_t, {\\boldsymbol o}_t\\))\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\n\n\nWih = lstmcell.weight_ih.T\nWih02 = Wih[:,0:2]\nWih24 = Wih[:,2:4]\nWih46 = Wih[:,4:6]\nWih68 = Wih[:,6:8]\n#--#\nWhh = lstmcell.weight_hh.T\nWhh02 = Whh[:,0:2]\nWhh24 = Whh[:,2:4]\nWhh46 = Whh[:,4:6]\nWhh68 = Whh[:,6:8]\n#--#\nbih02 = lstmcell.bias_ih[0:2]\nbih24 = lstmcell.bias_ih[2:4]\nbih46 = lstmcell.bias_ih[4:6]\nbih68 = lstmcell.bias_ih[6:8]\n#--#\nbhh02 = lstmcell.bias_hh[0:2]\nbhh24 = lstmcell.bias_hh[2:4]\nbhh46 = lstmcell.bias_hh[4:6]\nbhh68 = lstmcell.bias_hh[6:8]\n\n\nht = torch.zeros(2)\nct = torch.zeros(2)\n#--#\nit = sig(Xt@Wih02 + bih02 + ht@Whh02 + bhh02)\nft = sig(Xt@Wih24 + bih24 + ht@Whh24 + bhh24)\ngt = tanh(Xt@Wih46 + bih46 + ht@Whh46 + bhh46)\not = sig(Xt@Wih68 + bih68 + ht@Whh68 + bhh68)\n\n\nit,ft,gt,ot\n\n(tensor([0.3081, 0.5949], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([0.5065, 0.4264], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([0.5629, 0.4518], grad_fn=&lt;TanhBackward0&gt;),\n tensor([0.6216, 0.4072], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n그런데 아래와 같이 계산할수도 있음.\n\nifgo = Xt @ lstmcell.weight_ih.T +  lstmcell.bias_ih +\\\nht @ lstmcell.weight_hh.T +  lstmcell.bias_hh\n\n\nprint(f\"it = {sig(ifgo[0:2])}\")\nprint(f\"ft = {sig(ifgo[2:4])}\")\nprint(f\"gt = {tanh(ifgo[4:6])}\")\nprint(f\"ot = {sig(ifgo[6:8])}\")\n\nit = tensor([0.3081, 0.5949], grad_fn=&lt;SigmoidBackward0&gt;)\nft = tensor([0.5065, 0.4264], grad_fn=&lt;SigmoidBackward0&gt;)\ngt = tensor([0.5629, 0.4518], grad_fn=&lt;TanhBackward0&gt;)\not = tensor([0.6216, 0.4072], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 직접계산 (\\({\\boldsymbol c}_t, {\\boldsymbol h}_t\\))\n\nct = it*gt + ft*ct \nht = ot*tanh(ct)\n\n\nht,ct\n\n(tensor([0.1067, 0.1069], grad_fn=&lt;MulBackward0&gt;),\n tensor([0.1734, 0.2688], grad_fn=&lt;AddBackward0&gt;))\n\n\n\n\n# t=0 \\(\\to\\) t=L\n- lstmcell을 이용하여 구현해보자. (결과비교용)\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1) \n#---#\nL = len(X)\nfor epoc in range(1):\n    # 1~2 \n    loss = 0 \n    ht = torch.zeros(2)\n    ct = torch.zeros(2)\n    for t in range(L):\n        Xt,yt = X[t],y[t]\n        ht,ct = lstmcell(Xt,(ht,ct))\n        netout_t = cook(ht)\n        loss = loss + loss_fn(netout_t,yt) \n    loss = loss/L\n    # 3\n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([0.0533, 0.2075], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([0.1218, 0.5590], grad_fn=&lt;SqueezeBackward1&gt;))\n\n\n- 직접구현\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1) \n#---#\nL = len(X)\nfor epoc in range(1):\n    # 1~2 \n    loss = 0 \n    ht = torch.zeros(2)\n    ct = torch.zeros(2)\n    for t in range(L):\n        Xt,yt = X[t],y[t]\n        ifgo = Xt @ lstmcell.weight_ih.T +  lstmcell.bias_ih +\\\n                ht @ lstmcell.weight_hh.T +  lstmcell.bias_hh\n        it,ft,gt,ot = sig(ifgo[0:2]),sig(ifgo[2:4]),tanh(ifgo[4:6]),sig(ifgo[6:8])\n        ct = it*gt + ft*ct\n        ht = ot*tanh(ct)\n        netout_t = cook(ht)\n        loss = loss + loss_fn(netout_t,yt) \n    loss = loss/L\n    # 3\n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nht,ct\n\n(tensor([0.0533, 0.2075], grad_fn=&lt;MulBackward0&gt;),\n tensor([0.1218, 0.5590], grad_fn=&lt;AddBackward0&gt;))"
  },
  {
    "objectID": "posts/13wk-1.html#c.-torch.nn.lstm",
    "href": "posts/13wk-1.html#c.-torch.nn.lstm",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "C. torch.nn.LSTM",
    "text": "C. torch.nn.LSTM\n\ntorch.manual_seed(43052)\nlstmcell = torch.nn.LSTMCell(4,2) # 숙성담당\ncook = torch.nn.Linear(2,4)\nlstm = torch.nn.LSTM(4,2) # &lt;-- 이거로 학습\nlstm.weight_ih_l0.data = lstmcell.weight_ih.data\nlstm.weight_hh_l0.data = lstmcell.weight_hh.data\nlstm.bias_ih_l0.data = lstmcell.bias_ih.data\nlstm.bias_hh_l0.data = lstmcell.bias_hh.data\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(lstm.parameters())+list(cook.parameters()),lr=0.1) \n#---#\nL = len(X)\nWater = torch.zeros(1,2)\nfor epoc in range(1):\n    # 1 \n    h,(hL,cL) = lstm(X,(Water,Water))\n    netout = cook(h)\n    # 2 \n    loss = loss_fn(netout,y)\n    # 3\n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nhL,cL\n\n(tensor([[0.0533, 0.2075]], grad_fn=&lt;SqueezeBackward1&gt;),\n tensor([[0.1218, 0.5590]], grad_fn=&lt;SqueezeBackward1&gt;))"
  },
  {
    "objectID": "posts/13wk-1.html#a.-적합-및-시각화",
    "href": "posts/13wk-1.html#a.-적합-및-시각화",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "A. 적합 및 시각화",
    "text": "A. 적합 및 시각화\n- 적합\n\ntorch.manual_seed(43052)\nlstm = torch.nn.LSTM(4,2)\ncook = torch.nn.Linear(2,4)\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(lstm.parameters())+ list(cook.parameters()),lr=0.1)\n#--#\nWater = torch.zeros(1,2) \nfor epoc in range(200): \n    ## step1 \n    h, (hL,cL) = lstm(X,(Water,Water))\n    netout = cook(h)\n    ## step2\n    loss = loss_fn(netout,y) \n    ## step3\n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n- 시각화\n\nL = len(X)\ni = input_gate = torch.zeros(L,2)\nf = forget_gate = torch.zeros(L,2)\ng = gihhen_state = torch.zeros(L,2)\no = output_gate = torch.zeros(L,2)\nc = cell_state = torch.zeros(L,2)\nh = hidden_state = torch.zeros(L,2) \n#--#\nwater = torch.zeros(2)\nifgo = X[0] @ lstm.weight_ih_l0.T + lstm.bias_ih_l0 +\\\n        water @ lstm.weight_hh_l0.T + lstm.bias_hh_l0 \n# 위에서 water는 h0에 대응\ni[0] = sig(ifgo[0:2])\nf[0] = sig(ifgo[2:4])\ng[0] = tanh(ifgo[4:6])\no[0] = sig(ifgo[6:8])\nc[0] = f[0] * water + i[0] * g[0] # water는 c0에 대응 \nh[0] = o[0] * tanh(c[0])\n#--#\nfor t in range(1,L): \n    ## 1: calculate ifgo \n    ifgo = X[t] @ lstm.weight_ih_l0.T + lstm.bias_ih_l0 +\\\n            h[t-1] @ lstm.weight_hh_l0.T +  lstm.bias_hh_l0 \n    ## 2: decompose ifgo \n    i[t] = sig(ifgo[0:2])\n    f[t] = sig(ifgo[2:4])\n    g[t] = tanh(ifgo[4:6])\n    o[t] = sig(ifgo[6:8])\n    ## 3: calculate ht,ct \n    c[t] = f[t] * c[t-1] + i[t] * g[t]\n    h[t] = o[t] * tanh(c[t])\n\n\nmat = torch.concat([g,h,soft(netout)],axis=1)[:8].data\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1);\nplt.axvline(x=3.5,color=\"lime\")\nplt.xticks(\n    ticks=range(mat.shape[-1]),\n    labels=[r\"$g_0$\",r\"$g_1$\",r\"$h_0$\",r\"$h_1$\",\n            r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_C$\"]\n)\nplt.colorbar()"
  },
  {
    "objectID": "posts/13wk-1.html#b.-시각화1-boldsymbol-g_t-boldsymbol-c_t-1-to-boldsymbol-c_t",
    "href": "posts/13wk-1.html#b.-시각화1-boldsymbol-g_t-boldsymbol-c_t-1-to-boldsymbol-c_t",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "B. 시각화1: \\(({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}) \\to {\\boldsymbol c}_{t}\\)",
    "text": "B. 시각화1: \\(({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}) \\to {\\boldsymbol c}_{t}\\)\n\nmat1 = torch.concat([g[1:9],i[1:9],g[1:9]*i[1:9]],axis=1).data\nmat2 = torch.concat([c[:8],f[1:9],c[:8]*f[1:9]],axis=1).data\nmat3 = torch.concat([g[1:9]*i[1:9],c[:8]*f[1:9],c[1:9]],axis=1).data\n\n\nc[:8].min(),c[:8].max() \n\n(tensor(-1.0900, grad_fn=&lt;MinBackward1&gt;),\n tensor(0.9979, grad_fn=&lt;MaxBackward1&gt;))\n\n\n\n\\({\\boldsymbol c}_t\\)의 경우 원래 출력값이 -1, 1 사이라는 보장은 없으나, 이 예제의 경우에는 거의 -1, 1 사이임.\nmatshow로 시각화할때 vmin=-1, vmax=1로 설정해도 \\({\\boldsymbol c}_t\\)를 표현함에 부족함이 없을듯\n\n\nfig,ax = plt.subplots(1,3,figsize=(10,10))\nax[0].matshow(mat1,cmap='bwr',vmin=-1,vmax=1);\nax[0].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\nax[0].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\nax[0].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf g}_t$',r'${\\bf i}_t$',r'${\\bf g}_t \\odot {\\bf i}_t$']);\nax[1].matshow(mat2,cmap='bwr',vmin=-1,vmax=1);\nax[1].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\nax[1].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\nax[1].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf c}_{t-1}$',r'${\\bf f}_t$',r'${\\bf c}_{t-1} \\odot {\\bf f}_t$']);\nax[2].matshow(mat3,cmap='bwr',vmin=-1,vmax=1);\nax[2].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\nax[2].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\nax[2].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf g}_t \\odot {\\bf i}_t$',r'${\\bf c}_{t-1} \\odot {\\bf f}_t$',r'${\\bf c}_t$']);\nfig.tight_layout()\n\n\n\n\n\n\n\n\n- \\({\\boldsymbol g}_t\\) 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!)\n\n\\(\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})\\)\n\n- \\({\\boldsymbol c}_t\\) 특징: \\({\\boldsymbol g}_t\\)와 매우 비슷하지만 약간 다른값을 가진다. 그래서 \\({\\boldsymbol g}_t\\)와는 달리 -1,1 이외의 값도 종종 등장.\n\n\\({\\boldsymbol c}_t\\)의 값은 이론상 제한이 없음. (꼭 -1,1 사이에 있지 않음)"
  },
  {
    "objectID": "posts/13wk-1.html#c.-시각화2-boldsymbol-g_t-to-boldsymbol-h_t",
    "href": "posts/13wk-1.html#c.-시각화2-boldsymbol-g_t-to-boldsymbol-h_t",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "C. 시각화2: \\({\\boldsymbol g}_t \\to {\\boldsymbol h}_{t}\\)",
    "text": "C. 시각화2: \\({\\boldsymbol g}_t \\to {\\boldsymbol h}_{t}\\)\n\nmat = torch.concat([g[:8],tanh(c[:8]),o[:8],h[:8]],axis=1).data\n\n\nplt.matshow(mat.data,cmap='bwr',vmin=-1,vmax=1)\nplt.xticks([0.5,2.5,4.5,6.5],[r'${\\bf g}_t$',r'$tanh({\\bf c}_t)$',r'${\\bf o}_t$',r'${\\bf h}_t$']);\nplt.axvline(x=1.5,color=\"lime\",linewidth=3)\nplt.axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\nplt.axvline(x=5.5,linestyle=\"dashed\",color=\"lime\")\nplt.axvline(x=7.5,color=\"lime\",linewidth=3)\n\n\n\n\n\n\n\n\n- \\({\\boldsymbol h}_t\\) 특징: (1) \\({\\boldsymbol c}_t\\)에서 원하는 것만 선택적으로 특징으로 삼은 느낌. (2) \\(c_t\\)보다 훨씬 값을 다양하게 가진다. (\\(\\odot\\) 의 효과 )"
  },
  {
    "objectID": "posts/13wk-1.html#d.-lstm의-알고리즘-리뷰-i-수식위주",
    "href": "posts/13wk-1.html#d.-lstm의-알고리즘-리뷰-i-수식위주",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "D. LSTM의 알고리즘 리뷰 I (수식위주)",
    "text": "D. LSTM의 알고리즘 리뷰 I (수식위주)\n(step1) calculate \\({\\tt ifgo}\\)\n\\({\\tt ifgo} = {\\boldsymbol x}_t \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1} \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias\\)\n\\(=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias\\)\n참고: 위의 수식은 아래코드에 해당하는 부분\nifgo = Xt @ lstm_cell.weight_ih.T +\\\n       ht @ lstm_cell.weight_hh.T +\\\n       lstm_cell.bias_ih + lstm_cell.bias_hh\n(step2) decompose \\({\\tt ifgo}\\) and get \\({\\boldsymbol i}_t\\), \\({\\boldsymbol f}_t\\), \\({\\boldsymbol g}_t\\), \\({\\boldsymbol o}_t\\)\n\\({\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )\\)\n\\({\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )\\)\n\\({\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )\\)\n\\({\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )\\)\n(step3) calculate \\({\\boldsymbol c}_t\\) and \\({\\boldsymbol h}_t\\)\n\\({\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}\\)\n\\({\\boldsymbol h}_t = {\\boldsymbol o}_t \\odot \\tanh({\\boldsymbol c}_t)\\)"
  },
  {
    "objectID": "posts/13wk-1.html#e.-lstm의-알고리즘-리뷰-ii-느낌위주",
    "href": "posts/13wk-1.html#e.-lstm의-알고리즘-리뷰-ii-느낌위주",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "E. LSTM의 알고리즘 리뷰 II (느낌위주)",
    "text": "E. LSTM의 알고리즘 리뷰 II (느낌위주)\n\n이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다..\n\n- 느낌: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 단계를 나누어 숙성하는 느낌이다.\n\nRNN: \\({\\boldsymbol x}_t \\overset{{\\boldsymbol h}_{t-1}}{\\longrightarrow} {\\boldsymbol h}_t\\)\nLSTM: \\({\\boldsymbol x}_t \\overset{{\\boldsymbol h}_{t-1}}{\\longrightarrow} {\\boldsymbol g}_t \\overset{{\\boldsymbol c}_{t-1}}{\\longrightarrow} \\Big({\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\Big)\\)\n\n- \\({\\boldsymbol g}_t\\)에 대하여\n\n과거와 현재의 결합 (선형변환): \\({\\boldsymbol x}_t\\)와 \\({\\boldsymbol h}_{t-1}\\)를 \\({\\bf W}_{ig}, {\\bf W}_{hg}\\)를 이용해 선형결합\n숙성(비선형변환): \\(\\tanh\\)\n느낌: RNN에서 간장을 만들던 그 수식에서 \\(h_t\\)를 \\(g_t\\)로 바꾼것 그래서 RNN의 간장과 비슷하다고 생각하면 된다.\n노트: RNN의 간장은 한계를 가지고 있는데 그 한계를 극복하기 위해 만든 것이 \\({\\boldsymbol c}_t\\)\n\n- \\({\\boldsymbol c}_t\\)에 대하여\n\n과거와 현재의 결합 (선형변환): \\({\\boldsymbol g}_{t}\\)와 \\({\\boldsymbol c}_{t-1}\\)를 요소별로 선택하고 더하는 과정\n숙성 (비선형변환): 없음.\n느낌: 과거와 현재의 정보중 유리한것만 기억하여 선택적으로 결합함. 이때 결합방식에 대한 노하우는 \\({\\tt input-gate}\\), \\({\\tt forget-gate}\\) 에 있으며 그러한 결합의 결과가 \\({\\boldsymbol c}_t\\)에 있음. 이 \\({\\boldsymbol c}_t\\)에 대한 정보는 그대로 “냉동보관(?)”되어 다음세대로 내려옴.\n비고: \\({\\boldsymbol c}_t\\)는 사실상 LSTM 알고리즘의 꽃이라 할 수 있음. LSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함. LSTM이 장기기억을 잘 활용하는 비법은 바로 \\({\\boldsymbol c}_t\\)에 있다.\n\n- \\({\\boldsymbol h}_t\\)에 대하여\n\n과거와 현재의 결합 (선형변환): 없음\n숙성 (비선형변환): \\(\\tanh({\\boldsymbol c}_t)\\)를 요소별로 선택하여 숙성\n\n\nRNN은 기억할 과거정보가 \\({\\boldsymbol h}_{t-1}\\) 하나이지만 LSTM은 \\({\\boldsymbol c}_{t-1}\\), \\({\\boldsymbol h}_{t-1}\\) 2개이다."
  },
  {
    "objectID": "posts/13wk-1.html#f.-lstm이-강한이유",
    "href": "posts/13wk-1.html#f.-lstm이-강한이유",
    "title": "13wk-1: 순환신경망 (4) – LSTM 계산과정 재현, LSTM은 왜 강한가?",
    "section": "F. LSTM이 강한이유",
    "text": "F. LSTM이 강한이유\n- 답변1: LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 장기기억을 위한 역할을 하기 때문.\n\n비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (게이트는 꼭3개이어야 하는지?)\n\n- 답변2: 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다.\n\n실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n그 이유: RNN은 \\({\\boldsymbol h}_t\\)의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 \\({\\boldsymbol h}_t\\)이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음.\n왜 LSTM의 \\({\\boldsymbol h}_t\\)은 -1,1 이외의 값을 쉽게 가질 수 있는가? \\(\\odot\\) 때문에.. 즉 게이트때문에.."
  },
  {
    "objectID": "posts/02wk-2.html#a.-data",
    "href": "posts/02wk-2.html#a.-data",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "A. Data",
    "text": "A. Data\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "href": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "B. 파이토치를 이용한 학습",
    "text": "B. 파이토치를 이용한 학습\n- 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n- 결과 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step2의-수정",
    "href": "posts/02wk-2.html#c.-step2의-수정",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "C. Step2의 수정",
    "text": "C. Step2의 수정\n- 수정된 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    #loss = torch.mean((y-yhat)**2) \n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "href": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "D. Step1의 수정 – net의 이용",
    "text": "D. Step1의 수정 – net의 이용\n- net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\n(X@What.data)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]])\n\n\n이런식으로도 구할수 있음!\n\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\n\n\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "E. Step4의 수정 – optimizer의 이용",
    "text": "E. Step4의 수정 – optimizer의 이용\n기존코드의 에폭별분해\n- 준비과정\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\nnet.weight.grad = None\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n새로운코드의 에폭별분해\n- 준비과정 – 옵티마이저라는 오브젝트를 셋팅한다!\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step3을 위한 사전준비 \noptimizr = torch.optim.SGD(params=net.parameters(),lr=0.1)\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\n#net.weight.grad = None\noptimizr.zero_grad()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n최종코드\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/01wk-1.html#a.-최하니",
    "href": "posts/01wk-1.html#a.-최하니",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. 최하니",
    "text": "A. 최하니\n\nhani1 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nhani1\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani1)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([2.1732e-09, 1.0000e+00]))\n\n\n\nhani2 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani2.jpeg?raw=true').content)\nhani2\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani2)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([7.2584e-07, 1.0000e+00]))\n\n\n\nhani3 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani3.jpg?raw=true').content)\nhani3\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani3)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([6.7243e-05, 9.9993e-01]))"
  },
  {
    "objectID": "posts/01wk-1.html#b.-인터넷-고양이",
    "href": "posts/01wk-1.html#b.-인터넷-고양이",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. 인터넷 고양이",
    "text": "B. 인터넷 고양이\n\ncat1 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat1.png?raw=true').content)\ncat1\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat1)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 2.2610e-12]))\n\n\n\ncat2 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat2.jpeg?raw=true').content)\ncat2\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat2)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([9.9963e-01, 3.6982e-04]))"
  },
  {
    "objectID": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "href": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. Step1: DLS(=데이터) 준비",
    "text": "A. Step1: DLS(=데이터) 준비\n\ndls = fastai.vision.data.ImageDataLoaders.from_folder(\n    path = './images',\n    train='train',\n    valid_pct = 0.2,\n    item_tfms=fastai.vision.augment.Resize(224),\n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/01wk-1.html#b.-step2-러너생성",
    "href": "posts/01wk-1.html#b.-step2-러너생성",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. Step2: 러너생성",
    "text": "B. Step2: 러너생성\n\nlrnr = fastai.vision.learner.vision_learner(\n    dls = dls,\n    arch = fastai.vision.models.resnet34,\n    metrics = fastai.metrics.accuracy\n)"
  },
  {
    "objectID": "posts/01wk-1.html#c.-step3-학습",
    "href": "posts/01wk-1.html#c.-step3-학습",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "C. Step3: 학습",
    "text": "C. Step3: 학습\n\nlrnr.fine_tune(7)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.058250\n1.492724\n0.515625\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.611757\n0.886693\n0.625000\n00:05\n\n\n1\n0.467988\n0.630385\n0.765625\n00:05\n\n\n2\n0.336618\n0.560025\n0.812500\n00:05\n\n\n3\n0.259717\n0.571055\n0.812500\n00:05\n\n\n4\n0.212600\n0.535282\n0.812500\n00:05\n\n\n5\n0.176119\n0.523694\n0.828125\n00:05\n\n\n6\n0.147607\n0.508762\n0.843750\n00:05"
  },
  {
    "objectID": "posts/01wk-1.html#d.-step4-예측",
    "href": "posts/01wk-1.html#d.-step4-예측",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "D. Step4: 예측",
    "text": "D. Step4: 예측\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninter = fastai.interpret.Interpretation.from_learner(lrnr)\ninter.plot_top_losses(16)"
  },
  {
    "objectID": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "href": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "#. 크롤링을 활용한 이미지 자료 분석",
    "text": "#. 크롤링을 활용한 이미지 자료 분석\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것, 단 (iu,hynn)는 제외)\n(2) fastai.vision.data.ImageDataLoaders() 를 이용하여 dls를 만들고 dls.show_batch()를 이용하여 만들어진 이미지를 확인하라.\n(3) fastai.vision.learner.vision_learner()를 이용하여 lrnr를 만들고 lrnr.fine_tune()을 이용하여 학습하라. 이때 모형의 arch는 resnet34를 사용하라.\n(4) requests.get()을 이용하여 (1)의 키워드에 해당하는 새로운 이미지를 한장씩 다운받고 (3)에서 학습한 lrnr를 이용하여 예측하라.\n\n제출은 ipynb파일로 할 것. 혹은 스크린샷을 제출해도 괜찮음."
  },
  {
    "objectID": "posts/05wk-1.html#a.-gpu-사용방법",
    "href": "posts/05wk-1.html#a.-gpu-사용방법",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   35C    P8              34W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   37C    P2              39W / 420W |    287MiB / 24576MiB |      2%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    362478      C   ...b3/anaconda3/envs/dl2024/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n\n\n\n\n\n강의중 net을 재선언한 이유\n\n\n\n- 아래와 같이 x_cpu 혹은 y_cpu에 .to(\"cuda:0\")메소드를 쓸 경우\nx_cpu.to(\"cuda:0\")\ny_cpu.to(\"cuda:0\")\nx_cpu와 y_cpu는 cpu에 그대로 있음.\n- 그런데 아래와 같이 net_cpu에서 .to(\"cuda:0\")메소드를 쓸 경우\nnet_cpu.to(\"cuda:0\")\nnet_cpu 자체가 gpu에 올라가게 됨.\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-1.html#b.-시간측정-예비학습",
    "href": "posts/05wk-1.html#b.-시간측정-예비학습",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n1.2487025260925293"
  },
  {
    "objectID": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "href": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. CPU vs GPU (512 nodes)",
    "text": "C. CPU vs GPU (512 nodes)\n- CPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.35651373863220215\n\n\n- GPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5209517478942871\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "href": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CPU vs GPU (20,480 nodes)",
    "text": "D. CPU vs GPU (20,480 nodes)\n- CPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.7291958332061768\n\n\n- GPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.4499187469482422\n\n\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "href": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. CPU vs GPU (204,800 nodes)",
    "text": "E. CPU vs GPU (204,800 nodes)\n- CPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n85.68583369255066\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3954846858978271"
  },
  {
    "objectID": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터: 빅데이터..?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지는 순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요"
  },
  {
    "objectID": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…"
  },
  {
    "objectID": "posts/05wk-1.html#d.-용어의-정리",
    "href": "posts/05wk-1.html#d.-용어의-정리",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 힘들것 같아요.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- ds: 섭스크립터블함\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7fa66f6520d0&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n\n\n\n\n\n\nNote\n\n\n\n여기서 제가 __iter__ 가 숨겨져 있는 오브젝트일 경우만 for문이 동작한다고 설명 했는데요, __getitem__이 있는 경우도 동작한다고 합니다. 제가 잘못 알고 있었어요. 혼란을 드려 죄송합니다.\n\n그래도 dl은 for 를 돌리기위해서 만든 오브젝트라는 설명은 맞는 설명입니다.\nds역시 독특한 방식의 인덱싱을 지원하도록 한 오브젝트라는 설명도 맞는 설명입니다.\n\n\n\n- dl: 섭스크립터블하지 않지만 이터러블함\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\n#set(dir(dl)) & {'__iter__'}\n\n\nfor xi,yi in dl:\n    print(f\"x_batch:{xi.tolist()} \\t y_batch:{yi.tolist()}\")\n\nx_batch:[[0.0], [1.0], [2.0]]    y_batch:[[1.0], [1.0], [1.0]]\nx_batch:[[3.0], [4.0], [5.0]]    y_batch:[[1.0], [1.0], [0.0]]\nx_batch:[[6.0], [7.0], [8.0]]    y_batch:[[0.0], [0.0], [0.0]]\nx_batch:[[9.0]]      y_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor xi,yi in dl:\n    print(f'x_batch={xi.tolist()} \\t y_batch={yi.tolist()}')\n\nx_batch=[[1.0], [8.0], [0.0]]    y_batch=[[1.0], [0.0], [1.0]]\nx_batch=[[2.0], [7.0], [6.0]]    y_batch=[[1.0], [0.0], [0.0]]\nx_batch=[[5.0], [3.0], [9.0]]    y_batch=[[0.0], [1.0], [0.0]]\nx_batch=[[4.0]]      y_batch=[[1.0]]"
  },
  {
    "objectID": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "href": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. ds, dl을 이용한 MNIST 구현",
    "text": "F. ds, dl을 이용한 MNIST 구현\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n\nbatch_size = 2048로 설정할것\n\n- 그냥 경사하강법 – 미니배치 안쓰는 학습, 우리가 맨날하는 그거\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: Predict \n((yhat &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- “확률적”경사하강법 – 미니배치 쓰는 학습\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n# ## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        #yihat = net(xi)\n        # step2 \n        loss = loss_fn(net(xi),yi)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict \n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)\n\n\n- GPU를 활용하는 “확률적”경사하강법 – 실제적으로는 이게 최종알고리즘\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        # step2 \n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict\nnet.to(\"cpu\")\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)"
  },
  {
    "objectID": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "href": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 결론 (그냥 외우세요)",
    "text": "A. 결론 (그냥 외우세요)\n- 2개의 class를 구분하는 문제가 아니라 \\(k\\)개의 class를 구분해야 한다면?\n일반적인 개념\n\n손실함수: BCE loss \\(\\to\\) Cross Entropy loss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: sig \\(\\to\\) softmax\n\n파이토치 한정\n\ny의형태: (n,) vector + int형 // (n,k) one-hot encoded matrix + float형\n손실함수: torch.nn.BCEWithLogitsLoss, \\(\\to\\) torch.nn.CrossEntropyLoss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: None \\(\\to\\) None (손실함수에 이미 마지막층의 활성화가 포함)"
  },
  {
    "objectID": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "href": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 실습: 3개의 클래스를 구분",
    "text": "B. 실습: 3개의 클래스를 구분\n- 정리된 코드1: 통계잘하는데 파이토치 못쓰는 사람의 코드\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    \n## Step4: 적합 (혹은 적합결과확인)\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)\n\n\n- 정리된 코드2: 파이토치를 잘하는 사람의 코드\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\n#y = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: 적합 (혹은 적합결과확인)    \n(netout.argmax(axis=1) == y).float().mean()\n\ntensor(0.9827)\n\n\n\n완전같은코드임"
  },
  {
    "objectID": "posts/05wk-1.html#c.-softmax",
    "href": "posts/05wk-1.html#c.-softmax",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. Softmax",
    "text": "C. Softmax\n- 눈치: softmax를 쓰기 직전의 숫자들은 (n,k)꼴로 되어있음. 각 observation 마다 k개의 숫자가 있는데, 그중에서 유난히 큰 하나의 숫자가 있음.\n\nnet(X)\n\ntensor([[ 4.4836, -4.5924, -3.4632],\n        [ 1.9839, -3.4456,  0.3030],\n        [ 5.9082, -7.5250, -0.7634],\n        ...,\n        [-0.8089, -0.8294,  0.6012],\n        [-2.1901, -0.4458,  0.7465],\n        [-1.6856, -2.2825,  5.1892]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ny\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n- 수식\n\n\\(\\text{sig}(u)=\\frac{e^u}{1+e^u}\\)\n\\(\\text{softmax}({\\boldsymbol u})=\\text{softmax}([u_1,u_2,\\dots,u_k])=\\big[ \\frac{e^{u_1}}{e^{u_1}+\\dots e^{u_k}},\\dots,\\frac{e^{u_k}}{e^{u_1}+\\dots e^{u_k}}\\big]\\)\n\n- torch.nn.Softmax() 손계산\n(예시1) – 잘못계산\n\nsoftmax = torch.nn.Softmax(dim=0)\n\n\nnetout = torch.tensor([[-2.0,-2.0,0.0],\n                        [3.14,3.14,3.14],\n                        [0.0,0.0,2.0],\n                        [2.0,2.0,4.0],\n                        [0.0,0.0,0.0]])\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout) \n\ntensor([[0.0041, 0.0041, 0.0115],\n        [0.7081, 0.7081, 0.2653],\n        [0.0306, 0.0306, 0.0848],\n        [0.2265, 0.2265, 0.6269],\n        [0.0306, 0.0306, 0.0115]])\n\n\n(예시2) – 이게 맞게 계산되는 것임\n\nsoftmax = torch.nn.Softmax(dim=1)\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시3) – 차원을 명시안하면 맞게 계산해주고 경고 줌\n\nsoftmax = torch.nn.Softmax()\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\n/home/cgb3/anaconda3/envs/dl2024/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시4) – 진짜 손계산\n\nnetout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\ntorch.exp(netout)\n\ntensor([[ 0.1353,  0.1353,  1.0000],\n        [23.1039, 23.1039, 23.1039],\n        [ 1.0000,  1.0000,  7.3891],\n        [ 7.3891,  7.3891, 54.5981],\n        [ 1.0000,  1.0000,  1.0000]])\n\n\n\n0.1353/(0.1353 + 0.1353 + 1.0000), 0.1353/(0.1353 + 0.1353 + 1.0000), 1.0000/(0.1353 + 0.1353 + 1.0000) # 첫 obs\n\n(0.10648512513773022, 0.10648512513773022, 0.7870297497245397)\n\n\n\ntorch.exp(netout[1])/torch.exp(netout[1]).sum() # 두번째 obs \n\ntensor([0.3333, 0.3333, 0.3333])"
  },
  {
    "objectID": "posts/05wk-1.html#d.-crossentropyloss",
    "href": "posts/05wk-1.html#d.-crossentropyloss",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CrossEntropyLoss",
    "text": "D. CrossEntropyLoss\n- 수식\n# 2개의 카테고리\n- 예제1: BCELoss vs BCEWithLogisticLoss\n\ny = torch.tensor([0,0,1]).reshape(-1,1).float()\nnetout = torch.tensor([-1, 0, 1]).reshape(-1,1).float()\ny,netout\n\n(tensor([[0.],\n         [0.],\n         [1.]]),\n tensor([[-1.],\n         [ 0.],\n         [ 1.]]))\n\n\n\n# 계산방법1: 공식암기\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\n- torch.sum(torch.log(yhat)*y + torch.log(1-yhat)*(1-y))/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.BCELoss() 이용\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\nloss_fn = torch.nn.BCELoss()\nloss_fn(yhat,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.BCEWithLogitsLoss() 이용\nloss_fn = torch.nn.BCEWithLogitsLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n- 예제2: BCEWithLogisticLoss vs CrossEntropyLoss\n\ntorch.concat([sig(netout),1-sig(netout)],axis=1)\n\ntensor([[0.2689, 0.7311],\n        [0.5000, 0.5000],\n        [0.7311, 0.2689]])\n\n\n\nnetout = torch.tensor([[3,2],[2,2],[5,6]]).float()\ny = torch.tensor([[1,0],[1,0],[0,1]]).float()\ny,netout #,netout[:,[1]]-netout[:,[0]]\n\n(tensor([[1., 0.],\n         [1., 0.],\n         [0., 1.]]),\n tensor([[3., 2.],\n         [2., 2.],\n         [5., 6.]]))\n\n\n\nsoftmax(netout)\n\ntensor([[0.7311, 0.2689],\n        [0.5000, 0.5000],\n        [0.2689, 0.7311]])\n\n\n\n# 계산방법1: 공식암기\n-torch.sum(torch.log(softmax(netout))*y)/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.CrossEntropyLoss() 이용 + y는 one-hot으로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.CrossEntropyLoss() 이용 + y는 0,1 로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n#\n# 3개의 카테고리\n\ny = torch.tensor([2,1,2,2,0])\ny_onehot = torch.nn.functional.one_hot(y)\nnetout = torch.tensor(\n    [[-2.0000, -2.0000,  0.0000],\n     [ 3.1400,  3.1400,  3.1400],\n     [ 0.0000,  0.0000,  2.0000],\n     [ 2.0000,  2.0000,  4.0000],\n     [ 0.0000,  0.0000,  0.0000]]\n)\ny,y_onehot\n\n(tensor([2, 1, 2, 2, 0]),\n tensor([[0, 0, 1],\n         [0, 1, 0],\n         [0, 0, 1],\n         [0, 0, 1],\n         [1, 0, 0]]))\n\n\n\n## 방법1 -- 추천X\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y_onehot.float())\n\ntensor(0.5832)\n\n\n\n## 방법2 -- 추천O\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.5832)\n\n\n\n## 방법3 -- 공식.. (이걸 쓰는사람은 없겠지?)\nsoftmax = torch.nn.Softmax() \nloss_fn = torch.nn.CrossEntropyLoss()\n- torch.sum(torch.log(softmax(netout))*y_onehot)/5\n\ntensor(0.5832)\n\n\n#\n- 계산하는 공식을 아는것도 중요한데 torch.nn.CrossEntropyLoss() 에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 더 중요함.\n- torch.nn.CrossEntropyLoss() 는 사실 torch.nn.CEWithSoftmaxLoss() 정도로 바꾸는 것이 더 말이 되는 것 같다."
  },
  {
    "objectID": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "href": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Minor Topic: 이진분류와 CrossEntropy",
    "text": "E. Minor Topic: 이진분류와 CrossEntropy\n- 2개의 클래스일경우에도 CrossEntropy를 쓸 수 있지 않을까?\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data(fastai.data.external.URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1]).reshape(-1,1*28*28)/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: fit  \nfor epoc in range(70): \n    ## 1 \n    ## 2 \n    loss= loss_fn(net(X),y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n## Step4: Predict \nsoftmax = torch.nn.Softmax()\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.9983)\n\n\n- 이진분류문제 = “y=0 or y=1” 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제\n- softmax, sigmoid\n\nsoftmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다.\nsigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다.\n\n- 그런데 “실패확률=1-성공확률” 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까)\n- 즉 아래는 같은 표현력을 가진 모형이다.\n\n\n- 둘은 같은 표현력을 가진 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. \\(\\to\\) sigmoid를 사용하는 모형이 비용은 싸고 효과는 동일하다는 말 \\(\\to\\) 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함.\n\nsoftmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음."
  },
  {
    "objectID": "posts/05wk-1.html#f.-정리",
    "href": "posts/05wk-1.html#f.-정리",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. 정리",
    "text": "F. 정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (그냥 좀 비효율적인 느낌이 드는 것 뿐임. 흑백이미지를 칼라잉크로 출력하는 느낌)\n참고\n\n\n\n\\(y\\)\n분포가정\n마지막층의 활성화함수\n손실함수\n\n\n\n\n3.45, 4.43, … (연속형)\n정규분포\nNone (or Identity)\nMSE\n\n\n0 or 1\n이항분포 with \\(n=1\\) (=베르누이)\nSigmoid\nBCE\n\n\n[0,0,1], [0,1,0], [1,0,0]\n다항분포 with \\(n=1\\)\nSoftmax\nCross Entropy"
  },
  {
    "objectID": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "href": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "A. 기존모형에 대한 불만",
    "text": "A. 기존모형에 대한 불만\n\n- 왜 28 \\(\\times\\) 28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다."
  },
  {
    "objectID": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "href": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "B. 새로운 아키텍처의 제시",
    "text": "B. 새로운 아키텍처의 제시\n- 예전 아키텍처들\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 아키텍처들의 공통점?\n\n\\(l_1\\): 선형변환, feature를 뽑아내는 역할 (뻥튀기 혹은 요약)\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처\n\n\\(conv\\): feature를 뽑아내는 역할 (뻥튀기 혹은 요약) (2d ver \\(l_1\\) 느낌)\n\\(relu\\):\n\\(pooling\\): 데이터를 요약하는 역할"
  },
  {
    "objectID": "posts/05wk-2.html#c.-torch.nn.conv2d",
    "href": "posts/05wk-2.html#c.-torch.nn.conv2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.manual_seed(43052)\nconv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,1,2,2).float() # 2,2 흑백이미지. \n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\nconv(_X)\n\ntensor([[[[1.5410]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시2) 평균\n\nconv = torch.nn.Conv2d(1,1,(2,2))\nconv.weight.data = conv.weight.data * 0 + 1/4\nconv.bias.data = conv.bias.data * 0\n\n\n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\nconv(_X)\n\ntensor([[[[1.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(16).reshape(1,1,4,4).float()\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]]]),\n tensor([[[[ 2.5000,  3.5000,  4.5000],\n           [ 6.5000,  7.5000,  8.5000],\n           [10.5000, 11.5000, 12.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_X = torch.arange(16).reshape(1,1,4,4).float()\nconv = torch.nn.Conv2d(1,1,(3,3))\nconv.weight.data = conv.weight.data * 0 + 1/9\nconv.bias.data = conv.bias.data * 0\n\n\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]]]),\n tensor([[[[ 5.0000,  6.0000],\n           [ 9.0000, 10.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시5) 2개의 이미지\n\n_X = torch.arange(32).reshape(2,1,4,4).float()\nconv = torch.nn.Conv2d(1,1,(3,3))\nconv.weight.data = conv.weight.data * 0 + 1/9\nconv.bias.data = conv.bias.data * 0\n\n\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]],\n \n \n         [[[16., 17., 18., 19.],\n           [20., 21., 22., 23.],\n           [24., 25., 26., 27.],\n           [28., 29., 30., 31.]]]]),\n tensor([[[[ 5.0000,  6.0000],\n           [ 9.0000, 10.0000]]],\n \n \n         [[[21.0000, 22.0000],\n           [25.0000, 26.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시6) 피처뻥튀기\n\n_X = torch.arange(32).reshape(2,1,4,4).float()\nconv = torch.nn.Conv2d(1,16,(3,3))\n\n\n_X.shape,conv(_X).shape\n\n(torch.Size([2, 1, 4, 4]), torch.Size([2, 16, 2, 2]))"
  },
  {
    "objectID": "posts/05wk-2.html#d.-torch.nn.relu",
    "href": "posts/05wk-2.html#d.-torch.nn.relu",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "D. torch.nn.ReLU",
    "text": "D. torch.nn.ReLU\n\na1 = torch.nn.ReLU()\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,a1(_X)\n\n(tensor([[[[-0.2818, -1.1458,  1.8352,  1.8220,  0.2402],\n           [ 0.2336, -0.3763, -0.2860,  1.3095,  0.1935],\n           [ 2.2810, -0.0667, -1.0980, -0.8768, -1.2860],\n           [-2.0301,  2.0058, -1.4996, -2.3721, -0.2790],\n           [ 0.5234, -2.3032,  0.3850,  0.3517, -0.7517]]]]),\n tensor([[[[0.0000, 0.0000, 1.8352, 1.8220, 0.2402],\n           [0.2336, 0.0000, 0.0000, 1.3095, 0.1935],\n           [2.2810, 0.0000, 0.0000, 0.0000, 0.0000],\n           [0.0000, 2.0058, 0.0000, 0.0000, 0.0000],\n           [0.5234, 0.0000, 0.3850, 0.3517, 0.0000]]]]))"
  },
  {
    "objectID": "posts/05wk-2.html#e.-torch.nn.maxpool2d",
    "href": "posts/05wk-2.html#e.-torch.nn.maxpool2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "E. torch.nn.MaxPool2d",
    "text": "E. torch.nn.MaxPool2d\n\nm1 = torch.nn.MaxPool2d((2,2))\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,m1(_X)\n\n(tensor([[[[ 0.0766, -1.5961,  1.3616, -1.0197,  1.7961],\n           [ 1.0320, -1.4307,  1.5249,  0.5566,  0.4670],\n           [-1.2974, -0.0475,  0.0949, -0.5826, -0.2989],\n           [-1.6870,  0.0900, -0.2950,  1.1790,  0.5042],\n           [-1.7903,  0.8574, -1.2283,  0.6094,  0.0668]]]]),\n tensor([[[[1.0320, 1.5249],\n           [0.0900, 1.1790]]]]))"
  },
  {
    "objectID": "posts/05wk-2.html#a.-conv2d",
    "href": "posts/05wk-2.html#a.-conv2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "A. Conv2d",
    "text": "A. Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5))\nprint(X.shape)\nprint(c1(X).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#b.-relu",
    "href": "posts/05wk-2.html#b.-relu",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "B. ReLU",
    "text": "B. ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#c.-maxpool2d",
    "href": "posts/05wk-2.html#c.-maxpool2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "C. MaxPool2D",
    "text": "C. MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])"
  },
  {
    "objectID": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "href": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "D. 적당히 마무리하고 시그모이드 태우자",
    "text": "D. 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,16*12*12).shape\n\ntorch.Size([12665, 2304])\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a2(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])"
  },
  {
    "objectID": "posts/05wk-2.html#e.-학습",
    "href": "posts/05wk-2.html#e.-학습",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "E. 학습",
    "text": "E. 학습\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d-&gt;1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(50): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/08wk-1-2.html#a.-생성모형이란-쉬운-설명",
    "href": "posts/08wk-1-2.html#a.-생성모형이란-쉬운-설명",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "A. 생성모형이란? (쉬운 설명)",
    "text": "A. 생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼 수 있는가?\n- 진정으로 인공지능이 이미지자료를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공"
  },
  {
    "objectID": "posts/08wk-1-2.html#b.-gan의-응용분야",
    "href": "posts/08wk-1-2.html#b.-gan의-응용분야",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "B. GAN의 응용분야",
    "text": "B. GAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면?\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 거북이의 커버..\n- 너무 많아요….."
  },
  {
    "objectID": "posts/08wk-1-2.html#c.-생성모형이란-통계학과-버전의-설명",
    "href": "posts/08wk-1-2.html#c.-생성모형이란-통계학과-버전의-설명",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "C. 생성모형이란? 통계학과 버전의 설명",
    "text": "C. 생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고 (=문제를 괜히 어렵게 만들어서 풀지 말고), 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{X}\\) 가 주어졌을 경우 라벨을 \\(y\\) 라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{X})\\)에 관심이 있다. – 판별모형\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{X},y)\\)에 관심이 있는것이다. – 생성모형\n- 데이터의 생성확률 \\(p(\\boldsymbol{X},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{X})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol X}) = \\frac{p({\\boldsymbol X},y)}{p({\\boldsymbol X})} = \\frac{p({\\boldsymbol X},y)}{\\sum_{y}p({\\boldsymbol X},y)}\\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 일반적인 분류문제를 해결할때 “판별모형이 생성모형보다 더 바람직한 접근법”이라 할 수 있음. 즉 개와 고양이를 구분할 때, 그려진 개와 고양이 사진을 잘 구분하면 되는 것이지 굳이 개와 고양이를 그릴줄 알아야하는건 아니라는 의미.\n- 예전에는 머신러닝의 응용분야가 “분류/회귀”에 한정된 느낌이었는데 요즘은 생성모형도 인기있음."
  },
  {
    "objectID": "posts/08wk-1-2.html#d.-gan의-원리",
    "href": "posts/08wk-1-2.html#d.-gan의-원리",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "D. GAN의 원리",
    "text": "D. GAN의 원리\n- GAN은 생성모형 중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of fakers, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –&gt; 상사에게 혼남. 그것도 구분못하냐고 –&gt; (판별능력 업그레이드) –&gt; 이건 가짜다!!\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/08wk-1-2.html#a.-data",
    "href": "posts/08wk-1-2.html#a.-data",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "A. Data",
    "text": "A. Data\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.MNIST)\npath\n\nPath('/home/cgb3/.fastai/data/mnist_png')\n\n\n\nX_real = torch.stack([torchvision.io.read_image(str(l)) for l in (path/'training/3').ls()],axis=0)/255\nX_real.shape\n\ntorch.Size([6131, 1, 28, 28])\n\n\n\nplt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")"
  },
  {
    "objectID": "posts/08wk-1-2.html#b.-페이커-생성",
    "href": "posts/08wk-1-2.html#b.-페이커-생성",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "B. 페이커 생성",
    "text": "B. 페이커 생성\n\n“net_faker: noise \\(\\to\\) 가짜이미지” 를 만들자.\n\n- 네트워크의 입력: (n,??) 인 랜덤으로 뽑은 숫자.\n- 네트워크의 출력: (n,1,28,28)의 텐서\n\ntorch.randn(1,4) # 이게 들어온다고 상상하자.\n\ntensor([[-0.2251,  0.2474,  0.7297, -1.1856]])\n\n\n\nclass Reshape2828(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28) \n\n\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n    Reshape2828()\n)\n\n\nnet_faker(torch.randn(1,4)).shape # 가짜이미지!\n\ntorch.Size([1, 1, 28, 28])"
  },
  {
    "objectID": "posts/08wk-1-2.html#c.-경찰-생성",
    "href": "posts/08wk-1-2.html#c.-경찰-생성",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "C. 경찰 생성",
    "text": "C. 경찰 생성\n\nnet_police: 진짜이미지 \\(\\to\\) 0 // 가짜이미지 \\(\\to\\) 1 와 같은 네트워크를 설계하자.\n\n- 네트워크의 입력: (n,1,28,28) 인 이미지\n- 네트워크의 출력: 0,1\n\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)"
  },
  {
    "objectID": "posts/08wk-1-2.html#d.-바보경찰-바보페이커",
    "href": "posts/08wk-1-2.html#d.-바보경찰-바보페이커",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "D. 바보경찰, 바보페이커",
    "text": "D. 바보경찰, 바보페이커\n\n스토리를 전개해볼까?\n\n- 경찰네트워크가 가짜이미지를 봤을때 어떤 판단을 하는지, 진짜 이미지를 봤을떄 어떤 판단을 하는지 살펴보자.\n&lt;경찰이 진짜이미지를 봤다면&gt;\n- 진짜이미지\n\nplt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- 진짜 이미지를 경찰한테 한장 줘볼까? \\(\\to\\) yhat이 나올텐데, 이 값이 0이어야 함\n\nyhat_real = net_police(X_real[[0]]) # 이 값이 0이어야 하는데..\nyhat_real\n\ntensor([[0.5373]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n진짜 이미지가 입력으로 왔으므로 yhat_real \\(\\approx\\) 0 이어야 함\n그런데 0과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)\n\n&lt;경찰이 가짜이미지를 봤다면&gt;\n- 가짜이미지 – 데이터셋이 있는게 아니고 net_faker가 생성해야하는 데이터\n\nNoise = torch.randn(1,4)\nNoise\n\ntensor([[ 1.5179, -0.6278, -0.1390, -1.1916]])\n\n\n\nnet_faker(Noise).shape # 페이커가 만든 가짜 이미지\n\ntorch.Size([1, 1, 28, 28])\n\n\n\nplt.imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n누가봐도 가짜이미지\n\n- 가짜 이미지를 경찰한테 한장 줘볼까? \\(\\to\\) yhat이 나올텐데, 이 값이 1이어야 함\n\nyhat_fake = net_police(net_faker(Noise).data) # 이 값이 1이어야 하는데..\nyhat_fake\n\ntensor([[0.5402]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n가짜 이미지가 입력으로 왔으므로 yhat_fake \\(\\approx\\) 1 이어야 함\n그런데 1과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)\n\n- 페이커의 무능함 (왼쪽 이미지를 가짜이미라고 만들어 놓았음) + 경찰의 무능함 (왼쪽과 오른쪽을 보고 뭐가 진짜인지도 모름)\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\nax[1].imshow(X_real[[0]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")\n\nText(0.5, 1.0, 'real')"
  },
  {
    "objectID": "posts/08wk-1-2.html#e.-똑똑해진-경찰",
    "href": "posts/08wk-1-2.html#e.-똑똑해진-경찰",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "E. 똑똑해진 경찰",
    "text": "E. 똑똑해진 경찰\n\nX_real.shape\n\ntorch.Size([6131, 1, 28, 28])\n\n\n- 데이터 정리\n\n원래 \\(n=6131\\)개의 이미지 자료가 있음. 이를 \\({\\bf X}_{real}\\) 라고 하자. 따라서 \\({\\bf X}_{real}\\) 의 차원은 (6131,1,28,28).\n위조범이 만든 가짜자료를 원래 자료와 같은 숫자인 6131개 만듦. 이 가짜자료를 \\({\\bf X}_{fake}\\) 라고 하자. 따라서 \\({\\bf X}_{fake}\\) 의 차원은 (6131,1,28,28).\n진짜자료는 0, 가짜자료는 1으로 라벨링.\n\n\nNoise = torch.randn(6131,4)\nX_fake = net_faker(Noise).data\ny_real = torch.tensor([0]*6131).reshape(-1,1).float()\ny_fake = torch.tensor([1]*6131).reshape(-1,1).float()\n\n- step1: X_real, X_fake를 보고 각가 yhat_real, yhat_fake를 만드는 과정\n\nyhat_real = net_police(X_real)\nyhat_fake = net_police(X_fake)\n\n- step2: 손실을 계산 – 경찰의 미덕은 (1) 가짜이미지를 가짜라고 하고 (yhat_fake \\(\\approx\\) y_fake) (2) 진짜이미지를 진짜라고 해야한다. (yhat_real \\(\\approx\\) y_real)\n\nbce = torch.nn.BCELoss()\nloss_police = bce(yhat_fake,y_fake) + bce(yhat_real,y_real)\nloss_police\n\ntensor(1.3711, grad_fn=&lt;AddBackward0&gt;)\n\n\n- step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자.\n\n##\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters())\n##\nfor epoc in range(30):\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise).data\n    ## step1 \n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    ## step2\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    ## step3 \n    loss_police.backward()\n    ## step4 \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n\n- 훈련된 경찰의 성능을 살펴보자.\n\nnet_police(X_real) # 거의 0으로!\n\ntensor([[0.0105],\n        [0.2350],\n        [0.0329],\n        ...,\n        [0.0623],\n        [0.0407],\n        [0.0266]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet_police(X_fake) # 거의 1로!\n\ntensor([[0.9803],\n        [0.9800],\n        [0.9802],\n        ...,\n        [0.9802],\n        [0.9801],\n        [0.9801]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 꽤 우수한 경찰이 되었음\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_fake[[-1]].data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\nax[1].imshow(X_real[[-1]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")\n\nText(0.5, 1.0, 'real')"
  },
  {
    "objectID": "posts/08wk-1-2.html#f.-더-똑똑해지는-페이커",
    "href": "posts/08wk-1-2.html#f.-더-똑똑해지는-페이커",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "F. 더 똑똑해지는 페이커",
    "text": "F. 더 똑똑해지는 페이커\n- step1: Noise \\(\\to\\) X_fake\n\nNoise = torch.randn(6131,4)\nX_fake = net_faker(Noise) \n\n- step2: 손실함수 – 페이커의 미덕은 (잘 훈련된) 경찰이 가짜이미지를 진짜라고 판단하는 것. 즉 yhat_fake \\(\\approx\\) y_real 이어야 페이커의 실력이 우수하다고 볼 수 있음.\n\nyhat_fake = net_police(X_fake) \nloss_faker = bce(yhat_fake,y_real) ## 가짜이미지를 보고 잘 훈련된 경찰조차 진짜이미지라고 깜빡 속으면 위조범의 실력이 좋은 것임\n\n- step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자.\n\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n    Reshape2828()\n)\n#bce = torch.nn.BCELoss()\noptimizr_faker = torch.optim.Adam(net_faker.parameters())\n#--#\n\n\nfor epoc in range(1):\n    # step1\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise) \n    # step2\n    yhat_fake = net_police(X_fake) \n    loss_faker = bce(yhat_fake,y_real)\n    # step3 \n    loss_faker.backward()\n    # step4 \n    optimizr_faker.step()\n    optimizr_faker.zero_grad()\n\n- 위조범의 실력향상을 감상해보자.\n\nfig,ax = plt.subplots(2,5,figsize=(10,4))\nk = 0 \nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n        k = k+1 \nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n((yhat_fake &gt; 0.5) == 0).float().mean() # 경찰이 가짜이미지를 진짜라고 생각한 비율 = 페이커가 사기에 성공한 비율\n\ntensor(0.)"
  },
  {
    "objectID": "posts/08wk-1-2.html#g.-경쟁학습",
    "href": "posts/08wk-1-2.html#g.-경쟁학습",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "G. 경쟁학습",
    "text": "G. 경쟁학습\n\n두 적대적인 네트워크를 경쟁시키자!\n\n\ntorch.manual_seed(43052)\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), \n    Reshape2828()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters(),lr=0.001,betas=(0.5,0.999))\noptimizr_faker = torch.optim.Adam(net_faker.parameters(),lr=0.0002,betas=(0.5,0.999))\n\n\nfor epoc in range(1000):\n    # net_police 을 훈련\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise).data # net_faker에 대한 미분꼬리표는 여기선 필요없으므로 .data 만을 이용\n    ## step1 \n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    ## step2 \n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    ## step3 \n    loss_police.backward()\n    ## step4 \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n    # net_faker 를 훈련\n    ## step1 \n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise)\n    ## step2 \n    yhat_fake = net_police(X_fake)\n    loss_faker = bce(yhat_fake,y_real) \n    ## step3\n    loss_faker.backward()\n    ## step4 \n    optimizr_faker.step()\n    optimizr_faker.zero_grad()\n\n\nfig,ax = plt.subplots(2,5,figsize=(10,4))\nk = 0 \nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n        k = k+1 \nfig.tight_layout()"
  },
  {
    "objectID": "posts/10wk-2.html#a.-data-나는-solo",
    "href": "posts/10wk-2.html#a.-data-나는-solo",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "A. Data: 나는 SOLO",
    "text": "A. Data: 나는 SOLO\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_view\n\n\n\n\n\n\n\n\n영식(IN)\n영철(IN)\n영호(IS)\n광수(IS)\n상철(EN)\n영수(EN)\n규빈(ES)\n다호(ES)\n\n\n\n\n옥순(IN)\nNaN\n4.02\n3.45\n3.42\n0.84\n1.12\n0.43\n0.49\n\n\n영자(IN)\n3.93\n3.99\n3.63\n3.43\n0.98\n0.96\n0.52\nNaN\n\n\n정숙(IS)\n3.52\n3.42\n4.05\n4.06\n0.39\nNaN\n0.93\n0.99\n\n\n영숙(IS)\n3.43\n3.57\nNaN\n3.95\n0.56\n0.52\n0.89\n0.89\n\n\n순자(EN)\n1.12\nNaN\n0.59\n0.43\n4.01\n4.16\n3.52\n3.38\n\n\n현숙(EN)\n0.94\n1.05\n0.32\n0.45\n4.02\n3.78\nNaN\n3.54\n\n\n서연(ES)\n0.51\n0.56\n0.88\n0.89\n3.50\n3.64\n4.04\n4.10\n\n\n보람(ES)\n0.48\n0.51\n1.03\nNaN\n3.52\n4.00\n3.82\nNaN\n\n\n하니(I)\n4.85\n4.82\nNaN\n4.98\n4.53\n4.39\n4.45\n4.52\n\n\n\n\n\n\n\n- 데이터를 이해할 때 필요한 가정들 – 제가 마음대로 설정했어요..\n\n궁합이 잘맞으면 5점, 잘 안맞으면 0점 이다.\nMBTI 성향에 따라서 궁함의 정도가 다르다. 특히 I/E의 성향일치가 중요하다.\n하니는 모든 사람들과 대체로 궁합이 잘 맞는다.\n하니는 I성향의 사람들과 좀 더 잘 맞는다."
  },
  {
    "objectID": "posts/10wk-2.html#b.-fit-predict",
    "href": "posts/10wk-2.html#b.-fit-predict",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "B. Fit / Predict",
    "text": "B. Fit / Predict\n- 목표: NaN을 추정\n- 수동추론: 그럴듯한 숫자를 추정해보자.\n\n옥순(IN),영식(IN)의 궁합은? \\(\\to\\) 둘다 IN 이므로 잘 맞을듯 \\(\\to\\) 4.0 정도?\n영자(IN),다호(ES)의 궁합은? \\(\\to\\) 잘 안맞을듯\n하니(I),영호(IS)의 궁합은? \\(\\to\\) 하니는 모두 좋아하므로 기본적으로 4.5 정도 + 하니는 I성향이므로 더 잘 맞을듯 \\(\\to\\) 거의 4.9 아닐까?\n\n- 좀 더 체계적인 추론 전략: (1) 사람들이 가지고 있는 성향 (2) 사람자체의 절대매력을 수치화 하자.\n\n옥순(IN)의 IN성향, 옥순(IN)의 매력 = (1.22, 0.49), 1.21\n영식(IN)의 IN성향, 영식(IN)의 매력 = (1.20, 0.50), 1.20\n영자(IN)의 IN성향, 영자(IN)의 매력 = (1.17 ,0.44), 1.25\n다호(ES)의 IN성향, 다호(ES)의 매력 = (-1.22 ,-0.60), 1.15\n하니(I)의 IN성향, 하니(I)의 매력 = (0.20,0.00), 3.60\n영호(IS)의 IS성향, 영호(IS)의 매력 = (1.23 , -0.7), 1.11\n\n(1) 옥순(IN)과 영식(IN)의 궁합 \\(\\approx\\) 옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의N성향\\(\\times\\)영식의N성향 \\(+\\) 옥순의매력 \\(+\\) 영식의매력\n\n옥순성향 = torch.tensor([1.22,0.49]).reshape(1,2)\n옥순매력 = torch.tensor(1.21)\n영식성향 = torch.tensor([1.20,0.5]).reshape(1,2)\n영식매력 = torch.tensor(1.2)\n((옥순성향*영식성향).sum() + 옥순매력 + 영식매력) # 옥순과 영식의 궁합: a ∘ b 로 내적구함 + 이후에 매력을 더함 \n(옥순성향 @ 영식성향.T + 옥순매력 + 영식매력) # 옥순과 영식의 궁합: a.T @ b 로 내적구함 + 이후에 매력을 더함\n\ntensor([[4.1190]])\n\n\n(2) 영자(IN)와 다호(ES)의 궁합 \\(\\approx\\) 영자I성향\\(\\times\\)다호I성향 \\(+\\) 영자N성향\\(\\times\\)다호의N성향 \\(+\\) 영자의매력 \\(+\\) 다호의매력\n\n영자성향 = torch.tensor([1.17,0.44]).reshape(1,2)\n영자매력 = torch.tensor(1.25).reshape(1,1)\n다호성향 = torch.tensor([-1.22,-0.6]).reshape(1,2)\n다호매력 = torch.tensor(1.15).reshape(1,1)\n((영자성향*다호성향).sum() + 영자성향 + 다호성향)\n(영자성향 @ 다호성향.T + 영자매력 + 다호매력)\n\ntensor([[0.7086]])\n\n\n(3) 하니(I)와 영호(IS)의 궁합 \\(\\approx\\) 하니I성향\\(\\times\\)영호I성향 \\(+\\) 하니N성향\\(\\times\\)영호의N성향 \\(+\\) 하니의매력 \\(+\\) 영호의매력\n\n하니성향 = torch.tensor([0.2,0]).reshape(1,2)\n하니매력 = torch.tensor(3.6)\n영호성향 = torch.tensor([1.23,-0.7]).reshape(1,2)\n영호매력 = torch.tensor(1.11)\n((하니성향*영호성향).sum() + 하니매력 + 영호매력)\n(하니성향 @ 영호성향.T + 하니매력 + 영호매력)\n\ntensor([[4.9560]])\n\n\n\n전체적으로 그럴싸함\n\n- 전체 사용자의 설정값\n\n옥순성향 = torch.tensor([1.22,0.49]).reshape(1,2)\n영자성향 = torch.tensor([1.17,0.44]).reshape(1,2)\n정숙성향 = torch.tensor([1.21,-0.45]).reshape(1,2)\n영숙성향 = torch.tensor([1.20,-0.50]).reshape(1,2)\n순자성향 = torch.tensor([-1.20,0.51]).reshape(1,2)\n현숙성향 = torch.tensor([-1.23,0.48]).reshape(1,2)\n서연성향 = torch.tensor([-1.20,-0.48]).reshape(1,2)\n보람성향 = torch.tensor([-1.19,-0.49]).reshape(1,2)\n하니성향 = torch.tensor([0.2,0]).reshape(1,2)\nW = torch.concat([옥순성향,영자성향,정숙성향,영숙성향,순자성향,현숙성향,서연성향,보람성향,하니성향])\nb1 = torch.tensor([1.21,1.25,1.10,1.11,1.12,1.13,1.14,1.12,3.6]).reshape(-1,1) \nW,b1\n\n(tensor([[ 1.2200,  0.4900],\n         [ 1.1700,  0.4400],\n         [ 1.2100, -0.4500],\n         [ 1.2000, -0.5000],\n         [-1.2000,  0.5100],\n         [-1.2300,  0.4800],\n         [-1.2000, -0.4800],\n         [-1.1900, -0.4900],\n         [ 0.2000,  0.0000]]),\n tensor([[1.2100],\n         [1.2500],\n         [1.1000],\n         [1.1100],\n         [1.1200],\n         [1.1300],\n         [1.1400],\n         [1.1200],\n         [3.6000]]))\n\n\n\n영식성향 = torch.tensor([1.20,0.5]).reshape(1,2)\n영철성향 = torch.tensor([1.22,0.45]).reshape(1,2)\n영호성향 = torch.tensor([1.23,-0.7]).reshape(1,2)\n광수성향 = torch.tensor([1.21,-0.6]).reshape(1,2)\n상철성향 = torch.tensor([-1.28,0.6]).reshape(1,2)\n영수성향 = torch.tensor([-1.24,0.5]).reshape(1,2)\n규빈성향 = torch.tensor([-1.20,-0.5]).reshape(1,2)\n다호성향 = torch.tensor([-1.22,-0.6]).reshape(1,2)\nM = torch.concat([영식성향,영철성향,영호성향,광수성향,상철성향,영수성향,규빈성향,다호성향]) # 각 column은 남성출연자의 성향을 의미함\nb2 = torch.tensor([1.2,1.10,1.11,1.25,1.18,1.11,1.15,1.15]).reshape(-1,1)\nM,b2\n\n(tensor([[ 1.2000,  0.5000],\n         [ 1.2200,  0.4500],\n         [ 1.2300, -0.7000],\n         [ 1.2100, -0.6000],\n         [-1.2800,  0.6000],\n         [-1.2400,  0.5000],\n         [-1.2000, -0.5000],\n         [-1.2200, -0.6000]]),\n tensor([[1.2000],\n         [1.1000],\n         [1.1100],\n         [1.2500],\n         [1.1800],\n         [1.1100],\n         [1.1500],\n         [1.1500]]))\n\n\n- 아래의 행렬곱 관찰\n\nW @ M.T + (b1 + b2.T)\n\ntensor([[4.1190, 4.0189, 3.4776, 3.6422, 1.1224, 1.0522, 0.6510, 0.5776],\n        [4.0740, 3.9754, 3.4911, 3.6517, 1.1964, 1.1292, 0.7760, 0.7086],\n        [3.5270, 3.4737, 4.0133, 4.0841, 0.4612, 0.4846, 1.0230, 1.0438],\n        [3.5000, 3.4490, 4.0460, 4.1120, 0.4540, 0.4820, 1.0700, 1.0960],\n        [1.1350, 0.9855, 0.3970, 0.6120, 4.1420, 3.9730, 3.4550, 3.4280],\n        [1.0940, 0.9454, 0.3911, 0.6037, 4.1724, 4.0052, 3.5160, 3.4926],\n        [0.6600, 0.5600, 1.1100, 1.2260, 3.5680, 3.4980, 3.9700, 4.0420],\n        [0.6470, 0.5477, 1.1093, 1.2241, 3.5292, 3.4606, 3.9430, 4.0158],\n        [5.0400, 4.9440, 4.9560, 5.0920, 4.5240, 4.4620, 4.5100, 4.5060]])\n\n\n—저거 따져보자—\n\\({\\bf W} = \\begin{bmatrix} 1.2200 & 0.4900 \\\\ 1.1700 & 0.4400 \\\\ 1.2100 & -0.4500 \\\\ 1.2000 & -0.5000 \\\\ -1.2000 & 0.5100 \\\\ -1.2300 & 0.4800 \\\\ -1.2000 & -0.4800 \\\\ -1.1900 & -0.4900 \\\\ 0.2000 & 0.0000 \\end{bmatrix}\\)\n\\({\\bf M}^\\top = \\begin{bmatrix} 1.2000 & 1.2200 & 1.2300 & 1.2100 & -1.2800 & -1.2400 & -1.2000 & -1.2200 \\\\ 0.5000 & 0.4500 & -0.7000 & -0.6000 & 0.6000 & 0.5000 & -0.5000 & -0.6000 \\end{bmatrix}\\)\n\\({\\bf W} @ {\\bf M}^\\top = \\begin{bmatrix} 1.7090 & 1.7089 & 1.1576 & 1.1822 & -1.2676 & -1.2678 & -1.7090 & -1.7824 \\\\ 1.6240 & 1.6254 & 1.1311 & 1.1517 & -1.2336 & -1.2308 & -1.6240 & -1.6914 \\\\ 1.2270 & 1.2737 & 1.8033 & 1.7341 & -1.8188 & -1.7254 & -1.2270 & -1.2062 \\\\ 1.1900 & 1.2390 & 1.8260 & 1.7520 & -1.8360 & -1.7380 & -1.1900 & -1.1640 \\\\ -1.1850 & -1.2345 & -1.8330 & -1.7580 & 1.8420 & 1.7430 & 1.1850 & 1.1580 \\\\ -1.2360 & -1.2846 & -1.8489 & -1.7763 & 1.8624 & 1.7652 & 1.2360 & 1.2126 \\\\ -1.6800 & -1.6800 & -1.1400 & -1.1640 & 1.2480 & 1.2480 & 1.6800 & 1.7520 \\\\ -1.6730 & -1.6723 & -1.1207 & -1.1459 & 1.2292 & 1.2306 & 1.6730 & 1.7458 \\\\ 0.2400 & 0.2440 & 0.2460 & 0.2420 & -0.2560 & -0.2480 & -0.2400 & -0.2440 \\end{bmatrix}\\)\n\\(\\begin{align*} bias =~& \\begin{bmatrix} 1.2100 \\\\ 1.2500 \\\\ 1.1000 \\\\ 1.1100 \\\\ 1.1200 \\\\ 1.1300 \\\\ 1.1400 \\\\ 1.1200 \\\\ 3.6000 \\end{bmatrix} +\\begin{bmatrix} 1.2000 & 1.1000 & 1.1100 & 1.2500 & 1.1800 & 1.1100 & 1.1500 & 1.1500 \\end{bmatrix}\\\\ \\\\ =~& \\begin{bmatrix} 2.4100 & 2.3100 & 2.3200 & 2.4600 & 2.3900 & 2.3200 & 2.3600 & 2.3600 \\\\ 2.4500 & 2.3500 & 2.3600 & 2.5000 & 2.4300 & 2.3600 & 2.4000 & 2.4000 \\\\ 2.3000 & 2.2000 & 2.2100 & 2.3500 & 2.2800 & 2.2100 & 2.2500 & 2.2500 \\\\ 2.3100 & 2.2100 & 2.2200 & 2.3600 & 2.2900 & 2.2200 & 2.2600 & 2.2600 \\\\ 2.3200 & 2.2200 & 2.2300 & 2.3700 & 2.3000 & 2.2300 & 2.2700 & 2.2700 \\\\ 2.3300 & 2.2300 & 2.2400 & 2.3800 & 2.3100 & 2.2400 & 2.2800 & 2.2800 \\\\ 2.3400 & 2.2400 & 2.2500 & 2.3900 & 2.3200 & 2.2500 & 2.2900 & 2.2900 \\\\ 2.3200 & 2.2200 & 2.2300 & 2.3700 & 2.3000 & 2.2300 & 2.2700 & 2.2700 \\\\ 4.8000 & 4.7000 & 4.7100 & 4.8500 & 4.7800 & 4.7100 & 4.7500 & 4.7500 \\end{bmatrix} \\end{align*}\\)\n\\({\\bf W} @ {\\bf M}^\\top + bias = \\begin{bmatrix} 4.1190 & 4.0189 & 3.4776 & 3.6422 & 1.1224 & 1.0522 & 0.6510 & 0.5776 \\\\ 4.0740 & 3.9754 & 3.4911 & 3.6517 & 1.1964 & 1.1292 & 0.7760 & 0.7086 \\\\ 3.5270 & 3.4737 & 4.0133 & 4.0841 & 0.4612 & 0.4846 & 1.0230 & 1.0438 \\\\ 3.5000 & 3.4490 & 4.0460 & 4.1120 & 0.4540 & 0.4820 & 1.0700 & 1.0960 \\\\ 1.1350 & 0.9855 & 0.3970 & 0.6120 & 4.1420 & 3.9730 & 3.4550 & 3.4280 \\\\ 1.0940 & 0.9454 & 0.3911 & 0.6037 & 4.1724 & 4.0052 & 3.5160 & 3.4926 \\\\ 0.6600 & 0.5600 & 1.1100 & 1.2260 & 3.5680 & 3.4980 & 3.9700 & 4.0420 \\\\ 0.6470 & 0.5477 & 1.1093 & 1.2241 & 3.5292 & 3.4606 & 3.9430 & 4.0158 \\\\ 5.0400 & 4.9440 & 4.9560 & 5.0920 & 4.5240 & 4.4620 & 4.5100 & 4.5060 \\end{bmatrix}\\)\n- \\({\\bf W} @ {\\bf M}^\\top + bias\\) 의 (1,1)의 원소값을 계산해보면 아래와 같다.\n\n옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의N성향\\(\\times\\)영식의N성향 \\(+\\) 옥순의매력 \\(+\\) 영식의매력 = 4.1190\n\\(1.220 \\times 1.2000 + 0.4900 \\times 0.5000 + 1.2100 + 2.4100 = 4.1190\\)\n\n- 궁합매트릭스: \\({\\bf W} @ {\\bf M}^\\top + bias\\)를 계산하면 (9,8) 인 행렬이 나올텐데 이 행렬의 \\((i,j)\\)의 원소는 \\(i\\)-th 여성출연자와 \\(j\\)-th 남성출연자가 얼마나 잘 맞는지를 나타내는 숫자가 된다. (숫자가 높을수록 잘 맞음) 편의상 이 수업에서는 이 매트릭스를 “궁합매트릭스” 라고 정의하자.\n- 주어진 자료와 우리가 임의로 만든 궁합매트릭스를 비교해보자.\n\nprint(f\"주어진자료:\\n{np.array(df_view)}\")\nprint(f\"궁합매트릭스:\\n{np.array(W @ M.T + b1 + b2.T).round(2)}\")\n\n주어진자료:\n[[ nan 4.02 3.45 3.42 0.84 1.12 0.43 0.49]\n [3.93 3.99 3.63 3.43 0.98 0.96 0.52  nan]\n [3.52 3.42 4.05 4.06 0.39  nan 0.93 0.99]\n [3.43 3.57  nan 3.95 0.56 0.52 0.89 0.89]\n [1.12  nan 0.59 0.43 4.01 4.16 3.52 3.38]\n [0.94 1.05 0.32 0.45 4.02 3.78  nan 3.54]\n [0.51 0.56 0.88 0.89 3.5  3.64 4.04 4.1 ]\n [0.48 0.51 1.03  nan 3.52 4.   3.82  nan]\n [4.85 4.82  nan 4.98 4.53 4.39 4.45 4.52]]\n궁합매트릭스:\n[[4.12 4.02 3.48 3.64 1.12 1.05 0.65 0.58]\n [4.07 3.98 3.49 3.65 1.2  1.13 0.78 0.71]\n [3.53 3.47 4.01 4.08 0.46 0.48 1.02 1.04]\n [3.5  3.45 4.05 4.11 0.45 0.48 1.07 1.1 ]\n [1.14 0.99 0.4  0.61 4.14 3.97 3.46 3.43]\n [1.09 0.95 0.39 0.6  4.17 4.01 3.52 3.49]\n [0.66 0.56 1.11 1.23 3.57 3.5  3.97 4.04]\n [0.65 0.55 1.11 1.22 3.53 3.46 3.94 4.02]\n [5.04 4.94 4.96 5.09 4.52 4.46 4.51 4.51]]\n\n\n- 우리의 전략\n\n\\({\\bf W} @ {\\bf M}^\\top + bias\\)의 값과 df_view 의 값이 nan을 제외한 곳에서 거의 비슷하게 되도록 \\({\\bf W}\\), \\({\\bf M}\\), \\(bias\\)를 잘 때려맞추면 되는것 아니야?\n1을 만족하는 \\({\\bf W}\\), \\({\\bf M}\\), \\(bias\\)를 찾았으면 그 숫자들을 이용하여 df_view의 nan 을 추정한다.\n\n- 따라서 모형은 아래와 같이 볼 수 있다.\n\\[{\\tt df\\_view} \\approx {\\bf W}@{\\bf M}^\\top + bias\\]\n- 아래의 정보를 참고하여 위의 수식을 다시 정리하면..\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nW\nM\n여성특징\n남성특징\nI궁합\nN궁합\nbias\nyhat\ny\n\n\n\n\n옥순(IN)\n영철(IN)\n1.22, 0.49\n1.22, 0.45\n1.48841\n0.22052\n2.313\n4.0189\n4.02\n\n\n옥순(IN)\n영호(IS)\n1.22, 0.49\n1.23, -0.7\n1.15764\n-0.34235\n2.326\n3.4776\n3.45\n\n\n…\n…\n…\n…\n…\n…\n\n\n\n\n\n하니(I)\n영식(IN)\n0.20, 0.00\n1.20, 0.5\n0.24\n0\n4.8\n5.04\n4.85\n\n\n…\n…\n…\n…\n…\n…\n\n\n\n\n\n\n1 1.22 *1.22 = 1.48842 0.49 * 0.45 = 0.22053 1.21+1.1 = 2.314 1.22 *1.23 = 1.50065 0.49 * -0.7 = -0.34236 1.21+1.11 = 2.32\n걱정1: 5.0이 넘는 값도 있네? 잘못잡으면 음수가 나올지도?\n걱정2: 저러한 yhat (4.0189, 3.4776, 5.04)을 만드는게 꼭 저 조합만 있는게 아님. 당장에 남성의 바이어스에 일괄적으로 -2를 넣고 여성의 바이어스에 일괄적으로 +2를 해도 성립함.\n\n- (걱정은 뒤로 하고) yhat \\(\\approx\\) y 를 만족하도록 해보자! (1) 아무 yhat 을 구한다. (2) yhat과 y가 비슷한 정도를 측정한다. (3) 더 적당한 yhat값을 update한다.\n\nyhat은 어떻게 구하지? (여성특징\\(\\otimes\\)남성특징).sum() + bias?\n그럼 여성특징,남성특징,여성bias(=여성매력),남성bias(=남성매력)는 어떻게 구하지?? 생각해보니까 데이터에서 주어진건 아니잖아??\n\n- 여성특징,남성특징, 여성bais,남성bais 를 어떻게 만들지?\n\n그전엔 어떻게 했지?? W을 보고 적당히 특징을 상상하고 여성특징,여성bias의 값을 때려넣음 + M를 보고 적당히 특징을 상상하고 남성특징, 남성bias의 값을 채워 넣음.\n자동화하려면? W \\(\\to\\) 여성특징, W \\(\\to\\) 여성bias, M \\(\\to\\) 남성특징, M \\(\\to\\) 남성bias 인 함수를 만들자.\n\n- 앞으로 할일1: 아래와 같은 함수들을 만들자.\n\n옥순 \\(\\to\\) 옥순의 특징 = (1.22, 0.49)\n옥순 \\(\\to\\) 옥순의 매력 = 1.22\n영철 \\(\\to\\) 영철의 특징 = (1.22, 0.45)\n영철 \\(\\to\\) 영철의 매력 = 1.22 …\n\n- 앞으로 할일2: 우리가 익숙한 셋팅 (step1~4)\n\n여성특징, 여성bias, 남성특징, 남성bias \\(\\to\\) yhat 를 수행\ny \\(\\approx\\) yhat 인지 체크: loss = loss_fn(yhat,y)\nloss.backward()\n더 나은 여성특징, 여성bias, 남성특징, 남성bias 로 update!"
  },
  {
    "objectID": "posts/10wk-2.html#c.-할일1의-구현",
    "href": "posts/10wk-2.html#c.-할일1의-구현",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "C. 할일1의 구현",
    "text": "C. 할일1의 구현\n- dataframe의 변형\n\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\ndf_train\n\n\n\n\n\n\n\n\nW\nM\ny\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n\n\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n\n\n59\n하니(I)\n상철(EN)\n4.53\n\n\n60\n하니(I)\n영수(EN)\n4.39\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n\n\n62\n하니(I)\n다호(ES)\n4.52\n\n\n\n\n63 rows × 3 columns\n\n\n\n- 이름을 숫자화\n\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\n\n\ndf_train['X1']= df_train['W'].map(w)\ndf_train['X2']= df_train['M'].map(m)\ndf_train\n\n\n\n\n\n\n\n\nW\nM\ny\nX1\nX2\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n4.02\n0\n1\n\n\n1\n옥순(IN)\n영호(IS)\n3.45\n0\n2\n\n\n2\n옥순(IN)\n광수(IS)\n3.42\n0\n3\n\n\n3\n옥순(IN)\n상철(EN)\n0.84\n0\n4\n\n\n4\n옥순(IN)\n영수(EN)\n1.12\n0\n5\n\n\n...\n...\n...\n...\n...\n...\n\n\n58\n하니(I)\n광수(IS)\n4.98\n8\n3\n\n\n59\n하니(I)\n상철(EN)\n4.53\n8\n4\n\n\n60\n하니(I)\n영수(EN)\n4.39\n8\n5\n\n\n61\n하니(I)\n규빈(ES)\n4.45\n8\n6\n\n\n62\n하니(I)\n다호(ES)\n4.52\n8\n7\n\n\n\n\n63 rows × 5 columns\n\n\n\n- 텐서화 + one_hot-인코딩\n\nX1 = torch.tensor(df_train['X1'])\nX2 = torch.tensor(df_train['X2'])\nE1 = torch.nn.functional.one_hot(X1).float()\nE2 = torch.nn.functional.one_hot(X2).float()\n\n\nprint(f\"y.shape: {y.shape},\\t y.dtype: {y.dtype}\")\nprint(f\"X1.shape: {X1.shape},\\t X1.dtype: {X1.dtype} // X1.unique: {X1.unique()}\")\nprint(f\"X2.shape: {X2.shape},\\t X2.dtype: {X2.dtype} // X2.unique: {X2.unique()}\")\nprint(f\"E1.shape: {E1.shape},\\t E1.dtype: {E1.dtype} -- shape에서 9는 여성이 9명이라는 의미\")\nprint(f\"E2.shape: {E2.shape},\\t E2.dtype: {E2.dtype} -- shape에서 8은 남성이 8명이라는 의미\")\n\ny.shape: torch.Size([63, 1]),    y.dtype: torch.float32\nX1.shape: torch.Size([63]),  X1.dtype: torch.int64 // X1.unique: tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\nX2.shape: torch.Size([63]),  X2.dtype: torch.int64 // X2.unique: tensor([0, 1, 2, 3, 4, 5, 6, 7])\nE1.shape: torch.Size([63, 9]),   E1.dtype: torch.float32 -- shape에서 9는 여성이 9명이라는 의미\nE2.shape: torch.Size([63, 8]),   E2.dtype: torch.float32 -- shape에서 8은 남성이 8명이라는 의미\n\n\n- X1 -&gt; 여성특징, X1 -&gt; 여성bias, X2 -&gt; 남성특징, X2 -&gt; 남성bias 구현\n\nl1 = torch.nn.Linear(in_features=9, out_features=2, bias=False) # \"E1-&gt;여성특징\"인 함수 \nb1 = torch.nn.Linear(in_features=9, out_features=1, bias=False) # \"E1-&gt;여성bias\"인 함수 \nl2 = torch.nn.Linear(in_features=8, out_features=2, bias=False) # \"E2-&gt;남성특징\"인 함수 \nb2 = torch.nn.Linear(in_features=8, out_features=1, bias=False) # \"E2-&gt;남성bias\"인 함수"
  },
  {
    "objectID": "posts/10wk-2.html#d.-할일2의-구현-step14-수행",
    "href": "posts/10wk-2.html#d.-할일2의-구현-step14-수행",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "D. 할일2의 구현 – step1~4 수행",
    "text": "D. 할일2의 구현 – step1~4 수행\n- step1: yhat을 구하자.\n\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=9, out_features=2, bias=False) # \"E1-&gt;여성특징\"인 함수 \nb1 = torch.nn.Linear(in_features=9, out_features=1, bias=False) # \"E1-&gt;여성bias\"인 함수 \nl2 = torch.nn.Linear(in_features=8, out_features=2, bias=False) # \"E2-&gt;남성특징\"인 함수 \nb2 = torch.nn.Linear(in_features=8, out_features=1, bias=False) # \"E2-&gt;남성bias\"인 함수 \nW_features = l1(E1) # l1(onehot(X1))\nW_bias = b1(E1) # b1(onehot(X1))\nM_features = l2(E2) # l2(onehot(X2))\nM_bias = b2(E2) # b2(onehot(X2))\n\n\nsig = torch.nn.Sigmoid()\nscore = (W_features*M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias\nyhat = sig(score)*5\n\n- step2: 손실계산\n\nloss_fn = torch.nn.MSELoss()\nloss = loss_fn(yhat,y)\n\n- step3: 미분\n(미분전)\n\nl1.weight.data, b1.weight.data, l2.weight.data, b2.weight.data\n\n(tensor([[-0.1156, -0.2823,  0.1201,  0.3112,  0.1358, -0.2962,  0.1086, -0.2071,\n          -0.0864],\n         [ 0.2082,  0.3231, -0.1724, -0.2224,  0.0670,  0.1536, -0.0552,  0.2843,\n          -0.1426]]),\n tensor([[-0.0210,  0.3022, -0.0259,  0.1251, -0.2812,  0.2052,  0.1129, -0.2435,\n           0.2790]]),\n tensor([[ 0.1425,  0.0621,  0.1415, -0.0449,  0.2502, -0.2042, -0.0980,  0.3091],\n         [-0.1902, -0.0075,  0.2070,  0.2928,  0.1697,  0.0928,  0.0474, -0.2111]]),\n tensor([[ 0.3028, -0.1884,  0.2234, -0.1377, -0.3145,  0.0662, -0.2995,  0.1305]]))\n\n\n\nl1.weight.grad, b1.weight.grad, l2.weight.grad, b2.weight.grad\n\n(None, None, None, None)\n\n\n(미분)\n\nloss.backward()\n\n(미분후)\n\nl1.weight.data, b1.weight.data, l2.weight.data, b2.weight.data\n\n(tensor([[-0.1156, -0.2823,  0.1201,  0.3112,  0.1358, -0.2962,  0.1086, -0.2071,\n          -0.0864],\n         [ 0.2082,  0.3231, -0.1724, -0.2224,  0.0670,  0.1536, -0.0552,  0.2843,\n          -0.1426]]),\n tensor([[-0.0210,  0.3022, -0.0259,  0.1251, -0.2812,  0.2052,  0.1129, -0.2435,\n           0.2790]]),\n tensor([[ 0.1425,  0.0621,  0.1415, -0.0449,  0.2502, -0.2042, -0.0980,  0.3091],\n         [-0.1902, -0.0075,  0.2070,  0.2928,  0.1697,  0.0928,  0.0474, -0.2111]]),\n tensor([[ 0.3028, -0.1884,  0.2234, -0.1377, -0.3145,  0.0662, -0.2995,  0.1305]]))\n\n\n\nl1.weight.grad, b1.weight.grad, l2.weight.grad, b2.weight.grad\n\n(tensor([[ 0.0125, -0.0184,  0.0226,  0.0183,  0.0050,  0.0058,  0.0141,  0.0276,\n          -0.0295],\n         [-0.0172,  0.0171, -0.0282, -0.0106,  0.0072,  0.0231,  0.0107, -0.0233,\n          -0.0265]]),\n tensor([[ 0.1172,  0.0943, -0.0167,  0.1680, -0.0704,  0.1955,  0.1052, -0.0075,\n          -0.5161]]),\n tensor([[-0.0145, -0.0087, -0.0224, -0.0196,  0.0313,  0.0104, -0.0032,  0.0270],\n         [ 0.0383,  0.0184,  0.0313,  0.0375, -0.0164,  0.0008,  0.0108, -0.0092]]),\n tensor([[ 0.1859, -0.1176,  0.2194, -0.0823, -0.1017, -0.0458, -0.0408,  0.0526]]))\n\n\n- step4: update\n(옵티마이저 선언)\n\nparams = list(l1.parameters())+list(l2.parameters())+list(b1.parameters())+list(b2.parameters())\noptimizr = torch.optim.Adam(params, lr=0.1) \n\n(update전)\n\nl1.weight.data, b1.weight.data, l2.weight.data, b2.weight.data\n\n(tensor([[-0.1156, -0.2823,  0.1201,  0.3112,  0.1358, -0.2962,  0.1086, -0.2071,\n          -0.0864],\n         [ 0.2082,  0.3231, -0.1724, -0.2224,  0.0670,  0.1536, -0.0552,  0.2843,\n          -0.1426]]),\n tensor([[-0.0210,  0.3022, -0.0259,  0.1251, -0.2812,  0.2052,  0.1129, -0.2435,\n           0.2790]]),\n tensor([[ 0.1425,  0.0621,  0.1415, -0.0449,  0.2502, -0.2042, -0.0980,  0.3091],\n         [-0.1902, -0.0075,  0.2070,  0.2928,  0.1697,  0.0928,  0.0474, -0.2111]]),\n tensor([[ 0.3028, -0.1884,  0.2234, -0.1377, -0.3145,  0.0662, -0.2995,  0.1305]]))\n\n\n\nl1.weight.grad, b1.weight.grad, l2.weight.grad, b2.weight.grad\n\n(tensor([[ 0.0125, -0.0184,  0.0226,  0.0183,  0.0050,  0.0058,  0.0141,  0.0276,\n          -0.0295],\n         [-0.0172,  0.0171, -0.0282, -0.0106,  0.0072,  0.0231,  0.0107, -0.0233,\n          -0.0265]]),\n tensor([[ 0.1172,  0.0943, -0.0167,  0.1680, -0.0704,  0.1955,  0.1052, -0.0075,\n          -0.5161]]),\n tensor([[-0.0145, -0.0087, -0.0224, -0.0196,  0.0313,  0.0104, -0.0032,  0.0270],\n         [ 0.0383,  0.0184,  0.0313,  0.0375, -0.0164,  0.0008,  0.0108, -0.0092]]),\n tensor([[ 0.1859, -0.1176,  0.2194, -0.0823, -0.1017, -0.0458, -0.0408,  0.0526]]))\n\n\n(update)\n\noptimizr.step()\n\n(update후)\n\nl1.weight.data, b1.weight.data, l2.weight.data, b2.weight.data\n\n(tensor([[-0.2156, -0.1823,  0.0201,  0.2112,  0.0358, -0.3962,  0.0086, -0.3071,\n           0.0136],\n         [ 0.3082,  0.2231, -0.0724, -0.1224, -0.0330,  0.0536, -0.1552,  0.3843,\n          -0.0426]]),\n tensor([[-0.1210,  0.2022,  0.0741,  0.0251, -0.1812,  0.1052,  0.0129, -0.1435,\n           0.3790]]),\n tensor([[ 0.2425,  0.1621,  0.2415,  0.0551,  0.1502, -0.3042,  0.0020,  0.2091],\n         [-0.2902, -0.1075,  0.1070,  0.1928,  0.2697, -0.0072, -0.0526, -0.1111]]),\n tensor([[ 0.2028, -0.0884,  0.1234, -0.0377, -0.2145,  0.1662, -0.1995,  0.0305]]))\n\n\n\nl1.weight.grad, b1.weight.grad, l2.weight.grad, b2.weight.grad\n\n(tensor([[ 0.0125, -0.0184,  0.0226,  0.0183,  0.0050,  0.0058,  0.0141,  0.0276,\n          -0.0295],\n         [-0.0172,  0.0171, -0.0282, -0.0106,  0.0072,  0.0231,  0.0107, -0.0233,\n          -0.0265]]),\n tensor([[ 0.1172,  0.0943, -0.0167,  0.1680, -0.0704,  0.1955,  0.1052, -0.0075,\n          -0.5161]]),\n tensor([[-0.0145, -0.0087, -0.0224, -0.0196,  0.0313,  0.0104, -0.0032,  0.0270],\n         [ 0.0383,  0.0184,  0.0313,  0.0375, -0.0164,  0.0008,  0.0108, -0.0092]]),\n tensor([[ 0.1859, -0.1176,  0.2194, -0.0823, -0.1017, -0.0458, -0.0408,  0.0526]]))\n\n\n(zero_grad)\n\noptimizr.zero_grad()\n\n(zero_grad후)\n\nl1.weight.data, b1.weight.data, l2.weight.data, b2.weight.data\n\n(tensor([[-0.2156, -0.1823,  0.0201,  0.2112,  0.0358, -0.3962,  0.0086, -0.3071,\n           0.0136],\n         [ 0.3082,  0.2231, -0.0724, -0.1224, -0.0330,  0.0536, -0.1552,  0.3843,\n          -0.0426]]),\n tensor([[-0.1210,  0.2022,  0.0741,  0.0251, -0.1812,  0.1052,  0.0129, -0.1435,\n           0.3790]]),\n tensor([[ 0.2425,  0.1621,  0.2415,  0.0551,  0.1502, -0.3042,  0.0020,  0.2091],\n         [-0.2902, -0.1075,  0.1070,  0.1928,  0.2697, -0.0072, -0.0526, -0.1111]]),\n tensor([[ 0.2028, -0.0884,  0.1234, -0.0377, -0.2145,  0.1662, -0.1995,  0.0305]]))\n\n\n\nl1.weight.grad, b1.weight.grad, l2.weight.grad, b2.weight.grad\n\n(None, None, None, None)"
  },
  {
    "objectID": "posts/10wk-2.html#e.-코드정리",
    "href": "posts/10wk-2.html#e.-코드정리",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "E. 코드정리",
    "text": "E. 코드정리\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.tensor(df_train['W'].map(w)) # length-n vector \nX2 = torch.tensor(df_train['M'].map(m)) # length-n vector \nE1 = torch.nn.functional.one_hot(X1).float()\nE2 = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df_train['y']).float().reshape(-1,1)\n#--#\ntorch.manual_seed(43052)\nl1 = torch.nn.Linear(in_features=9, out_features=2, bias=False)\nb1 = torch.nn.Linear(in_features=9, out_features=1, bias=False)\nl2 = torch.nn.Linear(in_features=8, out_features=2, bias=False)\nb2 = torch.nn.Linear(in_features=8, out_features=1, bias=False)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.MSELoss()\nparams = list(l1.parameters())+list(b1.parameters())+list(l2.parameters())+list(b2.parameters())\noptimizr = torch.optim.Adam(params, lr=0.1) \n#--#\nfor epoc in range(100):\n    ## step1 \n    W_features = l1(E1)\n    W_bias = b1(E1)\n    M_features = l2(E2) \n    M_bias = b2(E2)\n    score = (W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias\n    yhat = sig(score) * 5 \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\ntorch.concat([yhat,y],axis=1)[::4] # 꽤 잘맞음\n\ntensor([[4.0679, 4.0200],\n        [0.9554, 1.1200],\n        [3.9950, 3.9900],\n        [0.9580, 0.9600],\n        [4.1490, 4.0500],\n        [0.9765, 0.9900],\n        [0.5392, 0.5600],\n        [1.1028, 1.1200],\n        [4.1009, 4.1600],\n        [0.9950, 1.0500],\n        [3.9835, 3.7800],\n        [0.9398, 0.8800],\n        [3.9916, 4.0400],\n        [0.9030, 1.0300],\n        [4.8949, 4.8500],\n        [4.5048, 4.3900]], grad_fn=&lt;SliceBackward0&gt;)"
  },
  {
    "objectID": "posts/10wk-2.html#f.-모형의-해석-쉬운경우",
    "href": "posts/10wk-2.html#f.-모형의-해석-쉬운경우",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "F. 모형의 해석 – 쉬운경우",
    "text": "F. 모형의 해석 – 쉬운경우\n\ndf_match = pd.DataFrame((W_features*M_features).data).set_axis(['잠재특징궁합1','잠재특징궁합2'],axis=1)\ndf_bias = pd.DataFrame(torch.concat([W_bias, M_bias],axis=1).data).set_axis(['여성bias','남성bias'],axis=1)\ndf_features = pd.concat([df_train.loc[:,'W':'M'],df_match,df_bias],axis=1)\ndf_features[:56]\n\n\n\n\n\n\n\n\nW\nM\n잠재특징궁합1\n잠재특징궁합2\n여성bias\n남성bias\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n0.302724\n1.411065\n-0.983853\n0.705386\n\n\n1\n옥순(IN)\n영호(IS)\n0.743988\n0.439198\n-0.983853\n0.618197\n\n\n2\n옥순(IN)\n광수(IS)\n0.776415\n0.382274\n-0.983853\n0.545838\n\n\n3\n옥순(IN)\n상철(EN)\n-0.992729\n-0.430939\n-0.983853\n0.886856\n\n\n4\n옥순(IN)\n영수(EN)\n-0.942706\n-0.539754\n-0.983853\n1.032223\n\n\n5\n옥순(IN)\n규빈(ES)\n-0.569901\n-1.434720\n-0.983853\n0.853764\n\n\n6\n옥순(IN)\n다호(ES)\n-0.556357\n-1.467226\n-0.983853\n0.944640\n\n\n7\n영자(IN)\n영식(IN)\n0.323436\n1.356050\n-0.930421\n0.651731\n\n\n8\n영자(IN)\n영철(IN)\n0.324665\n1.285471\n-0.930421\n0.705386\n\n\n9\n영자(IN)\n영호(IS)\n0.797912\n0.400107\n-0.930421\n0.618197\n\n\n10\n영자(IN)\n광수(IS)\n0.832689\n0.348249\n-0.930421\n0.545838\n\n\n11\n영자(IN)\n상철(EN)\n-1.064682\n-0.392583\n-0.930421\n0.886856\n\n\n12\n영자(IN)\n영수(EN)\n-1.011034\n-0.491713\n-0.930421\n1.032223\n\n\n13\n영자(IN)\n규빈(ES)\n-0.611208\n-1.307021\n-0.930421\n0.853764\n\n\n14\n정숙(IS)\n영식(IN)\n0.659914\n0.304652\n-0.846774\n0.651731\n\n\n15\n정숙(IS)\n영철(IN)\n0.662421\n0.288796\n-0.846774\n0.705386\n\n\n16\n정숙(IS)\n영호(IS)\n1.627999\n0.089888\n-0.846774\n0.618197\n\n\n17\n정숙(IS)\n광수(IS)\n1.698955\n0.078238\n-0.846774\n0.545838\n\n\n18\n정숙(IS)\n상철(EN)\n-2.172296\n-0.088198\n-0.846774\n0.886856\n\n\n19\n정숙(IS)\n규빈(ES)\n-1.247061\n-0.293637\n-0.846774\n0.853764\n\n\n20\n정숙(IS)\n다호(ES)\n-1.217423\n-0.300290\n-0.846774\n0.944640\n\n\n21\n영숙(IS)\n영식(IN)\n0.628118\n0.407719\n-0.884238\n0.651731\n\n\n22\n영숙(IS)\n영철(IN)\n0.630504\n0.386498\n-0.884238\n0.705386\n\n\n23\n영숙(IS)\n광수(IS)\n1.617095\n0.104707\n-0.884238\n0.545838\n\n\n24\n영숙(IS)\n상철(EN)\n-2.067629\n-0.118037\n-0.884238\n0.886856\n\n\n25\n영숙(IS)\n영수(EN)\n-1.963442\n-0.147842\n-0.884238\n1.032223\n\n\n26\n영숙(IS)\n규빈(ES)\n-1.186974\n-0.392978\n-0.884238\n0.853764\n\n\n27\n영숙(IS)\n다호(ES)\n-1.158764\n-0.401881\n-0.884238\n0.944640\n\n\n28\n순자(EN)\n영식(IN)\n-0.553524\n-0.133968\n-1.260765\n0.651731\n\n\n29\n순자(EN)\n영호(IS)\n-1.365535\n-0.039528\n-1.260765\n0.618197\n\n\n30\n순자(EN)\n광수(IS)\n-1.425051\n-0.034405\n-1.260765\n0.545838\n\n\n31\n순자(EN)\n상철(EN)\n1.822081\n0.038784\n-1.260765\n0.886856\n\n\n32\n순자(EN)\n영수(EN)\n1.730267\n0.048578\n-1.260765\n1.032223\n\n\n33\n순자(EN)\n규빈(ES)\n1.046011\n0.129124\n-1.260765\n0.853764\n\n\n34\n순자(EN)\n다호(ES)\n1.021151\n0.132050\n-1.260765\n0.944640\n\n\n35\n현숙(EN)\n영식(IN)\n-0.521171\n-0.265791\n-1.371327\n0.651731\n\n\n36\n현숙(EN)\n영철(IN)\n-0.523151\n-0.251958\n-1.371327\n0.705386\n\n\n37\n현숙(EN)\n영호(IS)\n-1.285721\n-0.078422\n-1.371327\n0.618197\n\n\n38\n현숙(EN)\n광수(IS)\n-1.341758\n-0.068258\n-1.371327\n0.545838\n\n\n39\n현숙(EN)\n상철(EN)\n1.715582\n0.076948\n-1.371327\n0.886856\n\n\n40\n현숙(EN)\n영수(EN)\n1.629135\n0.096378\n-1.371327\n1.032223\n\n\n41\n현숙(EN)\n다호(ES)\n0.961466\n0.261986\n-1.371327\n0.944640\n\n\n42\n서연(ES)\n영식(IN)\n-0.218469\n-1.394457\n-1.191920\n0.651731\n\n\n43\n서연(ES)\n영철(IN)\n-0.219299\n-1.321879\n-1.191920\n0.705386\n\n\n44\n서연(ES)\n영호(IS)\n-0.538959\n-0.411439\n-1.191920\n0.618197\n\n\n45\n서연(ES)\n광수(IS)\n-0.562449\n-0.358112\n-1.191920\n0.545838\n\n\n46\n서연(ES)\n상철(EN)\n0.719152\n0.403702\n-1.191920\n0.886856\n\n\n47\n서연(ES)\n영수(EN)\n0.682914\n0.505639\n-1.191920\n1.032223\n\n\n48\n서연(ES)\n규빈(ES)\n0.412847\n1.344040\n-1.191920\n0.853764\n\n\n49\n서연(ES)\n다호(ES)\n0.403035\n1.374491\n-1.191920\n0.944640\n\n\n50\n보람(ES)\n영식(IN)\n-0.269182\n-1.233859\n-1.178461\n0.651731\n\n\n51\n보람(ES)\n영철(IN)\n-0.270204\n-1.169639\n-1.178461\n0.705386\n\n\n52\n보람(ES)\n영호(IS)\n-0.664067\n-0.364054\n-1.178461\n0.618197\n\n\n53\n보람(ES)\n상철(EN)\n0.886088\n0.357208\n-1.178461\n0.886856\n\n\n54\n보람(ES)\n영수(EN)\n0.841439\n0.447405\n-1.178461\n1.032223\n\n\n55\n보람(ES)\n규빈(ES)\n0.508681\n1.189248\n-1.178461\n0.853764\n\n\n\n\n\n\n\n\ndf_features[56:]\n\n\n\n\n\n\n\n\nW\nM\n잠재특징궁합1\n잠재특징궁합2\n여성bias\n남성bias\n\n\n\n\n56\n하니(I)\n영식(IN)\n0.209820\n0.540235\n2.115016\n0.651731\n\n\n57\n하니(I)\n영철(IN)\n0.210617\n0.512117\n2.115016\n0.705386\n\n\n58\n하니(I)\n광수(IS)\n0.540183\n0.138738\n2.115016\n0.545838\n\n\n59\n하니(I)\n상철(EN)\n-0.690681\n-0.156401\n2.115016\n0.886856\n\n\n60\n하니(I)\n영수(EN)\n-0.655878\n-0.195893\n2.115016\n1.032223\n\n\n61\n하니(I)\n규빈(ES)\n-0.396503\n-0.520703\n2.115016\n0.853764\n\n\n62\n하니(I)\n다호(ES)\n-0.387079\n-0.532500\n2.115016\n0.944640"
  },
  {
    "objectID": "posts/10wk-2.html#g.-모형의-해석-어려운-경우",
    "href": "posts/10wk-2.html#g.-모형의-해석-어려운-경우",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "G. 모형의 해석 – 어려운 경우",
    "text": "G. 모형의 해석 – 어려운 경우\n- 적합을 시켜보자.\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\ndf_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\nw = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\nm = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\nX1 = torch.tensor(df_train['W'].map(w)) # length-n vector \nX2 = torch.tensor(df_train['M'].map(m)) # length-n vector \nE1 = torch.nn.functional.one_hot(X1).float()\nE2 = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df_train['y']).float().reshape(-1,1)\n#--#\ntorch.manual_seed(8)\nl1 = torch.nn.Linear(in_features=9, out_features=2, bias=False)\nb1 = torch.nn.Linear(in_features=9, out_features=1, bias=False)\nl2 = torch.nn.Linear(in_features=8, out_features=2, bias=False)\nb2 = torch.nn.Linear(in_features=8, out_features=1, bias=False)\nsig = torch.nn.Sigmoid()\nloss_fn = torch.nn.MSELoss()\nparams = list(l1.parameters())+list(b1.parameters())+list(l2.parameters())+list(b2.parameters())\noptimizr = torch.optim.Adam(params, lr=0.1) \n#--#\nfor epoc in range(100):\n    ## step1 \n    W_features = l1(E1)\n    W_bias = b1(E1)\n    M_features = l2(E2) \n    M_bias = b2(E2)\n    score = (W_features * M_features).sum(axis=1).reshape(-1,1) + W_bias + M_bias\n    yhat = sig(score) * 5 \n    ## step2 \n    loss = loss_fn(yhat,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 잘 맞추는듯\n\ntorch.concat([yhat,y],axis=1)[::4] # 꽤 잘맞음\n\ntensor([[4.0386, 4.0200],\n        [0.9623, 1.1200],\n        [3.9990, 3.9900],\n        [0.9883, 0.9600],\n        [4.0799, 4.0500],\n        [0.9734, 0.9900],\n        [0.5064, 0.5600],\n        [1.0738, 1.1200],\n        [4.1248, 4.1600],\n        [0.9569, 1.0500],\n        [4.0001, 3.7800],\n        [0.8943, 0.8800],\n        [4.0257, 4.0400],\n        [0.8481, 1.0300],\n        [4.8558, 4.8500],\n        [4.5425, 4.3900]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 해석을 해보자.\n\ndf_match = pd.DataFrame((W_features*M_features).data).set_axis(['잠재특징궁합1','잠재특징궁합2'],axis=1)\ndf_bias = pd.DataFrame(torch.concat([W_bias, M_bias],axis=1).data).set_axis(['여성bias','남성bias'],axis=1)\ndf_features = pd.concat([df_train.loc[:,'W':'M'],df_match,df_bias],axis=1)\ndf_features[:56]\n\n\n\n\n\n\n\n\nW\nM\n잠재특징궁합1\n잠재특징궁합2\n여성bias\n남성bias\n\n\n\n\n0\n옥순(IN)\n영철(IN)\n0.302724\n1.411065\n-0.983853\n0.705386\n\n\n1\n옥순(IN)\n영호(IS)\n0.743988\n0.439198\n-0.983853\n0.618197\n\n\n2\n옥순(IN)\n광수(IS)\n0.776415\n0.382274\n-0.983853\n0.545838\n\n\n3\n옥순(IN)\n상철(EN)\n-0.992729\n-0.430939\n-0.983853\n0.886856\n\n\n4\n옥순(IN)\n영수(EN)\n-0.942706\n-0.539754\n-0.983853\n1.032223\n\n\n5\n옥순(IN)\n규빈(ES)\n-0.569901\n-1.434720\n-0.983853\n0.853764\n\n\n6\n옥순(IN)\n다호(ES)\n-0.556357\n-1.467226\n-0.983853\n0.944640\n\n\n7\n영자(IN)\n영식(IN)\n0.323436\n1.356050\n-0.930421\n0.651731\n\n\n8\n영자(IN)\n영철(IN)\n0.324665\n1.285471\n-0.930421\n0.705386\n\n\n9\n영자(IN)\n영호(IS)\n0.797912\n0.400107\n-0.930421\n0.618197\n\n\n10\n영자(IN)\n광수(IS)\n0.832689\n0.348249\n-0.930421\n0.545838\n\n\n11\n영자(IN)\n상철(EN)\n-1.064682\n-0.392583\n-0.930421\n0.886856\n\n\n12\n영자(IN)\n영수(EN)\n-1.011034\n-0.491713\n-0.930421\n1.032223\n\n\n13\n영자(IN)\n규빈(ES)\n-0.611208\n-1.307021\n-0.930421\n0.853764\n\n\n14\n정숙(IS)\n영식(IN)\n0.659914\n0.304652\n-0.846774\n0.651731\n\n\n15\n정숙(IS)\n영철(IN)\n0.662421\n0.288796\n-0.846774\n0.705386\n\n\n16\n정숙(IS)\n영호(IS)\n1.627999\n0.089888\n-0.846774\n0.618197\n\n\n17\n정숙(IS)\n광수(IS)\n1.698955\n0.078238\n-0.846774\n0.545838\n\n\n18\n정숙(IS)\n상철(EN)\n-2.172296\n-0.088198\n-0.846774\n0.886856\n\n\n19\n정숙(IS)\n규빈(ES)\n-1.247061\n-0.293637\n-0.846774\n0.853764\n\n\n20\n정숙(IS)\n다호(ES)\n-1.217423\n-0.300290\n-0.846774\n0.944640\n\n\n21\n영숙(IS)\n영식(IN)\n0.628118\n0.407719\n-0.884238\n0.651731\n\n\n22\n영숙(IS)\n영철(IN)\n0.630504\n0.386498\n-0.884238\n0.705386\n\n\n23\n영숙(IS)\n광수(IS)\n1.617095\n0.104707\n-0.884238\n0.545838\n\n\n24\n영숙(IS)\n상철(EN)\n-2.067629\n-0.118037\n-0.884238\n0.886856\n\n\n25\n영숙(IS)\n영수(EN)\n-1.963442\n-0.147842\n-0.884238\n1.032223\n\n\n26\n영숙(IS)\n규빈(ES)\n-1.186974\n-0.392978\n-0.884238\n0.853764\n\n\n27\n영숙(IS)\n다호(ES)\n-1.158764\n-0.401881\n-0.884238\n0.944640\n\n\n28\n순자(EN)\n영식(IN)\n-0.553524\n-0.133968\n-1.260765\n0.651731\n\n\n29\n순자(EN)\n영호(IS)\n-1.365535\n-0.039528\n-1.260765\n0.618197\n\n\n30\n순자(EN)\n광수(IS)\n-1.425051\n-0.034405\n-1.260765\n0.545838\n\n\n31\n순자(EN)\n상철(EN)\n1.822081\n0.038784\n-1.260765\n0.886856\n\n\n32\n순자(EN)\n영수(EN)\n1.730267\n0.048578\n-1.260765\n1.032223\n\n\n33\n순자(EN)\n규빈(ES)\n1.046011\n0.129124\n-1.260765\n0.853764\n\n\n34\n순자(EN)\n다호(ES)\n1.021151\n0.132050\n-1.260765\n0.944640\n\n\n35\n현숙(EN)\n영식(IN)\n-0.521171\n-0.265791\n-1.371327\n0.651731\n\n\n36\n현숙(EN)\n영철(IN)\n-0.523151\n-0.251958\n-1.371327\n0.705386\n\n\n37\n현숙(EN)\n영호(IS)\n-1.285721\n-0.078422\n-1.371327\n0.618197\n\n\n38\n현숙(EN)\n광수(IS)\n-1.341758\n-0.068258\n-1.371327\n0.545838\n\n\n39\n현숙(EN)\n상철(EN)\n1.715582\n0.076948\n-1.371327\n0.886856\n\n\n40\n현숙(EN)\n영수(EN)\n1.629135\n0.096378\n-1.371327\n1.032223\n\n\n41\n현숙(EN)\n다호(ES)\n0.961466\n0.261986\n-1.371327\n0.944640\n\n\n42\n서연(ES)\n영식(IN)\n-0.218469\n-1.394457\n-1.191920\n0.651731\n\n\n43\n서연(ES)\n영철(IN)\n-0.219299\n-1.321879\n-1.191920\n0.705386\n\n\n44\n서연(ES)\n영호(IS)\n-0.538959\n-0.411439\n-1.191920\n0.618197\n\n\n45\n서연(ES)\n광수(IS)\n-0.562449\n-0.358112\n-1.191920\n0.545838\n\n\n46\n서연(ES)\n상철(EN)\n0.719152\n0.403702\n-1.191920\n0.886856\n\n\n47\n서연(ES)\n영수(EN)\n0.682914\n0.505639\n-1.191920\n1.032223\n\n\n48\n서연(ES)\n규빈(ES)\n0.412847\n1.344040\n-1.191920\n0.853764\n\n\n49\n서연(ES)\n다호(ES)\n0.403035\n1.374491\n-1.191920\n0.944640\n\n\n50\n보람(ES)\n영식(IN)\n-0.269182\n-1.233859\n-1.178461\n0.651731\n\n\n51\n보람(ES)\n영철(IN)\n-0.270204\n-1.169639\n-1.178461\n0.705386\n\n\n52\n보람(ES)\n영호(IS)\n-0.664067\n-0.364054\n-1.178461\n0.618197\n\n\n53\n보람(ES)\n상철(EN)\n0.886088\n0.357208\n-1.178461\n0.886856\n\n\n54\n보람(ES)\n영수(EN)\n0.841439\n0.447405\n-1.178461\n1.032223\n\n\n55\n보람(ES)\n규빈(ES)\n0.508681\n1.189248\n-1.178461\n0.853764\n\n\n\n\n\n\n\n\ndf_features[56:]\n\n\n\n\n\n\n\n\nW\nM\n잠재특징궁합1\n잠재특징궁합2\n여성bias\n남성bias\n\n\n\n\n56\n하니(I)\n영식(IN)\n0.209820\n0.540235\n2.115016\n0.651731\n\n\n57\n하니(I)\n영철(IN)\n0.210617\n0.512117\n2.115016\n0.705386\n\n\n58\n하니(I)\n광수(IS)\n0.540183\n0.138738\n2.115016\n0.545838\n\n\n59\n하니(I)\n상철(EN)\n-0.690681\n-0.156401\n2.115016\n0.886856\n\n\n60\n하니(I)\n영수(EN)\n-0.655878\n-0.195893\n2.115016\n1.032223\n\n\n61\n하니(I)\n규빈(ES)\n-0.396503\n-0.520703\n2.115016\n0.853764\n\n\n62\n하니(I)\n다호(ES)\n-0.387079\n-0.532500\n2.115016\n0.944640\n\n\n\n\n\n\n\n\nI보다 E성향 남성이 좀 더 인기 있음.\nE보다 I성향 여성이 좀 더 인기 있음.\n궁합1: (IN, IN) = 0.3 // (IN, IS) = 0.8 // (IN, EN) = -1.0 // (IN, ES) = -0.5\n궁합2: (IN, IN) = 1.4 // (IN, IS) = 0.4 // (IN, EN) = -0.4 // (IN, ES) = -1.4\n\n\ndf_features[df_features.W.str.contains('IN') & df_features.M.str.contains('ES')]\n\n\n\n\n\n\n\n\nW\nM\n잠재특징궁합1\n잠재특징궁합2\n여성bias\n남성bias\n\n\n\n\n5\n옥순(IN)\n규빈(ES)\n-0.569901\n-1.434720\n-0.983853\n0.853764\n\n\n6\n옥순(IN)\n다호(ES)\n-0.556357\n-1.467226\n-0.983853\n0.944640\n\n\n13\n영자(IN)\n규빈(ES)\n-0.611208\n-1.307021\n-0.930421\n0.853764"
  },
  {
    "objectID": "posts/10wk-2.html#h.-nan-에-대한-예측-숙제",
    "href": "posts/10wk-2.html#h.-nan-에-대한-예측-숙제",
    "title": "10wk-2: 추천시스템 (1) – optimizer 사용 고급, MF-based 추천시스템",
    "section": "H. NaN 에 대한 예측 – 숙제",
    "text": "H. NaN 에 대한 예측 – 숙제"
  },
  {
    "objectID": "posts/15wk-1.html#a.-collections.deque",
    "href": "posts/15wk-1.html#a.-collections.deque",
    "title": "15wk-1: 강화학습 (4) – LunarLander, A1, A2",
    "section": "A. collections.deque",
    "text": "A. collections.deque\n- collections.deque 의 기능\n\na = collections.deque([12,21,33], maxlen = 5)\na\n\ndeque([12, 21, 33], maxlen=5)\n\n\n\na.append(44)\na\n\ndeque([12, 21, 33, 44], maxlen=5)\n\n\n\na.append(55)\na\n\ndeque([12, 21, 33, 44, 55], maxlen=5)\n\n\n\na.append(-66)\na\n\ndeque([21, 33, 44, 55, -66], maxlen=5)\n\n\n\na.append(-40)\na\n\ndeque([33, 44, 55, -66, -40], maxlen=5)\n\n\n- 단점? numpy array 보다는 list 느낌임 (연산에 특화된건 아님)\n\na + 1\n\nTypeError: can only concatenate deque (not \"int\") to deque\n\n\n- 그렇지만 필요하다면 np.array 화 시킬 수 있음.\n\nnp.array(a) + 1 \n\narray([ 34,  45,  56, -65, -39])\n\n\n\ntorch.tensor(a) + 1\n\ntensor([ 34,  45,  56, -65, -39])\n\n\n- collection.deque 는 리플레이 버퍼를 구현할때 유용한 자료구조이다.\n\n(우리가 했던) 기존방식: 모든 데이터를 저장하며 하나의 경험씩 학습함\n리플레이버퍼: 최근 \\(N\\)개의 데이터를 저장하여 여러경험을 샘플링하여 학습하는 방식\n리플레이버퍼의 장점: 메모리를 아낄 수 있다, 다양한 종류의 경험을 저장하고 무작위로 재사용하여 학습이 안정적으로 된다, “저장 -&gt; 학습 -&gt; 저장” 순으로 반드시 실시간으로 학습할 필요가 없어서 병렬처리에 용이하다, 강화학습에서 연속된 경험은 상관관계가 있을 수 있는데 무작위 샘플로 이러한 상관관계를 제거할 수 있음"
  },
  {
    "objectID": "posts/15wk-1.html#b.-replay_buffer",
    "href": "posts/15wk-1.html#b.-replay_buffer",
    "title": "15wk-1: 강화학습 (4) – LunarLander, A1, A2",
    "section": "B. replay_buffer",
    "text": "B. replay_buffer\n\ncurrent_states = collections.deque([torch.tensor([0.23,0.1]),torch.tensor([0.34,0.2])],maxlen=5)\nactions = collections.deque([torch.tensor(0), torch.tensor(1)],maxlen=5)\nrewards = collections.deque([torch.tensor(3.43), torch.tensor(0.13)],maxlen=5)\nnext_states = collections.deque([torch.tensor([0.34,0.2]),torch.tensor([0.45,0.3])],maxlen=5)\nterminations = collections.deque([torch.tensor(False),torch.tensor(False)],maxlen=5)\n\n\ncurrent_states, actions,rewards,next_states,terminations\n\n(deque([tensor([0.2300, 0.1000]), tensor([0.3400, 0.2000])], maxlen=5),\n deque([tensor(0), tensor(1)], maxlen=5),\n deque([tensor(3.4300), tensor(0.1300)], maxlen=5),\n deque([tensor([0.3400, 0.2000]), tensor([0.4500, 0.3000])], maxlen=5),\n deque([tensor(False), tensor(False)], maxlen=5))\n\n\n\nmemory = list(zip(current_states,actions,rewards,next_states,terminations))\nmemory\n\n[(tensor([0.2300, 0.1000]),\n  tensor(0),\n  tensor(3.4300),\n  tensor([0.3400, 0.2000]),\n  tensor(False)),\n (tensor([0.3400, 0.2000]),\n  tensor(1),\n  tensor(0.1300),\n  tensor([0.4500, 0.3000]),\n  tensor(False))]\n\n\n\nrandom.sample(memory,1)\n\n[(tensor([0.2300, 0.1000]),\n  tensor(0),\n  tensor(3.4300),\n  tensor([0.3400, 0.2000]),\n  tensor(False))]"
  },
  {
    "objectID": "posts/15wk-1.html#a.-q_net",
    "href": "posts/15wk-1.html#a.-q_net",
    "title": "15wk-1: 강화학습 (4) – LunarLander, A1, A2",
    "section": "A. q_net",
    "text": "A. q_net\n- 전략: 4x4에서 q_table에 대응하는 정보가 있으면 된다. 그런데 q_table와 같이 테이블 형식으로는 힘들것 같다. \\(\\to\\) q_net를 만들자.\n\n4x4 grid: 상태공간의 차원은 2차원이며 가질수 있는 값은 16개, 각 상태공간에서 할수 있는 행동이 4개 -&gt; 총 16*4의 경우의 수에 대한 reward만 조사하면 되었음\nLunarLander: 상태공간의 차원은 8차원이지만 가질수 있는 값의 범위는 무한대 -&gt; 무수히 많은 경우에 대한 reward 값을 조사하는건 현실적으로 불가능\n\n- 4x4 코드\nclass AgentGreedy(AgentRandom):\n    def __init__(self,env):\n        super().__init__(env)\n        #--#\n        self.q_table = np.zeros([4,4,4])\n    def learn(self): # q_table \n        s1,s2 = self.current_state\n        ss1,ss2 = self.next_state\n        a = self.action\n        r = self.reward\n        q_hat = self.q_table[s1,s2,a] \n        if self.terminated:\n            q = r \n        else:\n            future_reward = self.q_table[ss1,ss2,:].max()\n            q = r + 0.99 * future_reward \n        diff = q - q_hat\n        self.q_table[s1,s2,a] = q_hat + 0.05 * diff         \n    def act(self):\n        if self.n_experiences &lt; 3000:\n            self.action = self.action_space.sample()\n        else: \n            s1,s2 = self.current_state \n            self.action = self.q_table[s1,s2,:].argmax()\n수정 1. agent.q_table 에 대응하는 과정\n\nagent.q_net = torch.nn.Sequential(\n    torch.nn.Linear(8,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,128),\n    torch.nn.ReLU(),\n    torch.nn.Linear(128,64),\n    torch.nn.ReLU(),    \n    torch.nn.Linear(64,4)\n)    \n\n\nagent.q_net # &lt;- 8개의 숫작가 들어가면 4개의 숫자가 나옴 \n\nSequential(\n  (0): Linear(in_features=8, out_features=256, bias=True)\n  (1): ReLU()\n  (2): Linear(in_features=256, out_features=128, bias=True)\n  (3): ReLU()\n  (4): Linear(in_features=128, out_features=64, bias=True)\n  (5): ReLU()\n  (6): Linear(in_features=64, out_features=4, bias=True)\n)\n\n\n\ns = torch.tensor(agent.current_state)\nagent.q_net(s)\n\ntensor([0.0175, 0.0499, 0.1191, 0.0083], grad_fn=&lt;ViewBackward0&gt;)\n\n\n\nq_net은 8개의 숫자가 입력으로 오면 4개의 숫자가 리턴되는 함수이다.\n해석을 하면 8개의 숫자는 state를 나타내는 숫자로 이해할 수 있고 4개의 숫자는 각 action에 대한 q값으로 해석할 수 있다.\n출력되는 4개의 숫자는 합리적인 숫자가 아님 (최초의 숫자임) 그렇지만 데이터를 학습하여 점점 합리적으로 변할 것임.\n\n2. q_hat\n\ns = torch.tensor(agent.current_state)\na = torch.tensor(agent.action)\nq_hat = agent.q_net(s)[a]\n\n\nq_hat\n\ntensor(0.1191, grad_fn=&lt;SelectBackward0&gt;)\n\n\n3. q (\\(q = r + 0.99 \\times {\\tt future\\_reward}\\))\n\ns = torch.tensor(agent.current_state)\na = torch.tensor(agent.action)\nr = torch.tensor(agent.reward)\nss = torch.tensor(agent.next_state)\n\n\nif agent.terminated:\n    q = r\nelse:\n    future_reward = agent.q_net(ss).max().data\n    q = r + 0.99 * future_reward \n\n4. q_hat 을 점점 q 와 비슷하게 만드는 과정\n\nmemory = list(zip(agent.current_states,agent.actions,agent.rewards,agent.next_states,agent.terminations))\n\n\nagent.batch_size = 4 \nminibatch = random.sample(memory,agent.batch_size)\nminibatch[0] # s,a,r,ss,t \n\n(tensor([-0.0827,  0.4462, -0.4321, -1.1998,  0.7915,  0.1979,  0.0000,  0.0000]),\n tensor(1),\n tensor(-1.9897, dtype=torch.float64),\n tensor([-0.0871,  0.4186, -0.4399, -1.2323,  0.8041,  0.2514,  0.0000,  0.0000]),\n tensor(False))\n\n\n\nagent.optimizr = torch.optim.Adam(agent.q_net.parameters())\nfor epoc in range(5):\n    memory = list(zip(agent.current_states,agent.actions,agent.rewards,agent.next_states,agent.terminations))\n    minibatch = random.sample(memory,agent.batch_size)\n    ## step 1~2 \n    loss = 0 \n    for s,a,r,ss,terminated in minibatch:\n        # step1: q_hat \n        q_hat = agent.q_net(s)[a]        \n        # step2: loss를 계산한다. \n        if agent.terminated:\n            q = r\n        else:\n            future_reward = agent.q_net(ss).max().data\n            q = r + 0.99 * future_reward\n        loss = loss + (q_hat-q)**2 \n    loss = loss / agent.batch_size \n    # step3 \n    loss.backward()\n    # step4 \n    agent.optimizr.step()\n    agent.optimizr.zero_grad() \n\n5. 행동..?\n\nagent.q_net(s).argmax().item()\n\n2\n\n\n\nagent.eps = 0.5 \nif np.random.rand() &lt; agent.eps: \n    agent.action = agent.action_space.sample()\nelse: \n    s = torch.tensor(agent.current_state)\n    agent.q_net(s).argmax().item()"
  },
  {
    "objectID": "posts/15wk-1.html#b.-클래스의-설계",
    "href": "posts/15wk-1.html#b.-클래스의-설계",
    "title": "15wk-1: 강화학습 (4) – LunarLander, A1, A2",
    "section": "B. 클래스의 설계",
    "text": "B. 클래스의 설계\n\nclass AgentExplorer(AgentRandom):\n    def __init__(self,env):\n        super().__init__(env)\n        self.eps = 0 \n        self.q_net = torch.nn.Sequential(\n            torch.nn.Linear(8,256),\n            torch.nn.ReLU(),\n            torch.nn.Linear(256,128),\n            torch.nn.ReLU(),\n            torch.nn.Linear(128,64),\n            torch.nn.ReLU(),    \n            torch.nn.Linear(64,4)\n        )\n        self.optimizr = torch.optim.Adam(self.q_net.parameters(),lr=0.0001)\n        self.batch_size = 64\n    def act(self):\n        if np.random.rand() &lt; self.eps: \n            self.action = self.action_space.sample()\n        else: \n            s = torch.tensor(self.current_state)\n            self.action = self.q_net(s).argmax().item() \n    def learn(self):\n        if self.n_experiences &lt; self.batch_size:\n            pass \n        else: \n            for epoc in range(1):\n                memory = list(zip(\n                    self.current_states,\n                    self.actions,\n                    self.rewards,\n                    self.next_states,\n                    self.terminations\n                ))\n                minibatch = random.sample(memory,self.batch_size)\n                ## step 1~2 \n                loss = 0 \n                for s,a,r,ss,terminated in minibatch:\n                    # step1: q_hat \n                    q_hat = self.q_net(s)[a]        \n                    # step2: loss를 계산한다. \n                    if self.terminated:\n                        q = r\n                    else:\n                        future_reward = self.q_net(ss).max().data\n                        q = r + 0.99 * future_reward\n                    loss = loss + (q_hat-q)**2 \n                loss = loss / self.batch_size \n                # step3 \n                loss.backward()\n                # step4 \n                self.optimizr.step()\n                self.optimizr.zero_grad()"
  },
  {
    "objectID": "posts/15wk-1.html#c.-환경과-상호작용",
    "href": "posts/15wk-1.html#c.-환경과-상호작용",
    "title": "15wk-1: 강화학습 (4) – LunarLander, A1, A2",
    "section": "C. 환경과 상호작용",
    "text": "C. 환경과 상호작용\n\nenv = gym.make(\"LunarLander-v2\",render_mode = 'rgb_array')\nagent = AgentExplorer(env)\nagent.eps = 1 \n#--#\nfor _ in range(2000): \n    # STEP1: 에피소드 준비 \n    agent.current_state,_ = env.reset()\n    agent.score = 0\n    # STEP2: 에피소드 진행 \n    for t in range(1,1001):\n        ## step1: 행동 \n        agent.act()\n        ## step2: 보상\n        agent.next_state, agent.reward, agent.terminated, _, _ = env.step(agent.action)\n        ## step3: 저장 & 학습 \n        agent.save_experience()\n        agent.learn()\n        ## step4: \n        agent.current_state = agent.next_state \n        if agent.terminated: break \n    # STEP3: 다음에피소드준비 \n    agent.scores.append(agent.score) \n    agent.playtimes.append(t) \n    agent.n_episodes = agent.n_episodes + 1\n    agent.eps = agent.eps * 0.995 \n    if np.mean(agent.scores[-100:]) &gt; 200: \n        print(f\"---game cleared in {agent.n_episodes} episodes! ---\")\n        torch.save(agent.q_net.state_dict(),f\"q_net_final.pth\")\n        break \n    #---#\n    logfreq = 100\n    if (agent.n_episodes % logfreq) == 0: \n        print(\n            f\"에피소드:{agent.n_episodes}\\t\"\n            f\"경험(t):{agent.n_experiences}\\t\"            \n            f\"점수(에피소드):{np.mean(agent.scores[-logfreq:]):.2f}\\t\"\n            f\"게임시간(에피소드):{np.mean(agent.playtimes[-logfreq:]):.2f}\\t\"\n            f\"돌발행동(에피소드):{agent.eps:.2f}\"\n        )\n        torch.save(agent.q_net.state_dict(),f\"q_net_{agent.n_episodes}.pth\")\n\n에피소드:100    경험(t):10838 점수(에피소드):-176.71    게임시간(에피소드):108.38   돌발행동(에피소드):0.61\n에피소드:200    경험(t):51270 점수(에피소드):-56.40 게임시간(에피소드):404.32   돌발행동(에피소드):0.37\n에피소드:300    경험(t):127024    점수(에피소드):97.89  게임시간(에피소드):757.54   돌발행동(에피소드):0.22\n에피소드:400    경험(t):181605    점수(에피소드):161.62 게임시간(에피소드):545.81   돌발행동(에피소드):0.13\n---game cleared in 468 episodes!---\n\n\n\n아래코드 실행하면 제가 실습에 사용한 파일 받아올수있어요\n!wget https://github.com/guebin/DL2024/raw/main/posts/LunarLander/q_net_100.pth\n!wget https://github.com/guebin/DL2024/raw/main/posts/LunarLander/q_net_200.pth\n!wget https://github.com/guebin/DL2024/raw/main/posts/LunarLander/q_net_300.pth\n!wget https://github.com/guebin/DL2024/raw/main/posts/LunarLander/q_net_400.pth\n!wget https://github.com/guebin/DL2024/raw/main/posts/LunarLander/q_net_final.pth\n\n\nagent_dummy = AgentExplorer(env) \n#agent_dummy.q_net = agent.q_net # 비법전수 \nagent_dummy.q_net.load_state_dict(torch.load(\"q_net_final.pth\"))\n\nagent_dummy.current_state, _ = env.reset()\nagent_dummy.terminated = False \nims = [] \nims.append(env.render())\nfor t in range(1001):\n    agent_dummy.act() \n    agent_dummy.next_state, agent_dummy.reward, agent_dummy.terminated, _, _  = env.step(agent_dummy.action)\n    ims.append(env.render())\n    agent_dummy.current_state = agent_dummy.next_state\n    if agent_dummy.terminated: break \n\n\nshow(ims)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/12wk-1.html#a.-data",
    "href": "posts/12wk-1.html#a.-data",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "A. Data",
    "text": "A. Data\n- 데이터 정리\n\ntxt = list('AbAcAd'*50)\ntxt[:10]\n\n['A', 'b', 'A', 'c', 'A', 'd', 'A', 'b', 'A', 'c']\n\n\n\ndf_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\ndf_train[:5]\n\n\n\n\n\n\n\n\nx\ny\n\n\n\n\n0\nA\nb\n\n\n1\nb\nA\n\n\n2\nA\nc\n\n\n3\nc\nA\n\n\n4\nA\nd\n\n\n\n\n\n\n\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\n\n\nx[:8],y[:8]\n\n(tensor([0, 1, 0, 2, 0, 3, 0, 1]), tensor([1, 0, 2, 0, 3, 0, 1, 0]))"
  },
  {
    "objectID": "posts/12wk-1.html#b.-풀이-실패",
    "href": "posts/12wk-1.html#b.-풀이-실패",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "B. 풀이 – 실패",
    "text": "B. 풀이 – 실패\n\nnet = torch.nn.Sequential(\n    torch.nn.Embedding(4,2),\n    torch.nn.Tanh(),\n    torch.nn.Linear(2,4)\n)\nebdd,tanh,linr = net\nebdd.weight.data = ebdd.weight.data*0 +0.1\nlinr.weight.data = linr.weight.data*0 +0.1\nlinr.bias.data = linr.bias.data*0 +0.1\n#\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.1)\n#---#\nfor epoc in range(200):\n    # 1 \n    netout = net(x)\n    # 2 \n    loss = loss_fn(netout,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nh = tanh(ebdd(x))\nyhat = soft(net(x))\nmat = torch.concat([h,yhat],axis=1).data[:10]\nplt.matshow(mat,cmap=\"bwr\",vmin=-1,vmax=1)\nplt.axvline(1.5,color=\"lime\")\nplt.xticks(ticks=range(6),labels=[r\"$h_1$\",r\"$h_2$\",r\"$P_A$\",r\"$P_b$\",r\"$P_c$\",r\"$P_d$\"]);\n\n\n\n\n\n\n\n\n\n망했음\n왜?\n\n- 일단 망한건 망한거고 분석을 위해서 숫자좀 체크하자.\n\nnet(x)\n\ntensor([[-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        ...,\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836]], grad_fn=&lt;AddmmBackward0&gt;)"
  },
  {
    "objectID": "posts/12wk-1.html#c.-실패한-풀이의-다른구현1",
    "href": "posts/12wk-1.html#c.-실패한-풀이의-다른구현1",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "C. 실패한 풀이의 다른구현1",
    "text": "C. 실패한 풀이의 다른구현1\n- B를 다른방식으로 구현해보자.\n- 새로운 방식의 데이터 정리\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n- 사용자 정의 Hnet를 사용\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2,bias=False)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,X):\n        h = self.tanh(self.i2h(X))\n        return h\nhnet = Hnet()\nlinr = torch.nn.Linear(2,4)\nhnet.i2h.weight.data = hnet.i2h.weight.data*0 + 0.1\nlinr.weight.data = linr.weight.data*0 + 0.1\nlinr.bias.data = linr.bias.data*0 + 0.1\n# \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()),lr=0.1)\n#---#\nfor epoc in range(200):\n    # 1 \n    h = hnet(X)\n    netout = linr(h)\n    # 2 \n    loss = loss_fn(netout,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 이것도 숫자좀 체크해보자.\n\nlinr(hnet(X))\n\ntensor([[-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        ...,\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\n이전코드와 결과가 같음"
  },
  {
    "objectID": "posts/12wk-1.html#d.-실패한-풀이의-다른구현2",
    "href": "posts/12wk-1.html#d.-실패한-풀이의-다른구현2",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "D. 실패한 풀이의 다른구현2",
    "text": "D. 실패한 풀이의 다른구현2\n# 예비학습 – 아래를 관찰하자.\n\nX = torch.tensor(\n    [[1., 0., 0., 0.],\n     [0., 1., 0., 0.]]\n)\nlinr = torch.nn.Linear(4,2)\n\n\nlinr(X)\n\ntensor([[-0.1147,  0.6200],\n        [-0.3293,  0.4397]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\nlinr(X[[0]]),linr(X[[1]])\n\n(tensor([[-0.1147,  0.6200]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.3293,  0.4397]], grad_fn=&lt;AddmmBackward0&gt;))\n\n\n\nlinr(X[0]),linr(X[1])\n\n(tensor([-0.1147,  0.6200], grad_fn=&lt;ViewBackward0&gt;),\n tensor([-0.3293,  0.4397], grad_fn=&lt;ViewBackward0&gt;))\n\n\n#\n- 또 다른방식의 구현\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n\nclass Hnet(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2,bias=False)\n        self.tanh = torch.nn.Tanh()\n    def forward(self,X):\n        h = self.tanh(self.i2h(X))\n        return h\nhnet = Hnet()\nlinr = torch.nn.Linear(2,4)\nhnet.i2h.weight.data = hnet.i2h.weight.data*0 + 0.1\nlinr.weight.data = linr.weight.data*0 + 0.1\nlinr.bias.data = linr.bias.data*0 + 0.1\n# \nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(hnet.parameters())+list(linr.parameters()),lr=0.1)\n#---#\nL = len(X)\nfor epoc in range(200):\n    # 1~2 \n    loss = 0 \n    for t in range(L):\n        Xt,yt = X[t],y[t]\n        ht = hnet(Xt)\n        ot = linr(ht)\n        loss = loss + loss_fn(ot,yt)\n    loss = loss/L\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 이것도 숫자좀 체크해보자.\n\nlinr(hnet(X))\n\ntensor([[-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        ...,\n        [-3.8668,  3.6836,  3.6836,  3.6836],\n        [ 5.4879, -4.9081, -4.9081, -4.9081],\n        [-3.8668,  3.6836,  3.6836,  3.6836]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 임베딩공간의 해석\n\nh = hnet(X)\n\n\nh.shape\n\ntorch.Size([299, 2])\n\n\n\nh1,h2 = h.T.data\n# h1 = h[:,0].data\n# h2 = h[:,1].data\n\n\nplt.plot(h1[::6],h2[::6],'X',label=\"A\")\nplt.plot(h1[1::6],h2[1::6],'X',label=\"b\")\nplt.plot(h1[2::6],h2[2::6],'X',label=\"A\")\nplt.plot(h1[3::6],h2[3::6],'X',label=\"c\")\nplt.plot(h1[4::6],h2[4::6],'X',label=\"A\")\nplt.plot(h1[5::6],h2[5::6],'X',label=\"d\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n임베딩공간의 해석? b,c,d는 사실상 같은 문자로 취급한다."
  },
  {
    "objectID": "posts/12wk-1.html#a.-순환신경망의-모티브",
    "href": "posts/12wk-1.html#a.-순환신경망의-모티브",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "A. 순환신경망의 모티브",
    "text": "A. 순환신경망의 모티브\n(예비생각1) \\({\\boldsymbol h}\\)에 대한 이해\n- \\({\\boldsymbol h}\\)는 사실 문자열 “Abcd”들을 숫자로 바꾼 표현이라 해석할 수 있음. 즉 원핫인코딩과 다른 또 다른 형태의 숫자표현이라 해석할 수 있다.\n- 사실 \\({\\boldsymbol h}\\)는 원핫인코딩보다 약간 더 (1) 액기스만 남은 느낌 + (2) 숙성된 느낌을 준다\n\n(why1) \\({\\boldsymbol h}\\)는 \\({\\boldsymbol x}\\) 보다 \\({\\boldsymbol y}\\)를 예측함에 좀 더 직접적인 역할을 한다. 즉 \\({\\boldsymbol x}\\) 숫자보다 \\({\\boldsymbol h}\\) 숫자가 잘 정리되어 있고 (차원이 낮고) 입력의 특징을 잘 정리한 (추천시스템의 MBTI처럼) 의미있는 숫자이다.\n(why2) \\({\\boldsymbol x}\\)는 학습없이 그냥 얻어지는 숫자표현이지만, \\({\\boldsymbol h}\\)는 학습을 통하여 고치고 고치고 고친 숫자표현이다.\n\n결론: 사실 \\({\\boldsymbol h}\\)는 잘 숙성되어있는 입력정보 \\({\\boldsymbol x}\\) 그 자체로 해석 할 수 있다.\n(예비생각2) 수백년전통을 이어가는 방법\n“1리터에 500만원에 낙찰된 적 있습니다.”\n“2kg에 1억원 정도 추산됩니다.”\n“20여 종 종자장을 블렌딩해 100ml에 5000만원씩 분양 예정입니다.”\n\n모두 씨간장(종자장) 가격에 관한 실제 일화다.\n\n(중략...)\n\n위스키나 와인처럼 블렌딩을 하기도 한다. \n새로 담근 간장에 씨간장을 넣거나, 씨간장독에 햇간장을 넣어 맛을 유지하기도 한다. \n이를 겹장(또는 덧장)이라 한다. \n몇몇 종갓집에선 씨간장 잇기를 몇백 년째 해오고 있다. \n매년 새로 간장을 담가야 이어갈 수 있으니 불씨 꺼트리지 않는 것처럼 굉장히 어려운 일이다.\n이렇게 하는 이유는 집집마다 내려오는 고유 장맛을 잃지 않기 위함이다. \n씨간장이란 그만큼 소중한 주방의 자산이며 정체성이다.\n덧장: 새로운간장을 만들때, 옛날간장을 섞어서 만듬\n* 기존방식 - \\(\\text{콩물} \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}\\)\n* 수백년 전통의 간장맛을 유지하는 방식\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3\\)\n\n* 수백년 전통의 간장맛을 유지하면서 조리를 한다면?\n\n\\(\\text{콩물}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n점점 맛있는 간장계란밥이 탄생함\n* 알고리즘의 편의상 아래와 같이 생각해도 무방\n\n\\(\\text{콩물}_1, \\text{간장}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_1 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_1\\), \\(\\text{간장}_0=\\text{맹물}\\)\n\\(\\text{콩물}_2, \\text{간장}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_2 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_2\\)\n\\(\\text{콩물}_3, \\text{간장}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\text{간장}_3 \\overset{\\text{조리}}{\\longrightarrow} \\text{간장계란밥}_3\\)\n\n아이디어\n* 수백년 전통의 간장맛을 유지하면서 조리하는 과정을 수식으로? (콩물을 \\(x\\)로, 간장을 \\(h\\)로!!)\n\n\\(\\boldsymbol{x}_1, \\boldsymbol{h}_0 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_1 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_1\\)\n\\(\\boldsymbol{x}_2, \\boldsymbol{h}_1 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_2 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_2\\)\n\\(\\boldsymbol{x}_3, \\boldsymbol{h}_2 \\overset{\\text{숙성}}{\\longrightarrow} \\boldsymbol{h}_3 \\overset{\\text{조리}}{\\longrightarrow} \\hat{\\boldsymbol y}_3\\)\n\n이제 우리가 배울것은 (1) “\\(\\text{콩물}_{t}\\)”와 “\\(\\text{간장}_{t-1}\\)”로 “\\(\\text{간장}_t\\)”를 숙성하는 방법 (2) “\\(\\text{간장}_t\\)”로 “\\(\\text{간장계란밥}_t\\)를 조리하는 방법이다\n즉 숙성담당 네트워크와 조리담당 네트워크를 각각 만들어 학습하면 된다."
  },
  {
    "objectID": "posts/12wk-1.html#b.-순환신경망-알고리즘",
    "href": "posts/12wk-1.html#b.-순환신경망-알고리즘",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "B. 순환신경망 알고리즘",
    "text": "B. 순환신경망 알고리즘\n# 버전1\nstep 1: 일단 \\(\\text{간장}_0(={\\boldsymbol h}_0)\\)을 맹물로 초기화 한다. 즉 아래를 수행한다.\n\\[{\\boldsymbol h}_0 = [[0,0]]\\]\n이때 \\({\\boldsymbol h}_0 = [[0,0]]\\) 은 이론상에서는 shape이 (1,2) 이지만 알고리즘 상에서는 shape 을 (2,)로 생각해도 무방하다.\nstep 2: \\(\\text{콩물}_1(={\\boldsymbol x}_1)\\), \\(\\text{간장}_0(={\\boldsymbol h}_0)\\) 을 이용하여 \\(\\text{간장}_1(={\\boldsymbol h}_1)\\)을 숙성한다. 즉 아래를 수행한다.\n\\[{\\boldsymbol h}_1= \\tanh({\\boldsymbol x}_1{\\bf W}_{ih}+{\\boldsymbol h}_0{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\]\n이때 변수들의 차원은 아래와 같다.\n\n\\({\\boldsymbol x}_1\\): (1,4) 이지만 (4,) 로 생각한다.\n\\({\\boldsymbol h}_0\\),\\({\\boldsymbol h}_1\\): (1,2) 이지만 (2,) 로 생각한다.\n\\({\\bf W}_{ih}\\): (4,2) // \\({\\bf W}_{hh}\\): (2,2) // \\({\\boldsymbol b}_{ih}\\): (1,2) // \\({\\boldsymbol b}_{hh}\\): (1,2) 로 생각한다.\n\nstep 3: \\(\\text{간장}_1\\)을 이용하여 \\(\\text{간장계란밥}_1\\)을 만든다. 그리고 \\(\\hat{\\boldsymbol y}_1\\)을 만든다.\n\\[{\\boldsymbol o}_1= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\]\n\\[\\hat{\\boldsymbol y}_1 = \\text{soft}({\\boldsymbol o}_1)\\]\nstep 4: \\(t=2,3,4,5,\\dots,L\\) 에 대하여 step2-3을 반복한다.\n#\n# 버전2\ninit \\(\\boldsymbol{h}_0\\)\nfor \\(t\\) in \\(1:L\\)\n\n\\({\\boldsymbol h}_t= \\tanh({\\boldsymbol x}_t{\\bf W}_{ih}+{\\boldsymbol h}_{t-1}{\\bf W}_{hh}+{\\boldsymbol b}_{ih}+{\\boldsymbol b}_{hh})\\)\n\\({\\boldsymbol o}_t= {\\bf W}_{ho}{\\boldsymbol h}_1+{\\boldsymbol b}_{ho}\\)\n\\(\\hat{\\boldsymbol y}_t = \\text{soft}({\\boldsymbol o}_t)\\)\n\n#\n# 버전3\nht = [0,0]\nfor t in 1:T \n    ht = tanh(linr(xt)+linr(ht))\n    ot = linr(ht)\n    yt_hat = soft(ot)\n\n코드상으로는 \\(h_t\\)와 \\(h_{t-1}\\)의 구분이 교모하게 사라진다. (그래서 오히려 좋아)\n\n#\n- 따라서 실질적인 전체코드는 아래와 같은 방식으로 구현할 수 있다.\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        linr1 = torch.nn.Linear(?,?) \n        linr2 = torch.nn.Linear(?,?) \n        tanh = torch.nn.Tanh()\n    def forward(self,Xt,ht):\n        ht = tanh(lrnr1(Xt)+lrnr2(ht))\n        return ht\n\ninit ht\nrnncell = rNNCell()\n\nfor t in 1:L \n    Xt, yt = X[t], y[t]\n    ht = rnncell(Xt, ht)\n    ot = linr(ht) \n    loss = loss + loss_fn(ot, yt)"
  },
  {
    "objectID": "posts/12wk-1.html#c.-구현1-rnncell",
    "href": "posts/12wk-1.html#c.-구현1-rnncell",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "C. 구현1 – rNNCell",
    "text": "C. 구현1 – rNNCell\n- 데이터정리\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n- 순환신경망으로 적합\n\nclass rNNCell(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.i2h = torch.nn.Linear(4,2) \n        self.h2h = torch.nn.Linear(2,2) \n        self.tanh = torch.nn.Tanh()\n    def forward(self,Xt,ht):\n        ht = self.tanh(self.i2h(Xt)+self.h2h(ht))\n        return ht\ntorch.manual_seed(43052) # 시드고정해야만 답나옴 --&gt; 임베딩공간이 부족하다는 의미 (사실상 6개의 문자니까!)\nrnncell = rNNCell() # 너는 간장숙성을 담당해라\ncook = torch.nn.Linear(2,4) # 너는 요리를 담당해라. \n#\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(list(rnncell.parameters())+ list(cook.parameters()),lr=0.1)\n#---#\nL = len(X)\nfor epoc in range(200):\n    ## 1~2 \n    ht = torch.zeros(2) # 첫간장은 맹물\n    loss = 0\n    for t in range(L):\n        Xt, yt = X[t], y[t]\n        ht = rnncell(Xt, ht)\n        ot = cook(ht) \n        loss = loss + loss_fn(ot, yt)\n    loss = loss/L\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과 확인 및 시각화\n\nh = torch.zeros(L,2)\nwater = torch.zeros(2)\nh[0] = rnncell(X[0],water)\nfor t in range(1,L):\n    h[t] = rnncell(X[t],h[t-1])\nyhat = soft(cook(h))\nyhat    \n\ntensor([[4.1978e-03, 9.4555e-01, 1.9557e-06, 5.0253e-02],\n        [9.9994e-01, 5.5569e-05, 8.4751e-10, 1.3143e-06],\n        [2.1349e-07, 1.1345e-06, 9.7019e-01, 2.9806e-02],\n        ...,\n        [2.1339e-07, 1.1339e-06, 9.7020e-01, 2.9798e-02],\n        [9.9901e-01, 9.6573e-04, 6.9303e-09, 2.1945e-05],\n        [7.2919e-04, 2.5484e-02, 3.3011e-02, 9.4078e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\nmat = torch.concat([h,yhat],axis=1).data[:10]\nplt.matshow(mat,cmap='bwr',vmin=-1,vmax=1)\nplt.axvline(x=1.5,color='lime')\nplt.xticks(range(6),[r'$h_1$',r'$h_2$',r'$P_A$',r'$P_b$',r'$P_c$',r'$P_d$']);\n\n\n\n\n\n\n\n\n- yhat 값 분석\n\nyhat.data.numpy().round(3)[:10]\n\narray([[0.004, 0.946, 0.   , 0.05 ],\n       [1.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.97 , 0.03 ],\n       [0.999, 0.001, 0.   , 0.   ],\n       [0.001, 0.025, 0.033, 0.941],\n       [0.983, 0.016, 0.   , 0.   ],\n       [0.004, 0.965, 0.   , 0.031],\n       [1.   , 0.   , 0.   , 0.   ],\n       [0.   , 0.   , 0.97 , 0.03 ],\n       [0.999, 0.001, 0.   , 0.   ]], dtype=float32)\n\n\n\n미세하지만 뒤로갈수록 좀 더 성능이 좋다.\n\n- h1,h2 분석 (= 임베딩스페이스 분석)\n\nh1,h2 = h.T.data\nplt.plot(h1[::6],h2[::6],'X',label=\"A\")\nplt.plot(h1[1::6],h2[1::6],'X',label=\"b\")\nplt.plot(h1[2::6],h2[2::6],'X',label=\"A\")\nplt.plot(h1[3::6],h2[3::6],'X',label=\"c\")\nplt.plot(h1[4::6],h2[4::6],'X',label=\"A\")\nplt.plot(h1[5::6],h2[5::6],'X',label=\"d\")\nplt.legend()"
  },
  {
    "objectID": "posts/12wk-1.html#d.-구현2-rnncell",
    "href": "posts/12wk-1.html#d.-구현2-rnncell",
    "title": "12wk-1: 순환신경망 (2) – 순환신경망의 이해, rNNCell, RNNCell",
    "section": "D. 구현2 – RNNCell",
    "text": "D. 구현2 – RNNCell\nref: https://pytorch.org/docs/stable/generated/torch.nn.RNNCell.html\n- 데이터정리\n\nx = torch.tensor(df_train.x.map({'A':0,'b':1,'c':2,'d':3}))\ny = torch.tensor(df_train.y.map({'A':0,'b':1,'c':2,'d':3}))\nX = torch.nn.functional.one_hot(x).float()\ny = torch.nn.functional.one_hot(y).float()\n\n- Net설계 및 가중치 설정 (구현1과 동일하도록 가중치 초기화)\n\ntorch.manual_seed(43052) \n_rnncell = rNNCell()\ncook = torch.nn.Linear(2,4)\n\n\nrnncell = torch.nn.RNNCell(4,2)\nrnncell.weight_ih.data = _rnncell.i2h.weight.data \nrnncell.weight_hh.data = _rnncell.h2h.weight.data \nrnncell.bias_ih.data = _rnncell.i2h.bias.data \nrnncell.bias_hh.data = _rnncell.h2h.bias.data \n\n- 손실함수 및 옵티마이저 설정\n\nloss_fn = torch.nn.CrossEntropyLoss() \noptimizr = torch.optim.Adam(list(rnncell.parameters())+list(cook.parameters()),lr=0.1)\n\n- 학습\n\nL = len(X)\nfor epoc in range(200):\n    ## 1~2 \n    ht = torch.zeros(2) # 첫간장은 맹물\n    loss = 0\n    for t in range(L):\n        Xt, yt = X[t], y[t]\n        ht = rnncell(Xt, ht)\n        ot = cook(ht) \n        loss = loss + loss_fn(ot, yt)\n    loss = loss/L\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과확인\n\nh = torch.zeros(L,2)\nwater = torch.zeros(2)\nh[0] = rnncell(X[0],water)\nfor t in range(1,L):\n    h[t] = rnncell(X[t],h[t-1])\nyhat = soft(cook(h))\nyhat\n\ntensor([[4.1978e-03, 9.4555e-01, 1.9557e-06, 5.0253e-02],\n        [9.9994e-01, 5.5569e-05, 8.4751e-10, 1.3143e-06],\n        [2.1349e-07, 1.1345e-06, 9.7019e-01, 2.9806e-02],\n        ...,\n        [2.1339e-07, 1.1339e-06, 9.7020e-01, 2.9798e-02],\n        [9.9901e-01, 9.6573e-04, 6.9303e-09, 2.1945e-05],\n        [7.2919e-04, 2.5484e-02, 3.3011e-02, 9.4078e-01]],\n       grad_fn=&lt;SoftmaxBackward0&gt;)\n\n\n\n구현1과 같은 결과"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  }
]