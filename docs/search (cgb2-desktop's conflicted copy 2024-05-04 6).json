[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "딥러닝 (2024)",
    "section": "",
    "text": "질문하는 방법\n\n이메일: guebin@jbnu.ac.kr\n직접방문: 자연과학대학 본관 205호\nZoom: 이메일로 미리 시간을 정할 것\n카카오톡: http://pf.kakao.com/_txeIFG/chat\n\n강의노트\n\n\n\n\n\n\n\n\n\nDate\n\n\nTitle\n\n\nAuthor\n\n\n\n\n\n\nMay 1, 2024\n\n\n09wk-2: 중간고사\n\n\n최규빈 \n\n\n\n\nApr 29, 2024\n\n\n09wk-1: 추천시스템\n\n\n최규빈 \n\n\n\n\nApr 22, 2024\n\n\n08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)\n\n\n최규빈 \n\n\n\n\nApr 15, 2024\n\n\n07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM\n\n\n최규빈 \n\n\n\n\nApr 8, 2024\n\n\n06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10\n\n\n최규빈 \n\n\n\n\nApr 3, 2024\n\n\n05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석\n\n\n최규빈 \n\n\n\n\nApr 1, 2024\n\n\n05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy\n\n\n최규빈 \n\n\n\n\nMar 27, 2024\n\n\n04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현\n\n\n최규빈 \n\n\n\n\nMar 25, 2024\n\n\n04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST\n\n\n최규빈 \n\n\n\n\nMar 20, 2024\n\n\n03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복\n\n\n최규빈 \n\n\n\n\nMar 18, 2024\n\n\n03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계\n\n\n최규빈 \n\n\n\n\nMar 13, 2024\n\n\n02wk-2: 회귀분석 (3) – Step1,2,4 의 변형\n\n\n최규빈 \n\n\n\n\nMar 11, 2024\n\n\n02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분\n\n\n최규빈 \n\n\n\n\nMar 6, 2024\n\n\n01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법\n\n\n최규빈 \n\n\n\n\nMar 4, 2024\n\n\n01wk-1: 이미지 자료 분석 (겉핥기)\n\n\n최규빈 \n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/02wk-1.html#a.-소설",
    "href": "posts/02wk-1.html#a.-소설",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 소설",
    "text": "A. 소설\n- 카페주인인 박혜원씨는 온도와 아이스아메리카노 판매량이 관계가 있다는 것을 알았다. 구체적으로는\n\n“온도가 높아질 수록 (=날씨가 더울수록) 아이스아메리카노의 판매량이 증가”\n\n한다는 사실을 알게 되었다. 박혜원씨는\n\n일기예보를 보고 오늘의 평균 기온을 입력하면, 오늘의 아이스아메리카노 판매량을 미리 예측할 수 있지 않을까? 그 예측량만큼 아이스아메리카노를 준비하면 장사에 도움이 되지 않을까???\n\n라는 생각을 하게 되었고 이를 위하여 아래와 같이 100개의 데이터를 모았다.\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\n\n\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\n\n여기에서 temp는 평균기온이고, sales는 아이스아메리카노 판매량이다.1 평균기온과 판매량의 그래프를 그려보면 아래와 같다.\n1 판매량이 소수점이고 심지어 음수인것은 그냥 그려러니 하자..\nplt.plot(temp,sales,'o')"
  },
  {
    "objectID": "posts/02wk-1.html#b.-모델링",
    "href": "posts/02wk-1.html#b.-모델링",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 모델링",
    "text": "B. 모델링\n- 산점도를 살펴본 박혜원씨는 평균기온이 올라갈수록 아이스아메리카노 판매량이 “선형적”으로 증가한다는 사실을 캐치했다. 물론 약간의 오차는 있어보였다. 오차까지 고려하여 평균기온과 아이스판매량의 관계를 추정하면 아래와 같이 생각할 수 있다.\n\n아이스아메리카노 판매량 \\(\\approx\\) \\(w_0\\) \\(+\\) \\(w_1\\) \\(\\times\\) 평균기온\n\n위의 수식에서 만약에 \\(w_0\\)와 \\(w_1\\)의 값을 적절히 추정한다면, 평균기온량을 입력으로 하였을때 아이스아메리카노 판매량을 예측할 수 있을 것이다.\n- 아이스크림 판매량을 \\(y_i\\)로, 평균기온을 \\(x_i\\)로 변수화한뒤 박혜원의 수식을 좀 더 수학적으로 표현하면\n\\[y_i \\approx w_0 + w_1 x_i,\\quad i=1,2,\\dots,100\\]\n와 같이 쓸 수 있다. 오차항을 포함하여 좀 더 엄밀하게 쓰면\n\\[y_i = w_0 + w_1 x_i + \\epsilon_i,\\quad i=1,2,\\dots,100\\]\n와 같이 나타낼 수 있어보인다. 여기에서 \\(\\epsilon_i \\sim N(0,\\sigma^2)\\) 로 가정해도 무방할 듯 하다. 그런데 이를 다시 아래와 같이 표현하는 것이 가능하다.\n\\[{\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\]\n단 여기에서\n\\[{\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf x}=\\begin{bmatrix} x_1 \\\\ x_2 \\\\ \\dots \\\\ x_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} {\\bf 1} & {\\bf x} \\end{bmatrix}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} w_0 \\\\ w_1 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\]\n이다."
  },
  {
    "objectID": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "href": "posts/02wk-1.html#c.-데이터를-torch.tensor로-변환",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 데이터를 torch.tensor로 변환",
    "text": "C. 데이터를 torch.tensor로 변환\n- 현재까지의 상황을 파이토치로 코딩하면 아래와 같다.\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n#W = ?? 이건 모름.. 추정해야함. \n#ϵ = ?? 이것도 모름!!"
  },
  {
    "objectID": "posts/02wk-1.html#d.-아무렇게나-추정",
    "href": "posts/02wk-1.html#d.-아무렇게나-추정",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 아무렇게나 추정",
    "text": "D. 아무렇게나 추정\n- \\({\\bf W}\\) 에 대한 추정값을 \\(\\hat{\\bf W}\\)라고 할때\n\\[\\hat{\\bf W}=\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix} =\\begin{bmatrix} -5 \\\\ 10 \\end{bmatrix}\\]\n으로 추정한 상황이라면 커피판매량의 예측값은\n\\[\\hat{\\bf y} = {\\bf X}\\hat{\\bf W}\\]\n이라고 표현할 수 있다. 이 의미는 아래의 그림에서 주황색 점선으로 커피판매량을 예측한다는 의미이다.\n\nWhat = torch.tensor([[-5.0],\n                     [10.0]])\nWhat\n\ntensor([[-5.],\n        [10.]])\n\n\n\nyhat = X@What\n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat,'--')"
  },
  {
    "objectID": "posts/02wk-1.html#e.-추정의-방법",
    "href": "posts/02wk-1.html#e.-추정의-방법",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 추정의 방법",
    "text": "E. 추정의 방법\n- 방법1: 이론적으로 추론 &lt;- 회귀분석시간에 배운것\n\ntorch.linalg.inv((X.T @ X)) @ X.T @ y # 공식~\n\ntensor([[2.4459],\n        [4.0043]])\n\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.4459 + 4.0043*x,'--')\n\n\n\n\n\n\n\n\n- 방법2: 컴퓨터의 반복계산을 이용하여 추론 (손실함수도입 + 경사하강법)\n\n1단계: 아무 점선이나 그어본다..\n2단계: 1단계에서 그은 점선보다 더 좋은 점선으로 바꾼다.\n3단계: 1-2단계를 반복한다."
  },
  {
    "objectID": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "href": "posts/02wk-1.html#a.-문제셋팅-다시-복습",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 문제셋팅 다시 복습",
    "text": "A. 문제셋팅 다시 복습\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "href": "posts/02wk-1.html#b.-1단계-최초의-점선",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 1단계 – 최초의 점선",
    "text": "B. 1단계 – 최초의 점선\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nyhat = X@What \n\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--') # 그림을 그리기 위해서 yhat의 미분꼬리표를 제거"
  },
  {
    "objectID": "posts/02wk-1.html#c.-2단계-update",
    "href": "posts/02wk-1.html#c.-2단계-update",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 2단계 – update",
    "text": "C. 2단계 – update\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\[loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6240, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6240)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다.\n\n- 발상의 전환: 가만히 보니까 loss는 \\(\\hat{\\bf W} =\\begin{bmatrix} \\hat{w}_0 \\\\ \\hat{w}_1 \\end{bmatrix}\\) 에 따라서 값이 바뀌는 함수잖아??? 즉 아래와 같이 생각할 수 있음.\n\\[ loss(\\hat{w}_0,\\hat{w}_1) := loss(\\hat{\\bf W})=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\]\n따라서 구하고 싶은것은 아래와 같음\n\\[\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\]\n- \\(loss({\\bf W})\\)를 최소로 만드는 \\({\\bf W}\\)를 컴퓨터로 구하는 방법, 즉 \\(\\hat{\\bf W} := \\underset{\\bf W}{\\operatorname{argmin}} ~ loss({\\bf W})\\)를 구하는 방법을 요약하면 아래와 같다.\n1. 임의의 점 \\(\\hat{\\bf W}\\)를 찍는다.\n2. 그 점에서 순간기울기를 구한다. 즉 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\) 를 계산한다.\n3. \\(\\hat{\\bf W}\\)에서의 순간기울기2의 부호를 살펴보고 부호와 반대방향으로 움직인다. 이때 기울기의 절대값 크기3와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. 즉 아래의 수식에 따라 업데이트 한다.\n2 \\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\)3 \\(\\left|\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\right|\\)\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n- 여기에서 미분을 어떻게…?? 즉 아래를 어떻게 계산해..?\n\\[\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W}):= \\begin{bmatrix} \\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1}\\end{bmatrix}loss({\\bf W}) =  \\begin{bmatrix} \\frac{\\partial}{\\partial w_0}loss({\\bf W}) \\\\ \\frac{\\partial}{\\partial w_1}loss({\\bf W})\\end{bmatrix} \\]\n\nloss.backward()를 실행하면 What.grad에 미분값이 업데이트 되어요!\n\n(실행전)\n\nprint(What.grad)\n\nNone\n\n\n(실행후)\n\nloss.backward()\n\n\nprint(What.grad)\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 계산결과의 검토 (1)\n\n\\(loss({\\bf W})=({\\bf y}-\\hat{\\bf y})^\\top ({\\bf y}-\\hat{\\bf y})=({\\bf y}-{\\bf XW})^\\top ({\\bf y}-{\\bf XW})\\)\n\\(\\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})=-2{\\bf X}^\\top {\\bf y}+2{\\bf X}^\\top {\\bf X W}\\)\n\n\n- 2 * X.T @ y + 2 * X.T @ X @ What\n\ntensor([[-1342.2466],\n        [ 1188.9198]], grad_fn=&lt;AddBackward0&gt;)\n\n\n- 계산결과의 검토 (2)\n\\[\\frac{\\partial}{\\partial {\\bf W} } loss({\\bf W})=\\begin{bmatrix}\\frac{\\partial}{\\partial w_0} \\\\ \\frac{\\partial}{\\partial w_1} \\end{bmatrix}loss({\\bf W}) =\\begin{bmatrix}\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\\\ \\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\end{bmatrix}\\]\n를 계산하고 싶은데 벡터미분을 할줄 모른다고 하자. 편미분의 정의를 살펴보면,\n\\[\\frac{\\partial}{\\partial w_0}loss(w_0,w_1) \\approx \\frac{loss(w_0+h,w_1)-loss(w_0,w_1)}{h}\\]\n\\[\\frac{\\partial}{\\partial w_1}loss(w_0,w_1) \\approx \\frac{loss(w_0,w_1+h)-loss(w_0,w_1)}{h}\\]\n라고 볼 수 있다. 이를 이용하여 근사계산하면\n\ndef l(w0,w1):\n    return torch.sum((y-w0-w1*x)**2)\n\n\nl(-5,10), loss # 로스값일치\n\n(tensor(8587.6240), tensor(8587.6240, grad_fn=&lt;SumBackward0&gt;))\n\n\n\nh=0.001 \n(l(-5+h,10) - l(-5,10))/h\n\ntensor(-1342.7733)\n\n\n\nh=0.001 \n(l(-5,10+h) - l(-5,10))/h\n\ntensor(1189.4531)\n\n\n이 값은 What.grad에 저장된 값과 거의 비슷하다.\n\nWhat.grad\n\ntensor([[-1342.2465],\n        [ 1188.9203]])\n\n\n- 이제 아래의 공식에 넣고 업데이트해보자\n\\[\\hat{\\bf W} \\leftarrow \\hat{\\bf W} - \\alpha \\times \\frac{\\partial}{\\partial {\\bf W}}loss({\\bf W})\\]\n\nalpha = 0.001 \nprint(f\"{What.data} -- 수정전\")\nprint(f\"{-alpha*What.grad} -- 수정하는폭\")\nprint(f\"{What.data-alpha*What.grad} -- 수정후\")\nprint(f\"{torch.linalg.inv((X.T @ X)) @ X.T @ y} -- 회귀분석으로 구한값\")\nprint(f\"{torch.tensor([[2.5],[4]])} -- 참값(이건 비밀~~)\")\n\ntensor([[-5.],\n        [10.]]) -- 수정전\ntensor([[ 1.3422],\n        [-1.1889]]) -- 수정하는폭\ntensor([[-3.6578],\n        [ 8.8111]]) -- 수정후\ntensor([[2.4459],\n        [4.0043]]) -- 회귀분석으로 구한값\ntensor([[2.5000],\n        [4.0000]]) -- 참값(이건 비밀~~)\n\n\n\nalpha를 잘 잡아야함~\n\n- 1회 수정결과를 시각화\n\nWbefore = What.data\nWafter = What.data - alpha * What.grad \nWbefore, Wafter\n\n(tensor([[-5.],\n         [10.]]),\n tensor([[-3.6578],\n         [ 8.8111]]))\n\n\n\nplt.plot(x,y,'o',label=r'observed data')\nplt.plot(x,X@Wbefore,'--', label=r\"$\\hat{\\bf y}_{before}={\\bf X}@\\hat{\\bf W}_{before}$\")\nplt.plot(x,X@Wafter,'--', label=r\"$\\hat{\\bf y}_{after}={\\bf X}@\\hat{\\bf W}_{after}$\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "href": "posts/02wk-1.html#d.-3단계-iteration-learn-estimate-bfhat-w",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))",
    "text": "D. 3단계 – iteration (=learn = estimate \\(\\bf{\\hat W}\\))\n\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nWhat\n\ntensor([[-5.],\n        [10.]], requires_grad=True)\n\n\n\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n\nplt.plot(x,y,'o', label = \"ovserved data\")\nplt.plot(x,X@What.data,'--', label = r\"$\\hat{\\bf y}={\\bf X}@\\hat{\\bf W}$ after 30 iterations (=epochs)\")\nplt.legend()"
  },
  {
    "objectID": "posts/02wk-1.html#a.-단순무식한-print",
    "href": "posts/02wk-1.html#a.-단순무식한-print",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 단순무식한 print",
    "text": "A. 단순무식한 print\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nprint(f\"시작값 = {What.data.reshape(-1)}\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    print(f'loss = {loss:.2f} \\t 업데이트폭 = {-0.001 * What.grad.reshape(-1)} \\t 업데이트결과: {What.data.reshape(-1)}')\n    What.grad = None\n\n시작값 = tensor([-5., 10.])\nloss = 8587.62   업데이트폭 = tensor([ 1.3422, -1.1889])      업데이트결과: tensor([-3.6578,  8.8111])\nloss = 5675.18   업데이트폭 = tensor([ 1.1029, -0.9499])      업데이트결과: tensor([-2.5548,  7.8612])\nloss = 3755.63   업데이트폭 = tensor([ 0.9056, -0.7596])      업데이트결과: tensor([-1.6492,  7.1016])\nloss = 2489.58   업데이트폭 = tensor([ 0.7431, -0.6081])      업데이트결과: tensor([-0.9061,  6.4935])\nloss = 1654.04   업데이트폭 = tensor([ 0.6094, -0.4872])      업데이트결과: tensor([-0.2967,  6.0063])\nloss = 1102.33   업데이트폭 = tensor([ 0.4995, -0.3907])      업데이트결과: tensor([0.2028, 5.6156])\nloss = 737.85    업데이트폭 = tensor([ 0.4091, -0.3136])      업데이트결과: tensor([0.6119, 5.3020])\nloss = 496.97    업데이트폭 = tensor([ 0.3350, -0.2519])      업데이트결과: tensor([0.9469, 5.0501])\nloss = 337.72    업데이트폭 = tensor([ 0.2742, -0.2025])      업데이트결과: tensor([1.2211, 4.8477])\nloss = 232.40    업데이트폭 = tensor([ 0.2243, -0.1629])      업데이트결과: tensor([1.4453, 4.6848])\nloss = 162.73    업데이트폭 = tensor([ 0.1834, -0.1311])      업데이트결과: tensor([1.6288, 4.5537])\nloss = 116.64    업데이트폭 = tensor([ 0.1500, -0.1056])      업데이트결과: tensor([1.7787, 4.4481])\nloss = 86.13     업데이트폭 = tensor([ 0.1226, -0.0851])      업데이트결과: tensor([1.9013, 4.3629])\nloss = 65.94     업데이트폭 = tensor([ 0.1001, -0.0687])      업데이트결과: tensor([2.0014, 4.2942])\nloss = 52.57     업데이트폭 = tensor([ 0.0818, -0.0554])      업데이트결과: tensor([2.0832, 4.2388])\nloss = 43.72     업데이트폭 = tensor([ 0.0668, -0.0447])      업데이트결과: tensor([2.1500, 4.1941])\nloss = 37.86     업데이트폭 = tensor([ 0.0545, -0.0361])      업데이트결과: tensor([2.2045, 4.1579])\nloss = 33.98     업데이트폭 = tensor([ 0.0445, -0.0292])      업데이트결과: tensor([2.2490, 4.1287])\nloss = 31.41     업데이트폭 = tensor([ 0.0363, -0.0236])      업데이트결과: tensor([2.2853, 4.1051])\nloss = 29.70     업데이트폭 = tensor([ 0.0296, -0.0191])      업데이트결과: tensor([2.3150, 4.0860])\nloss = 28.58     업데이트폭 = tensor([ 0.0242, -0.0155])      업데이트결과: tensor([2.3391, 4.0705])\nloss = 27.83     업데이트폭 = tensor([ 0.0197, -0.0125])      업데이트결과: tensor([2.3589, 4.0580])\nloss = 27.33     업데이트폭 = tensor([ 0.0161, -0.0101])      업데이트결과: tensor([2.3749, 4.0479])\nloss = 27.01     업데이트폭 = tensor([ 0.0131, -0.0082])      업데이트결과: tensor([2.3881, 4.0396])\nloss = 26.79     업데이트폭 = tensor([ 0.0107, -0.0067])      업데이트결과: tensor([2.3988, 4.0330])\nloss = 26.65     업데이트폭 = tensor([ 0.0087, -0.0054])      업데이트결과: tensor([2.4075, 4.0276])\nloss = 26.55     업데이트폭 = tensor([ 0.0071, -0.0044])      업데이트결과: tensor([2.4146, 4.0232])\nloss = 26.49     업데이트폭 = tensor([ 0.0058, -0.0035])      업데이트결과: tensor([2.4204, 4.0197])\nloss = 26.45     업데이트폭 = tensor([ 0.0047, -0.0029])      업데이트결과: tensor([2.4251, 4.0168])\nloss = 26.42     업데이트폭 = tensor([ 0.0038, -0.0023])      업데이트결과: tensor([2.4289, 4.0145])"
  },
  {
    "objectID": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "href": "posts/02wk-1.html#b.-반복시각화-yhat의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 반복시각화 – yhat의 관점에서!",
    "text": "B. 반복시각화 – yhat의 관점에서!\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfig = plt.plot(x,y,'o',label = \"observed\")\nplt.plot(x,X@What.data,'--',color=\"C1\")\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    plt.plot(x,X@What.data,'--',color=\"C1\",alpha=0.1)\n    What.grad = None"
  },
  {
    "objectID": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "href": "posts/02wk-1.html#c.-반복시각화-loss의-관점에서",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "C. 반복시각화 – loss의 관점에서!!",
    "text": "C. 반복시각화 – loss의 관점에서!!\n\ndef plot_loss():\n    fig = plt.figure()\n    ax = fig.add_subplot(projection='3d')\n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax.azim = 30  ## 3d plot의 view 조절 \n    ax.dist = 8   ## 3d plot의 view 조절 \n    ax.elev = 5   ## 3d plot의 view 조절 \n    ax.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    return fig\n\n\nl(-5,10)\n\ntensor(8587.6240)\n\n\n\nfig = plot_loss()\n\n\n\n\n\n\n\n\n\nfig = plot_loss()\nax = fig.gca()\nax.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\nax.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue', label=r\"initial $\\hat{\\bf W}=[-5, 10]'$\")\nax.legend()\n\n\n\n\n\n\n\n\n\nw0,w1 = What.data.reshape(-1)\n\n\nWhat.data\n\ntensor([[2.4289],\n        [4.0145]])\n\n\n\nw0,w1\n\n(tensor(2.4289), tensor(4.0145))\n\n\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad=True)\nalpha = 0.001\nfor epoc in range(30):\n    yhat = X @ What\n    loss = torch.sum((y-yhat)**2)\n    loss.backward()\n    What.data = What.data - 0.001 * What.grad\n    w0,w1 = What.data.reshape(-1) \n    ax.scatter(w0,w1,l(w0,w1),s=5,marker='o',color='blue')\n    What.grad = None\n\n\nfig"
  },
  {
    "objectID": "posts/02wk-1.html#d.-애니메이션",
    "href": "posts/02wk-1.html#d.-애니메이션",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "D. 애니메이션",
    "text": "D. 애니메이션\n\nfrom matplotlib import animation\n\n\nplt.rcParams['figure.figsize'] = (7.5,2.5)\nplt.rcParams[\"animation.html\"] = \"jshtml\" \n\n\ndef show_animation(alpha=0.001):\n    ## 1. 히스토리 기록을 위한 list 초기화\n    loss_history = [] \n    yhat_history = [] \n    What_history = [] \n\n    ## 2. 학습 + 학습과정기록\n    What= torch.tensor([[-5.0],[10.0]],requires_grad=True)\n    What_history.append(What.data.tolist())\n    for epoc in range(30): \n        yhat=X@What ; yhat_history.append(yhat.data.tolist())\n        loss=torch.sum((y-yhat)**2); loss_history.append(loss.item())\n        loss.backward() \n        What.data = What.data - alpha * What.grad; What_history.append(What.data.tolist())\n        What.grad = None    \n\n    ## 3. 시각화 \n    fig = plt.figure()\n    ax1 = fig.add_subplot(1, 2, 1)\n    ax2 = fig.add_subplot(1, 2, 2, projection='3d')\n\n    #### ax1: yhat의 관점에서.. \n    ax1.plot(x,y,'o',label=r\"$(x_i,y_i)$\")\n    line, = ax1.plot(x,yhat_history[0],label=r\"$(x_i,\\hat{y}_i)$\") \n    ax1.legend()\n    #### ax2: loss의 관점에서.. \n    w0 = np.arange(-6, 11, 0.5) \n    w1 = np.arange(-6, 11, 0.5)\n    W1,W0 = np.meshgrid(w1,w0)\n    LOSS=W0*0\n    for i in range(len(w0)):\n        for j in range(len(w1)):\n            LOSS[i,j]=torch.sum((y-w0[i]-w1[j]*x)**2)\n    ax2.plot_surface(W0, W1, LOSS, rstride=1, cstride=1, color='b',alpha=0.1)\n    ax2.azim = 30  ## 3d plot의 view 조절 \n    ax2.dist = 8   ## 3d plot의 view 조절 \n    ax2.elev = 5   ## 3d plot의 view 조절 \n    ax2.set_xlabel(r'$w_0$')  # x축 레이블 설정\n    ax2.set_ylabel(r'$w_1$')  # y축 레이블 설정\n    ax2.set_xticks([-5,0,5,10])  # x축 틱 간격 설정\n    ax2.set_yticks([-5,0,5,10])  # y축 틱 간격 설정\n    ax2.scatter(2.5, 4, l(2.5,4), s=200, marker='*', color='red', label=r\"${\\bf W}=[2.5, 4]'$\")\n    ax2.scatter(-5, 10, l(-5,10), s=200, marker='*', color='blue')\n    ax2.legend()\n    def animate(epoc):\n        line.set_ydata(yhat_history[epoc])\n        ax2.scatter(np.array(What_history)[epoc,0],np.array(What_history)[epoc,1],loss_history[epoc],color='grey')\n        fig.suptitle(f\"alpha = {alpha} / epoch = {epoc}\")\n        return line\n\n    ani = animation.FuncAnimation(fig, animate, frames=30)\n    plt.close()\n    return ani\n\n\nepoch = 0 부터 시작하여 시작점에서 출발하도록 애니메이션을 수정했습니당.\n\n\nani = show_animation(alpha=0.001)\nani\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "href": "posts/02wk-1.html#e.-학습률에-따른-시각화",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "E. 학습률에 따른 시각화",
    "text": "E. 학습률에 따른 시각화\n- \\(\\alpha\\)가 너무 작다면 비효율적임\n\nshow_animation(alpha=0.0001)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- \\(\\alpha\\)가 크다고 무조건 좋은건 또 아님\n\nshow_animation(alpha=0.0083)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 수틀리면 수렴안할수도??\n\nshow_animation(alpha=0.0085)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- 그냥 망할수도??\n\nshow_animation(alpha=0.01)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/02wk-1.html#a.-해결하고-싶은것",
    "href": "posts/02wk-1.html#a.-해결하고-싶은것",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "A. 해결하고 싶은것",
    "text": "A. 해결하고 싶은것\n아래와 같은 선형모형이 있다고 가정하자.\n\\[{\\bf y}={\\bf X}{\\boldsymbol \\beta} + {\\boldsymbol \\epsilon}\\]\n이러한 모형에 대하여 아래와 같이 손실함수를 정의하자.\n\\[loss({\\boldsymbol \\beta}) = ({\\bf y} - {\\bf X}{\\boldsymbol \\beta})^\\top({\\bf y} - {\\bf X}{\\boldsymbol \\beta}) \\]\n이때 손실함수의 미분값을 아래와 같이 주어지고,\n\\[\\frac{\\partial}{\\partial {\\boldsymbol \\beta}}loss({\\boldsymbol \\beta}) = -2{\\bf X}^\\top{\\bf y}+2{\\bf X}^\\top{\\bf X}{\\boldsymbol \\beta}\\]\n따라서 손실함수를 최소화하는 추정량이 아래와 같이 주어짐을 보여라.\n\\[\\hat{\\boldsymbol \\beta} = ({\\bf X}^\\top {\\bf X})^{-1}{\\bf X}^\\top{\\bf y}\\]"
  },
  {
    "objectID": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "href": "posts/02wk-1.html#b.-해설강의-및-보충자료",
    "title": "02wk-1: 회귀분석 (2) – Step1~4 / 벡터미분",
    "section": "B. 해설강의 및 보충자료",
    "text": "B. 해설강의 및 보충자료\n\nhttps://github.com/guebin/DL2024/blob/main/posts/02wksupp.pdf"
  },
  {
    "objectID": "posts/09wk-2.html",
    "href": "posts/09wk-2.html",
    "title": "09wk-2: 중간고사",
    "section": "",
    "text": "import torch \nimport torchvision\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport fastai.vision.all\n\n\n1. 크롤링을 통한 이미지 분석 및 CAM – 30점\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것) – 01wk-1 의 HW를 그대로 활용해도 무방\n(2) ImageDataLoaders.from_folder 를 이용하여 dls를 만들어라.\n(3) resnet34를 이용하여 학습하라.\n(4) CAM (class activation mapping)을 이용하여 (3)의 모형의 판단근거를 시각화하라.\n\n\n2. 생성모형 / GAN – 40점\n아래는 torchvision을 활용하여 MNIST 데이터를 불러오고 DataLoader를 생성하는 코드이다.\n\n# Data preprocessing\nds = dataset = torchvision.datasets.MNIST(\n    root = './data',\n    download=True,\n    transform = torchvision.transforms.Compose([\n        torchvision.transforms.Resize(64), # 이미지를 (64,64)로 resize \n        torchvision.transforms.ToTensor(),\n        torchvision.transforms.Normalize((0.5,), (0.5,))\n    ])\n)\n# Dataloader\ndl = torch.utils.data.DataLoader(\n    ds, \n    batch_size=120,\n    shuffle=True, \n)\n\n(1) iter와 next를 이용하여 데이터로더의 첫번째 배치를 출력하라. 하나의 배치에 몇개의 이미지가 있는가? 이미지는 흑백인가 칼라인가? 이미지의 크기는 얼마인가?\n(풀이)\n\nxi_real, _  = next(iter(dl))\n\n\nxi_real.shape\n\ntorch.Size([120, 1, 64, 64])\n\n\n(2) 아래의 함수를 이용하여 하나의 배치에 포함된 이미지를 출력하라.\n\ndef imshow(xi_real):\n    plt.imshow(torch.einsum('cij-&gt;ijc',torchvision.utils.make_grid(xi_real, padding=2, normalize=True)))\n\n(풀이)\n\nxi_real, _ = next(iter(dl))\n\n\nimshow(xi_real)\n\n\n\n\n\n\n\n\n(3) 아래의 코드를 이용하여 net_police를 생성하라.\n\nnet_police = torch.nn.Sequential(\n    # Layer1\n    torch.nn.Conv2d(1, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.LeakyReLU(0.2),\n    # Layer2\n    torch.nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(128),\n    torch.nn.LeakyReLU(0.2),\n    # Layer3\n    torch.nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(256),\n    torch.nn.LeakyReLU(0.2),\n    # Layer4\n    torch.nn.Conv2d(256, 512, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(512),\n    torch.nn.LeakyReLU(0.2),\n    # Layer5\n    torch.nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0, bias=False),\n    torch.nn.Sigmoid(),\n    torch.nn.Flatten()\n)\n\nnet_police에 하나의 배치를 넣어보고 각 층별 출력크기를 조사하라.\n(풀이)\n\nxi_real, _ = next(iter(dl))\n\n\nprint(f'xi_real -- {xi_real.shape}')\nprint(f'Layer1 -- {net_police[:2](xi_real).shape}')\nprint(f'Layer2 -- {net_police[:5](xi_real).shape}')\nprint(f'Layer3 -- {net_police[:8](xi_real).shape}')\nprint(f'Layer4 -- {net_police[:11](xi_real).shape}')\nprint(f'Layer5 -- {net_police(xi_real).shape}')\n\nxi_real -- torch.Size([120, 1, 64, 64])\nLayer1 -- torch.Size([120, 64, 32, 32])\nLayer2 -- torch.Size([120, 128, 16, 16])\nLayer3 -- torch.Size([120, 256, 8, 8])\nLayer4 -- torch.Size([120, 512, 4, 4])\nLayer5 -- torch.Size([120, 1])\n\n\n(4) 아래의 코드를 이용하여 net_faker를 생성하라.\n\nnet_faker = torch.nn.Sequential(\n    # Layer1\n    torch.nn.ConvTranspose2d(100, 512, kernel_size=4, stride=1, padding=0, bias=False),\n    torch.nn.BatchNorm2d(512),\n    torch.nn.ReLU(),\n    # Layer2\n    torch.nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(256),\n    torch.nn.ReLU(),\n    # Layer3\n    torch.nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(128),\n    torch.nn.ReLU(),\n    # Layer4\n    torch.nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.BatchNorm2d(64),\n    torch.nn.ReLU(),\n    # Layer5\n    torch.nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n    torch.nn.Tanh()\n)\n\nnet_faker에 아래의 noise를 넣어보고 각 층별 출력크기를 조사하라.\nni = torch.randn(batch_size, 100, 1, 1)\n(풀이)\n\nni = torch.randn(120, 100, 1, 1)\n\n\nprint(f'ni -- {ni.shape}')\nprint(f'Layer1 -- {net_faker[:3](ni).shape}')\nprint(f'Layer2 -- {net_faker[:6](ni).shape}')\nprint(f'Layer3 -- {net_faker[:9](ni).shape}')\nprint(f'Layer4 -- {net_faker[:12](ni).shape}')\nprint(f'Layer5 -- {net_faker(ni).shape}')\n\nni -- torch.Size([120, 100, 1, 1])\nLayer1 -- torch.Size([120, 512, 4, 4])\nLayer2 -- torch.Size([120, 256, 8, 8])\nLayer3 -- torch.Size([120, 128, 16, 16])\nLayer4 -- torch.Size([120, 64, 32, 32])\nLayer5 -- torch.Size([120, 1, 64, 64])\n\n\n(5) 아래와 같이 두개의 optimizr 를 선언하라.\n\noptimizr_police = torch.optim.Adam(net_police.parameters(), lr=0.0002, betas=(0.5, 0.999))\noptimizr_faker = torch.optim.Adam(net_faker.parameters(), lr=0.0002, betas=(0.5, 0.999))\n\n아래의 세부지침에 맞추어 net_police 와 net_faker를 학습하라.\n\n5 Epoch을 진행하여 학습할 것\nGPU를 이용하여 학습할 것\n\n(풀이)\n\nbce = torch.nn.BCELoss()\n\n\nnet_faker.to(\"cuda:0\")\nnet_police.to(\"cuda:0\")\nfor epoc in range(5):\n    for xi_real, _ in dl:\n        xi_real = xi_real.to(\"cuda:0\")\n        ni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\n        xi_fake = net_faker(ni).data\n        yi_real = torch.zeros(120).reshape(-1,1).to(\"cuda:0\")\n        yi_fake = torch.ones(120).reshape(-1,1).to(\"cuda:0\")\n        # step1 \n        yi_hat_real = net_police(xi_real)\n        yi_hat_fake = net_police(xi_fake)\n        # step2 \n        loss_police = bce(yi_hat_real, yi_real) + bce(yi_hat_fake, yi_fake)        \n        # step3 \n        loss_police.backward()\n        # step4 \n        optimizr_police.step()\n        optimizr_police.zero_grad()    \n        #--#\n        # step1\n        ni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\n        xi_fake = net_faker(ni)\n        # step2\n        yi_hat_fake = net_police(net_faker(ni))\n        loss_faker = bce(yi_hat_fake, yi_real)\n        # step3 \n        loss_faker.backward()\n        # step4 \n        optimizr_faker.step()\n        optimizr_faker.zero_grad()\n    print(f\"epoch = {epoc+1}/5\")\n\nepoch = 1/5\nepoch = 2/5\nepoch = 3/5\nepoch = 4/5\nepoch = 5/5\n\n\n(6) 학습결과를 (2)의 imshow 함수를 이용하여 시각화하라.\n(풀이)\n\nni = torch.randn(120, 100, 1, 1).to(\"cuda:0\")\nxi_fake = net_faker(ni).data.to(\"cpu\")\nimshow(xi_fake)\n\n\n\n\n\n\n\n\n\n\n3. 단순회귀문제 – 10점\n주어진 자료가 아래와 같다고 하자.\n\ntorch.manual_seed(43052)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = 2.5+ 4*x + ϵ\n\n\nplt.plot(x,y,'o')\n\n\n\n\n\n\n\n\n(1) torch.nn.Linear를 이용하여 아래와 같은 최초의 직선을 생성하는 네트워크를 설계하라. – 1점\n\\[\\hat{y}_i = -5.0 + 10.0 x_i \\]\n(풀이)\n\nl = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nl.weight.data = l.weight.data*0 + 10 \nl.bias.data = l.bias.data*0 - 5 \n\n\nl(x)[:5], (-5+10*x)[:5] \n\n(tensor([[-29.8211],\n         [-28.6215],\n         [-24.9730],\n         [-21.2394],\n         [-19.7919]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[-29.8211],\n         [-28.6215],\n         [-24.9730],\n         [-21.2394],\n         [-19.7919]]))\n\n\n(2) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (1)의 결과로 얻은 값을 사용하라. – 1점\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(풀이)\n\nloss_fn = torch.nn.MSELoss()\nloss_fn(y,l(x))\n\ntensor(85.8769, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n(3) 적당한 matrix \\({\\bf X}_{n\\times 2}\\) 와 \\(\\hat{\\bf W}_{2\\times 1}\\) 을 정의하여 아래와 같이 \\(\\hat{y}_i\\)을 구하라. – 1점\n\\[\\hat{y}_i = -5.0 + 5.0 x_i \\]\n(풀이)\n\nWhat = torch.tensor([[-5.0],[5.0]],requires_grad=True)\nX = torch.concat([torch.ones(100,1),x],axis=1)\n(X@What)[:5], (-5+5*x)[:5] \n\n(tensor([[-17.4106],\n         [-16.8107],\n         [-14.9865],\n         [-13.1197],\n         [-12.3960]], grad_fn=&lt;SliceBackward0&gt;),\n tensor([[-17.4106],\n         [-16.8107],\n         [-14.9865],\n         [-13.1197],\n         [-12.3960]]))\n\n\n(4) 아래의 수식에 대응하는 loss를 계산하라. 여기에서 \\(\\hat{y}_i\\)은 (3)의 결과로 얻은 값을 사용하라. – 1점\n\\[loss = \\frac{1}{n}\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2\\]\n(풀이)\n\nloss_fn(y,X@What)\n\ntensor(55.0216, grad_fn=&lt;MseLossBackward0&gt;)\n\n\n(5) (2)에서 얻은 \\(\\hat{y}_i\\) (4)에서 얻은 \\(\\hat{y}_i\\) 중 무엇이 더 적절하다고 생각하는가? 이유는 무엇인가? 손실(=loss)에 근거하여 설명하라. – 2점\n(풀이)\n(4)에서 얻은 \\(\\hat{y}_i\\)이 더 적절하다. 이유는 loss값이 더 작기 때문. (55.0216 &lt; 85.8769)\n(6) .backward() 를 이용하여 (2)와 (4)에 해당하는 미분값을 계산하라. 학습률이 0.01인 경사하강법을 이용하여 (1),(3) 에 대응하는 가중치를 update 하라. – 4점\n(풀이)\n\nloss = loss_fn(y,l(x)) \nloss.backward()\nl.weight.data = l.weight.data - 0.01 * l.weight.grad\nl.bias.data = l.bias.data - 0.01 * l.bias.grad\n\n\nprint(f\"(2)의 update\\nbias = {l.bias.data}\\nweight = {l.weight.data}\")\n\n(2)의 update\nbias = tensor([-4.8658])\nweight = tensor([[9.8811]])\n\n\n\nloss = loss_fn(y,X@What) \nloss.backward()\nWhat = What.data - 0.01 * What.grad\n\n\nprint(f\"(4)의 update\\n{What.data}\")\n\n(4)의 update\ntensor([[-4.8535],\n        [ 4.9955]])\n\n\n(또 다른 풀이)\n\nl = torch.nn.Linear(in_features=1,out_features=1,bias=True)\nl.weight.data = l.weight.data*0 + 10 \nl.bias.data = l.bias.data*0 - 5 \nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(l.parameters(),lr=0.01) \n#--# \nyhat = l(x) # step1 \nloss = loss_fn(y,yhat) # step2 \nloss.backward() # step 3 \noptimizr.step() # step 4 \nprint(f\"(2)의 update\\nbias = {l.bias.data}\\nweight = {l.weight.data}\")\n\n(2)의 update\nbias = tensor([-4.8658])\nweight = tensor([[9.8811]])\n\n\n\nWhat = torch.tensor([[-5.0],[5.0]],requires_grad=True)\nX = torch.concat([torch.ones(100,1),x],axis=1)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD([What],lr=0.01) # 이건 안알려준 코드임\n#--#\nyhat = X@What # step1 \nloss = loss_fn(y,yhat) # step2  \nloss.backward() # step3 \noptimizr.step() # step4 \nprint(f\"(4)의 update\\n{What.data}\")\n\n(4)의 update\ntensor([[-4.8535],\n        [ 4.9955]])\n\n\n\n\n4. 네트워크 설계 – 10점\n아래는 mnist자료를 분류하는 네트워크의 예시이다. 그림에 대응하는 네트워크를 파이토치로 설계하라.\n\n\n그림에서 n1=6, n2=16, n3=120 으로 설정하고, 드랍아웃비율은 50%로 설정하라.\n인풋이미지의 차원은 (28,28,1) 이 아니라 (n,1,28,28) 로 해석하라. 동일한 논리로 Conv1의 통과결과도 (n,n1,24,24) 로 해석하라.\nvalid padding 의 의미는 padding 을 하지 않는다는 의미이다.\n\n(풀이)\n\nx = torch.zeros(1,1,28,28)\nx.shape\n\ntorch.Size([1, 1, 28, 28])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(1,6,kernel_size=(5,5)),\n    torch.nn.MaxPool2d(2,2),\n    torch.nn.Conv2d(6,16,kernel_size=(5,5)),\n    torch.nn.MaxPool2d(2,2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(256,120),\n    torch.nn.ReLU(),\n    torch.nn.Linear(120,10),\n    torch.nn.Dropout(0.5),\n    #torch.nn.Softmax()\n)\n\n\nfor i,l in enumerate(net):\n    print(f\"{i}: {net[:i](x).shape} --&gt; {str(l)}\")\n\n0: torch.Size([1, 1, 28, 28]) --&gt; Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n1: torch.Size([1, 6, 24, 24]) --&gt; MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n2: torch.Size([1, 6, 12, 12]) --&gt; Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n3: torch.Size([1, 16, 8, 8]) --&gt; MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n4: torch.Size([1, 16, 4, 4]) --&gt; Flatten(start_dim=1, end_dim=-1)\n5: torch.Size([1, 256]) --&gt; Linear(in_features=256, out_features=120, bias=True)\n6: torch.Size([1, 120]) --&gt; ReLU()\n7: torch.Size([1, 120]) --&gt; Linear(in_features=120, out_features=10, bias=True)\n8: torch.Size([1, 10]) --&gt; Dropout(p=0.5, inplace=False)\n\n\n\n\n5. 신경망의 학습 – 10점\n아래를 이용하여 데이터를 불러오라.\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nu = -1 + 5*x\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n(1) torch.utils.data.TensorDataset, torch.utils.data.DataLoader 를 이용하여 아래의 세부지침을 따르는 적당한 dataloader를 만들라. – 2점\n세부지침\n\nbatch_size = 128 로 설정할 것\nshuffle = False 로 설정할 것\n\n(풀이)\n\nds = torch.utils.data.TensorDataset(x,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128,shuffle=False)\n\n(2) 주어진 자료를 해석할 수 있는 적절한 net 및 손실함수를 설정하고 아래의 세부지침에 맞추어 학습하라. – 8점\n세부지침\n\n30 epochs 학습\nGPU를 이용하여 학습 할 것\n옵티마이저로 torch.optim.Adam을 사용하고 학습률은 0.05로 설정할 것\n\n(풀이)\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.05)\n\n\nfor epoc in range(30):\n    for xi,yi in dl:\n        ## step0: 싹다 쿠다로..\n        xi = xi.to(\"cuda:0\")\n        yi = yi.to(\"cuda:0\")\n        ## step1 \n        yi_hat = net(xi)\n        ## step2 \n        loss = loss_fn(yi_hat, yi) \n        ## step3 \n        loss.backward()\n        ## step4 \n        optimizr.step()\n        optimizr.zero_grad()\n\n\nnet.to(\"cpu\")\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,net(x).data,'--b',label=r\"prob (estimated)\")\nplt.legend()"
  },
  {
    "objectID": "posts/01wk-1.html#a.-최하니",
    "href": "posts/01wk-1.html#a.-최하니",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. 최하니",
    "text": "A. 최하니\n\nhani1 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nhani1\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani1)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([2.1732e-09, 1.0000e+00]))\n\n\n\nhani2 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani2.jpeg?raw=true').content)\nhani2\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani2)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([7.2584e-07, 1.0000e+00]))\n\n\n\nhani3 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani3.jpg?raw=true').content)\nhani3\n\n\n\n\n\n\n\n\n\nlrnr.predict(hani3)\n\n\n\n\n\n\n\n\n('dog', tensor(1), tensor([6.7243e-05, 9.9993e-01]))"
  },
  {
    "objectID": "posts/01wk-1.html#b.-인터넷-고양이",
    "href": "posts/01wk-1.html#b.-인터넷-고양이",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. 인터넷 고양이",
    "text": "B. 인터넷 고양이\n\ncat1 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat1.png?raw=true').content)\ncat1\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat1)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([1.0000e+00, 2.2610e-12]))\n\n\n\ncat2 = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-cat2.jpeg?raw=true').content)\ncat2\n\n\n\n\n\n\n\n\n\nlrnr.predict(cat2)\n\n\n\n\n\n\n\n\n('cat', tensor(0), tensor([9.9963e-01, 3.6982e-04]))"
  },
  {
    "objectID": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "href": "posts/01wk-1.html#a.-step1-dls데이터-준비",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "A. Step1: DLS(=데이터) 준비",
    "text": "A. Step1: DLS(=데이터) 준비\n\ndls = fastai.vision.data.ImageDataLoaders.from_folder(\n    path = './images',\n    train='train',\n    valid_pct = 0.2,\n    item_tfms=fastai.vision.augment.Resize(224),\n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/01wk-1.html#b.-step2-러너생성",
    "href": "posts/01wk-1.html#b.-step2-러너생성",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "B. Step2: 러너생성",
    "text": "B. Step2: 러너생성\n\nlrnr = fastai.vision.learner.vision_learner(\n    dls = dls,\n    arch = fastai.vision.models.resnet34,\n    metrics = fastai.metrics.accuracy\n)"
  },
  {
    "objectID": "posts/01wk-1.html#c.-step3-학습",
    "href": "posts/01wk-1.html#c.-step3-학습",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "C. Step3: 학습",
    "text": "C. Step3: 학습\n\nlrnr.fine_tune(7)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.058250\n1.492724\n0.515625\n00:05\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.611757\n0.886693\n0.625000\n00:05\n\n\n1\n0.467988\n0.630385\n0.765625\n00:05\n\n\n2\n0.336618\n0.560025\n0.812500\n00:05\n\n\n3\n0.259717\n0.571055\n0.812500\n00:05\n\n\n4\n0.212600\n0.535282\n0.812500\n00:05\n\n\n5\n0.176119\n0.523694\n0.828125\n00:05\n\n\n6\n0.147607\n0.508762\n0.843750\n00:05"
  },
  {
    "objectID": "posts/01wk-1.html#d.-step4-예측",
    "href": "posts/01wk-1.html#d.-step4-예측",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "D. Step4: 예측",
    "text": "D. Step4: 예측\n\nlrnr.show_results()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ninter = fastai.interpret.Interpretation.from_learner(lrnr)\ninter.plot_top_losses(16)"
  },
  {
    "objectID": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "href": "posts/01wk-1.html#크롤링을-활용한-이미지-자료-분석",
    "title": "01wk-1: 이미지 자료 분석 (겉핥기)",
    "section": "#. 크롤링을 활용한 이미지 자료 분석",
    "text": "#. 크롤링을 활용한 이미지 자료 분석\n(1) 두 가지 키워드로 크롤링을 수행하여 이미지자료를 모아라. (키워드는 각자 마음에 드는 것으로 설정할 것, 단 (iu,hynn)는 제외)\n(2) fastai.vision.data.ImageDataLoaders() 를 이용하여 dls를 만들고 dls.show_batch()를 이용하여 만들어진 이미지를 확인하라.\n(3) fastai.vision.learner.vision_learner()를 이용하여 lrnr를 만들고 lrnr.fine_tune()을 이용하여 학습하라. 이때 모형의 arch는 resnet34를 사용하라.\n(4) requests.get()을 이용하여 (1)의 키워드에 해당하는 새로운 이미지를 한장씩 다운받고 (3)에서 학습한 lrnr를 이용하여 예측하라.\n\n제출은 ipynb파일로 할 것. 혹은 스크린샷을 제출해도 괜찮음."
  },
  {
    "objectID": "posts/02wk-2.html#a.-data",
    "href": "posts/02wk-2.html#a.-data",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "A. Data",
    "text": "A. Data\n\ntemp = [-2.4821, -2.3621, -1.9973, -1.6239, -1.4792, -1.4635, -1.4509, -1.4435,\n        -1.3722, -1.3079, -1.1904, -1.1092, -1.1054, -1.0875, -0.9469, -0.9319,\n        -0.8643, -0.7858, -0.7549, -0.7421, -0.6948, -0.6103, -0.5830, -0.5621,\n        -0.5506, -0.5058, -0.4806, -0.4738, -0.4710, -0.4676, -0.3874, -0.3719,\n        -0.3688, -0.3159, -0.2775, -0.2772, -0.2734, -0.2721, -0.2668, -0.2155,\n        -0.2000, -0.1816, -0.1708, -0.1565, -0.1448, -0.1361, -0.1057, -0.0603,\n        -0.0559, -0.0214,  0.0655,  0.0684,  0.1195,  0.1420,  0.1521,  0.1568,\n         0.2646,  0.2656,  0.3157,  0.3220,  0.3461,  0.3984,  0.4190,  0.5443,\n         0.5579,  0.5913,  0.6148,  0.6469,  0.6469,  0.6523,  0.6674,  0.7059,\n         0.7141,  0.7822,  0.8154,  0.8668,  0.9291,  0.9804,  0.9853,  0.9941,\n         1.0376,  1.0393,  1.0697,  1.1024,  1.1126,  1.1532,  1.2289,  1.3403,\n         1.3494,  1.4279,  1.4994,  1.5031,  1.5437,  1.6789,  2.0832,  2.2444,\n         2.3935,  2.6056,  2.6057,  2.6632]\nsales= [-8.5420, -6.5767, -5.9496, -4.4794, -4.2516, -3.1326, -4.0239, -4.1862,\n        -3.3403, -2.2027, -2.0262, -2.5619, -1.3353, -2.0466, -0.4664, -1.3513,\n        -1.6472, -0.1089, -0.3071, -0.6299, -0.0438,  0.4163,  0.4166, -0.0943,\n         0.2662,  0.4591,  0.8905,  0.8998,  0.6314,  1.3845,  0.8085,  1.2594,\n         1.1211,  1.9232,  1.0619,  1.3552,  2.1161,  1.1437,  1.6245,  1.7639,\n         1.6022,  1.7465,  0.9830,  1.7824,  2.1116,  2.8621,  2.1165,  1.5226,\n         2.5572,  2.8361,  3.3956,  2.0679,  2.8140,  3.4852,  3.6059,  2.5966,\n         2.8854,  3.9173,  3.6527,  4.1029,  4.3125,  3.4026,  3.2180,  4.5686,\n         4.3772,  4.3075,  4.4895,  4.4827,  5.3170,  5.4987,  5.4632,  6.0328,\n         5.2842,  5.0539,  5.4538,  6.0337,  5.7250,  5.7587,  6.2020,  6.5992,\n         6.4621,  6.5140,  6.6846,  7.3497,  8.0909,  7.0794,  6.8667,  7.4229,\n         7.2544,  7.1967,  9.5006,  9.0339,  7.4887,  9.0759, 11.0946, 10.3260,\n        12.2665, 13.0983, 12.5468, 13.8340]\nx = torch.tensor(temp).reshape(-1,1)\nones = torch.ones(100).reshape(-1,1)\nX = torch.concat([ones,x],axis=1)\ny = torch.tensor(sales).reshape(-1,1)"
  },
  {
    "objectID": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "href": "posts/02wk-2.html#b.-파이토치를-이용한-학습",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "B. 파이토치를 이용한 학습",
    "text": "B. 파이토치를 이용한 학습\n- 외우세여\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    loss = torch.sum((y-yhat)**2)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.001 * What.grad\n    What.grad = None\n\n- 결과 시각화\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#c.-step2의-수정",
    "href": "posts/02wk-2.html#c.-step2의-수정",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "C. Step2의 수정",
    "text": "C. Step2의 수정\n- 수정된 코드\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = X@What \n    # step2: loss\n    #loss = torch.sum((y-yhat)**2)/100\n    #loss = torch.mean((y-yhat)**2) \n    loss = loss_fn(yhat,y) # 여기서는 큰 상관없지만 습관적으로 yhat을 먼저넣는 연습을 하자!!\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    What.data = What.data - 0.1 * What.grad\n    What.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,X@What.data,'--')\nplt.title(f'What={What.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "href": "posts/02wk-2.html#d.-step1의-수정-net의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "D. Step1의 수정 – net의 이용",
    "text": "D. Step1의 수정 – net의 이용\n- net 오브젝트란?\n원래 yhat을 이런식으로 구했는데 ~\n\nWhat = torch.tensor([[-5.0],[10.0]],requires_grad = True)\n(X@What.data)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]])\n\n\n이런식으로도 구할수 있음!\n\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\n\n\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\nnet.weight\n\nParameter containing:\ntensor([[-5., 10.]], requires_grad=True)\n\n\n\nnet(X)[:5]\n\ntensor([[-29.8210],\n        [-28.6210],\n        [-24.9730],\n        [-21.2390],\n        [-19.7920]], grad_fn=&lt;SliceBackward0&gt;)\n\n\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    net.weight.data = net.weight.data - 0.1 * net.weight.grad\n    net.weight.grad = None\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,net(X).data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "href": "posts/02wk-2.html#e.-step4의-수정-optimizer의-이용",
    "title": "02wk-2: 회귀분석 (3) – Step1,2,4 의 변형",
    "section": "E. Step4의 수정 – optimizer의 이용",
    "text": "E. Step4의 수정 – optimizer의 이용\n기존코드의 에폭별분해\n- 준비과정\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\nnet.weight.data = net.weight.data - 0.1 * net.weight.grad\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\nnet.weight.grad = None\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n새로운코드의 에폭별분해\n- 준비과정 – 옵티마이저라는 오브젝트를 셋팅한다!\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step3을 위한 사전준비 \noptimizr = torch.optim.SGD(params=net.parameters(),lr=0.1)\n\n- 에폭별분해\n(미분전) – step1~2 완료\n\nyhat = net(X)\nloss = loss_fn(yhat,y)\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = None\n\n\n(미분후, 업데이트 진행전) – step3 완료\n\nloss.backward()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-5., 10.]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 진행후) – step4 의 첫째줄 완료\n\n#net.weight.data = net.weight.data - 0.1 * net.weight.grad\noptimizr.step()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = tensor([[-13.4225,  11.8892]])\n\n\n(업데이트 완료 후 초기화까지 끝냄) – step4 의 두번째줄 완료\n\n#net.weight.grad = None\noptimizr.zero_grad()\n\n\nprint(f'파라메터 = {net.weight.data}')\nprint(f'미분값 = {net.weight.grad}')\n\n파라메터 = tensor([[-3.6578,  8.8111]])\n미분값 = None\n\n\n최종코드\n- 학습\n\n# step1을 위한 사전준비\nnet = torch.nn.Linear(\n    in_features=2,\n    out_features=1,\n    bias=False\n)\nnet.weight.data = torch.tensor([[-5.0,  10.0]])\n# step2를 위한 사전준비\nloss_fn = torch.nn.MSELoss()\n# step4를 위한 사전준비 \noptimizr = torch.optim.SGD(net.parameters(),lr=0.1)\nfor epoc in range(30):\n    # step1: yhat \n    yhat = net(X)\n    # step2: loss\n    loss = loss_fn(yhat,y)\n    # step3: 미분\n    loss.backward()\n    # step4: update\n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과확인\n\nplt.plot(x,y,'o')\nplt.plot(x,yhat.data,'--')\nplt.title(f'net.weight={net.weight.data.reshape(-1)}');"
  },
  {
    "objectID": "posts/08wk-1,2.html#a.-생성모형이란-쉬운-설명",
    "href": "posts/08wk-1,2.html#a.-생성모형이란-쉬운-설명",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "A. 생성모형이란? (쉬운 설명)",
    "text": "A. 생성모형이란? (쉬운 설명)\n\n만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자)\n\n- 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼 수 있는가?\n- 진정으로 인공지능이 이미지자료를 이해했다면, 이미지를 만들수도 있어야 한다. \\(\\to\\) 이미지를 생성하는 모형을 만들어보자 \\(\\to\\) 성공"
  },
  {
    "objectID": "posts/08wk-1,2.html#b.-gan의-응용분야",
    "href": "posts/08wk-1,2.html#b.-gan의-응용분야",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "B. GAN의 응용분야",
    "text": "B. GAN의 응용분야\n- 내가 찍은 사진이 피카소의 화풍으로 표현된다면?\n- 퀸의 라이브에이드가 4k로 나온다면?\n- 1920년대 서울의 모습이 칼라로 복원된다면?\n- 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소)\n- 거북이의 커버..\n- 너무 많아요….."
  },
  {
    "objectID": "posts/08wk-1,2.html#c.-생성모형이란-통계학과-버전의-설명",
    "href": "posts/08wk-1,2.html#c.-생성모형이란-통계학과-버전의-설명",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "C. 생성모형이란? 통계학과 버전의 설명",
    "text": "C. 생성모형이란? 통계학과 버전의 설명\n\n제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고 (=문제를 괜히 어렵게 만들어서 풀지 말고), 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자)\n\n- 이미지 \\(\\boldsymbol{X}\\) 가 주어졌을 경우 라벨을 \\(y\\) 라고 하자.\n- 이미지를 보고 라벨을 맞추는 일은 \\(p(y| \\boldsymbol{X})\\)에 관심이 있다. – 판별모형\n- 이미지를 생성하는 일은 \\(p(\\boldsymbol{X},y)\\)에 관심이 있는것이다. – 생성모형\n- 데이터의 생성확률 \\(p(\\boldsymbol{X},y)\\)을 알면 클래스의 사후확률 \\(p(y|\\boldsymbol{X})\\)를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능\n\\[p(y|{\\boldsymbol X}) = \\frac{p({\\boldsymbol X},y)}{p({\\boldsymbol X})} = \\frac{p({\\boldsymbol X},y)}{\\sum_{y}p({\\boldsymbol X},y)}\\]\n\n즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능\n\n- 따라서 배프닉의 원리에 의하면 일반적인 분류문제를 해결할때 “판별모형이 생성모형보다 더 바람직한 접근법”이라 할 수 있음. 즉 개와 고양이를 구분할 때, 그려진 개와 고양이 사진을 잘 구분하면 되는 것이지 굳이 개와 고양이를 그릴줄 알아야하는건 아니라는 의미.\n- 예전에는 머신러닝의 응용분야가 “분류/회귀”에 한정된 느낌이었는데 요즘은 생성모형도 인기있음."
  },
  {
    "objectID": "posts/08wk-1,2.html#d.-gan의-원리",
    "href": "posts/08wk-1,2.html#d.-gan의-원리",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "D. GAN의 원리",
    "text": "D. GAN의 원리\n- GAN은 생성모형 중 하나임\n- GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다.\n\nThe generative model can be thought of as analogous to a team of fakers, trying to produce fake currency and use it without detection, while the discriminative model is analogous to the police, trying to detect the counterfeit currency. Competition in this game drives both teams to improve their methods until the counterfeits are indistiguishable from the genuine articles.\n\n- 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate)\n- 무식한 상황극..\n\n위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림)\n경찰: (위조범이 만든 돈을 보고) 이건 가짜다!\n위조범: 걸렸군.. 더 정교하게 만들어야지..\n경찰: 이건 진짠가?… –&gt; 상사에게 혼남. 그것도 구분못하냐고 –&gt; (판별능력 업그레이드) –&gt; 이건 가짜다!!\n위조범: 더 정교하게 만들자..\n경찰: 더 판별능력을 업그레이드 하자!\n반복..\n\n- 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다."
  },
  {
    "objectID": "posts/08wk-1,2.html#a.-data",
    "href": "posts/08wk-1,2.html#a.-data",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "A. Data",
    "text": "A. Data\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.MNIST)\npath\n\nPath('/home/cgb3/.fastai/data/mnist_png')\n\n\n\nX_real = torch.stack([torchvision.io.read_image(str(l)) for l in (path/'training/3').ls()],axis=0)/255\nX_real.shape\n\ntorch.Size([6131, 1, 28, 28])\n\n\n\nplt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")"
  },
  {
    "objectID": "posts/08wk-1,2.html#b.-페이커-생성",
    "href": "posts/08wk-1,2.html#b.-페이커-생성",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "B. 페이커 생성",
    "text": "B. 페이커 생성\n\n“net_faker: noise \\(\\to\\) 가짜이미지” 를 만들자.\n\n- 네트워크의 입력: (n,??) 인 랜덤으로 뽑은 숫자.\n- 네트워크의 출력: (n,1,28,28)의 텐서\n\ntorch.randn(1,4) # 이게 들어온다고 상상하자.\n\ntensor([[-0.2251,  0.2474,  0.7297, -1.1856]])\n\n\n\nclass Reshape2828(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self,X):\n        return X.reshape(-1,1,28,28) \n\n\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n    Reshape2828()\n)\n\n\nnet_faker(torch.randn(1,4)).shape # 가짜이미지!\n\ntorch.Size([1, 1, 28, 28])"
  },
  {
    "objectID": "posts/08wk-1,2.html#c.-경찰-생성",
    "href": "posts/08wk-1,2.html#c.-경찰-생성",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "C. 경찰 생성",
    "text": "C. 경찰 생성\n\nnet_police: 진짜이미지 \\(\\to\\) 0 // 가짜이미지 \\(\\to\\) 1 와 같은 네트워크를 설계하자.\n\n- 네트워크의 입력: (n,1,28,28) 인 이미지\n- 네트워크의 출력: 0,1\n\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)"
  },
  {
    "objectID": "posts/08wk-1,2.html#d.-바보경찰-바보페이커",
    "href": "posts/08wk-1,2.html#d.-바보경찰-바보페이커",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "D. 바보경찰, 바보페이커",
    "text": "D. 바보경찰, 바보페이커\n\n스토리를 전개해볼까?\n\n- 경찰네트워크가 가짜이미지를 봤을때 어떤 판단을 하는지, 진짜 이미지를 봤을떄 어떤 판단을 하는지 살펴보자.\n&lt;경찰이 진짜이미지를 봤다면&gt;\n- 진짜이미지\n\nplt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n- 진짜 이미지를 경찰한테 한장 줘볼까? \\(\\to\\) yhat이 나올텐데, 이 값이 0이어야 함\n\nyhat_real = net_police(X_real[[0]]) # 이 값이 0이어야 하는데..\nyhat_real\n\ntensor([[0.5373]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n진짜 이미지가 입력으로 왔으므로 yhat_real \\(\\approx\\) 0 이어야 함\n그런데 0과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)\n\n&lt;경찰이 가짜이미지를 봤다면&gt;\n- 가짜이미지 – 데이터셋이 있는게 아니고 net_faker가 생성해야하는 데이터\n\nNoise = torch.randn(1,4)\nNoise\n\ntensor([[ 1.5179, -0.6278, -0.1390, -1.1916]])\n\n\n\nnet_faker(Noise).shape # 페이커가 만든 가짜 이미지\n\ntorch.Size([1, 1, 28, 28])\n\n\n\nplt.imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\")\n\n\n\n\n\n\n\n\n\n누가봐도 가짜이미지\n\n- 가짜 이미지를 경찰한테 한장 줘볼까? \\(\\to\\) yhat이 나올텐데, 이 값이 1이어야 함\n\nyhat_fake = net_police(net_faker(Noise).data) # 이 값이 1이어야 하는데..\nyhat_fake\n\ntensor([[0.5402]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\n가짜 이미지가 입력으로 왔으므로 yhat_fake \\(\\approx\\) 1 이어야 함\n그런데 1과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)\n\n- 페이커의 무능함 (왼쪽 이미지를 가짜이미라고 만들어 놓았음) + 경찰의 무능함 (왼쪽과 오른쪽을 보고 뭐가 진짜인지도 모름)\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\nax[1].imshow(X_real[[0]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")\n\nText(0.5, 1.0, 'real')"
  },
  {
    "objectID": "posts/08wk-1,2.html#e.-똑똑해진-경찰",
    "href": "posts/08wk-1,2.html#e.-똑똑해진-경찰",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "E. 똑똑해진 경찰",
    "text": "E. 똑똑해진 경찰\n\nX_real.shape\n\ntorch.Size([6131, 1, 28, 28])\n\n\n- 데이터 정리\n\n원래 \\(n=6131\\)개의 이미지 자료가 있음. 이를 \\({\\bf X}_{real}\\) 라고 하자. 따라서 \\({\\bf X}_{real}\\) 의 차원은 (6131,1,28,28).\n위조범이 만든 가짜자료를 원래 자료와 같은 숫자인 6131개 만듦. 이 가짜자료를 \\({\\bf X}_{fake}\\) 라고 하자. 따라서 \\({\\bf X}_{fake}\\) 의 차원은 (6131,1,28,28).\n진짜자료는 0, 가짜자료는 1으로 라벨링.\n\n\nNoise = torch.randn(6131,4)\nX_fake = net_faker(Noise).data\ny_real = torch.tensor([0]*6131).reshape(-1,1).float()\ny_fake = torch.tensor([1]*6131).reshape(-1,1).float()\n\n- step1: X_real, X_fake를 보고 각가 yhat_real, yhat_fake를 만드는 과정\n\nyhat_real = net_police(X_real)\nyhat_fake = net_police(X_fake)\n\n- step2: 손실을 계산 – 경찰의 미덕은 (1) 가짜이미지를 가짜라고 하고 (yhat_fake \\(\\approx\\) y_fake) (2) 진짜이미지를 진짜라고 해야한다. (yhat_real \\(\\approx\\) y_real)\n\nbce = torch.nn.BCELoss()\nloss_police = bce(yhat_fake,y_fake) + bce(yhat_real,y_real)\nloss_police\n\ntensor(1.3711, grad_fn=&lt;AddBackward0&gt;)\n\n\n- step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자.\n\n##\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters())\n##\nfor epoc in range(30):\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise).data\n    ## step1 \n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    ## step2\n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    ## step3 \n    loss_police.backward()\n    ## step4 \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n\n- 훈련된 경찰의 성능을 살펴보자.\n\nnet_police(X_real) # 거의 0으로!\n\ntensor([[0.0105],\n        [0.2350],\n        [0.0329],\n        ...,\n        [0.0623],\n        [0.0407],\n        [0.0266]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet_police(X_fake) # 거의 1로!\n\ntensor([[0.9803],\n        [0.9800],\n        [0.9802],\n        ...,\n        [0.9802],\n        [0.9801],\n        [0.9801]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n- 꽤 우수한 경찰이 되었음\n\nfig, ax = plt.subplots(1,2)\nax[0].imshow(X_fake[[-1]].data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\nax[1].imshow(X_real[[-1]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")\n\nText(0.5, 1.0, 'real')"
  },
  {
    "objectID": "posts/08wk-1,2.html#f.-더-똑똑해지는-페이커",
    "href": "posts/08wk-1,2.html#f.-더-똑똑해지는-페이커",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "F. 더 똑똑해지는 페이커",
    "text": "F. 더 똑똑해지는 페이커\n- step1: Noise \\(\\to\\) X_fake\n\nNoise = torch.randn(6131,4)\nX_fake = net_faker(Noise) \n\n- step2: 손실함수 – 페이커의 미덕은 (잘 훈련된) 경찰이 가짜이미지를 진짜라고 판단하는 것. 즉 yhat_fake \\(\\approx\\) y_real 이어야 페이커의 실력이 우수하다고 볼 수 있음.\n\nyhat_fake = net_police(X_fake) \nloss_faker = bce(yhat_fake,y_real) ## 가짜이미지를 보고 잘 훈련된 경찰조차 진짜이미지라고 깜빡 속으면 위조범의 실력이 좋은 것임\n\n- step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자.\n\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n    Reshape2828()\n)\n#bce = torch.nn.BCELoss()\noptimizr_faker = torch.optim.Adam(net_faker.parameters())\n#--#\n\n\nfor epoc in range(1):\n    # step1\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise) \n    # step2\n    yhat_fake = net_police(X_fake) \n    loss_faker = bce(yhat_fake,y_real)\n    # step3 \n    loss_faker.backward()\n    # step4 \n    optimizr_faker.step()\n    optimizr_faker.zero_grad()\n\n- 위조범의 실력향상을 감상해보자.\n\nfig,ax = plt.subplots(2,5,figsize=(10,4))\nk = 0 \nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n        k = k+1 \nfig.tight_layout()\n\n\n\n\n\n\n\n\n\n((yhat_fake &gt; 0.5) == 0).float().mean() # 경찰이 가짜이미지를 진짜라고 생각한 비율 = 페이커가 사기에 성공한 비율\n\ntensor(0.)"
  },
  {
    "objectID": "posts/08wk-1,2.html#g.-경쟁학습",
    "href": "posts/08wk-1,2.html#g.-경쟁학습",
    "title": "08wk-1,2: 생성모형 – Generative Adversarial Network (GAN)",
    "section": "G. 경쟁학습",
    "text": "G. 경쟁학습\n\n두 적대적인 네트워크를 경쟁시키자!\n\n\ntorch.manual_seed(43052)\nnet_police = torch.nn.Sequential(\n    torch.nn.Flatten(),\n    torch.nn.Linear(in_features=784,out_features=30),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=30,out_features=1),\n    torch.nn.Sigmoid()\n)\nnet_faker = torch.nn.Sequential(\n    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -&gt; (n,64) \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -&gt; (n,64)   \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -&gt; (n,784) \n    torch.nn.Sigmoid(), \n    Reshape2828()\n)\nbce = torch.nn.BCELoss()\noptimizr_police = torch.optim.Adam(net_police.parameters(),lr=0.001,betas=(0.5,0.999))\noptimizr_faker = torch.optim.Adam(net_faker.parameters(),lr=0.0002,betas=(0.5,0.999))\n\n\nfor epoc in range(1000):\n    # net_police 을 훈련\n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise).data # net_faker에 대한 미분꼬리표는 여기선 필요없으므로 .data 만을 이용\n    ## step1 \n    yhat_real = net_police(X_real)\n    yhat_fake = net_police(X_fake)\n    ## step2 \n    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n    ## step3 \n    loss_police.backward()\n    ## step4 \n    optimizr_police.step()\n    optimizr_police.zero_grad()\n    # net_faker 를 훈련\n    ## step1 \n    Noise = torch.randn(6131,4) \n    X_fake = net_faker(Noise)\n    ## step2 \n    yhat_fake = net_police(X_fake)\n    loss_faker = bce(yhat_fake,y_real) \n    ## step3\n    loss_faker.backward()\n    ## step4 \n    optimizr_faker.step()\n    optimizr_faker.zero_grad()\n\n\nfig,ax = plt.subplots(2,5,figsize=(10,4))\nk = 0 \nfor i in range(2):\n    for j in range(5):\n        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n        k = k+1 \nfig.tight_layout()"
  },
  {
    "objectID": "posts/01wk-2.html#a.-모형소개",
    "href": "posts/01wk-2.html#a.-모형소개",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 모형소개",
    "text": "A. 모형소개\n- model: \\(y_i= w_0+w_1 x_i +\\epsilon_i = 2.5 + 4x_i +\\epsilon_i, \\quad i=1,2,\\dots,n\\)\n- model: \\({\\bf y}={\\bf X}{\\bf W} +\\boldsymbol{\\epsilon}\\)\n\n\\({\\bf y}=\\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\dots \\\\ y_n\\end{bmatrix}, \\quad {\\bf X}=\\begin{bmatrix} 1 & x_1 \\\\ 1 & x_2 \\\\ \\dots \\\\ 1 & x_n\\end{bmatrix}, \\quad {\\bf W}=\\begin{bmatrix} 2.5 \\\\ 4 \\end{bmatrix}, \\quad \\boldsymbol{\\epsilon}= \\begin{bmatrix} \\epsilon_1 \\\\ \\dots \\\\ \\epsilon_n\\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "href": "posts/01wk-2.html#b.-회귀모형에서-데이터-생성",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 회귀모형에서 데이터 생성",
    "text": "B. 회귀모형에서 데이터 생성\n\ntorch.manual_seed(43052)\nones= torch.ones(100).reshape(-1,1)\nx,_ = torch.randn(100).sort()\nx = x.reshape(-1,1)\nX = torch.concat([ones,x],axis=-1)\nW = torch.tensor([[2.5],[4]])\nϵ = torch.randn(100).reshape(-1,1)*0.5\ny = X@W + ϵ\n\n\nplt.plot(x,y,'o')\nplt.plot(x,2.5+4*x,'--')"
  },
  {
    "objectID": "posts/01wk-2.html#a.-손실함수",
    "href": "posts/01wk-2.html#a.-손실함수",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "A. 손실함수",
    "text": "A. 손실함수\n- ’적당한 정도’를 판단하기 위한 장치: loss function 도입!\n\\(loss=\\sum_{i=1}^{n}(y_i-\\hat{y}_i)^2=\\sum_{i=1}^{n}(y_i-(\\hat{w}_0+\\hat{w}_1x_i))^2\\)\n\\(=({\\bf y}-{\\bf\\hat{y}})^\\top({\\bf y}-{\\bf\\hat{y}})=({\\bf y}-{\\bf X}{\\bf \\hat{W}})^\\top({\\bf y}-{\\bf X}{\\bf \\hat{W}})\\)\n- loss 함수의 특징\n\n\\(y_i \\approx \\hat{y}_i\\) 일수록 loss값이 작다.\n\\(y_i \\approx \\hat{y}_i\\) 이 되도록 \\((\\hat{w}_0,\\hat{w}_1)\\)을 잘 찍으면 loss값이 작다.\n(중요) 주황색 점선이 ‘적당할 수록’ loss값이 작다.\n\n\nloss = torch.sum((y-yhat)**2)\nloss\n\ntensor(8587.6875, grad_fn=&lt;SumBackward0&gt;)\n\n\n- 우리의 목표: 이 loss(=8587.6875)을 더 줄이자.\n\n궁극적으로는 아예 모든 조합 \\((\\hat{w}_0,\\hat{w}_1)\\)에 대하여 가장 작은 loss를 찾으면 좋겠다. (단계2에서 할일은 아님)\n\n- 문제의 치환: 생각해보니까 우리의 문제는 아래와 같이 수학적으로 단순화 되었다.\n\n적당해보이는 주황색 선을 찾자 \\(\\to\\) \\(loss(w_0,w_1)\\)를 최소로하는 \\((w_0,w_1)\\)의 값을 찾자.\n\n- 수정된 목표: \\(loss(w_0,w_1)\\)를 최소로 하는 \\((w_0,w_1)\\)을 구하라.\n\n단순한 수학문제가 되었다. 이것은 마치 \\(f(x,y)\\)를 최소화하는 \\((x,y)\\)를 찾으라는 것임.\n함수의 최대값 혹은 최소값을 컴퓨터를 이용하여 찾는것을 “최적화”라고 하며 이는 산공교수님들이 가장 잘하는 분야임. (산공교수님들에게 부탁하면 잘해줌, 산공교수님들은 보통 최적화해서 어디에 쓸지보다 최적화 자체에 더 관심을 가지고 연구하심)\n최적화를 하는 방법? 경사하강법"
  },
  {
    "objectID": "posts/01wk-2.html#b.-경사하강법",
    "href": "posts/01wk-2.html#b.-경사하강법",
    "title": "01wk-2: 회귀분석 (1) – 단순회귀의 학습전략, 경사하강법",
    "section": "B. 경사하강법",
    "text": "B. 경사하강법\n- 경사하강법 아이디어 (1차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접선) &lt;– 미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 움직인다.\n\n\n팁: 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입\n\n\n최종수식: \\(w \\leftarrow w - \\alpha \\times \\frac{\\partial}{\\partial w}loss(w)\\)\n\n- 경사하강법 아이디어 (2차원)\n\n임의의 점을 찍는다.\n그 점에서 순간기울기를 구한다. (접평면) &lt;– 편미분\n순간기울기(=미분계수)의 부호를 살펴보고 부호와 반대방향으로 각각 움직인다.\n\n\n팁: 여기서도 기울기의 절대값 크기와 비례하여 보폭(=움직이는 정도)을 각각 조절한다. \\(\\to\\) \\(\\alpha\\)를 도입.\n\n- 경사하강법 = loss를 줄이도록 \\({\\bf W}\\)를 개선하는 방법\n\n업데이트 공식: 수정값 = 원래값 - \\(\\alpha\\) \\(\\times\\) 기울어진크기(=미분계수)\n여기에서 \\(\\alpha\\)는 전체적인 보폭의 크기를 결정한다. 즉 \\(\\alpha\\)값이 클수록 한번의 update에 움직이는 양이 크다."
  },
  {
    "objectID": "posts/06wk-1.html#a.-transpose",
    "href": "posts/06wk-1.html#a.-transpose",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. transpose",
    "text": "A. transpose\n\ntsr = torch.arange(12).reshape(4,3)\ntsr\n\ntensor([[ 0,  1,  2],\n        [ 3,  4,  5],\n        [ 6,  7,  8],\n        [ 9, 10, 11]])\n\n\n\ntsr.t()\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])\n\n\n\ntorch.einsum('ij-&gt;ji',tsr)\n\ntensor([[ 0,  3,  6,  9],\n        [ 1,  4,  7, 10],\n        [ 2,  5,  8, 11]])"
  },
  {
    "objectID": "posts/06wk-1.html#b.-행렬곱",
    "href": "posts/06wk-1.html#b.-행렬곱",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 행렬곱",
    "text": "B. 행렬곱\n\ntsr1 = torch.arange(12).reshape(4,3).float()\ntsr2 = torch.arange(15).reshape(3,5).float()\n\n\ntsr1.shape\n\ntorch.Size([4, 3])\n\n\n\ntsr2.shape\n\ntorch.Size([3, 5])\n\n\n\ntsr1 @ tsr2\n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])\n\n\n\ntorch.einsum('ij,jk -&gt; ik',tsr1,tsr2) \n\ntensor([[ 25.,  28.,  31.,  34.,  37.],\n        [ 70.,  82.,  94., 106., 118.],\n        [115., 136., 157., 178., 199.],\n        [160., 190., 220., 250., 280.]])"
  },
  {
    "objectID": "posts/06wk-1.html#c.-이미지변환",
    "href": "posts/06wk-1.html#c.-이미지변환",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. 이미지변환",
    "text": "C. 이미지변환\n\nr = torch.zeros(16).reshape(4,4) + 1.0\ng = torch.zeros(16).reshape(4,4)\nb = torch.zeros(16).reshape(4,4)\nimg_plt = torch.stack([r,g,b],axis=-1) # matplotlib 를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \nimg_torch = torch.stack([r,g,b],axis=0).reshape(1,3,4,4) # torch를 쓰기 위해서는 이미지가 이렇게 저장되어있어야한다. \n\n\nimg_plt.shape, img_torch.shape\n\n(torch.Size([4, 4, 3]), torch.Size([1, 3, 4, 4]))\n\n\n\nplt.imshow(img_plt)\n\n\n\n\n\n\n\n\n만약에 img_torch를 matplotlib 으로 보고싶다면?\n\n# 잘못된코드\nplt.imshow(img_torch.reshape(4,4,3))\n\n\n\n\n\n\n\n\n\n# 올바른코드\nplt.imshow(torch.einsum('ocij -&gt; ijc',img_torch))"
  },
  {
    "objectID": "posts/06wk-1.html#a.-y-n3-float",
    "href": "posts/06wk-1.html#a.-y-n3-float",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. y: (n,3)-float",
    "text": "A. y: (n,3)-float\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y.argmax(axis=1)).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy.argmax(axis=1)).float().mean():.4f}')\n\ntrain: 0.9851\nval: 0.9898"
  },
  {
    "objectID": "posts/06wk-1.html#b.-y-n-int",
    "href": "posts/06wk-1.html#b.-y-n-int",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. y: (n,)-int",
    "text": "B. y: (n,)-int\n\ny = y.argmax(axis=-1)\nyy = yy.argmax(axis=-1)\ny,yy\n\n(tensor([0, 0, 0,  ..., 2, 2, 2]), tensor([0, 0, 0,  ..., 2, 2, 2]))\n\n\n\nprint(X.shape,'\\t',X.dtype)\nprint(y.shape,'\\t\\t',y.dtype)\nprint(XX.shape,'\\t',XX.dtype)\nprint(yy.shape,'\\t\\t',yy.dtype)\n\ntorch.Size([18623, 1, 28, 28])   torch.float32\ntorch.Size([18623])          torch.int64\ntorch.Size([3147, 1, 28, 28])    torch.float32\ntorch.Size([3147])       torch.int64\n\n\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,3),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}') # &lt;-- 여기수정\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}') # &lt;-- 여기수정\n\ntrain: 0.9836\nval: 0.9895"
  },
  {
    "objectID": "posts/06wk-1.html#a.-torch",
    "href": "posts/06wk-1.html#a.-torch",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. torch",
    "text": "A. torch\n\n# Step1: 데이터정리 (dls생성)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=128) \n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n# Step3: 적합 \nnet.to(\"cuda:0\")\nfor epoc in range(10):\n    for xi,yi in dl:\n        ## 1\n        ## 2\n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        ## 3 \n        loss.backward()\n        ## 4 \n        optimizr.step()\n        optimizr.zero_grad()\nnet.to(\"cpu\")\n# Step4: 예측 및 평가 \nprint(f'train: {(net(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(net(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\ntrain: 0.9077\nval: 0.8723"
  },
  {
    "objectID": "posts/06wk-1.html#b.-fastai",
    "href": "posts/06wk-1.html#b.-fastai",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. fastai",
    "text": "B. fastai\n\n# Step1: 데이터정리 (dls생성)\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=128) \ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100) \ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2: 적합에 필요한 오브젝트 생성\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(1,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(2304,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\n#optimizr = torch.optim.Adam(net.parameters())\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3: 적합 \nlrnr.fit(10)\n# Step4: 예측 및 평가 \n\nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.484642\n0.444805\n0.858300\n00:01\n\n\n1\n0.393360\n0.413498\n0.862200\n00:01\n\n\n2\n0.340997\n0.403366\n0.866100\n00:01\n\n\n3\n0.310863\n0.421401\n0.866300\n00:01\n\n\n4\n0.291870\n0.426586\n0.865400\n00:01\n\n\n5\n0.277852\n0.429622\n0.866500\n00:01\n\n\n6\n0.266723\n0.444076\n0.870700\n00:01\n\n\n7\n0.260530\n0.456487\n0.871100\n00:01\n\n\n8\n0.253032\n0.458816\n0.875000\n00:01\n\n\n9\n0.247392\n0.483315\n0.870800\n00:01\n\n\n\n\n\ntrain: 0.9124\nval: 0.8708"
  },
  {
    "objectID": "posts/06wk-1.html#a.-알렉스넷krizhevsky2012imagenet의-의미",
    "href": "posts/06wk-1.html#a.-알렉스넷krizhevsky2012imagenet의-의미",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. 알렉스넷(Krizhevsky, Sutskever, and Hinton 2012)의 의미",
    "text": "A. 알렉스넷(Krizhevsky, Sutskever, and Hinton 2012)의 의미\n\nKrizhevsky, Alex, Ilya Sutskever, and Geoffrey E Hinton. 2012. “Imagenet Classification with Deep Convolutional Neural Networks.” Advances in Neural Information Processing Systems 25.\n- 야사로 배우는 인공지능: https://brunch.co.kr/@hvnpoet/109"
  },
  {
    "objectID": "posts/06wk-1.html#b.-알렉스넷의-아키텍처-써보기",
    "href": "posts/06wk-1.html#b.-알렉스넷의-아키텍처-써보기",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 알렉스넷의 아키텍처 써보기",
    "text": "B. 알렉스넷의 아키텍처 써보기\n- 알렉스넷의 아키텍처:\n-ref: https://en.wikipedia.org/wiki/AlexNet#:~:text=AlexNet%20is%20the%20name%20of,at%20the%20University%20of%20Toronto.\n\n- 재미삼아 써보면..\n\nimg = torch.zeros(1,3*227*227).reshape(1,3,227,227)\nimg.shape\n\ntorch.Size([1, 3, 227, 227])\n\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Conv2d(3,96,kernel_size=(11,11),stride=4),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(96,256,kernel_size=(5,5),padding=2),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((3,3),stride=2), # default stride는 3\n    torch.nn.Conv2d(256,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(384,384,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.Conv2d(384,256,kernel_size=(3,3),padding=1),\n    torch.nn.ReLU(),    \n    torch.nn.MaxPool2d((3,3),stride=2),\n    torch.nn.Flatten(),\n    torch.nn.Linear(9216,4096),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),\n    torch.nn.Linear(4096,4096),        \n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.5),    \n    torch.nn.Linear(4096,1000),\n)\n\n- 참고사항: torchvision.models.alexnet()을 이용하여 네크워크를 선언할 수도 있음.\n\ntorchvision.models.alexnet()\n\nAlexNet(\n  (features): Sequential(\n    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n    (1): ReLU(inplace=True)\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n    (4): ReLU(inplace=True)\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (7): ReLU(inplace=True)\n    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (9): ReLU(inplace=True)\n    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (11): ReLU(inplace=True)\n    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n  (classifier): Sequential(\n    (0): Dropout(p=0.5, inplace=False)\n    (1): Linear(in_features=9216, out_features=4096, bias=True)\n    (2): ReLU(inplace=True)\n    (3): Dropout(p=0.5, inplace=False)\n    (4): Linear(in_features=4096, out_features=4096, bias=True)\n    (5): ReLU(inplace=True)\n    (6): Linear(in_features=4096, out_features=1000, bias=True)\n  )\n)\n\n\n\n\n\n\n\n\nNote\n\n\n\n직접구현한 알렉스넷과 torchvision.models.alexnet()를 이용한 알렉스넷은 약간다름.\n그 이유는 파이토치에서는 원래 논문에서 구현된 알렉스넷이 아니라 이후 수정된 알렉스넷을 사용하기 때문임. 이 내용은 파이토치 공식홈페이지에서 아래와 같이 명시되어있음.\nAlexNet was originally introduced in the ImageNet Classification with Deep Convolutional Neural Networks paper. Our implementation is based instead on the “One weird trick” paper above.\nref: https://pytorch.org/vision/main/models/generated/torchvision.models.alexnet.html"
  },
  {
    "objectID": "posts/06wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "href": "posts/06wk-1.html#c.-알렉스넷으로-imagenet-적합",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. 알렉스넷으로 ImageNet 적합",
    "text": "C. 알렉스넷으로 ImageNet 적합\n\npass # 데이터가 너무 커서.. 코랩에서 못할것같아요"
  },
  {
    "objectID": "posts/06wk-1.html#a.-dls-만들자",
    "href": "posts/06wk-1.html#a.-dls-만들자",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "A. dls 만들자",
    "text": "A. dls 만들자\n- X,y를 얻자.\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.CIFAR)\npath.ls()\n\n\n\n\n\n\n    \n      \n      100.00% [168173568/168168549 00:49&lt;00:00]\n    \n    \n\n\n(#3) [Path('/root/.fastai/data/cifar10/train'),Path('/root/.fastai/data/cifar10/labels.txt'),Path('/root/.fastai/data/cifar10/test')]\n\n\n\nlabels = [str(l).split('/')[-1] for l in (path/'train').ls()]\nlabels\n\n['deer',\n 'airplane',\n 'ship',\n 'dog',\n 'automobile',\n 'truck',\n 'cat',\n 'frog',\n 'horse',\n 'bird']\n\n\n\nX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'train/{l}').ls()],axis=0).float()/255\nXX = torch.stack([torchvision.io.read_image(str(fname)) for l in labels for fname in (path/f'test/{l}').ls()],axis=0).float()/255\ny = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'train/{l}').ls()])\nyy = torch.tensor([i for i,l in enumerate(labels) for fname in (path/f'test/{l}').ls()])\n\n\nprint(X.shape,'\\t',X.dtype)\nprint(y.shape,'\\t\\t\\t',y.dtype)\nprint(XX.shape,'\\t',XX.dtype)\nprint(yy.shape,'\\t\\t\\t',yy.dtype)\n\ntorch.Size([50000, 3, 32, 32])   torch.float32\ntorch.Size([50000])              torch.int64\ntorch.Size([10000, 3, 32, 32])   torch.float32\ntorch.Size([10000])              torch.int64\n\n\n- 데이터를 시각화해보자.\n\nylabel = [l for l in labels for fname in (path/f'train/{l}').ls()]\ni = 30002\nplt.imshow(torch.einsum('cij-&gt;ijc',X[i]))\nplt.title(f'{ylabel[i]},{y[i]}')\n\nText(0.5, 1.0, 'cat,6')\n\n\n\n\n\n\n\n\n\n\n그림이 너무 어려운데?\n맞추기 힘들겠는데..\n\n- dls를 만들자.\n\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n\n- 아래와 같이 쉽게 만들수도있음…\n\n# dls = fastai.vision.data.ImageDataLoaders.from_folder(path,train='train',valid='test')\n# dls.show_batch()"
  },
  {
    "objectID": "posts/06wk-1.html#b.-수제네트워크로-학습",
    "href": "posts/06wk-1.html#b.-수제네트워크로-학습",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "B. 수제네트워크로 학습",
    "text": "B. 수제네트워크로 학습\n- 시도1: 이게 좀 힘들어요 ㅎㅎ\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n2.429019\n2.301729\n0.121900\n00:00\n\n\n1\n2.867480\n2.297742\n0.121600\n00:00\n\n\n2\n2.798708\n2.350770\n0.099900\n00:00\n\n\n3\n2.378768\n2.292685\n0.116900\n00:00\n\n\n4\n2.436424\n2.289784\n0.126600\n00:00\n\n\n5\n2.972414\n2.361609\n0.122900\n00:01\n\n\n6\n2.285441\n5.540118\n0.100300\n00:00\n\n\n7\n2.908635\n2.349017\n0.131200\n00:00\n\n\n8\n3.101591\n3.855471\n0.103200\n00:00\n\n\n9\n2.130486\n17.543028\n0.100200\n00:00\n\n\n\n\n\ntrain: 0.1000\nval: 0.1002\n\n\n\n????\n\n- 시도2: 셔플!\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,16,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(3136,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.629887\n1.535057\n0.463400\n00:00\n\n\n1\n1.438346\n1.392916\n0.512500\n00:00\n\n\n2\n1.355882\n1.374366\n0.518900\n00:00\n\n\n3\n1.289650\n1.298758\n0.542500\n00:01\n\n\n4\n1.256436\n1.278826\n0.555900\n00:00\n\n\n5\n1.225732\n1.244056\n0.563800\n00:00\n\n\n6\n1.204093\n1.234391\n0.563100\n00:00\n\n\n7\n1.179638\n1.228574\n0.569700\n00:00\n\n\n8\n1.163272\n1.187201\n0.585200\n00:00\n\n\n9\n1.146735\n1.199569\n0.578300\n00:00\n\n\n\n\n\ntrain: 0.6101\nval: 0.5783\n\n\n\n셔플의 차이가 이렇게 크다니??\n\n- 시도3: 복잡하게..\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=256,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet1 = torch.nn.Sequential(\n    torch.nn.Conv2d(3,256,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(256,64,(5,5)),\n    torch.nn.ReLU(),\n    torch.nn.Conv2d(64,16,(5,5)),\n    torch.nn.MaxPool2d((2,2)),\n    torch.nn.Flatten()\n)\nnet2 = torch.nn.Sequential(\n    torch.nn.Linear(1600,10),\n)\nnet = torch.nn.Sequential(\n    net1, # 2d-part\n    net2, # 1d-part \n)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \n# 코랩사용시 아래는 주석처리할것 (이유: 코랩의 RAM이 충분하지 않음) valiation set의 accuracy는 fastai결과로 확인할것. \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}')\nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.476197\n1.479258\n0.465500\n00:02\n\n\n1\n1.310572\n1.284226\n0.538200\n00:02\n\n\n2\n1.204503\n1.222977\n0.572300\n00:02\n\n\n3\n1.102717\n1.093513\n0.615500\n00:02\n\n\n4\n1.042015\n1.047397\n0.627400\n00:02\n\n\n5\n0.998049\n1.077097\n0.621600\n00:02\n\n\n6\n0.985487\n0.986339\n0.660600\n00:02\n\n\n7\n0.924648\n0.977845\n0.663900\n00:02\n\n\n8\n0.897980\n0.997572\n0.658000\n00:02\n\n\n9\n0.879995\n0.981113\n0.660500\n00:02\n\n\n\n\n\ntrain: 0.7026\nval: 0.6605"
  },
  {
    "objectID": "posts/06wk-1.html#c.-transferlearning으로-학습",
    "href": "posts/06wk-1.html#c.-transferlearning으로-학습",
    "title": "06wk-1: 합성곱 신경망 (2) – MNIST, Fashion MNIST, ImageNet, CIFAR10",
    "section": "C. TransferLearning으로 학습",
    "text": "C. TransferLearning으로 학습\n- ResNet18을 다운로드\n\nnet = torchvision.models.resnet18()\nnet\n\nResNet(\n  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  (relu): ReLU(inplace=True)\n  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  (layer1): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer2): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer3): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (layer4): Sequential(\n    (0): BasicBlock(\n      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (downsample): Sequential(\n        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (1): BasicBlock(\n      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      (relu): ReLU(inplace=True)\n      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (fc): Linear(in_features=512, out_features=1000, bias=True)\n)\n\n\n- 마지막의 레이어만 수정\n\nnet.fc = torch.nn.Linear(512,10)\n\n- 학습해보자.\n\n# Step1:\nds1 = torch.utils.data.TensorDataset(X,y)\nds2 = torch.utils.data.TensorDataset(XX,yy)\ndl1 = torch.utils.data.DataLoader(ds1,batch_size=64,shuffle=True)\ndl2 = torch.utils.data.DataLoader(ds2,batch_size=100)\ndls = fastai.data.core.DataLoaders(dl1,dl2)\n# Step2:\nnet = torchvision.models.resnet18()\nnet.fc = torch.nn.Linear(512,10)\nloss_fn = torch.nn.CrossEntropyLoss()\nlrnr = fastai.learner.Learner(\n    dls=dls,\n    model=net,\n    loss_func=loss_fn,\n    #--#\n    metrics=[fastai.metrics.accuracy]\n)\n# Step3:\nlrnr.fit(10)\n# Step4: \n# 코랩사용시 아래는 주석처리할것 (이유: 코랩의 RAM이 충분하지 않음) valiation set의 accuracy는 fastai결과로 확인할것. \nlrnr.model.to(\"cpu\")\nprint(f'train: {(lrnr.model(X).data.argmax(axis=1) == y).float().mean():.4f}') # \nprint(f'val: {(lrnr.model(XX).data.argmax(axis=1) == yy).float().mean():.4f}')\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n1.157889\n1.281547\n0.540200\n00:11\n\n\n1\n0.924410\n1.179057\n0.596200\n00:11\n\n\n2\n0.797667\n0.948804\n0.678700\n00:11\n\n\n3\n0.681159\n0.877607\n0.699700\n00:11\n\n\n4\n0.568150\n0.818889\n0.726400\n00:11\n\n\n5\n0.509804\n0.842927\n0.725800\n00:11\n\n\n6\n0.428966\n0.836546\n0.736100\n00:11\n\n\n7\n0.378433\n0.825805\n0.753200\n00:11\n\n\n8\n0.297282\n0.917828\n0.734000\n00:11\n\n\n9\n0.244396\n0.876090\n0.763200\n00:11\n\n\n\n\n\ntrain: 0.9523\nval: 0.7632\n\n\n\n\n\n\n\n\nCaution\n\n\n\n통계학과서버를 이용하시는 분들은 다른 학생들을 위하여 실습이 끝난이후 커널을 죽여주시기 바랍니다. 그렇지 않으면 GPU메모리 부족으로 다른학생들이 실습하기 어렵습니다.(무슨말인지 모르겠으면 저에게 물어보세요)"
  },
  {
    "objectID": "posts/07wk-1-2.html#a.-dls",
    "href": "posts/07wk-1-2.html#a.-dls",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "A. DLS",
    "text": "A. DLS\n\npath = fastai.data.external.untar_data(fastai.data.external.URLs.PETS)\n#path.ls()\n(path/'images').ls()\n\n(#7393) [Path('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/american_bulldog_224.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/chihuahua_133.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Bombay_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/english_setter_153.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Ragdoll_188.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/newfoundland_125.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Bombay_156.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/keeshond_122.jpg'),Path('/root/.fastai/data/oxford-iiit-pet/images/Birman_115.jpg')...]\n\n\n\n(path/'images').ls()[214],(path/'images').ls()[448],(path/'images').ls()[2976]\n\n(Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_101.mat'),\n Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_100.mat'),\n Path('/root/.fastai/data/oxford-iiit-pet/images/Abyssinian_102.mat'))\n\n\n\nfnames = fastai.data.transforms.get_image_files(path/'images')\n#fnames = [l for l in (path/'images').ls() if str(l).split('.')[-1] == 'jpg']\n\n\ndef label_func(fname):\n    if fname[0].isupper():\n        return 'cat'\n    else:\n        return 'dog'\n\n\ndls = fastai.vision.data.ImageDataLoaders.from_name_func(\n    path = path/'images',\n    fnames = fnames,\n    label_func = label_func,\n    item_tfms = fastai.vision.augment.Resize(512),\n    bs = 32 # batch_size = 32 \n)\n\n\ndls.show_batch()"
  },
  {
    "objectID": "posts/07wk-1-2.html#b.-이미지-자료-불러오기",
    "href": "posts/07wk-1-2.html#b.-이미지-자료-불러오기",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "B. 이미지 자료 불러오기",
    "text": "B. 이미지 자료 불러오기\n- 원래 우리가 아는 방법: path를 의미하는 string \\(\\to\\) torch.tensor\n\nx = torchvision.io.read_image('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'torch.Tensor'&gt;\nshape: torch.Size([3, 333, 500])\ndtype: torch.uint8\n\n\n- fastai를 이용하는 방법: path를 의미하는 string \\(\\to\\) PILImage \\(\\to\\) fastai.torch_core.TensorImage \\(\\to\\) torch.tensor\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n# print('---')\n# x = torch.tensor(x)\n# print(f\"type: {type(x)}\")\n# print(f\"shape: {x.shape}\")\n# print(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([1, 3, 512, 512])\ndtype: torch.float32\n\n\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0]\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([1, 3, 512, 512])\ndtype: torch.float32\n\n\n- 참고로 아래와 같이 이미지변환할 수도 있음.\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\n#x = next(iter(dls.test_dl([x_pil])))[0]\nx = fastai.torch_core.TensorImage(x_pil)\nprint(f\"type: {type(x)}\")\nprint(f\"shape: {x.shape}\")\nprint(f\"dtype: {x.dtype}\")\n\ntype: &lt;class 'fastai.torch_core.TensorImage'&gt;\nshape: torch.Size([333, 500, 3])\ndtype: torch.uint8"
  },
  {
    "objectID": "posts/07wk-1-2.html#c.-이미지-자료-시각화",
    "href": "posts/07wk-1-2.html#c.-이미지-자료-시각화",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "C. 이미지 자료 시각화",
    "text": "C. 이미지 자료 시각화\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n\n\n\n\n\n\n\n\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))"
  },
  {
    "objectID": "posts/07wk-1-2.html#d.-ap-layer",
    "href": "posts/07wk-1-2.html#d.-ap-layer",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "D. AP layer",
    "text": "D. AP layer\n\nap = torch.nn.AdaptiveAvgPool2d(output_size=1)\nap\n\nAdaptiveAvgPool2d(output_size=1)\n\n\n\nX = torch.arange(1*3*4*4).reshape(1,3,4,4)*1.0 \nX\n\ntensor([[[[ 0.,  1.,  2.,  3.],\n          [ 4.,  5.,  6.,  7.],\n          [ 8.,  9., 10., 11.],\n          [12., 13., 14., 15.]],\n\n         [[16., 17., 18., 19.],\n          [20., 21., 22., 23.],\n          [24., 25., 26., 27.],\n          [28., 29., 30., 31.]],\n\n         [[32., 33., 34., 35.],\n          [36., 37., 38., 39.],\n          [40., 41., 42., 43.],\n          [44., 45., 46., 47.]]]])\n\n\n\nap(X) # 채널별로 평균을 구해줌. \n\ntensor([[[[ 7.5000]],\n\n         [[23.5000]],\n\n         [[39.5000]]]])\n\n\n\nr,g,b = X[0]\n\n\nr.mean(), g.mean(), b.mean()\n\n(tensor(7.5000), tensor(23.5000), tensor(39.5000))\n\n\n\nap(r), ap(g), ap(b) \n\n(tensor([[7.5000]]), tensor([[23.5000]]), tensor([[39.5000]]))"
  },
  {
    "objectID": "posts/07wk-1-2.html#e.-ap-linear의-교환",
    "href": "posts/07wk-1-2.html#e.-ap-linear의-교환",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "E. AP, Linear의 교환",
    "text": "E. AP, Linear의 교환\n- 신기한 거 보여줄까요??\n\nap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\n\ntensor([[17.3000]])\n\n\n\nap(r*0.1 + g*0.2 + b*0.3)\n\ntensor([[17.3000]])\n\n\n\n별로 안 신기함.. 당연한것 아니야?\n\n- torch.nn.Linear() 와 torch.nn.Flatten() 를 이용한 구현\n\nflatten = torch.nn.Flatten()\nl = torch.nn.Linear(3,1,bias=False)\n\n\n# ap(r)*0.1 + ap(g)*0.2 + ap(b)*0.3\nl.weight.data = torch.tensor([[0.1, 0.2, 0.3]])\nl(flatten(ap(X)))\n\ntensor([[17.3000]], grad_fn=&lt;MmBackward0&gt;)\n\n\n\n#ap(r*0.1 + g*0.2 + b*0.3) ## 각각의 픽셀에 l을 취하고 그 결과에 ap를 취해야함 \nflatten(ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data)))\n\ntensor([[17.3000]])\n\n\n- 정리\n\n# 계산1: x를 ap, flatten, linear 순서로 적용\nprint(f\"{X.shape} -- X\")\nprint(f\"{ap(X).shape} -- ap(X)\")\nprint(f\"{flatten(ap(X)).shape} -- flatten(ap(X))\")\nprint(f\"{l(flatten(ap(X))).shape} -- l(flatten(ap(X)))\")\n\ntorch.Size([1, 3, 4, 4]) -- X\ntorch.Size([1, 3, 1, 1]) -- ap(X)\ntorch.Size([1, 3]) -- flatten(ap(X))\ntorch.Size([1, 1]) -- l(flatten(ap(X)))\n\n\n\n# 계산2: x를 linear, ap, flatten 순서로 적용\nprint(f\"{X.shape} -- X\")\nprint(f\"{torch.einsum('ocij,kc -&gt; okij',X,l.weight.data).shape} -- l(X)\")\nprint(f\"{ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data)).shape} -- ap(l(X))\")\nprint(f\"{flatten(ap(torch.einsum('ocij,kc -&gt; okij',X,l.weight.data))).shape} -- flatten(ap(l(X)))\")\n\ntorch.Size([1, 3, 4, 4]) -- X\ntorch.Size([1, 1, 4, 4]) -- l(X)\ntorch.Size([1, 1, 1, 1]) -- ap(l(X))\ntorch.Size([1, 1]) -- flatten(ap(l(X)))\n\n\n\\[\\underset{(n,3,4,4)}{\\boldsymbol X} \\overset{ap}{\\to} \\underset{(n,3,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(n,3)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}} = [[17.3],...]\\]\n\\[\\underset{(n,3,4,4)}{\\boldsymbol X} \\overset{linear}{\\to} \\underset{(n,1,4,4)}{{\\boldsymbol \\sharp}}\\overset{ap}{\\to} \\underset{(n,1,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}} = [[17.3],...]\\]"
  },
  {
    "objectID": "posts/07wk-1-2.html#a.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "href": "posts/07wk-1-2.html#a.-1단계-이미지분류-잘하는-네트워크-선택-후-학습",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "A. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습",
    "text": "A. 1단계 – 이미지분류 잘하는 네트워크 선택 후 학습\n\nlrnr = fastai.vision.learner.vision_learner(\n    dls = dls,\n    arch = fastai.vision.models.resnet34, \n    metrics = [fastai.metrics.accuracy]\n)    \n\n\nlrnr.fine_tune(1)\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.101094\n0.035343\n0.989851\n00:20\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.068278\n0.004763\n0.997970\n00:26"
  },
  {
    "objectID": "posts/07wk-1-2.html#b.-2단계-네트워크의-끝-부분-수정하고-재학습",
    "href": "posts/07wk-1-2.html#b.-2단계-네트워크의-끝-부분-수정하고-재학습",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "B. 2단계– 네트워크의 끝 부분 수정하고 재학습",
    "text": "B. 2단계– 네트워크의 끝 부분 수정하고 재학습\n- 일반적으로 CNN계열은 2D-part와 1D-part로 구분되어있음.\n\nnet1 = lrnr.model[0] # 2d-part \nnet2 = lrnr.model[1] # 1d-part \n\n\n# 하나의 배치를 테스트용으로 임시로 가져옴\n_X, _y = dls.one_batch()\n_X.shape,_y.shape \n\n(torch.Size([32, 3, 512, 512]), torch.Size([32]))\n\n\n\nprint(f\"입력이미지:\\t\\t {_X.shape}\")\nprint(f\"net1통과직후:\\t\\t {net1(_X).shape}\")\nprint(f\"net2의AP까지통과직후:\\t {net2[0](net1(_X)).shape}\")\nprint(f\"net2의Flatten까지통과직후:\\t {net2[1](net2[0](net1(_X))).shape}\")\nprint(f\"net2끝까지통과:\\t\\t {net2(net1(_X)).shape}\")\n\n입력이미지:       torch.Size([32, 3, 512, 512])\nnet1통과직후:        torch.Size([32, 512, 16, 16])\nnet2의AP까지통과직후:   torch.Size([32, 1024, 1, 1])\nnet2의Flatten까지통과직후:  torch.Size([32, 1024])\nnet2끝까지통과:       torch.Size([32, 2])\n\n\n- net2를 아래와 같이 수정하자. (왜??)\n\nnet2 = torch.nn.Sequential(\n    torch.nn.AdaptiveAvgPool2d(output_size=1), # [n, 512, 16, 16] --&gt; [n, 512, 1, 1]\n    torch.nn.Flatten(), # [n, 512, 1, 1] --&gt;  [n, 512]\n    torch.nn.Linear(512,2,bias=False) # [n,512] --&gt; [n,2] \n)\n\n\nnet = torch.nn.Sequential(\n    net1, # 원래 resnet34에 있던거..\n    net2 # 내가 (CAM을 위해서) 마음대로 바꾼것.. \n)\n\n\nlrnr2 = fastai.learner.Learner(\n    dls = dls, \n    model = net,\n    metrics = [fastai.metrics.accuracy] \n)    \n\n\nlrnr.loss_func, lrnr2.loss_func # loss_fn 은 따로 정의안했는데 알아서 잘 들어가 있음\n\n(FlattenedLoss of CrossEntropyLoss(), FlattenedLoss of CrossEntropyLoss())\n\n\n\nlrnr2.fine_tune(5) # net2를 내마음대로 수정했고, 그것에 대한 패널티로 accuracy가 안좋아짐! 그렇지만 그런대로 쓸만함. \n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.323613\n1.646134\n0.705007\n00:26\n\n\n\n\n\n\n\n\n\n\n\n\nepoch\ntrain_loss\nvalid_loss\naccuracy\ntime\n\n\n\n\n0\n0.166095\n0.257160\n0.905954\n00:26\n\n\n1\n0.160385\n0.132229\n0.953315\n00:26\n\n\n2\n0.106043\n0.093649\n0.962111\n00:26\n\n\n3\n0.050350\n0.056827\n0.979702\n00:26\n\n\n4\n0.029413\n0.058543\n0.981732\n00:26"
  },
  {
    "objectID": "posts/07wk-1-2.html#c.-3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "href": "posts/07wk-1-2.html#c.-3단계-수정된-net2에서-linear와-ap의-순서를-바꿈",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "C. 3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈",
    "text": "C. 3단계– 수정된 net2에서 Linear와 AP의 순서를 바꿈\n- 1개의 observation을 고정\n\nx_pil = fastai.vision.core.PILImage.create('/root/.fastai/data/oxford-iiit-pet/images/Sphynx_14.jpg')\nx = next(iter(dls.test_dl([x_pil])))[0]\nx_dec = dls.decode([x])[0]\nplt.imshow(torch.einsum('ocij -&gt; ijc', x_dec))\n\n\n\n\n\n\n\n\n- 하나의 observation이 yhat까지 나오는 과정\n\n# 계산방식1: 원래계산방식\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\nprint(f\"{x.shape} -- x\")\nprint(f\"{net1(x).shape} -- net1(x)\")\nprint(f\"{ap(net1(x)).shape} -- ap(net1(x))\")\nprint(f\"{fl(ap(net1(x))).shape} -- flatten(ap(net1(x)))\")\nprint(f\"{l(fl(ap(net1(x)))).shape} -- l(flatten(ap(net1(x))))\")\nl(fl(ap(net1(x))))\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- net1(x)\ntorch.Size([1, 512, 1, 1]) -- ap(net1(x))\ntorch.Size([1, 512]) -- flatten(ap(net1(x)))\ntorch.Size([1, 2]) -- l(flatten(ap(net1(x))))\n\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\nnet2의 순서 바꾸기 전 전체 네트워크 \\[\\underset{(1,3,512,512)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{ap}{\\to} \\underset{(1,512,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,512)}{{\\boldsymbol \\sharp}}\\overset{linear}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [[2.7846, -2.7945]]\\]\n\n# 계산방식2: net2의 순서를 바꾼 계산\nap = lrnr2.model[-1][0]\nfl = lrnr2.model[-1][1]\nl = lrnr2.model[-1][2]\nWHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\nprint(f\"{x.shape} -- x\")\nprint(f\"{net1(x).shape} -- net1(x)\")\nprint(f\"{WHY.shape} -- l(net1(x)):=WHY\")\nprint(f\"{ap(WHY).shape} -- ap(l(net1(x)))=ap(WHY)\")\nprint(f\"{fl(ap(WHY)).shape} -- flatten(ap(l(net1(x)))))=flatten(ap(WHY))\")\nfl(ap(torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)))\n\ntorch.Size([1, 3, 512, 512]) -- x\ntorch.Size([1, 512, 16, 16]) -- net1(x)\ntorch.Size([1, 2, 16, 16]) -- l(net1(x)):=WHY\ntorch.Size([1, 2, 1, 1]) -- ap(l(net1(x)))=ap(WHY)\ntorch.Size([1, 2]) -- flatten(ap(l(net1(x)))))=flatten(ap(WHY))\n\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\nnet2의 순서를 바꾼후 전체 네트워크 \\[\\underset{(1,3,224,224)}{\\boldsymbol x} \\overset{net_1}{\\to} \\left( \\underset{(1,512,16,16)}{\\tilde{\\boldsymbol x}} \\overset{linear}{\\to} \\underset{(1,2,16,16)}{{\\bf WHY}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}}\\right) = [[2.7846,-2.7945]]\\]\n\n참고: 여기에서 linear는 (1,512,16,16)의 each pixel에 torch.nn.Linear(512,2)를 수행함.\n\n\n\\(\\star\\) 잠깐 멈추고 생각 좀 해보자..\n- 입력이미지\n\nx_pil, x\n\n(PILImage mode=RGB size=500x333,\n TensorImage([[[[ 0.8104,  0.7933,  0.7762,  ..., -0.6794, -0.6794, -0.6794],\n                [ 0.8104,  0.7933,  0.7762,  ..., -0.6965, -0.6965, -0.6965],\n                [ 0.8104,  0.7933,  0.7762,  ..., -0.7137, -0.7137, -0.7137],\n                ...,\n                [-0.6623, -0.2171,  0.3138,  ...,  0.5707,  0.5364,  0.5022],\n                [-0.7650, -0.3541,  0.1597,  ...,  0.5707,  0.5193,  0.4851],\n                [-0.8335, -0.4568,  0.0398,  ...,  0.5707,  0.5193,  0.4679]],\n \n               [[ 0.9930,  0.9755,  0.9580,  ..., -0.5301, -0.5126, -0.4951],\n                [ 0.9930,  0.9755,  0.9580,  ..., -0.5301, -0.5126, -0.4951],\n                [ 1.0105,  0.9930,  0.9580,  ..., -0.5126, -0.4951, -0.4951],\n                ...,\n                [-1.0553, -0.5301,  0.1527,  ..., -0.0399,  0.0126,  0.0476],\n                [-1.1604, -0.6527,  0.0301,  ...,  0.0301,  0.0651,  0.0651],\n                [-1.2479, -0.7402, -0.0574,  ...,  0.0826,  0.0826,  0.0651]],\n \n               [[ 0.9668,  0.9494,  0.9319,  ..., -0.3927, -0.4624, -0.5147],\n                [ 0.9494,  0.9494,  0.9319,  ..., -0.3927, -0.4624, -0.4973],\n                [ 0.9319,  0.9319,  0.9319,  ..., -0.3927, -0.4450, -0.4798],\n                ...,\n                [-0.9156, -0.3578,  0.3393,  ..., -0.0615,  0.0082,  0.0256],\n                [-1.0550, -0.5147,  0.1825,  ...,  0.0431,  0.0082, -0.0267],\n                [-1.1596, -0.6367,  0.0779,  ...,  0.1128,  0.0082, -0.0790]]]],\n             device='cuda:0'))\n\n\n- 원래 net2를 그대로 적용한 결과를 해석\n\nnet2(net1(x))\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\n“2.7846 &gt; -2.7945” 이므로, ximg는 높은 확률로 고양이라는 것을 의미함.\n\n- 바뀐 net2를 적용해볼까?\n\nflatten(ap(WHY))\n\nTensorImage([[ 2.7846, -2.7945]], device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nWHY[0,0,:,:].mean() # 이 값이 클수록 고양이\n\nTensorImage(2.7846, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n\nWHY[0,1,:,:].mean() # 이 값이 클수록 강아지 \n\nTensorImage(-2.7945, device='cuda:0', grad_fn=&lt;AliasBackward0&gt;)\n\n\n- 좀더 파고들어서 분석해보자.\n\nWHY[0,0,:,:].int() # 이 값들의 평균이 2.7846임. 그리고 이 평균값이 클수록 고양이\n\nTensorImage([[ 0,  0,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  2,  5,  2,  1,  1,  0,  0,  0,  0,  0,  0,  0, -1, -1],\n             [ 0,  0,  1,  3,  2,  0,  0,  0,  0,  0,  0,  0,  0, -1, -1, -3],\n             [ 0,  0,  0,  0,  0, -1,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0, -1, -3, -2,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0, -3, -1,  1,  2,  1,  0,  0, -1,  0,  0,  1],\n             [ 0,  0,  0,  0,  0, -1,  1, 11, 19, 14,  4,  0, -1, -1,  0,  0],\n             [ 0,  0,  0,  0,  0, -1,  6, 24, 40, 28,  9,  0,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  0,  1, 11, 31, 46, 33, 11,  1,  0,  0,  0,  0],\n             [ 0,  0,  0,  0,  1,  7, 16, 27, 32, 23,  9,  1,  0,  1,  1,  1],\n             [-1,  0,  0,  0,  4, 14, 22, 20, 17, 11,  5,  2,  2,  3,  4,  3],\n             [-1,  0,  0,  1,  6, 16, 23, 12,  4,  2,  3,  3,  3,  3,  4,  4],\n             [ 0,  0,  1,  1,  5, 11, 13,  7,  2,  1,  2,  1,  1,  2,  1,  1],\n             [ 0,  1,  3,  2,  3,  5,  6,  4,  1,  0,  1,  0,  0,  0,  0,  0],\n             [ 0,  0,  1,  1,  0,  0,  1,  1,  0,  0,  0,  0, -1, -2, -1, -1],\n             [ 0, -1, -1, -1, -1,  0,  0,  0,  0,  0,  0,  0, -1, -2, -2, -2]],\n            device='cuda:0', dtype=torch.int32)\n\n\n\n이 값들의 평균은 2.7846임.\n이 값들이 클수록 이 그림은 고양이라는 의미임 = 이 값이 작을수록 이 그림은 고양이 그림이 아니라는 의미임.\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가지고, 특정 위치에서만 엄청 큰 값이 있어서 2.7846이라는 값이 나온 것임.\n특정위치에 존재하는 엄청 큰 값들은, x가 고양이 이미지라고 판단하는 근거가 된다.\n\n\nWHY[0,1,:,:].int() # 이 값들의 평균이 -2.7945임. 그리고 이 평균값이 클수록 강아지\n\nTensorImage([[  0,   0,  -1,  -1,  -1,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,  -2,  -6,  -2,  -1,  -1,  -1,   0,   0,   0,   0,   0,\n                0,   1,   0],\n             [  0,   0,  -1,  -2,  -2,  -1,   0,   0,   0,   0,   0,  -1,   0,\n                0,   1,   2],\n             [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   1,   2,   1,   0,   0,   0,   0,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,   2,   0,  -1,  -2,  -2,   0,   0,   0,\n                0,   0,  -2],\n             [  0,   0,   0,   0,   0,   0,  -1, -11, -18, -15,  -5,   0,   0,\n                1,   0,   0],\n             [  0,   0,   0,   0,   0,   0,  -6, -22, -34, -26,  -9,   0,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,   0,  -1, -10, -28, -41, -30, -11,  -1,   0,\n                0,   0,   0],\n             [  0,   0,   0,   0,  -1,  -6, -15, -27, -31, -22,  -9,  -1,   0,\n               -1,  -1,  -1],\n             [  1,   0,   0,   0,  -4, -12, -20, -19, -17, -10,  -5,  -2,  -1,\n               -2,  -4,  -3],\n             [  1,   0,   0,  -1,  -5, -15, -21, -11,  -4,  -2,  -3,  -4,  -4,\n               -3,  -5,  -4],\n             [  1,   0,   0,  -1,  -5, -11, -12,  -7,  -2,  -1,  -2,  -1,  -1,\n               -2,  -2,  -1],\n             [  0,  -1,  -3,  -2,  -3,  -5,  -6,  -3,  -1,  -1,  -1,   0,   0,\n                0,   0,   0],\n             [  0,   0,  -2,  -1,   0,  -1,  -1,  -1,  -1,   0,   0,   0,   0,\n                1,   1,   0],\n             [  0,   0,   1,   1,   1,   0,   0,   0,   0,   0,   0,   0,   1,\n                2,   2,   2]], device='cuda:0', dtype=torch.int32)\n\n\n\n이 값들의 평균은 -2.7945임.\n이 값들이 클수록 이 그림은 강아지라는 의미임 = 이 값이 작을수록 이 그림은 강아지가 아니라는 의미임.\n그런데 살펴보니 대부분의 위치에서 0에 가까운 값을 가지고, 특정 위치에서만 엄청 큰 작은값이 있어서 -2.7945라는 값이 나온 것임.\n특정위치에 존재하는 엄청 큰 작은값들은, x가 강아지 이미지가 아니라고 판단하는 근거가 된다.\n\n\\[\\underset{(1,2,16,16)}{{\\bf WHY}}\\overset{ap}{\\to} \\underset{(1,2,1,1)}{{\\boldsymbol \\sharp}}\\overset{flatten}{\\to} \\underset{(1,2)}{\\hat{\\boldsymbol y}} = [[2.7846,-2.7945]]\\]\n- 시각화1\n\nWHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\nWHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n\n\nfig,ax = plt.subplots(1,3,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYCAT,cmap='magma')\nax[2].imshow(WHYDOG,cmap='magma')\n\n\n\n\n\n\n\n\n\nmagma: 검은색 &lt; 보라색 &lt; 빨간색 &lt; 노란색\n가운데 그림의 노란부분은 고양이라는 증거, 오른쪽 그림의 검보라색 부분은 강아지가 아니라는 증거\n\n- 시각화2\n\nWHYCAT.shape\n\ntorch.Size([16, 16])\n\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n\n\n\n\n\n\n\n\n- 하니를 활용한 시각화\n\nx_pil = fastai.vision.core.PILImage.create(requests.get('https://github.com/guebin/DL2024/blob/main/imgs/01wk-hani1.jpeg?raw=true').content)\nx = next(iter(dls.test_dl([x_pil])))[0] # lrnr를 학습이후에는 여기에 저장되는 x값이 조금 달라지게됨\nx_dec = dls.decode([x])\nWHY = torch.einsum('ocij,kc -&gt; okij', net1(x), l.weight.data)\nWHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\nWHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\nsoftmax = torch.nn.Softmax(dim=1)\ncat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n\n\nfig,ax = plt.subplots(1,2,figsize=(8,4))\nax[0].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[0].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[0].set_title(f\"cat prob = {cat_prob:.6f}\")\nax[1].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\nax[1].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\nax[1].set_title(f\"dog prob = {dog_prob:.6f}\")\n\nText(0.5, 1.0, 'dog prob = 0.999991')"
  },
  {
    "objectID": "posts/07wk-1-2.html#d.-4단계-cam-시각화",
    "href": "posts/07wk-1-2.html#d.-4단계-cam-시각화",
    "title": "07wk-1,2: 설명가능한 인공지능 (XAI) – Class Activation Map, CAM",
    "section": "D. 4단계 – CAM 시각화",
    "text": "D. 4단계 – CAM 시각화\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=0\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=25\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])\n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout() \n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=50\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()\n\n\n\n\n\n\n\n\n\nfig,ax = plt.subplots(5,5)\n#---#\nk=75\nfor i in range(5):\n    for j in range(5):\n        x_pil = fastai.vision.core.PILImage.create(fastai.data.transforms.get_image_files(path/'images')[k])\n        x = next(iter(dls.test_dl([x_pil])))[0] # 이걸로 WHY를 만들어보자. \n        x_dec = dls.decode([x])[0] # 이걸로 시각화 \n        WHY = torch.einsum('ocij,kc -&gt; okij',net1(x),l.weight.data)\n        WHYCAT = WHY[0,0,:,:].to(\"cpu\").detach()\n        WHYDOG = WHY[0,1,:,:].to(\"cpu\").detach()\n        cat_prob, dog_prob = softmax(flatten(ap(WHY))).to(\"cpu\").detach().tolist()[0]\n        if cat_prob &gt; dog_prob: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYCAT,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"cat({cat_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        else: \n            ax[i][j].imshow(torch.einsum('ocij -&gt; ijc',x_dec))\n            ax[i][j].imshow(WHYDOG,cmap='magma',extent = (0,511,511,0), interpolation='bilinear',alpha=0.5)\n            ax[i][j].set_title(f\"dog({dog_prob:.2f})\")\n            ax[i][j].set_xticks([])\n            ax[i][j].set_yticks([])            \n        k=k+1\nfig.set_figheight(16)\nfig.set_figwidth(16)\nfig.tight_layout()"
  },
  {
    "objectID": "posts/03wk-1.html#a.-로지스틱-모형",
    "href": "posts/03wk-1.html#a.-로지스틱-모형",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 로지스틱 모형",
    "text": "A. 로지스틱 모형\n- \\(x\\)가 커질수록 \\(y=1\\)이 잘나오는 모형은 아래와 같이 설계할 수 있음 &lt;— 외우세요!!!\n\n\\(y_i \\sim {\\cal B}(\\pi_i),\\quad\\) where \\(\\pi_i = \\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)} = \\frac{1}{1+\\exp(-w_0-w_1x_i)}\\)\n\\(\\hat{y}_i= \\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}=\\frac{1}{1+\\exp(-\\hat{w}_0-\\hat{w}_1x_i)}\\)\n\\(loss= - \\sum_{i=1}^{n} \\big(y_i\\log(\\hat{y}_i)+(1-y_i)\\log(1-\\hat{y}_i)\\big)\\) &lt;— 외우세요!!\n\n- 회귀모형과 로지스틱 모형의 비교\n\n회귀모형: \\(y_i \\sim {\\cal N}(w_0+w_1x_i, \\sigma^2)\\)1\n로지스틱: \\(y_i \\sim {\\cal B}\\big(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\big)\\)\n\n1 원래는 이렇게 썼었지.. \\(y_i = w_0 + w_1x_i + \\epsilon_i \\quad \\epsilon_i \\sim {\\cal N}(0,\\sigma^2)\\)- 우리가 예측하고 싶은것\n\n회귀모형: 정규분포의 평균을 예측하고 싶음. 즉 \\(w_0+w_1x_i\\)를 예측하고 싶음. 예측값으로는 \\(\\hat{w}_0 + \\hat{w}_1x_i\\)를 사용!\n로지스틱: 베르누이의 평균을 예측하고 싶음. 즉 \\(\\frac{\\exp(w_0+w_1x_i)}{1+\\exp(w_0+w_1x_i)}\\)를 예측하고 싶음. 예측값으로는 \\(\\frac{\\exp(\\hat{w}_0+\\hat{w}_1x_i)}{1+\\exp(\\hat{w}_0+\\hat{w}_1x_i)}\\)를 사용!"
  },
  {
    "objectID": "posts/03wk-1.html#b.-데이터",
    "href": "posts/03wk-1.html#b.-데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 데이터",
    "text": "B. 데이터\n\nx = torch.linspace(-1,1,2000).reshape(2000,1)\nw0 = -1\nw1 = 5\nu = w0 + x*w1 # 선형변환이네?\nv = torch.exp(u) / (1+torch.exp(u)) \ny = torch.bernoulli(v)\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.legend()\n\n\n\n\n\n\n\n\n우리의 목적: \\(x_i\\)가 들어가면 빨간곡선 \\(\\hat{y}_i\\)의 값을 만들어주는 mapping을 학습해보자."
  },
  {
    "objectID": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "href": "posts/03wk-1.html#c.-step1-net-설계-모델링",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. Step1: net 설계 (모델링)",
    "text": "C. Step1: net 설계 (모델링)\n- 최초의 곡선을 그려보자. (\\(net: x \\to yhat\\) 을 수행하는 네트워크를 설계해보자는 의미)\n\nw0hat = -0.8\nw1hat = -0.3\n\n\ndef sigmoid(x):\n    return torch.exp(x)/(1+torch.exp(x))\n\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.legend()\n\n\n\n\n\n\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = False)로 구현\n\nX = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=2, out_features=1, bias = False)\nl1.weight\n\nParameter containing:\ntensor([[-0.0370, -0.1980]], requires_grad=True)\n\n\n\nl1.weight.data = torch.tensor([[-0.8,  -0.3]])\n\n\nl1(X), w0hat + w1hat*x # 똑같죠\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;MmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- w0hat + w1hat*x 이 부분을 torch.nn.Linear(bias = True)로 구현\n\n#X = torch.concat([torch.ones(2000).reshape(-1,1),x],axis=1)\nl1 = torch.nn.Linear(in_features=1, out_features=1)\nl1.weight, l1.bias\n\n(Parameter containing:\n tensor([[-0.0153]], requires_grad=True),\n Parameter containing:\n tensor([-0.4743], requires_grad=True))\n\n\n\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n\n\nl1(x), w0hat + w1hat*x # 이것도 똑같죠!\n\n(tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-0.5000],\n         [-0.5003],\n         [-0.5006],\n         ...,\n         [-1.0994],\n         [-1.0997],\n         [-1.1000]]))\n\n\n- 내가만든 sigmoid 대신에 토치에서 제공하는 sigmoid 사용\n\na1 = torch.nn.Sigmoid()\n\n\nsigmoid(l1(x)), a1(l1(x)) # 똑같아요\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;DivBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;))\n\n\n- 지금까지의 구현 확인\n\nplt.plot(x,y,'.',alpha=0.03)\nplt.plot(x[0],y[0],'o',label=r\"$(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,v,'--r',label=r\"prob (true, unknown) = $\\frac{exp(-1+5x)}{1+exp(-1+5x)}$\")\nplt.plot(x,sigmoid(w0hat + w1hat*x),'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve\")\nplt.plot(x,a1(l1(x)).data,'--b', label=r\"prob (estimated) = $(x_i,\\hat{y}_i)$ -- first curve with $(a_1 \\circ l_1)(x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 관찰: 지금 아래의 구조이다.\n\\[{\\boldsymbol x} \\overset{l_1}{\\to} {\\boldsymbol u} \\overset{a_1}{\\to} {\\boldsymbol v} = \\hat{\\boldsymbol y}\\]\n- 소망: 함수 \\(l_1, a_1\\) 의 합성을 하나로 묶어서\n\\[(a_1\\circ l_1)({\\boldsymbol x}) := net({\\boldsymbol x})\\]\n이러한 기능을 하는 하나의 함수 \\(net\\)을 만들 수 없을까?\n\nnet = torch.nn.Sequential(l1,a1) #l1을 취하고 그다음에 a1을 취하라는 의미\n\n\nnet(x), a1(l1(x)), sigmoid(w0hat+ w1hat*x)\n\n(tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;),\n tensor([[0.3775],\n         [0.3775],\n         [0.3774],\n         ...,\n         [0.2499],\n         [0.2498],\n         [0.2497]]))\n\n\n- net 살펴보기: 초보버전 – “파이토치 30일만에 완성하기” 이런책에 보면 내용이 나올지도?\n\nnet\n\nSequential(\n  (0): Linear(in_features=1, out_features=1, bias=True)\n  (1): Sigmoid()\n)\n\n\n\n처음에는 선형변환하고, 그담에는 Sigmoid를 수행하라는 의미\n\n- net 살펴보기: 고수버전 – 책 안보고 코딩배우기\n\nset(dir(net)) & {'__call__', '__getitem__'}\n\n{'__call__', '__getitem__'}\n\n\n\n좋은거 가지고 있네 ㅎㅎ\ncallable 이면서 subscriptable 오브젝트..\n\n\nlst = [11,22,33]\nlst.__getitem__(-1) # lst[-1]\n\n33\n\n\n\nsigmoid.__call__(x) # sigmoid(x)\n\ntensor([[0.2689],\n        [0.2691],\n        [0.2693],\n        ...,\n        [0.7307],\n        [0.7309],\n        [0.7311]])\n\n\n\nsigmoid[0] # 난 스크립터블 하지 않은걸? (= 난 리스트처럼 인덱싱 못해요)\n\nTypeError: 'function' object is not subscriptable\n\n\n\nlst(x)# 난 컬러블하지 않은걸? (= 난 함수처럼 입력을 받고 출력을 주는 일은 못해요)\n\nTypeError: 'list' object is not callable\n\n\n\nnet(x) # 컬러블이면서\n\ntensor([[0.3775],\n        [0.3775],\n        [0.3774],\n        ...,\n        [0.2499],\n        [0.2498],\n        [0.2497]], grad_fn=&lt;SigmoidBackward0&gt;)\n\n\n\nnet[0],net[1] # 섭스크립터블\n\n(Linear(in_features=1, out_features=1, bias=True), Sigmoid())\n\n\n\n_l1, _a1 = net # 언패킹!! (섭스크립터블하니까..)\n\n\n_l1.weight, _l1.bias # 내가 설정한 웨이트도 그대로 들어가있음\n\n(Parameter containing:\n tensor([[-0.3000]], requires_grad=True),\n Parameter containing:\n tensor([-0.8000], requires_grad=True))"
  },
  {
    "objectID": "posts/03wk-1.html#d.-step-14",
    "href": "posts/03wk-1.html#d.-step-14",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. Step 1~4",
    "text": "D. Step 1~4\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\n#loss_fn = torch.nn.MSELoss() # -- 이 코드 일단 쓰지 않을게여\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n\nfor epoc in range(4900):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = torch.mean((y-yhat)**2)\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 5000 epochs')\n\nText(0.5, 1.0, 'after 5000 epochs')\n\n\n\n\n\n\n\n\n\n성공했나?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-좋은-초기값",
    "href": "posts/03wk-1.html#a.-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 좋은 초기값",
    "text": "A. 좋은 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "href": "posts/03wk-1.html#b.-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가능성 있는 초기값",
    "text": "B. 가능성 있는 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-최악의-초기값",
    "href": "posts/03wk-1.html#c.-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 최악의 초기값",
    "text": "C. 최악의 초기값\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n해결하는 접근법:\n\n컴공스타일: 에폭을 늘려볼까?\n산공스타일: 옵티마이저를 바꿔볼까?\n통계스타일: Loss를 바꿔볼까?"
  },
  {
    "objectID": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "href": "posts/03wk-1.html#a.-bce-loss를-사용하여-학습",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. BCE Loss를 사용하여 학습",
    "text": "A. BCE Loss를 사용하여 학습\n- BCE loss라는게 있음.\n\nhttps://en.wikipedia.org/wiki/Cross-entropy\n\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    #loss = torch.mean((y-yhat)**2)\n    loss = -torch.mean(y*torch.log(yhat) + (1-y)*torch.log(1-yhat))\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')\n\n\n\n\n\n\n\n\n\n같은 100 에폭인데 훨씬 잘맞춤..\n- loss수식을 못외우겠다면?\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1, out_features=1),\n    torch.nn.Sigmoid()\n)\nl1, a1 = net # 네트워크는 섭스크립터블 오브젝트이니까..\nl1.weight.data = torch.tensor([[-0.3]])\nl1.bias.data = torch.tensor([-0.8])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25)\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x) \n    ## 2 \n    loss = loss_fn(yhat,y) # yhat부터 써야함\n    ## 3\n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'.',alpha=0.05)\nplt.plot(x,v,'--r')\nplt.plot(x,yhat.data,'--b')\nplt.title('after 100 epochs')\n\nText(0.5, 1.0, 'after 100 epochs')"
  },
  {
    "objectID": "posts/03wk-1.html#b.-loss-function-시각화",
    "href": "posts/03wk-1.html#b.-loss-function-시각화",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. Loss Function 시각화",
    "text": "B. Loss Function 시각화\n\nplot_loss(torch.nn.MSELoss())\n\n\n\n\n\n\n\n\n\nplot_loss(torch.nn.BCELoss())\n\n\n\n\n\n\n\n\n- 비교해보자.\n\nfig = plt.figure()\nax1 = fig.add_subplot(1,2,1,projection='3d')\nax2 = fig.add_subplot(1,2,2,projection='3d')\nplot_loss(torch.nn.MSELoss(),ax1)\nplot_loss(torch.nn.BCELoss(),ax2)"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect\n    \n  \n\n\n\n\n\n\n- BCELoss\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "href": "posts/03wk-1.html#c.-학습과정-시각화-좋은-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 학습과정 시각화 – 좋은 초기값",
    "text": "C. 학습과정 시각화 – 좋은 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-0.8470])\n# net[0].weight.data = torch.tensor([[-0.3467]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-0.8])\nnet[0].weight.data = torch.tensor([[-0.3]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "href": "posts/03wk-1.html#d.-학습과정-시각화-가능성-있는-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 학습과정 시각화 – 가능성 있는 초기값",
    "text": "D. 학습과정 시각화 – 가능성 있는 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-3.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.25) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-3.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "href": "posts/03wk-1.html#e.-학습과정-시각화-최악의-초기값-1",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "E. 학습과정 시각화 – 최악의 초기값",
    "text": "E. 학습과정 시각화 – 최악의 초기값\n- MSELoss + SGD\n\n# net = torch.nn.Sequential(\n#     torch.nn.Linear(1,1),\n#     torch.nn.Sigmoid()\n# ) \n# net[0].bias.data = torch.tensor([-10.0])\n# net[0].weight.data = torch.tensor([[-1.0]])\n# loss_fn = torch.nn.MSELoss()\n# optimizr = torch.optim.SGD(net.parameters(),lr=0.05) \n# #---#\n# show_animation(net,loss_fn,optimizr)\n\n- MSELoss + Adam\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n) \nnet[0].bias.data = torch.tensor([-10.0])\nnet[0].weight.data = torch.tensor([[-1.0]])\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters(),lr=0.25) \n#---#\nshow_animation(net,loss_fn,optimizr)\n\n\n\n\n\n\n\n\n  \n  \n    \n    \n      \n          \n      \n        \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n      \n          \n    \n    \n      \n      Once\n      \n      Loop\n      \n      Reflect"
  },
  {
    "objectID": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "href": "posts/03wk-1.html#a.-신문기사-데이터의-모티브",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "A. 신문기사 (데이터의 모티브)",
    "text": "A. 신문기사 (데이터의 모티브)\n- 스펙이 높아도 취업이 안된다고 합니다..\n중소·지방 기업 “뽑아봤자 그만두니까”\n중소기업 관계자들은 고스펙 지원자를 꺼리는 이유로 높은 퇴직률을 꼽는다. 여건이 좋은 대기업으로 이직하거나 회사를 관두는 경우가 많다는 하소연이다. 고용정보원이 지난 3일 공개한 자료에 따르면 중소기업 청년취업자 가운데 49.5%가 2년 내에 회사를 그만두는 것으로 나타났다.\n중소 IT업체 관계자는 “기업 입장에서 가장 뼈아픈 게 신입사원이 그만둬서 새로 뽑는 일”이라며 “명문대 나온 스펙 좋은 지원자를 뽑아놔도 1년을 채우지 않고 그만두는 사원이 대부분이라 우리도 눈을 낮춰 사람을 뽑는다”고 말했다."
  },
  {
    "objectID": "posts/03wk-1.html#b.-가짜데이터",
    "href": "posts/03wk-1.html#b.-가짜데이터",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "B. 가짜데이터",
    "text": "B. 가짜데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "href": "posts/03wk-1.html#c.-로지스틱으로-적합",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "C. 로지스틱으로 적합",
    "text": "C. 로지스틱으로 적합\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---# \nfor epoc in range(5000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(yhat,y)\n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data, '--', label= r\"prob (estimated) = $(x_i,\\hat{y}_i)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- Epoch을 10억번으로 설정해도 이건 못 맞출것 같음.\n\n결국 올라가다가 내려가는 언더라잉을 맞춰야 하는데 현재 모형으로는 이걸 표현할 수 없다.\n모형의 표현력이 낮다."
  },
  {
    "objectID": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "href": "posts/03wk-1.html#d.-해결책-아이디어-수준만",
    "title": "03wk-1: 로지스틱 – 로지스틱 소개, BCELoss, Adam, 로지스틱의 한계",
    "section": "D. 해결책 (아이디어 수준만)",
    "text": "D. 해결책 (아이디어 수준만)\n- sigmoid를 넣기 전의 상태가 직선이 아니라 꺽이는 직선이야 한다.\n\na = torch.nn.Sigmoid()\n\n\nfig,ax = plt.subplots(4,2,figsize=(8,8))\nu1 = torch.tensor([-6,-4,-2,0,2,4,6])\nu2 = torch.tensor([6,4,2,0,-2,-4,-6])\nu3 = torch.tensor([-6,-2,2,6,2,-2,-6])\nu4 = torch.tensor([-6,-2,2,6,4,2,0])\nax[0,0].plot(u1,'--o',color='C0',label = r\"$u_1$\")\nax[0,0].legend()\nax[0,1].plot(a(u1),'--o',color='C0',label = r\"$a(u_1)=\\frac{exp(u_1)}{exp(u_1)+1}$\")\nax[0,1].legend()\nax[1,0].plot(u2,'--o',color='C1',label = r\"$u_2$\")\nax[1,0].legend()\nax[1,1].plot(a(u2),'--o',color='C1',label = r\"$a(u_2)=\\frac{exp(u_2)}{exp(u_2)+1}$\")\nax[1,1].legend()\nax[2,0].plot(u3,'--o',color='C2', label = r\"$u_3$\")\nax[2,0].legend()\nax[2,1].plot(a(u3),'--o',color='C2', label = r\"$a(u_3)=\\frac{exp(u_3)}{exp(u_3)+1}$\")\nax[2,1].legend()\nax[3,0].plot(u4,'--o',color='C3', label = r\"$u_4$\")\nax[3,0].legend()\nax[3,1].plot(a(u4),'--o',color='C3', label = r\"$a(u_4)=\\frac{exp(u_4)}{exp(u_4)+1}$\")\nax[3,1].legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#a.-step은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. Step은 표현 불가능하지 않나?",
    "text": "A. Step은 표현 불가능하지 않나?\n- 맞춰봐\n\ntorch.manual_seed(43052)\nx = torch.linspace(-1,1,2000).reshape(-1,1)\nu = 0*x-3\nu[x&lt;-0.2] = (15*x+6)[x&lt;-0.2]\nu[(-0.2&lt;x)&(x&lt;0.4)] = (0*x-1)[(-0.2&lt;x)&(x&lt;0.4)]\nsig = torch.nn.Sigmoid()\nv = π = sig(u)\ny = torch.bernoulli(v)\n\n\n#plt.plot(u,alpha=0.2)\nplt.plot(x,y,'.',alpha=0.01,color=\"C0\")\nplt.plot(x[0],y[0],'o',color=\"C0\",label=r\"observed data (with error): $(x_i,y_i)$\")\nplt.plot(x,v,'--',label=r\"prob (true, unknown): $(x_i,\\pi_i)$ or $(x_i,v_i)$\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 저 주황색 구조를 어떻게 표현하지? \\(\\to\\) 선이 많이 꺽이면되는거아냐?\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,256),\n    torch.nn.ReLU(),\n    torch.nn.Linear(256,1),\n    #torch.nn.Sigmoid()\n)\n#loss_fn = torch.nn.BCELoss()\nloss_fn = torch.nn.BCEWithLogitsLoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nfig,ax = plt.subplots(1,2)\nax[0].plot(x,u,'--',label=r\"$(x_i,u_i)$\")\nax[0].plot(x,yhat.data,'--',label=r\"$(x_i,\\hat{u}_i)$\")\nax[0].legend()\nax[0].set_title(\"before sig\")\nax[1].plot(x,y,'.',alpha=0.02,color=\"blue\")\nax[1].plot(x,v,'--', color=\"C0\", label=r\"$(x_i,v_i)$ or $(x_i,\\pi_i)$\")\nax[1].plot(x,sig(yhat.data),'--',color=\"C1\",label=r\"$(x_i,\\hat{v}_i)$ or $(x_i,\\hat{\\pi}_i)$\")\nax[1].legend()\nax[1].set_title(\"after sig\")\n\nText(0.5, 1.0, 'after sig')"
  },
  {
    "objectID": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "href": "posts/04wk-1.html#b.-곡선은-표현-불가능하지-않나",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 곡선은 표현 불가능하지 않나?",
    "text": "B. 곡선은 표현 불가능하지 않나?\n- 맞춰봐1\n1 2024년 수능 미적30번 문제에 나온 함수응용\\[y_i = e^{-x_i} \\times  |\\cos(5x_i)| \\times \\sin(5x) + \\epsilon_i, \\quad \\epsilon_i \\sim N(0,\\sigma^2)\\]\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\nplt.plot(x,y,label=r\"observed data (with error): $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unknown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.legend()\n\n\n\n\n\n\n\n\n- 맞춰본다..\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1024)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,1024)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n\n#torch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,1024),\n    torch.nn.ReLU(),\n    torch.nn.Linear(1024,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(5000):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,label=r\"observed data: $(x_i,y_i)$\", alpha=0.2)\nplt.plot(x,fx,'--',color=\"C0\",label=r\"underlying (true, unkown): $e^{-x}|\\cos(3x)|\\sin(3x)$\")\nplt.plot(x,yhat.data,'--',color=\"C1\",label=r\"underlying (esimated): $(x_i,\\hat{y}_i)$\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "href": "posts/04wk-1.html#a.-시벤코의-정리-소개",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 시벤코의 정리 소개",
    "text": "A. 시벤코의 정리 소개\n\n\n\n\n\n\nUniversal Approximation Thm (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다. 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 예를들면 심층신경망은 아래와 같은 문제를 해결할 수 있다.\n\n\\({\\bf X}\\)는 토익점수, GPA, 공모전참가여부, \\({\\bf y}\\)는 취업여부일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\\({\\bf X}\\)는 주택이미지, 지역정보, 주택면적, 주택에 대한 설명 \\({\\bf y}\\)는 주택가격일 경우 \\({\\bf X} \\to {\\bf y}\\)인 규칙을 심층신경망은 항상 찾을 수 있다.\n\n즉 하나의 은닉층을 가진 심층신경망 모델의 표현력은 무한대라 볼 수 있다.\n\n\n\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-1.html#b.-왜-가능한가",
    "href": "posts/04wk-1.html#b.-왜-가능한가",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 왜 가능한가?",
    "text": "B. 왜 가능한가?\n- 데이터\n\nx = torch.linspace(-10,10,200).reshape(-1,1)\n\n- 아래와 같은 네트워크를 고려하자. (스펙올라도 취업못하는 예제에서 썼던 네크워크랑 비슷해요)\n\nl1 = torch.nn.Linear(in_features=1,out_features=2)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=2,out_features=1)\n\n- 직관1: \\(l_1\\),\\(l_2\\)의 가중치를 잘 결합하다보면 우연히 아래와 같이 만들 수 있다.\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+10.00,+10.00])\n\n\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\n\n\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x)[:,[0]].data,label=r\"$-5x+10$\")\nax[0].plot(x,l1(x)[:,[1]].data,label=r\"$5x+10$\")\nax[0].set_title('$l_1(x)$')\nax[0].legend()\nax[1].plot(x,a1(l1(x))[:,[0]].data,label=r\"$v_1=sig(-5x+10)$\")\nax[1].plot(x,a1(l1(x))[:,[1]].data,label=r\"$v_2=sig(5x+10)$\")\nax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[1].legend()\nax[2].plot(x,l2(a1(l1(x))).data,color='C2',label=r\"$v_1+v_2-1$\")\nax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\nax[2].legend()\n\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:11: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:11: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/3092854458.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/3092854458.py:11: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$')\n\n\n\n\n\n\n\n\n\n- 직관2: 아래들도 가능할듯?\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+0.00,+20.00])\nl2.weight.data = torch.tensor([[1.00,1.00]])\nl2.bias.data = torch.tensor([-1.00])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C0'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/3368460049.py:7: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C0'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/3368460049.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].plot(x,l2(a1(l1(x))).data,'--',color='C0'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\n\n\n\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00]])\nl1.bias.data = torch.tensor([+20.00,+00.00])\nl2.weight.data = torch.tensor([[2.50,2.50]])\nl2.bias.data = torch.tensor([-2.50])\nfig,ax = plt.subplots(1,3,figsize=(9,3))\nax[0].plot(x,l1(x).data.numpy(),'--',color='C1'); ax[0].set_title('$l_1(x)$')\nax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\nax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\nax[2].set_ylim(-0.1,2.6)\n\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:7: SyntaxWarning: invalid escape sequence '\\c'\n&lt;&gt;:8: SyntaxWarning: invalid escape sequence '\\c'\n/tmp/ipykernel_31460/2330299143.py:7: SyntaxWarning: invalid escape sequence '\\c'\n  ax[1].plot(x,a1(l1(x)).data.numpy(),'--',color='C1'); ax[1].set_title('$(a_1 \\circ l_1)(x)$')\n/tmp/ipykernel_31460/2330299143.py:8: SyntaxWarning: invalid escape sequence '\\c'\n  ax[2].plot(x,l2(a1(l1(x))).data,'--',color='C1'); ax[2].set_title('$(l_2 \\circ a_1 \\circ \\l_1)(x)$');\n\n\n\n\n\n\n\n\n\n- 직관3: 은닉층의노드수=4로 하고 적당한 가중치를 조정하면 \\((l_2\\circ a_1 \\circ l_1)(x)\\)의 결과로 주황색선 + 파란색선도 가능할 것 같다. \\(\\to\\) 실제로 가능함\n\nl1 = torch.nn.Linear(in_features=1,out_features=4)\na1 = torch.nn.Sigmoid()\nl2 = torch.nn.Linear(in_features=4,out_features=1)\n\n\nl1.weight.data = torch.tensor([[-5.00],[5.00],[-5.00],[5.00]])\nl1.bias.data = torch.tensor([0.00, 20.00, 20.00, 0])\nl2.weight.data = torch.tensor([[1.00,  1.00, 2.50,  2.50]])\nl2.bias.data = torch.tensor([-1.0-2.5])\n\n\nplt.plot(l2(a1(l1(x))).data,'--')\nplt.title(r\"$(l_2 \\circ a_1 \\circ l_1)(x)$\")\n\nText(0.5, 1.0, '$(l_2 \\\\circ a_1 \\\\circ l_1)(x)$')\n\n\n\n\n\n\n\n\n\n\n이러한 함수는 계단모양이며, 0을 제외한 서로다른 계단의 높이는 2개가 된다. 이를 간단히 “2단계-계단함수”라고 칭하자.\n\n- 정리1: 2개의 시그모이드를 우연히 잘 결합하면 아래와 같은 “1단계-계단함수” 함수 \\(h\\)를 만들 수 있다.\n\nh = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n\n\nplt.plot(x,h(x))\nplt.title(\"$h(x)$\")\n\nText(0.5, 1.0, '$h(x)$')\n\n\n\n\n\n\n\n\n\n- 정리2: 위와 같은 함수 \\(h\\)를 활성화함수로 하고 \\(m\\)개의 노드를 가지는 은닉층을 생각해보자. 이러한 은닉층을 사용한다면 “m단계-계단함수”와 같은 형태의 네트워크는 아래와 같이 \\(m\\)개의 은닉노드를 써서 항상 표현할 수 있다.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n그리고 위의 네트워크와 동일한 효과를 주는 아래의 네트워크가 항상 존재함.\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,2m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- 직관4: 그런데 어떠한 함수형태라도 구불구불한 “m단계-계단함수”로 다 근사할 수 있지 않나?"
  },
  {
    "objectID": "posts/04wk-1.html#c.-h의-위력",
    "href": "posts/04wk-1.html#c.-h의-위력",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. \\(h\\)의 위력",
    "text": "C. \\(h\\)의 위력\n- \\(h(x)\\)를 생성하는 클래스를 만들어보자.\n\nclass MyActivation(torch.nn.Module): ## 사용자정의 활성화함수를 선언하는 방법\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v # activation 의 출력\n\n\na1 = MyActivation()\n# a1 = torch.nn.Sigmoid(), a1 = torch.nn.ReLU() 대신에 a1 = MyActivation()\n\n- 아래와 같이 하나의 은닉층을 가지고 있더라도 많은 노드수만 보장되면 매우 충분한 표현력을 가짐\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- \\(h\\)의 위력\n예제1 – 스펙높아도 취업이 안된다고??\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.2, label=\"observed data (with error)\")\nplt.plot(x,prob,'--', label=\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated)\")\nplt.legend()\n\n\n\n\n\n\n\n\n예제2 – 수능에 나왔다던 이상한 곡선..?\n\ntorch.manual_seed(43052)\nx = torch.linspace(0,2,2000).reshape(-1,1)\neps = torch.randn(2000).reshape(-1,1)*0.05\nfx = torch.exp(-1*x)* torch.abs(torch.cos(3*x))*(torch.sin(3*x))\ny = fx + eps\n\n\ntorch.manual_seed(43052)\nclass MyActivation(torch.nn.Module):\n    def __init__(self):\n        super().__init__()\n    def forward(self, u):\n        h = lambda x: torch.sigmoid(200*(x+0.5))+torch.sigmoid(-200*(x-0.5))-1.0\n        v = h(u)\n        return v\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2048),\n    MyActivation(),\n    torch.nn.Linear(2048,1),\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(100):\n    ## 1\n    yhat = net(x)\n    ## 2\n    loss = loss_fn(yhat,y)\n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,alpha=0.2,label=\"observed data (with error)\")\nplt.plot(x,fx,'--',label=\"underlying (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"underlying (estimated)\")\nplt.legend()"
  },
  {
    "objectID": "posts/04wk-1.html#d.-의문점",
    "href": "posts/04wk-1.html#d.-의문점",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 의문점",
    "text": "D. 의문점\n- 이 수업을 잘 이해한 사람: 그냥 활성화함수를 \\(h\\)로 쓰면 끝 아니야? 뭐하러 relu 를 쓰는거지?\n- 딥러닝을 좀 공부해본사람1: 왜 딥러닝이 2010년이 지나서야 떳지? 1989년에 세상의 모든 문제가 풀려야 하는것 아닌가?\n- 딥러닝을 좀 공부해본사람2: 하나의 은닉층을 표현하는 네크워크는 잘 안쓰지 않나? 은닉층이 많을수록 좋다고 들었는데?\n- 약간의 의구심이 있지만 아무튼 우리는 아래의 무기를 가진 꼴이 되었다.\n\n\n\n\n\n\n우리의 무기\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크로,\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(),\n    torch.nn.Linear(???,q)\n)\n\\(f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\) 인 모든 continuous mapping \\(f\\) 을 원하는 정확도로 “근사”시킬 수 있다."
  },
  {
    "objectID": "posts/04wk-1.html#a.-데이터-다운로드",
    "href": "posts/04wk-1.html#a.-데이터-다운로드",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "A. 데이터 다운로드",
    "text": "A. 데이터 다운로드\n\nimport fastai.data.all\n\n\nfastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\n\n\n\n\n\n\n    \n      \n      100.03% [15687680/15683414 00:03&lt;00:00]\n    \n    \n\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\n!ls '/root/.fastai/data/mnist_png'\n\ntesting  training\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/'\n\n0  1  2  3  4  5  6  7  8  9\n\n\n\n!ls '/root/.fastai/data/mnist_png/training/3' | head\n\n10.png\n10000.png\n10011.png\n10031.png\n10034.png\n10042.png\n10052.png\n1007.png\n10074.png\n10091.png\nls: write error: Broken pipe\n\n\n\nimport torchvision\n\n\nimg3 = torchvision.io.read_image('/root/.fastai/data/mnist_png/training/3/10.png')\nplt.imshow(img3.reshape(28,28),cmap=\"gray\")"
  },
  {
    "objectID": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "href": "posts/04wk-1.html#b.-예비학습-plt.imshow",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "B. 예비학습 – `plt.imshow()",
    "text": "B. 예비학습 – `plt.imshow()\n- plt.imshow(...) 에서 ...이 shape이 (??,??)이면 흑백이미지를 출력\n\nplt.imshow([[0,255],[0,255]],cmap='gray')\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 shape이 (??,??,3)이면 칼라이미지를 출력\n\nr = [[0,255],[0,255]]\ng = [[255,0],[0,0]]\nb = [[0,0],[255,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n- plt.imshow(...) 에서 ...의 자료형이 int인지 float인지에 따라서 인식이 다름\n\nr = [[0,1],[0,1]]\ng = [[1,0],[0,0]]\nb = [[0,0],[1,0]]\nplt.imshow(np.stack([r,g,b],axis=2))\n\n\n\n\n\n\n\n\n\nr = [[0,1.0],[0,1.0]]\ng = [[1.0,0],[0,0]]\nb = [[0,0],[1.0,0]]\nplt.imshow(np.stack([r,g,b],axis=2))"
  },
  {
    "objectID": "posts/04wk-1.html#c.-예비학습-pathlib",
    "href": "posts/04wk-1.html#c.-예비학습-pathlib",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "C. 예비학습 – pathlib",
    "text": "C. 예비학습 – pathlib\n- 오브젝트 생성\n\npath = fastai.imports.Path('.')\npath\n\nPath('.')\n\n\n- 기능1 – .ls()\n\npath.ls()\n\n(#6) [Path('.ipynb_checkpoints'),Path('05wk-2.ipynb'),Path('06wk-1.ipynb'),Path('01wk-1.ipynb'),Path('05wk-1.ipynb'),Path('04wk-1.ipynb')]\n\n\n- 이미지 파일이 저장된 경로로 새로운 path오브젝트를 만들고 기능1 수행\n\npath = fastai.imports.Path('/root/.fastai/data/mnist_png')\npath\n\nPath('/root/.fastai/data/mnist_png')\n\n\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n- 기능2: / 로 새로운 path 생성하기\n\n(path / 'training')\n\nPath('/root/.fastai/data/mnist_png/training')\n\n\n- 기능1,2의 결합\n\n(path / 'training').ls()\n\n(#10) [Path('/root/.fastai/data/mnist_png/training/5'),Path('/root/.fastai/data/mnist_png/training/3'),Path('/root/.fastai/data/mnist_png/training/7'),Path('/root/.fastai/data/mnist_png/training/8'),Path('/root/.fastai/data/mnist_png/training/1'),Path('/root/.fastai/data/mnist_png/training/4'),Path('/root/.fastai/data/mnist_png/training/6'),Path('/root/.fastai/data/mnist_png/training/2'),Path('/root/.fastai/data/mnist_png/training/0'),Path('/root/.fastai/data/mnist_png/training/9')]"
  },
  {
    "objectID": "posts/04wk-1.html#d.-데이터정리",
    "href": "posts/04wk-1.html#d.-데이터정리",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "D. 데이터정리",
    "text": "D. 데이터정리\n- 데이터가 저장된 path 설정\n\npath = fastai.imports.Path('/root/.fastai/data/mnist_png')\n\n- X ,y를 만듦\n\nX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/3').ls()],axis=0)\nX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'training/7').ls()],axis=0)\n\n\nX3.shape, X7.shape\n\n(torch.Size([6131, 1, 28, 28]), torch.Size([6265, 1, 28, 28]))\n\n\n\ny = torch.tensor([0.0]*6131+[1.0]*6265).reshape(-1,1)\n\n\nX = torch.concat([X3,X7],axis=0)\nX.shape\n\ntorch.Size([12396, 1, 28, 28])\n\n\n\nplt.plot(y,'o')\n\n\n\n\n\n\n\n\n\n“y=0.0” 은 숫자3을 의미함, “y=1.0” 은 숫자7을 의미함\n숫자3은 6131개, 숫자7은 6265개 있음\n\n- 우리는 \\({\\bf X}: (n,1,28,28)\\) 에서 \\({\\bf y}: (n,1)\\)으로 가는 맵핑을 배우고 싶음. \\(\\to\\) 이런건 배운적이 없는데?.. \\(\\to\\) 그렇다면 \\({\\bf X}:(n,784) \\to {\\bf y}:(n,1)\\) 으로 가는 맵핑을 학습하자.\n\nX = torch.concat([X3,X7],axis=0).reshape(-1,28*28).float()\nX.shape, y.shape\n\n(torch.Size([12396, 784]), torch.Size([12396, 1]))"
  },
  {
    "objectID": "posts/04wk-1.html#e.-학습",
    "href": "posts/04wk-1.html#e.-학습",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "E. 학습",
    "text": "E. 학습\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#--#\nfor epoc in range(200):\n    ## step1\n    yhat = net(X)\n    ## step2\n    loss = loss_fn(yhat,y)\n    ## step3\n    loss.backward()\n    ## step4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y,'o',label=r\"$(i,y_i)$ -- training data set\")\nplt.plot(net(X).data,'.',alpha=0.2, label=r\"$(i,\\hat{y}_i$ -- training data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n잘맞추는데?\n믿을수가 없는데..?\n\n\n((yhat.data &gt; 0.5) == y).float().mean() # train_accuracy\n\ntensor(0.9994)"
  },
  {
    "objectID": "posts/04wk-1.html#f.-test",
    "href": "posts/04wk-1.html#f.-test",
    "title": "04wk-1: 깊은 신경망 (2) – 꺽인그래프의 한계(?), 시벤코정리, MNIST",
    "section": "F. Test",
    "text": "F. Test\n\npath.ls()\n\n(#2) [Path('/root/.fastai/data/mnist_png/training'),Path('/root/.fastai/data/mnist_png/testing')]\n\n\n\nXX3 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/3').ls()],axis=0)\nXX7 = torch.stack([torchvision.io.read_image(str(i)) for i in (path/'testing/7').ls()],axis=0)\n\n\nXX3.shape,XX7.shape\n\n(torch.Size([1010, 1, 28, 28]), torch.Size([1028, 1, 28, 28]))\n\n\n\nXX = torch.concatenate([XX3,XX7],axis=0).reshape(-1,1*28*28).float()\nXX.shape\n\ntorch.Size([2038, 784])\n\n\n\nyy = torch.tensor([0]*1010 + [1]*1028).reshape(-1,1).float()\nyy.shape\n\ntorch.Size([2038, 1])\n\n\n\nplt.plot(yy,'o',label=r\"$(i,y_i)$ -- test data set\")\nplt.plot(net(XX).data,'.',label=r\"$(i,\\hat{y}_i)$ -- test data set\")\nplt.legend()\n\n\n\n\n\n\n\n\n\n(yy == (net(XX)&gt;0.5)).float().mean() # test accuracy\n\ntensor(0.9897)\n\n\n\ntest 에서도 잘 맞춘다.."
  },
  {
    "objectID": "posts/03wk-2.html#a.-방법1",
    "href": "posts/03wk-2.html#a.-방법1",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 방법1",
    "text": "A. 방법1\n\ny = x*0 \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\n\n\nplt.plot(y,'--')\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n강의영상에 보셨듯이 아래의 코드실행결과는 다르게 나옵니다.\n## 아래를 실행하면 꺽인선이 나오는데용...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x*0 + x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n## 이걸 실행하면 그냥 직선이 나옵니다...\nx = torch.linspace(-1,1,1001).reshape(-1,1)\ny = x \ny[x&lt;0] = (9*x+4.5)[x&lt;0]\ny[x&gt;0] = (-4.5*x+4.5)[x&gt;0]\nplt.plot(x,y)\n다르게 나오는 이유가 너무 궁금하시다면 아래의 링크로 가셔서 깊은복사/얕은복사에 대한 개념을 이해하시면 됩니다. (그렇지만 가능하다면 궁금해하지 마세요…..)\n\n깊은복사 얕은복사 강의들으러 가기"
  },
  {
    "objectID": "posts/03wk-2.html#b.-방법2-렐루이용",
    "href": "posts/03wk-2.html#b.-방법2-렐루이용",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. 방법2 – 렐루이용",
    "text": "B. 방법2 – 렐루이용\n\nrelu = torch.nn.ReLU()\n\n\nplt.plot(relu(x),'--',label=r'$relu(x)$')\nplt.plot(relu(-x),'--',label=r'$relu(-x)$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x),'--',label=r'$-4.5\\times relu(x) + 4.5$')\nplt.plot(-9*relu(-x),'--',label=r'$-9\\times relu(-x) + 4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n\nplt.plot(-4.5*relu(x)-9*relu(-x),'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)$')\nplt.plot(y,'--',label=r'$y$')\nplt.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',label=r'$-4.5\\times relu(x) -9 \\times relu(-x)+4.5$')\nplt.legend()\n\n\n\n\n\n\n\n\n- 우리의 목표: 저 초록선에서 시그모이드를 태우면된다. 즉 아래의 느낌임\n\nsig = torch.nn.Sigmoid()\n\n\nfig = plt.figure(figsize=(8, 4))\nspec = fig.add_gridspec(4, 4)\nax1 = fig.add_subplot(spec[:2,0]); ax1.set_title(r'$x$'); ax1.set_ylim(-1,1)\nax2 = fig.add_subplot(spec[2:,0]); ax2.set_title(r'$-x$'); ax2.set_ylim(-1,1)\nax3 = fig.add_subplot(spec[:2,1]); ax3.set_title(r'$relu(x)$'); ax3.set_ylim(-1,1)\nax4 = fig.add_subplot(spec[2:,1]); ax4.set_title(r'$relu(-x)$'); ax4.set_ylim(-1,1)\nax5 = fig.add_subplot(spec[1:3,2]); ax5.set_title(r'$-4.5 relu(x)-9 relu(-x)+4.5$')\nax6 = fig.add_subplot(spec[1:3,3]); ax6.set_title('sig(...)');\n#---#\nax1.plot(x,'--',color='C0')\nax2.plot(-x,'--',color='C1')\nax3.plot(relu(x),'--',color='C0')\nax4.plot(relu(-x),'--',color='C1')\nax5.plot(-4.5*relu(x)-9*relu(-x)+4.5,'--',color='C2')\nax6.plot(sig(-4.5*relu(x)-9*relu(-x)+4.5),'--',color='C2')\nfig.tight_layout()"
  },
  {
    "objectID": "posts/03wk-2.html#c.-방법2의-다른구현",
    "href": "posts/03wk-2.html#c.-방법2의-다른구현",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "C. 방법2의 다른구현",
    "text": "C. 방법2의 다른구현\n- 렐루이용하여 만드는 방법 정리\n\n벡터 x와 relu함수를 준비한다.\nu = [x,-x] 를 계산한다.\nv = [relu(x), relu(-x)] 를 계산한다.\ny = -4.5 * relu(x) + 9 * relu(-x) +4.5 를 계산한다.\n\n- 1단계\n\nx,relu\n\n(tensor([[-1.0000],\n         [-0.9980],\n         [-0.9960],\n         ...,\n         [ 0.9960],\n         [ 0.9980],\n         [ 1.0000]]),\n ReLU())\n\n\n- 2단계\n\nu = torch.concat([x,-x],axis=1) # u = [x, -x] 같은것\nu\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]])\n\n\n- 3단계\n\nv = relu(u) # 각각의 column에 렐루취함\nv\n\ntensor([[0.0000, 1.0000],\n        [0.0000, 0.9980],\n        [0.0000, 0.9960],\n        ...,\n        [0.9960, 0.0000],\n        [0.9980, 0.0000],\n        [1.0000, 0.0000]])\n\n\n- 4단계\n\n-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n\ny\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n- 그런데, 4단계는 아래와 같이 볼 수 있다.\n\n\\({\\boldsymbol v}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} v_{11} & v_{12} \\\\ v_{21} & v_{22} \\\\ \\dots & \\dots \\\\ v_{n1} & v_{n2} \\\\ \\end{bmatrix}\\begin{bmatrix} -4.5 \\\\ -9.0 \\end{bmatrix} + 4.5 = \\begin{bmatrix} -4.5 v_{11} - 9.0 v_{12} + 4.5 \\\\ -4.5 v_{21} - 9.0 v_{22} + 4.5 \\\\ \\dots \\\\ -4.5 v_{n1} - 9.0 v_{n2} + 4.5 \\\\ \\end{bmatrix}\\)\n\n위의 수식을 참고하여 매트릭스의 곱 형태로 다시 포현하면 아래와 같다.\n\n#-4.5 * v[:,[0]] - 9.0 * v[:,[1]] +4.5\nWhat = torch.tensor([[-4.5],[-9.0]]) \nv @ What + 4.5 \n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]])\n\n\n이제 매트릭스의 곱 대신에 torch.nn.Linear()를 이용하면 아래의 코드와 같아진다.\n\nl2 = torch.nn.Linear(\n    in_features=2,\n    out_features=1 \n)\n\n\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(v)\n\ntensor([[-4.5000],\n        [-4.4820],\n        [-4.4640],\n        ...,\n        [ 0.0180],\n        [ 0.0090],\n        [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 사실 2단계도 아래와 같이 볼 수 있다.\n\\[\\begin{bmatrix}\nx_1 \\\\\nx_2 \\\\\n\\dots \\\\\nx_n\n\\end{bmatrix}\\begin{bmatrix} 1 & -1 \\end{bmatrix} = \\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n \\end{bmatrix}\\]\n\n#u = torch.concat([x,-x],axis=1) # u1 = [x, -x] 같은것\n\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\n\n\nl1(x)\n\ntensor([[-1.0000,  1.0000],\n        [-0.9980,  0.9980],\n        [-0.9960,  0.9960],\n        ...,\n        [ 0.9960, -0.9960],\n        [ 0.9980, -0.9980],\n        [ 1.0000, -1.0000]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n- 따라서 torch.nn 에 포함된 레이어를 이용하면 아래와 같이 표현할 할 수 있다.\n\nl1 = torch.nn.Linear(1,2)\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\na1 = torch.nn.ReLU()\nl2 = torch.nn.Linear(2,1)\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nl2(a1(l1(x))), y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))\n\n\n- 각각의 layer를 torch.nn.Sequential() 로 묶으면 아래와 같이 정리할 수 있다.\n\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1)\n)\nl1,a1,l2 = net\nl1.weight.data = torch.tensor([[1.0],[-1.0]])\nl1.bias.data = torch.tensor([0.0,0.0])\nl2.weight.data = torch.tensor([[-4.5,-9.0]])\nl2.bias.data = torch.tensor([4.5])\n\n\nnet(x),y\n\n(tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]], grad_fn=&lt;AddmmBackward0&gt;),\n tensor([[-4.5000],\n         [-4.4820],\n         [-4.4640],\n         ...,\n         [ 0.0180],\n         [ 0.0090],\n         [ 0.0000]]))"
  },
  {
    "objectID": "posts/03wk-2.html#d.-수식표현",
    "href": "posts/03wk-2.html#d.-수식표현",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "D. 수식표현",
    "text": "D. 수식표현\n(1) \\({\\bf X}=\\begin{bmatrix} x_1 \\\\ \\dots \\\\ x_n \\end{bmatrix}\\)\n(2) \\(l_1({\\bf X})={\\bf X}{\\bf W}^{(1)}\\overset{bc}{+} {\\boldsymbol b}^{(1)}=\\begin{bmatrix} x_1 & -x_1 \\\\ x_2 & -x_2 \\\\ \\dots & \\dots \\\\ x_n & -x_n\\end{bmatrix}\\)\n\n\\({\\bf W}^{(1)}=\\begin{bmatrix} 1 & -1 \\end{bmatrix}\\)\n\\({\\boldsymbol b}^{(1)}=\\begin{bmatrix} 0 & 0 \\end{bmatrix}\\)\n\n(3) \\((a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big)=\\begin{bmatrix} \\text{relu}(x_1) & \\text{relu}(-x_1) \\\\ \\text{relu}(x_2) & \\text{relu}(-x_2) \\\\ \\dots & \\dots \\\\ \\text{relu}(x_n) & \\text{relu}(-x_n)\\end{bmatrix}\\)\n(4) \\((l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad=\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)\n\n\\({\\bf W}^{(2)}=\\begin{bmatrix} -4.5 \\\\ -9 \\end{bmatrix}\\)\n\\(b^{(2)}=4.5\\)\n\n(5) \\(net({\\bf X})=(l_2 \\circ a_1\\circ l_1)({\\bf X})=\\text{relu}\\big({\\bf X}{\\bf W}^{(1)}\\overset{bc}{+}{\\boldsymbol b}^{(1)}\\big){\\bf W}^{(2)}\\overset{bc}{+}b^{(2)}\\)\n\\(\\quad =\\begin{bmatrix} -4.5\\times\\text{relu}(x_1) -9.0 \\times \\text{relu}(-x_1) +4.5 \\\\ -4.5\\times\\text{relu}(x_2) -9.0 \\times\\text{relu}(-x_2) + 4.5 \\\\ \\dots \\\\ -4.5\\times \\text{relu}(x_n) -9.0 \\times\\text{relu}(-x_n)+4.5 \\end{bmatrix}\\)"
  },
  {
    "objectID": "posts/03wk-2.html#a.-데이터",
    "href": "posts/03wk-2.html#a.-데이터",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "A. 데이터",
    "text": "A. 데이터\n\ndf = pd.read_csv(\"https://raw.githubusercontent.com/guebin/DL2024/main/posts/dnnex.csv\")\ndf\n\n\n\n\n\n\n\n\nx\nprob\ny\n\n\n\n\n0\n-1.000000\n0.000045\n0.0\n\n\n1\n-0.998999\n0.000046\n0.0\n\n\n2\n-0.997999\n0.000047\n0.0\n\n\n3\n-0.996998\n0.000047\n0.0\n\n\n4\n-0.995998\n0.000048\n0.0\n\n\n...\n...\n...\n...\n\n\n1995\n0.995998\n0.505002\n0.0\n\n\n1996\n0.996998\n0.503752\n0.0\n\n\n1997\n0.997999\n0.502501\n0.0\n\n\n1998\n0.998999\n0.501251\n1.0\n\n\n1999\n1.000000\n0.500000\n1.0\n\n\n\n\n2000 rows × 3 columns\n\n\n\n\nx = torch.tensor(df.x).float().reshape(-1,1)\ny = torch.tensor(df.y).float().reshape(-1,1)\nprob = torch.tensor(df.prob).float().reshape(-1,1)\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.legend()"
  },
  {
    "objectID": "posts/03wk-2.html#b.-step-14",
    "href": "posts/03wk-2.html#b.-step-14",
    "title": "03wk-2: 깊은 신경망 (1) – 로지스틱의 한계 극복",
    "section": "B. Step 1~4",
    "text": "B. Step 1~4\n- Step1에 대한 생각: 네트워크를 어떻게 만들까? = 아키텍처를 어떻게 만들까? = 모델링\n\\[\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{a_1}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{a_2}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\]\n- Step2,3,4 는 너무 뻔해서..\n\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(2,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 3000 epochs\")\nplt.legend()\n\n\n\n\n\n\n\n\n\nfor epoc in range(3000):\n    ## \n    yhat = net(x)\n    ## \n    loss = loss_fn(yhat,y)\n    ## \n    loss.backward()\n    ## \n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(x,y,'o',alpha=0.02)\nplt.plot(x[0],y[0],'o',label= r\"observed data = $(x_i,y_i)$\",color=\"C0\")\nplt.plot(x,prob,'--b',label= r\"prob (true, unknown)\")\nplt.plot(x,net(x).data,'--',label=\"prob (estimated) -- after 6000 epochs\")\nplt.legend()"
  },
  {
    "objectID": "posts/05wk-1.html#a.-gpu-사용방법",
    "href": "posts/05wk-1.html#a.-gpu-사용방법",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. GPU 사용방법",
    "text": "A. GPU 사용방법\n- cpu 연산이 가능한 메모리에 데이터 저장\n\ntorch.manual_seed(43052)\nx_cpu = torch.tensor([0.0,0.1,0.2]).reshape(-1,1) \ny_cpu = torch.tensor([0.0,0.2,0.4]).reshape(-1,1) \nnet_cpu = torch.nn.Linear(1,1) \n\n- gpu 연산이 가능한 메모리에 데이터 저장\n\n!nvidia-smi # before\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   35C    P8              34W / 420W |     26MiB / 24576MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\ntorch.manual_seed(43052)\nx_gpu = x_cpu.to(\"cuda:0\")\ny_gpu = y_cpu.to(\"cuda:0\")\nnet_gpu = torch.nn.Linear(1,1).to(\"cuda:0\") \n\n\n!nvidia-smi\n\nMon Apr  1 16:42:53 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.161.07             Driver Version: 535.161.07   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  NVIDIA GeForce RTX 3090        Off | 00000000:09:00.0 Off |                  N/A |\n|  0%   37C    P2              39W / 420W |    287MiB / 24576MiB |      2%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n|    0   N/A  N/A      1130      G   /usr/lib/xorg/Xorg                            9MiB |\n|    0   N/A  N/A      1209      G   /usr/bin/gnome-shell                          8MiB |\n|    0   N/A  N/A    362478      C   ...b3/anaconda3/envs/dl2024/bin/python      256MiB |\n+---------------------------------------------------------------------------------------+\n\n\n\nGPU에 메모리를 올리면 GPU메모리가 점유된다! (26MiB -&gt; 287MiB)\n\n- cpu 혹은 gpu 연산이 가능한 메모리에 저장된 값들을 확인\n\nx_cpu, y_cpu, net_cpu.weight, net_cpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]]),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]]),\n Parameter containing:\n tensor([[-0.3467]], requires_grad=True),\n Parameter containing:\n tensor([-0.8470], requires_grad=True))\n\n\n\nx_gpu, y_gpu, net_gpu.weight, net_gpu.bias\n\n(tensor([[0.0000],\n         [0.1000],\n         [0.2000]], device='cuda:0'),\n tensor([[0.0000],\n         [0.2000],\n         [0.4000]], device='cuda:0'),\n Parameter containing:\n tensor([[-0.3467]], device='cuda:0', requires_grad=True),\n Parameter containing:\n tensor([-0.8470], device='cuda:0', requires_grad=True))\n\n\n- gpu는 gpu끼리 연산가능하고 cpu는 cpu끼리 연산가능함\n(예시1)\n\nnet_cpu(x_cpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시2)\n\nnet_gpu(x_gpu) \n\ntensor([[-0.8470],\n        [-0.8817],\n        [-0.9164]], device='cuda:0', grad_fn=&lt;AddmmBackward0&gt;)\n\n\n(예시3)\n\nnet_cpu(x_gpu) \n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cpu and cuda:0! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n\n\n\n\n\n\n강의중 net을 재선언한 이유\n\n\n\n- 아래와 같이 x_cpu 혹은 y_cpu에 .to(\"cuda:0\")메소드를 쓸 경우\nx_cpu.to(\"cuda:0\")\ny_cpu.to(\"cuda:0\")\nx_cpu와 y_cpu는 cpu에 그대로 있음.\n- 그런데 아래와 같이 net_cpu에서 .to(\"cuda:0\")메소드를 쓸 경우\nnet_cpu.to(\"cuda:0\")\nnet_cpu 자체가 gpu에 올라가게 됨.\n\n\n(예시4)\n\nnet_gpu(x_cpu)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument mat1 in method wrapper_CUDA_addmm)\n\n\n(예시5)\n\ntorch.mean((y_cpu-net_cpu(x_cpu))**2)\n\ntensor(1.2068, grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시6)\n\ntorch.mean((y_gpu-net_gpu(x_gpu))**2)\n\ntensor(1.2068, device='cuda:0', grad_fn=&lt;MeanBackward0&gt;)\n\n\n(예시7)\n\ntorch.mean((y_gpu-net_cpu(x_cpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!\n\n\n(예시8)\n\ntorch.mean((y_cpu-net_gpu(x_gpu))**2)\n\nRuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
  },
  {
    "objectID": "posts/05wk-1.html#b.-시간측정-예비학습",
    "href": "posts/05wk-1.html#b.-시간측정-예비학습",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 시간측정 (예비학습)",
    "text": "B. 시간측정 (예비학습)\n\nimport time \n\n\nt1 = time.time()\n\n\nt2 = time.time()\n\n\nt2-t1\n\n1.2487025260925293"
  },
  {
    "objectID": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "href": "posts/05wk-1.html#c.-cpu-vs-gpu-512-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. CPU vs GPU (512 nodes)",
    "text": "C. CPU vs GPU (512 nodes)\n- CPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.35651373863220215\n\n\n- GPU (512 nodes)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,512),\n    torch.nn.ReLU(),\n    torch.nn.Linear(512,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.5209517478942871\n\n\n\nCPU가 더 빠르다??"
  },
  {
    "objectID": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "href": "posts/05wk-1.html#d.-cpu-vs-gpu-20480-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CPU vs GPU (20,480 nodes)",
    "text": "D. CPU vs GPU (20,480 nodes)\n- CPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n2.7291958332061768\n\n\n- GPU (20,480)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,20480),\n    torch.nn.ReLU(),\n    torch.nn.Linear(20480,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n0.4499187469482422\n\n\n\n왜 이런 차이가 나는가?\n연산을 하는 주체는 코어인데 CPU는 수는 적지만 일을 잘하는 코어들을 가지고 있고 GPU는 일은 못하지만 다수의 코어를 가지고 있기 때문"
  },
  {
    "objectID": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "href": "posts/05wk-1.html#e.-cpu-vs-gpu-204800-nodes",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. CPU vs GPU (204,800 nodes)",
    "text": "E. CPU vs GPU (204,800 nodes)\n- CPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1)\ny=torch.randn(100).reshape(-1,1)*0.01\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n85.68583369255066\n\n\n- GPU (204,800)\n\ntorch.manual_seed(5) \nx=torch.linspace(0,1,100).reshape(-1,1).to(\"cuda:0\")\ny=(torch.randn(100).reshape(-1,1)*0.01).to(\"cuda:0\")\n#---#\nnet = torch.nn.Sequential(\n    torch.nn.Linear(1,204800),\n    torch.nn.ReLU(),\n    torch.nn.Linear(204800,1)\n).to(\"cuda:0\")\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n#---#\nt1 = time.time()\nfor epoc in range(1000):\n    # 1 \n    yhat = net(x)\n    # 2 \n    loss = loss_fn(yhat,y)\n    # 3 \n    loss.backward()\n    # 4 \n    optimizr.step()\n    optimizr.zero_grad()\nt2 = time.time()\nt2-t1\n\n1.3954846858978271"
  },
  {
    "objectID": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "href": "posts/05wk-1.html#a.-의문-좀-이상하지-않아요",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 의문: 좀 이상하지 않아요?",
    "text": "A. 의문: 좀 이상하지 않아요?\n- 국민상식: GPU 비싸요.. https://bbs.ruliweb.com/community/board/300143/read/61066881\n\nGPU 메모리 많아봐야 24GB, 그래도 비싸요.. http://shop.danawa.com/virtualestimate/?controller=estimateMain&methods=index&marketPlaceSeq=16\nGPU 메모리가 80GB일 경우 가격: https://prod.danawa.com/info/?pcode=21458333\n\n- 우리가 분석하는 데이터: 빅데이터..?\n\nx = torch.linspace(-10,10,100000).reshape(-1,1)\neps = torch.randn(100000).reshape(-1,1)\ny = x*2 + eps \n\n\nplt.plot(x,y,'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n- 데이터의 크기가 커지는 순간 X.to(\"cuda:0\"), y.to(\"cuda:0\") 쓰면 난리나겠는걸?\n- 데이터를 100개중에 1개만 꼴로만 쓰면 어떨까?\n\nplt.plot(x[::100],y[::100],'o',alpha=0.05)\nplt.plot(x,2*x,'--')\n\n\n\n\n\n\n\n\n\n대충 이거만 가지고 적합해도 충분히 정확할것 같은데?"
  },
  {
    "objectID": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "href": "posts/05wk-1.html#b.-xy-데이터를-굳이-모두-gpu에-넘겨야-하는가",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?",
    "text": "B. X,y 데이터를 굳이 모두 GPU에 넘겨야 하는가?\n- 데이터셋을 짝홀로 나누어서 번갈아가면서 GPU에 올렸다 내렸다하면 안되나?\n- 아래의 알고리즘을 생각해보자.\n\n데이터를 반으로 나눈다.\n짝수obs의 x,y 그리고 net의 모든 파라메터를 GPU에 올린다.\nyhat, loss, grad, update 수행\n짝수obs의 x,y를 GPU메모리에서 내린다. 그리고 홀수obs의 x,y를 GPU메모리에 올린다.\nyhat, loss, grad, update 수행\n홀수obs의 x,y를 GPU메모리에서 내린다. 그리고 짝수obs의 x,y를 GPU메모리에 올린다.\n반복\n\n\n이러면 되는거아니야???? —&gt; 맞아요"
  },
  {
    "objectID": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "href": "posts/05wk-1.html#c.-경사하강법-확률적경사하강법-미니배치-경사하강법",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법",
    "text": "C. 경사하강법, 확률적경사하강법, 미니배치 경사하강법\n10개의 샘플이 있다고 가정. \\(\\{(x_i,y_i)\\}_{i=1}^{10}\\)\n# ver1 – 모든 샘플을 이용하여 slope 계산\n(epoch 1) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n(epoch 2) \\(loss=\\sum_{i=1}^{10}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n…\n\n우리가 항상 이렇게 했죠!\n\n# ver2 – 하나의 샘플만을 이용하여 slope 계산\n(epoch 1)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=(y_1-w_0-w_1x_1)^2 \\to slope \\to update\\)\n\\(loss=(y_2-w_0-w_1x_2)^2 \\to slope \\to update\\)\n…\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…\n# ver3 – \\(m (\\leq n)\\) 개의 샘플을 이용하여 slope 계산\n\\(m=3\\)이라고 하자.\n(epoch 1)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n(epoch 2)\n\n\\(loss=\\sum_{i=1}^{3}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=4}^{6}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=\\sum_{i=7}^{9}(y_i-w_0-w_1x_i)^2 \\to slope \\to update\\)\n\\(loss=(y_{10}-w_0-w_1x_{10})^2 \\to slope \\to update\\)\n\n…"
  },
  {
    "objectID": "posts/05wk-1.html#d.-용어의-정리",
    "href": "posts/05wk-1.html#d.-용어의-정리",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. 용어의 정리",
    "text": "D. 용어의 정리\n옛날\n- ver1: gradient descent, batch gradient descent\n- ver2: stochastic gradient descent\n- ver3: mini-batch gradient descent, mini-batch stochastic gradient descent\n요즘\n- ver1: gradient descent\n- ver2: stochastic gradient descent with batch size = 1\n- ver3: stochastic gradient descent - https://www.deeplearningbook.org/contents/optimization.html, 알고리즘 8-1 참고."
  },
  {
    "objectID": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "href": "posts/05wk-1.html#e.-datasetds-dataloaderdl",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Dataset(ds), DataLoader(dl)",
    "text": "E. Dataset(ds), DataLoader(dl)\n\n취지는 알겠으나, C의 과정을 실제 구현하려면 진짜 힘들것 같아요.. (입코딩과 손코딩의 차이) –&gt; 이걸 해결하기 위해서 파이토치에서는 DataLoader라는 오브젝트를 준비했음!\n\n- ds: 섭스크립터블함\n\nx=torch.tensor(range(10)).float().reshape(-1,1)\ny=torch.tensor([1.0]*5+[0.0]*5).reshape(-1,1)\ntorch.concat([x,y],axis=1)\n\ntensor([[0., 1.],\n        [1., 1.],\n        [2., 1.],\n        [3., 1.],\n        [4., 1.],\n        [5., 0.],\n        [6., 0.],\n        [7., 0.],\n        [8., 0.],\n        [9., 0.]])\n\n\n\nds=torch.utils.data.TensorDataset(x,y)\nds\n\n&lt;torch.utils.data.dataset.TensorDataset at 0x7fa66f6520d0&gt;\n\n\n\nds.tensors \n# 생긴건 ds.tensors = (x,y) 임\n\n(tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]),\n tensor([[1.],\n         [1.],\n         [1.],\n         [1.],\n         [1.],\n         [0.],\n         [0.],\n         [0.],\n         [0.],\n         [0.]]))\n\n\n\nds[0],(x,y)[0] # (x,y) 튜플자체는 아님.. 인덱싱이 다르게 동작\n\n((tensor([0.]), tensor([1.])),\n tensor([[0.],\n         [1.],\n         [2.],\n         [3.],\n         [4.],\n         [5.],\n         [6.],\n         [7.],\n         [8.],\n         [9.]]))\n\n\n\n\n\n\n\n\nNote\n\n\n\n여기서 제가 __iter__ 가 숨겨져 있는 오브젝트일 경우만 for문이 동작한다고 설명 했는데요, __getitem__이 있는 경우도 동작한다고 합니다. 제가 잘못 알고 있었어요. 혼란을 드려 죄송합니다.\n\n그래도 dl은 for 를 돌리기위해서 만든 오브젝트라는 설명은 맞는 설명입니다.\nds역시 독특한 방식의 인덱싱을 지원하도록 한 오브젝트라는 설명도 맞는 설명입니다.\n\n\n\n- dl: 섭스크립터블하지 않지만 이터러블함\n\ndl=torch.utils.data.DataLoader(ds,batch_size=3)\n#set(dir(dl)) & {'__iter__'}\n\n\nfor xi,yi in dl:\n    print(f\"x_batch:{xi.tolist()} \\t y_batch:{yi.tolist()}\")\n\nx_batch:[[0.0], [1.0], [2.0]]    y_batch:[[1.0], [1.0], [1.0]]\nx_batch:[[3.0], [4.0], [5.0]]    y_batch:[[1.0], [1.0], [0.0]]\nx_batch:[[6.0], [7.0], [8.0]]    y_batch:[[0.0], [0.0], [0.0]]\nx_batch:[[9.0]]      y_batch:[[0.0]]\n\n\n- 마지막관측치는 뭔데 단독으로 업데이트하냐?? –&gt; shuffle True 같이 자잘한 옵션도 있음..\n\ndl = torch.utils.data.DataLoader(ds,batch_size=3,shuffle=True)\nfor xi,yi in dl:\n    print(f'x_batch={xi.tolist()} \\t y_batch={yi.tolist()}')\n\nx_batch=[[1.0], [8.0], [0.0]]    y_batch=[[1.0], [0.0], [1.0]]\nx_batch=[[2.0], [7.0], [6.0]]    y_batch=[[1.0], [0.0], [0.0]]\nx_batch=[[5.0], [3.0], [9.0]]    y_batch=[[0.0], [1.0], [0.0]]\nx_batch=[[4.0]]      y_batch=[[1.0]]"
  },
  {
    "objectID": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "href": "posts/05wk-1.html#f.-ds-dl을-이용한-mnist-구현",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. ds, dl을 이용한 MNIST 구현",
    "text": "F. ds, dl을 이용한 MNIST 구현\n- 목표: 확률적경사하강법과 그냥 경사하강법의 성능을 “동일 반복횟수”로 비교해보자.\n\nbatch_size = 2048로 설정할것\n\n- 그냥 경사하강법 – 미니배치 안쓰는 학습, 우리가 맨날하는 그거\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(700):\n    # step1 \n    yhat = net(X)\n    # step2 \n    loss = loss_fn(yhat,y)\n    # step3     \n    loss.backward()\n    # step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: Predict \n((yhat &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9953)\n\n\n- “확률적”경사하강법 – 미니배치 쓰는 학습\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n# ## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        #yihat = net(xi)\n        # step2 \n        loss = loss_fn(net(xi),yi)\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict \n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)\n\n\n- GPU를 활용하는 “확률적”경사하강법 – 실제적으로는 이게 최종알고리즘\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1],axis=0).reshape(-1,1*28*28)/255\ny = torch.tensor([0.0]*len(X0) + [1.0]*len(X1)).reshape(-1,1)\nds = torch.utils.data.TensorDataset(X,y)\ndl = torch.utils.data.DataLoader(ds,batch_size=2048)\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(1)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,1),\n    torch.nn.Sigmoid()\n).to(\"cuda:0\")\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.SGD(net.parameters())\n## Step3: fit  \nfor epoc in range(100):\n    for xi,yi in dl:        \n        # step1 \n        # step2 \n        loss = loss_fn(net(xi.to(\"cuda:0\")),yi.to(\"cuda:0\"))\n        # step3     \n        loss.backward()\n        # step4 \n        optimizr.step()\n        optimizr.zero_grad()\n# ## Step4: Predict\nnet.to(\"cpu\")\n((net(X) &gt; 0.5)*1.0 ==  y).float().mean()\n\ntensor(0.9931)"
  },
  {
    "objectID": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "href": "posts/05wk-1.html#a.-결론-그냥-외우세요",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "A. 결론 (그냥 외우세요)",
    "text": "A. 결론 (그냥 외우세요)\n- 2개의 class를 구분하는 문제가 아니라 \\(k\\)개의 class를 구분해야 한다면?\n일반적인 개념\n\n손실함수: BCE loss \\(\\to\\) Cross Entropy loss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: sig \\(\\to\\) softmax\n\n파이토치 한정\n\ny의형태: (n,) vector + int형 // (n,k) one-hot encoded matrix + float형\n손실함수: torch.nn.BCEWithLogitsLoss, \\(\\to\\) torch.nn.CrossEntropyLoss\n마지막층의 선형변환: torch.nn.Linear(?,1) \\(\\to\\) torch.nn.Linear(?,k)\n마지막층의 활성화: None \\(\\to\\) None (손실함수에 이미 마지막층의 활성화가 포함)"
  },
  {
    "objectID": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "href": "posts/05wk-1.html#b.-실습-3개의-클래스를-구분",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "B. 실습: 3개의 클래스를 구분",
    "text": "B. 실습: 3개의 클래스를 구분\n- 정리된 코드1: 통계잘하는데 파이토치 못쓰는 사람의 코드\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\ny = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n    \n## Step4: 적합 (혹은 적합결과확인)\n(netout.argmax(axis=1) == y.argmax(axis=1)).float().mean()\n\ntensor(0.9827)\n\n\n- 정리된 코드2: 파이토치를 잘하는 사람의 코드\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data('https://s3.amazonaws.com/fast-ai-imageclas/mnist_png.tgz')\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX2 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/2').ls()])\nX = torch.concat([X0,X1,X2]).reshape(-1,1*28*28)/255\n#y = torch.nn.functional.one_hot(torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))).float()\ny = torch.tensor([0]*len(X0) + [1]*len(X1)+ [2]*len(X2))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,3),\n#    torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: 적합 \nfor epoc in range(100):\n    ## step1 \n    netout = net(X)\n    ## step2 \n    loss = loss_fn(netout,y)\n    ## step3 \n    loss.backward()\n    ## step4 \n    optimizr.step()\n    optimizr.zero_grad()\n## Step4: 적합 (혹은 적합결과확인)    \n(netout.argmax(axis=1) == y).float().mean()\n\ntensor(0.9827)\n\n\n\n완전같은코드임"
  },
  {
    "objectID": "posts/05wk-1.html#c.-softmax",
    "href": "posts/05wk-1.html#c.-softmax",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "C. Softmax",
    "text": "C. Softmax\n- 눈치: softmax를 쓰기 직전의 숫자들은 (n,k)꼴로 되어있음. 각 observation 마다 k개의 숫자가 있는데, 그중에서 유난히 큰 하나의 숫자가 있음.\n\nnet(X)\n\ntensor([[ 4.4836, -4.5924, -3.4632],\n        [ 1.9839, -3.4456,  0.3030],\n        [ 5.9082, -7.5250, -0.7634],\n        ...,\n        [-0.8089, -0.8294,  0.6012],\n        [-2.1901, -0.4458,  0.7465],\n        [-1.6856, -2.2825,  5.1892]], grad_fn=&lt;AddmmBackward0&gt;)\n\n\n\ny\n\ntensor([0, 0, 0,  ..., 2, 2, 2])\n\n\n- 수식\n\n\\(\\text{sig}(u)=\\frac{e^u}{1+e^u}\\)\n\\(\\text{softmax}({\\boldsymbol u})=\\text{softmax}([u_1,u_2,\\dots,u_k])=\\big[ \\frac{e^{u_1}}{e^{u_1}+\\dots e^{u_k}},\\dots,\\frac{e^{u_k}}{e^{u_1}+\\dots e^{u_k}}\\big]\\)\n\n- torch.nn.Softmax() 손계산\n(예시1) – 잘못계산\n\nsoftmax = torch.nn.Softmax(dim=0)\n\n\nnetout = torch.tensor([[-2.0,-2.0,0.0],\n                        [3.14,3.14,3.14],\n                        [0.0,0.0,2.0],\n                        [2.0,2.0,4.0],\n                        [0.0,0.0,0.0]])\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout) \n\ntensor([[0.0041, 0.0041, 0.0115],\n        [0.7081, 0.7081, 0.2653],\n        [0.0306, 0.0306, 0.0848],\n        [0.2265, 0.2265, 0.6269],\n        [0.0306, 0.0306, 0.0115]])\n\n\n(예시2) – 이게 맞게 계산되는 것임\n\nsoftmax = torch.nn.Softmax(dim=1)\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시3) – 차원을 명시안하면 맞게 계산해주고 경고 줌\n\nsoftmax = torch.nn.Softmax()\n\n\nnetout\n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\nsoftmax(netout)\n\n/home/cgb3/anaconda3/envs/dl2024/lib/python3.11/site-packages/torch/nn/modules/module.py:1511: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  return self._call_impl(*args, **kwargs)\n\n\ntensor([[0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333],\n        [0.1065, 0.1065, 0.7870],\n        [0.1065, 0.1065, 0.7870],\n        [0.3333, 0.3333, 0.3333]])\n\n\n(예시4) – 진짜 손계산\n\nnetout \n\ntensor([[-2.0000, -2.0000,  0.0000],\n        [ 3.1400,  3.1400,  3.1400],\n        [ 0.0000,  0.0000,  2.0000],\n        [ 2.0000,  2.0000,  4.0000],\n        [ 0.0000,  0.0000,  0.0000]])\n\n\n\ntorch.exp(netout)\n\ntensor([[ 0.1353,  0.1353,  1.0000],\n        [23.1039, 23.1039, 23.1039],\n        [ 1.0000,  1.0000,  7.3891],\n        [ 7.3891,  7.3891, 54.5981],\n        [ 1.0000,  1.0000,  1.0000]])\n\n\n\n0.1353/(0.1353 + 0.1353 + 1.0000), 0.1353/(0.1353 + 0.1353 + 1.0000), 1.0000/(0.1353 + 0.1353 + 1.0000) # 첫 obs\n\n(0.10648512513773022, 0.10648512513773022, 0.7870297497245397)\n\n\n\ntorch.exp(netout[1])/torch.exp(netout[1]).sum() # 두번째 obs \n\ntensor([0.3333, 0.3333, 0.3333])"
  },
  {
    "objectID": "posts/05wk-1.html#d.-crossentropyloss",
    "href": "posts/05wk-1.html#d.-crossentropyloss",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "D. CrossEntropyLoss",
    "text": "D. CrossEntropyLoss\n- 수식\n# 2개의 카테고리\n- 예제1: BCELoss vs BCEWithLogisticLoss\n\ny = torch.tensor([0,0,1]).reshape(-1,1).float()\nnetout = torch.tensor([-1, 0, 1]).reshape(-1,1).float()\ny,netout\n\n(tensor([[0.],\n         [0.],\n         [1.]]),\n tensor([[-1.],\n         [ 0.],\n         [ 1.]]))\n\n\n\n# 계산방법1: 공식암기\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\n- torch.sum(torch.log(yhat)*y + torch.log(1-yhat)*(1-y))/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.BCELoss() 이용\nsig = torch.nn.Sigmoid()\nyhat = sig(netout)\nloss_fn = torch.nn.BCELoss()\nloss_fn(yhat,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.BCEWithLogitsLoss() 이용\nloss_fn = torch.nn.BCEWithLogitsLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n- 예제2: BCEWithLogisticLoss vs CrossEntropyLoss\n\ntorch.concat([sig(netout),1-sig(netout)],axis=1)\n\ntensor([[0.2689, 0.7311],\n        [0.5000, 0.5000],\n        [0.7311, 0.2689]])\n\n\n\nnetout = torch.tensor([[3,2],[2,2],[5,6]]).float()\ny = torch.tensor([[1,0],[1,0],[0,1]]).float()\ny,netout #,netout[:,[1]]-netout[:,[0]]\n\n(tensor([[1., 0.],\n         [1., 0.],\n         [0., 1.]]),\n tensor([[3., 2.],\n         [2., 2.],\n         [5., 6.]]))\n\n\n\nsoftmax(netout)\n\ntensor([[0.7311, 0.2689],\n        [0.5000, 0.5000],\n        [0.2689, 0.7311]])\n\n\n\n# 계산방법1: 공식암기\n-torch.sum(torch.log(softmax(netout))*y)/3\n\ntensor(0.4399)\n\n\n\n# 계산방법2: torch.nn.CrossEntropyLoss() 이용 + y는 one-hot으로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n\n# 계산방법3: torch.nn.CrossEntropyLoss() 이용 + y는 0,1 로 정리\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.4399)\n\n\n#\n# 3개의 카테고리\n\ny = torch.tensor([2,1,2,2,0])\ny_onehot = torch.nn.functional.one_hot(y)\nnetout = torch.tensor(\n    [[-2.0000, -2.0000,  0.0000],\n     [ 3.1400,  3.1400,  3.1400],\n     [ 0.0000,  0.0000,  2.0000],\n     [ 2.0000,  2.0000,  4.0000],\n     [ 0.0000,  0.0000,  0.0000]]\n)\ny,y_onehot\n\n(tensor([2, 1, 2, 2, 0]),\n tensor([[0, 0, 1],\n         [0, 1, 0],\n         [0, 0, 1],\n         [0, 0, 1],\n         [1, 0, 0]]))\n\n\n\n## 방법1 -- 추천X\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y_onehot.float())\n\ntensor(0.5832)\n\n\n\n## 방법2 -- 추천O\nloss_fn = torch.nn.CrossEntropyLoss()\nloss_fn(netout,y)\n\ntensor(0.5832)\n\n\n\n## 방법3 -- 공식.. (이걸 쓰는사람은 없겠지?)\nsoftmax = torch.nn.Softmax() \nloss_fn = torch.nn.CrossEntropyLoss()\n- torch.sum(torch.log(softmax(netout))*y_onehot)/5\n\ntensor(0.5832)\n\n\n#\n- 계산하는 공식을 아는것도 중요한데 torch.nn.CrossEntropyLoss() 에는 softmax 활성화함수가 이미 포함되어 있다는 것을 확인하는 것이 더 중요함.\n- torch.nn.CrossEntropyLoss() 는 사실 torch.nn.CEWithSoftmaxLoss() 정도로 바꾸는 것이 더 말이 되는 것 같다."
  },
  {
    "objectID": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "href": "posts/05wk-1.html#e.-minor-topic-이진분류와-crossentropy",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "E. Minor Topic: 이진분류와 CrossEntropy",
    "text": "E. Minor Topic: 이진분류와 CrossEntropy\n- 2개의 클래스일경우에도 CrossEntropy를 쓸 수 있지 않을까?\n\n## Step1: 데이터준비 \npath = fastai.data.external.untar_data(fastai.data.external.URLs.MNIST)\nX0 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/0').ls()])\nX1 = torch.stack([torchvision.io.read_image(str(fname)) for fname in (path/'training/1').ls()])\nX = torch.concat([X0,X1]).reshape(-1,1*28*28)/255\ny = torch.tensor([0]*len(X0) + [1]*len(X1))\n## Step2: 학습가능한 오브젝트 생성\ntorch.manual_seed(43052)\nnet = torch.nn.Sequential(\n    torch.nn.Linear(784,32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(32,2),\n    #torch.nn.Softmax()\n)\nloss_fn = torch.nn.CrossEntropyLoss()\noptimizr = torch.optim.Adam(net.parameters())\n## Step3: fit  \nfor epoc in range(70): \n    ## 1 \n    ## 2 \n    loss= loss_fn(net(X),y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n## Step4: Predict \nsoftmax = torch.nn.Softmax()\n(net(X).argmax(axis=1) == y).float().mean()\n\ntensor(0.9983)\n\n\n- 이진분류문제 = “y=0 or y=1” 을 맞추는 문제 = 성공과 실패를 맞추는 문제 = 성공확률과 실패확률을 추정하는 문제\n- softmax, sigmoid\n\nsoftmax: (실패확률, 성공확률) 꼴로 결과가 나옴 // softmax는 실패확률과 성공확률을 둘다 추정한다.\nsigmoid: (성공확률) 꼴로 결과가 나옴 // sigmoid는 성공확률만 추정한다.\n\n- 그런데 “실패확률=1-성공확률” 이므로 사실상 둘은 같은걸 추정하는 셈이다. (성공확률만 추정하면 실패확률은 저절로 추정되니까)\n- 즉 아래는 같은 표현력을 가진 모형이다.\n\n\n- 둘은 같은 표현력을 가진 모형인데 학습할 파라메터는 sigmoid의 경우가 더 적다. \\(\\to\\) sigmoid를 사용하는 모형이 비용은 싸고 효과는 동일하다는 말 \\(\\to\\) 이진분류 한정해서는 softmax를 쓰지말고 sigmoid를 써야함.\n\nsoftmax가 갑자기 너무 안좋아보이는데 sigmoid는 k개의 클래스로 확장이 불가능한 반면 softmax는 확장이 용이하다는 장점이 있음."
  },
  {
    "objectID": "posts/05wk-1.html#f.-정리",
    "href": "posts/05wk-1.html#f.-정리",
    "title": "05wk-1: 깊은 신경망 (4) – GPU 사용법, SGD, Softmax와 CrossEntropy",
    "section": "F. 정리",
    "text": "F. 정리\n- 결론\n\n소프트맥스는 시그모이드의 확장이다.\n클래스의 수가 2개일 경우에는 (Sigmoid, BCEloss) 조합을 사용해야 하고 클래스의 수가 2개보다 클 경우에는 (Softmax, CrossEntropyLoss) 를 사용해야 한다.\n\n- 그런데 사실.. 클래스의 수가 2개일 경우일때 (Softmax, CrossEntropyLoss)를 사용해도 그렇게 큰일나는것은 아니다. (그냥 좀 비효율적인 느낌이 드는 것 뿐임. 흑백이미지를 칼라잉크로 출력하는 느낌)\n참고\n\n\n\n\\(y\\)\n분포가정\n마지막층의 활성화함수\n손실함수\n\n\n\n\n3.45, 4.43, … (연속형)\n정규분포\nNone (or Identity)\nMSE\n\n\n0 or 1\n이항분포 with \\(n=1\\) (=베르누이)\nSigmoid\nBCE\n\n\n[0,0,1], [0,1,0], [1,0,0]\n다항분포 with \\(n=1\\)\nSoftmax\nCross Entropy"
  },
  {
    "objectID": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "href": "posts/05wk-2.html#a.-기존모형에-대한-불만",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "A. 기존모형에 대한 불만",
    "text": "A. 기존모형에 대한 불만\n\n- 왜 28 \\(\\times\\) 28 이미지를 784개의 벡터로 만든 다음에 모형을 돌려야 하는가?\n- 기존에 개발된 모형이 회귀분석 기반으로 되어있어서 결국 회귀분석 틀에 짜 맞추어서 이미지자료를 분석하는 느낌\n- observation의 차원은 \\(784\\)가 아니라 \\(1\\times (28\\times 28)\\)이 되어야 맞다."
  },
  {
    "objectID": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "href": "posts/05wk-2.html#b.-새로운-아키텍처의-제시",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "B. 새로운 아키텍처의 제시",
    "text": "B. 새로운 아키텍처의 제시\n- 예전 아키텍처들\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,256)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,256)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,30)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,30)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 아키텍처들의 공통점?\n\n\\(l_1\\): 선형변환, feature를 뽑아내는 역할 (뻥튀기 혹은 요약)\n\\(relu\\): 뻥튀기된 feature에 비선형을 추가하여 표현력 극대화\n\\(l_2\\): 선형변환, 뻥튀기된 feature를 요약 하는 역할 (=데이터를 요약하는 역할)\n\n- 새로운 아키텍처\n\n\\(conv\\): feature를 뽑아내는 역할 (뻥튀기 혹은 요약) (2d ver \\(l_1\\) 느낌)\n\\(relu\\):\n\\(pooling\\): 데이터를 요약하는 역할"
  },
  {
    "objectID": "posts/05wk-2.html#c.-torch.nn.conv2d",
    "href": "posts/05wk-2.html#c.-torch.nn.conv2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "C. torch.nn.Conv2d",
    "text": "C. torch.nn.Conv2d\n- 우선 연산하는 방법만 살펴보자.\n(예시1)\n\ntorch.manual_seed(43052)\nconv = torch.nn.Conv2d(1,1,(2,2)) # 입력1, 출력1, (2,2) window size\nconv.weight.data, conv.bias.data\n\n(tensor([[[[-0.1733, -0.4235],\n           [ 0.1802,  0.4668]]]]),\n tensor([0.2037]))\n\n\n\n_X = torch.arange(0,4).reshape(1,1,2,2).float() # 2,2 흑백이미지. \n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\n(-0.1733)*0 + (-0.4235)*1 +\\\n(0.1802)*2 + (0.4668)*3 + 0.2037\n\n1.541\n\n\n\nconv(_X)\n\ntensor([[[[1.5410]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시2) 평균\n\nconv = torch.nn.Conv2d(1,1,(2,2))\nconv.weight.data = conv.weight.data * 0 + 1/4\nconv.bias.data = conv.bias.data * 0\n\n\n_X\n\ntensor([[[[0., 1.],\n          [2., 3.]]]])\n\n\n\nconv(_X)\n\ntensor([[[[1.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;)\n\n\n(예시3) 이동평균?\n\n_X = torch.arange(16).reshape(1,1,4,4).float()\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]]]),\n tensor([[[[ 2.5000,  3.5000,  4.5000],\n           [ 6.5000,  7.5000,  8.5000],\n           [10.5000, 11.5000, 12.5000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시4) window size가 증가한다면? (2d의 이동평균느낌)\n\n_X = torch.arange(16).reshape(1,1,4,4).float()\nconv = torch.nn.Conv2d(1,1,(3,3))\nconv.weight.data = conv.weight.data * 0 + 1/9\nconv.bias.data = conv.bias.data * 0\n\n\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]]]),\n tensor([[[[ 5.0000,  6.0000],\n           [ 9.0000, 10.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시5) 2개의 이미지\n\n_X = torch.arange(32).reshape(2,1,4,4).float()\nconv = torch.nn.Conv2d(1,1,(3,3))\nconv.weight.data = conv.weight.data * 0 + 1/9\nconv.bias.data = conv.bias.data * 0\n\n\n_X,conv(_X)\n\n(tensor([[[[ 0.,  1.,  2.,  3.],\n           [ 4.,  5.,  6.,  7.],\n           [ 8.,  9., 10., 11.],\n           [12., 13., 14., 15.]]],\n \n \n         [[[16., 17., 18., 19.],\n           [20., 21., 22., 23.],\n           [24., 25., 26., 27.],\n           [28., 29., 30., 31.]]]]),\n tensor([[[[ 5.0000,  6.0000],\n           [ 9.0000, 10.0000]]],\n \n \n         [[[21.0000, 22.0000],\n           [25.0000, 26.0000]]]], grad_fn=&lt;ConvolutionBackward0&gt;))\n\n\n(예시6) 피처뻥튀기\n\n_X = torch.arange(32).reshape(2,1,4,4).float()\nconv = torch.nn.Conv2d(1,16,(3,3))\n\n\n_X.shape,conv(_X).shape\n\n(torch.Size([2, 1, 4, 4]), torch.Size([2, 16, 2, 2]))"
  },
  {
    "objectID": "posts/05wk-2.html#d.-torch.nn.relu",
    "href": "posts/05wk-2.html#d.-torch.nn.relu",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "D. torch.nn.ReLU",
    "text": "D. torch.nn.ReLU\n\na1 = torch.nn.ReLU()\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,a1(_X)\n\n(tensor([[[[-0.2818, -1.1458,  1.8352,  1.8220,  0.2402],\n           [ 0.2336, -0.3763, -0.2860,  1.3095,  0.1935],\n           [ 2.2810, -0.0667, -1.0980, -0.8768, -1.2860],\n           [-2.0301,  2.0058, -1.4996, -2.3721, -0.2790],\n           [ 0.5234, -2.3032,  0.3850,  0.3517, -0.7517]]]]),\n tensor([[[[0.0000, 0.0000, 1.8352, 1.8220, 0.2402],\n           [0.2336, 0.0000, 0.0000, 1.3095, 0.1935],\n           [2.2810, 0.0000, 0.0000, 0.0000, 0.0000],\n           [0.0000, 2.0058, 0.0000, 0.0000, 0.0000],\n           [0.5234, 0.0000, 0.3850, 0.3517, 0.0000]]]]))"
  },
  {
    "objectID": "posts/05wk-2.html#e.-torch.nn.maxpool2d",
    "href": "posts/05wk-2.html#e.-torch.nn.maxpool2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "E. torch.nn.MaxPool2d",
    "text": "E. torch.nn.MaxPool2d\n\nm1 = torch.nn.MaxPool2d((2,2))\n_X = torch.randn(25).reshape(1,1,5,5)\n_X,m1(_X)\n\n(tensor([[[[ 0.0766, -1.5961,  1.3616, -1.0197,  1.7961],\n           [ 1.0320, -1.4307,  1.5249,  0.5566,  0.4670],\n           [-1.2974, -0.0475,  0.0949, -0.5826, -0.2989],\n           [-1.6870,  0.0900, -0.2950,  1.1790,  0.5042],\n           [-1.7903,  0.8574, -1.2283,  0.6094,  0.0668]]]]),\n tensor([[[[1.0320, 1.5249],\n           [0.0900, 1.1790]]]]))"
  },
  {
    "objectID": "posts/05wk-2.html#a.-conv2d",
    "href": "posts/05wk-2.html#a.-conv2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "A. Conv2d",
    "text": "A. Conv2d\n\nc1 = torch.nn.Conv2d(1,16,(5,5))\nprint(X.shape)\nprint(c1(X).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#b.-relu",
    "href": "posts/05wk-2.html#b.-relu",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "B. ReLU",
    "text": "B. ReLU\n\na1 = torch.nn.ReLU()\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])"
  },
  {
    "objectID": "posts/05wk-2.html#c.-maxpool2d",
    "href": "posts/05wk-2.html#c.-maxpool2d",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "C. MaxPool2D",
    "text": "C. MaxPool2D\n\nm1 =  torch.nn.MaxPool2d((2,2)) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])"
  },
  {
    "objectID": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "href": "posts/05wk-2.html#d.-적당히-마무리하고-시그모이드-태우자",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "D. 적당히 마무리하고 시그모이드 태우자",
    "text": "D. 적당히 마무리하고 시그모이드 태우자\n- 펼치자.\n(방법1)\n\nm1(a1(c1(X))).reshape(-1,16*12*12).shape\n\ntorch.Size([12665, 2304])\n\n\n(방법2)\n\nflttn = torch.nn.Flatten()\n\n\nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\n\n\n- 2304 \\(\\to\\) 1 로 차원축소하는 선형레이어를 설계\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\n\n\n- 시그모이드\n\na2 = torch.nn.Sigmoid()\n\n\nl1 = torch.nn.Linear(in_features=2304,out_features=1) \nprint(X.shape)\nprint(c1(X).shape)\nprint(a1(c1(X)).shape)\nprint(m1(a1(c1(X))).shape)\nprint(flttn(m1(a1(c1(X)))).shape)\nprint(l1(flttn(m1(a1(c1(X))))).shape)\nprint(a2(l1(flttn(m1(a1(c1(X)))))).shape)\n\ntorch.Size([12665, 1, 28, 28])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 24, 24])\ntorch.Size([12665, 16, 12, 12])\ntorch.Size([12665, 2304])\ntorch.Size([12665, 1])\ntorch.Size([12665, 1])"
  },
  {
    "objectID": "posts/05wk-2.html#e.-학습",
    "href": "posts/05wk-2.html#e.-학습",
    "title": "05wk-2: 합성곱 신경망 (1) – CNN 예비학습, MNIST 자료 분석",
    "section": "E. 학습",
    "text": "E. 학습\n- 네트워크 설계\n\nnet = torch.nn.Sequential(\n    c1, # 2d: 컨볼루션(선형변환), 피처 뻥튀기 \n    a1, # 2d: 렐루(비선형변환)\n    m1, # 2d: 맥스풀링: 데이터요약\n    flttn, # 2d-&gt;1d \n    l1, # 1d: 선형변환\n    a2 # 1d: 시그모이드(비선형변환) \n)\nloss_fn = torch.nn.BCELoss()\noptimizr = torch.optim.Adam(net.parameters())\nfor epoc in range(50): \n    ## 1\n    yhat = net(X) \n    ## 2\n    loss = loss_fn(yhat,y) \n    ## 3\n    loss.backward()\n    ## 4\n    optimizr.step()\n    optimizr.zero_grad()\n\n\nplt.plot(y)\nplt.plot(net(X).data,'.')\nplt.title('Traning Set',size=15)\n\nText(0.5, 1.0, 'Traning Set')\n\n\n\n\n\n\n\n\n\n\nplt.plot(yy)\nplt.plot(net(XX).data,'.')\nplt.title('Test Set',size=15)\n\nText(0.5, 1.0, 'Test Set')"
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅",
    "href": "posts/04wk-2.html#a.-오버피팅",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅",
    "text": "A. 오버피팅\n- 오버피팅이란?\n\n위키: In mathematical modeling, overfitting is “the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably”.\n제 개념: 데이터를 “데이터 = 언더라잉 + 오차”라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상."
  },
  {
    "objectID": "posts/04wk-2.html#b.-오버피팅-예시",
    "href": "posts/04wk-2.html#b.-오버피팅-예시",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 오버피팅 예시",
    "text": "B. 오버피팅 예시\n- \\(m\\)이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n- 그런데 종종 맞추지 말아야 할 것들도 맞춘다.\nmodel: \\(y_i = (0\\times x_i) + \\epsilon_i\\), where \\(\\epsilon_i \\sim N(0,0.01^2)\\)\n\ntorch.manual_seed(5) \nx = torch.linspace(0,1,100).reshape(100,1)\ny = torch.randn(100).reshape(100,1)*0.01\nplt.plot(x,y,'--o',alpha=0.5)\n\n\n\n\n\n\n\n\n\ny는 그냥 정규분포에서 생성한 오차이므로 \\(X \\to y\\) 로 향하는 규칙따위는 없음\n\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat=net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    net.zero_grad() \n\n\nplt.plot(x,y,'--o',alpha=0.5)\nplt.plot(x,net(x).data,'--')\n\n\n\n\n\n\n\n\n\n우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 \\(\\to\\) 오버피팅 (underlying이 아니라 오차항을 따라가고 있음)"
  },
  {
    "objectID": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "href": "posts/04wk-2.html#c.-오버피팅이라는-뚜렷한-증거-train-test",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "C. 오버피팅이라는 뚜렷한 증거! (train / test)",
    "text": "C. 오버피팅이라는 뚜렷한 증거! (train / test)\n- 데이터의 분리하여 보자.\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- train만 학습\n\ntorch.manual_seed(1) \nnet=torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512), \n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=512,out_features=1)) \noptimizr= torch.optim.Adam(net.parameters())\nloss_fn= torch.nn.MSELoss()\n\nfor epoc in range(1000): \n    ## 1 \n    yhat = net(x) \n    ## 2 \n    loss=loss_fn(yhat,y) \n    ## 3 \n    loss.backward()\n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad() \n\n- training data로 학습한 net를 training data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain에서는 잘 맞추는듯이 보인다.\n\n- training data로 학습한 net를 test data 에 적용\n\nplt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\nplt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\nplt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\nplt.plot(xx,net(xx).data,label=\"predicted values, predicted values with new data\",color=\"C1\")\nplt.legend()\n\n\n\n\n\n\n\n\n\ntrain은 그럭저럭 따라가지만 test에서는 엉망이다. \\(\\to\\) overfit"
  },
  {
    "objectID": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "href": "posts/04wk-2.html#d.-시벤코정리의-올바른-이해",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "D. 시벤코정리의 올바른 이해",
    "text": "D. 시벤코정리의 올바른 이해\n\n\n\n\n\n\n시벤코정리의 항변(?) (Cybenko 1989)\n\n\n\n하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 \\(net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\)는\nnet = torch.nn.Sequential(\n    torch.nn.Linear(p,???),\n    torch.nn.Sigmoid(), ## &lt;-- 여기에 렐루를 써도 된다. \n    torch.nn.Linear(???,q)\n)\n모든 continuous mapping\n\\[f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 “근사”시킬 수 있다 (즉 마음만 먹으면 loss를 0에 가깝도록 만들 수 있다는 의다) 쉽게 말하면 \\({\\bf X} \\to {\\bf y}\\) 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. 그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data) \\({\\bf XX}_{m \\times p}\\), \\({\\bf yy}_{m \\times p}\\) 에 대하여서도 올바르게 적용된다라는 보장은 없다. 즉\n\\[{\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}\\]\n를 원하는 정확도로 근사시킨 네트워크라고 할지라도\n\\[{\\bf XX}_{m \\times p} \\to {\\bf yy}_{m\\times q}\\]\n는 엉터리로 나올 수 있다. 시벤코는 넓은 신경망이 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다. 넓은 신경망이 우수한 신경망1이라는 주장을 한적은 없다.\n\n\n1 여기에서 우수하다는 말은 여러의미가 있어요, 오버피팅이 없는 신경망이라든가, 경제적인 신경망이라든가..\nCybenko, George. 1989. “Approximation by Superpositions of a Sigmoidal Function.” Mathematics of Control, Signals and Systems 2 (4): 303–14."
  },
  {
    "objectID": "posts/04wk-2.html#a.-오버피팅의-해결",
    "href": "posts/04wk-2.html#a.-오버피팅의-해결",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "A. 오버피팅의 해결",
    "text": "A. 오버피팅의 해결\n- 오버피팅의 해결책: 드랍아웃\n- 데이터 – 재활용\n\ntorch.manual_seed(5) \nx_all = torch.linspace(0,1,100).reshape(100,1)\ny_all = torch.randn(100).reshape(100,1)*0.01\nx = x_all[:80] \ny = y_all[:80]\nxx = x_all[80:]\nyy = y_all[80:]\nplt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\nplt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\nplt.legend()\n\n\n\n\n\n\n\n\n- 학습\n\ntorch.manual_seed(1) \nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=512),\n    torch.nn.ReLU(),\n    torch.nn.Dropout(0.8),\n    torch.nn.Linear(in_features=512,out_features=1)\n)\nloss_fn = torch.nn.MSELoss()\noptimizr = torch.optim.Adam(net.parameters())\n\nfor epoc in range(1000):\n    ## 1 \n    yhat = net(x)\n    ## 2 \n    loss = loss_fn(net(x),y) \n    ## 3 \n    loss.backward() \n    ## 4 \n    optimizr.step()\n    optimizr.zero_grad()\n\n- 결과시각화 (잘못된 사용)\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = True')\n\n\n\n\n\n\n\n\n\n\nnet에 드랍아웃이 포함되어 있다면, net.training  == True 일때 결과가 엉망으로 나옴.\n왜??\n\n- 결과시각화 (올바른 사용)\n\nnet.training\n\nTrue\n\n\n\nnet.eval()\nnet.training\n\nFalse\n\n\n\nplt.plot(x,y,'o')\nplt.plot(xx,yy,'o')\nplt.plot(x,net(x).data,'--',color='C0') \nplt.plot(xx,net(xx).data,'--',color='C1') \nplt.title(f\"net.training = {net.training}\",fontsize=15)\n\nText(0.5, 1.0, 'net.training = False')\n\n\n\n\n\n\n\n\n\n\n이게 제대로 된 결과시각화임!"
  },
  {
    "objectID": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "href": "posts/04wk-2.html#b.-드랍아웃-레이어",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "B. 드랍아웃 레이어",
    "text": "B. 드랍아웃 레이어\n\nu = torch.randn(20).reshape(10,2)\nu\n\ntensor([[ 1.2686, -0.8109],\n        [-1.0100,  0.1346],\n        [-1.9911, -0.9007],\n        [ 0.7675, -0.7510],\n        [ 2.1963, -0.4903],\n        [-1.5218,  0.7236],\n        [-0.4238,  0.0079],\n        [ 1.5566,  1.6662],\n        [ 1.4546,  0.2123],\n        [-1.5117,  0.9293]])\n\n\n\nd = torch.nn.Dropout(0.9)\nd(u)\n\ntensor([[12.6862, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [ 0.0000, -0.0000],\n        [-0.0000,  0.0000],\n        [-0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [ 0.0000,  0.0000],\n        [-0.0000,  0.0000]])\n\n\n\n90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다.\n\n- 드랍아웃레이어 정리\n\n구조: 입력 -&gt; 드랍아웃레이어 -&gt; 출력\n역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정\n효과: 오버피팅을 억제하는 효과가 있음 (왜??) &lt;– 이거 너무 시간이 없어서 대충 설명했는데요.. 잘 이해가 안되시면 2023-기계학습활용-11wk-43, 2023-기계학습활용-12wk-44 참고하시면 될 겁니다. 그래도 이해가 안되면 일단은 외우세요. (진짜 궁금하시면 따로 물어보세요.. 제가 이걸 설명할 시간이 없을것 같아요.. 죄송합니다)\n의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨\n\n\n오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다..\n\n- ReLU + dropout의 특이한 성질\n\ndef my_dropout(x):\n    x[:5,[0]] = torch.zeros(5).reshape(-1,1)\n    x[5:,[1]] = torch.zeros(5).reshape(-1,1)\n    return 2*x\n\nrelu = torch.nn.ReLU()\nsig = torch.nn.Sigmoid()\n\n\nrelu(my_dropout(u)), my_dropout(relu(u))\n\n(tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]),\n tensor([[0.0000, 0.0000],\n         [0.0000, 0.2693],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [0.0000, 0.0000],\n         [3.1132, 0.0000],\n         [2.9091, 0.0000],\n         [0.0000, 0.0000]]))\n\n\n\nsig(my_dropout(u)), my_dropout(sig(u))\n\n(tensor([[0.5000, 0.1650],\n         [0.5000, 0.5669],\n         [0.5000, 0.1417],\n         [0.5000, 0.1821],\n         [0.5000, 0.2728],\n         [0.0455, 0.5000],\n         [0.2999, 0.5000],\n         [0.9574, 0.5000],\n         [0.9483, 0.5000],\n         [0.0464, 0.5000]]),\n tensor([[0.0000, 0.6154],\n         [0.0000, 1.0672],\n         [0.0000, 0.5778],\n         [0.0000, 0.6412],\n         [0.0000, 0.7597],\n         [0.3584, 0.0000],\n         [0.7912, 0.0000],\n         [1.6517, 0.0000],\n         [1.6214, 0.0000],\n         [0.3614, 0.0000]]))\n\n\n\n드랍아웃은 히든레이어사이, 즉 활성화 함수 바로 뒤에 오는게 맞음. 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함."
  },
  {
    "objectID": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제1-undersetn1bf-x-oversetl_1to-undersetn1boldsymbol-u1-oversetsigto-undersetn1boldsymbol-v1-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제1: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n- 모든 observation과 가중치를 명시한 버전\n(표현1)\n\n\n단점: 똑같은 그림의 반복이 너무 많음\n\n- observation 반복을 생략한 버전들\n(표현2) 모든 \\(i\\)에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다.\n\n(표현3) 그런데 (표현2)에서 아래와 같이 \\(x_i\\), \\(y_i\\) 대신에 간단히 \\(x\\), \\(y\\)로 쓰는 경우도 많음\n\n- 1을 생략한 버전들\n(표현4) bais=False 대신에 bias=True를 주면 1을 생략할 수 있음\n\n(표현4의 수정) \\(\\hat{w}_1\\)대신에 \\(\\hat{w}\\)를 쓰는 것이 더 자연스러움\n\n(표현5) 선형변환의 결과는 아래와 같이 \\(u\\)로 표현하기도 한다.\n\n\n다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요."
  },
  {
    "objectID": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제2-undersetn1bf-x-oversetl_1to-undersetn2boldsymbol-u1-oversetreluto-undersetn2boldsymbol-v1-oversetl_2to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2-undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제2: \\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n참고: 코드로 표현\ntorch.nn.Sequential(\n    torch.nn.Linear(in_features=1,out_features=2),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=2,out_features=1),\n    torch.nn.Sigmoid()\n)\n- 이해를 위해서 03kw-2에서 다루었던 아래의 상황을 고려하자.\n\n(강의노트의 표현)\n\n(좀 더 일반화된 표현) 상황을 일반화하면 아래와 같다.\n\n* Layer의 개념: \\({\\bf X}\\)에서 \\(\\hat{\\boldsymbol y}\\)로 가는 과정은 “선형변환+비선형변환”이 반복되는 구조이다. “선형변환+비선형변환”을 하나의 세트로 보면 아래와 같이 표현할 수 있다.\n\n\\(\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n\n이것을 다이어그램으로 표현한다면 아래와 같다.\n(선형+비선형을 하나의 Layer로 묶은 표현)\n\nLayer를 세는 방법\n\n제 방식: 학습가능한 파라메터가 몇층으로 있는지… &lt;– 이것만 기억하세여\n일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. &lt;– 무시하세요.. 이러면 헷갈립니다..\n위의 예제의 경우 number of layer = 2 이다.\n\nHidden Layer의 수를 세는 방법\n\n제 방식: Hidden Layer의 수 = Layer의 수 -1 &lt;– 이걸 기억하세여..\n\n일부 교재 설명: Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1 &lt;– 기억하지 마세여\n위의 예제의 경우 number of hidden layer = 1 이다.\n\n\n\n\n\n\n\nImportant\n\n\n\n무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n## 예시1 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n)\n## 예시2 -- 2층 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid(),\n)\n## 예시3 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n) \n## 예시4 -- 1층 (히든레이어는 없음!!)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n) \n## 예시5 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층    \n) \n## 예시6 -- 3층 (히든레이어는 2층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU()\n    torch.nn.Dropout(??)\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층  \n    torch.nn.Sigmoid()\n) \n\n\n\n\n\n\n\n\nImportant\n\n\n\n문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다.\n## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\ntorch.nn.Sequential(\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.ReLU(),\n    torch.nn.Linear(??,??), ## &lt;-- 학습해야할 가중치가 있는 층\n    torch.nn.Sigmoid()\n)\n예를 들어 여기에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 “무시”하세요. 제가 설명한 방식이 맞아요. 이 링크 잘못(?) 나와있는 이유는 아래와 같습니다.\n- 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. (Rosenblatt et al. 1962)\n- 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다.\n\n\n\nRosenblatt, Frank et al. 1962. Principles of Neurodynamics: Perceptrons and the Theory of Brain Mechanisms. Vol. 55. Spartan books Washington, DC.\n* node의 개념: \\(u\\to v\\)로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음.\n(노드의 개념이 포함된 그림)\n\n여기에서 node의 숫자 = feature의 숫자와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다.\n(“number of nodes = number of features”로 이해한 그림)\n\n\n다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다."
  },
  {
    "objectID": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "href": "posts/04wk-2.html#예제3-undersetn784bf-x-oversetl_1to-undersetn32boldsymbol-u1-oversetreluto-undersetn32boldsymbol-v1-oversetl_1to-undersetn1boldsymbol-u2-oversetsigto-undersetn1boldsymbol-v2undersetn1hatboldsymbol-y",
    "title": "04wk-2: 깊은 신경망 (3) – 오버피팅, 드랍아웃, 신경망의 표현",
    "section": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)",
    "text": "예제3: \\(\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}\\)\n(다이어그램표현)\n\n\nLayer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함\n\n- 위의 다이어그램에 대응하는 코드\nnet = torch.nn.Sequential(\n    torch.nn.Linear(in_features=28*28*1,out_features=32),\n    torch.nn.ReLU(),\n    torch.nn.Linear(in_features=32,out_features=1),\n    torch.nn.Sigmoid() \n)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/09wk-1.html#a.-data",
    "href": "posts/09wk-1.html#a.-data",
    "title": "09wk-1: 추천시스템",
    "section": "A. Data",
    "text": "A. Data\n- Data\n\ndf_view = pd.read_csv('https://raw.githubusercontent.com/guebin/STML2022/main/posts/V.%20RecSys/2022-12-21-rcmdsolo.csv',index_col=0)\ndf_view \n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n- 데이터를 이해할 때 필요한 가정들 – 제가 마음대로 설정했어요..\n\n궁합이 잘맞으면 5점, 잘 안맞으면 0점 이다.\n((옥순,영자,정숙),(영식,영철,영호))은 MBTI가 I로 시작하고 ((영숙,순자,현숙),(광수,상철,영수))는 MBTI가 E로 시작한다고 설정하자.\n(옥순,영자,정숙)은 (영식,영철,영호)와 성격이 잘 맞고 (영숙,순자,현숙)은 (광수,상철,영수)와 성격이 잘맞음.\n정숙은 대체적으로 모든 사람들이랑 궁합이 잘 맞는 편인것 같다.\n현숙은 전체적으로 모든 사람들이랑 궁합이 잘 안맞는 편인것 같다. (눈이 높아보인다)"
  },
  {
    "objectID": "posts/09wk-1.html#b.-fit-predict",
    "href": "posts/09wk-1.html#b.-fit-predict",
    "title": "09wk-1: 추천시스템",
    "section": "B. Fit / Predict",
    "text": "B. Fit / Predict\n- 목표: NaN을 추정\n- 수동추론:\n\n(옥순,영호)이 만난다면? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? \\(\\to\\) 4.0 정도?\n(정숙,영식)조합은? \\(\\to\\) 둘다 I성향이니까 잘 맞지 않을까? + 정숙은 다 잘맞던데..? \\(\\to\\) 4.8 정도?\n(현숙,영식)조합은? \\(\\to\\) 현숙은 E성향인데 영식은 I성향이므로 잘 안맞을 것임 + 현숙은 원래 좀 눈이 높음 \\(\\to\\) 0.25 정도?\n\n- 좀 더 체계적인 추론 전략: 사람들이 가지고 있는 성향들을 두 개의 숫자로 표현하자.\n\n옥순의 성향 = (I성향,E성향) = (1.9, 0.0)\n영식의 성향 = (I성향,E성향) = (2.0, 0.1)\n현숙의 성향 = (I성향,E성향) = (0.0, 1.5)\n\n\n사람에 따라 E,I 둘다 높게 설정할수도있고, 둘다 낮게 설정할 수도 있다.\n\n(1) 옥순과 영식의 궁합 \\(\\approx\\) 옥순의I성향\\(\\times\\)영식의I성향 \\(+\\) 옥순의E성향\\(\\times\\)영식의E성향 // 적합\n\n옥순성향 = torch.tensor([1.9,0.0]).reshape(2,1) \n영식성향 = torch.tensor([2.0,0.1]).reshape(2,1) \n(옥순성향*영식성향).sum().item() # 옥순과 영식의 궁합\n\n3.799999952316284\n\n\n(2) 현숙과 영식의 궁합 \\(\\approx\\) 현숙의I성향\\(\\times\\)영식의I성향 \\(+\\) 현숙의E성향\\(\\times\\)영식의E성향 // 예측\n\n현숙성향 = torch.tensor([0.0,1.5]).reshape(2,1)\n(현숙성향*영식성향).sum().item()\n\n0.15000000596046448\n\n\n\n그럴싸함.\n\n- 전체 사용자의 설정값\n\n옥순성향 = a1 = torch.tensor([1.9,0.0]).reshape(2,1)\n영자성향 = a2 = torch.tensor([2.0,0.1]).reshape(2,1)\n정숙성향 = a3 = torch.tensor([2.5,1.0]).reshape(2,1)\n영숙성향 = a4 = torch.tensor([0.1,1.9]).reshape(2,1)\n순자성향 = a5 = torch.tensor([0.2,2.1]).reshape(2,1)\n현숙성향 = a6 = torch.tensor([0.0,1.5]).reshape(2,1)\nA = torch.concat([a1,a2,a3,a4,a5,a6],axis=1)\nA # 각 column은 여성출연자들의 성향을 의미함 \n\ntensor([[1.9000, 2.0000, 2.5000, 0.1000, 0.2000, 0.0000],\n        [0.0000, 0.1000, 1.0000, 1.9000, 2.1000, 1.5000]])\n\n\n\n영식성향 = b1 = torch.tensor([2.0,0.1]).reshape(2,1)\n영철성향 = b2 = torch.tensor([1.9,0.2]).reshape(2,1)\n영호성향 = b3 = torch.tensor([1.8,0.3]).reshape(2,1)\n광수성향 = b4 = torch.tensor([0.3,2.1]).reshape(2,1)\n상철성향 = b5 = torch.tensor([0.2,2.0]).reshape(2,1)\n영수성향 = b6 = torch.tensor([0.1,1.9]).reshape(2,1)\nB = torch.concat([b1,b2,b3,b4,b5,b6],axis=1)\nB # 각 column은 남성출연자의 성향을 의미함\n\ntensor([[2.0000, 1.9000, 1.8000, 0.3000, 0.2000, 0.1000],\n        [0.1000, 0.2000, 0.3000, 2.1000, 2.0000, 1.9000]])\n\n\n- 아래의 행렬곱 관찰\n\\({\\bf A}_{2 \\times 6} = \\begin{bmatrix} {\\boldsymbol a}_1 & {\\boldsymbol a}_2 & {\\boldsymbol a}_3 & {\\boldsymbol a}_4 & {\\boldsymbol a}_5 & {\\boldsymbol a}_6 \\end{bmatrix} = \\begin{bmatrix} 1.9 & 2.0 & 2.5 & 0.1 & 0.2 & 0 \\\\ 0 & 0.1 & 1.0 & 1.9 & 2.1 & 1.5 \\end{bmatrix}\\)\n\\({\\bf B}_{2 \\times 6} = \\begin{bmatrix} {\\boldsymbol b}_1 & {\\boldsymbol b}_2 & {\\boldsymbol b}_3 & {\\boldsymbol b}_4 & {\\boldsymbol b}_5 & {\\boldsymbol b}_6 \\end{bmatrix} = \\begin{bmatrix} 2.0 & 1.0 & 1.8 & 0.3 & 0.2 & 0.1 \\\\ 0.1 & 0.2 & 0.3 & 2.1 & 2.0 & 1.9 \\end{bmatrix}\\)\n\\(\\begin{align*}{\\bf A}^\\top @ {\\bf B} & = \\begin{bmatrix} 1.9 & 0.0 \\\\ 2.0 & 0.1 \\\\ 2.5 & 1.0 \\\\ 0.1 & 1.9 \\\\ 0.2 & 2.1 \\\\ 0.0 & 1.5 \\\\ \\end{bmatrix} \\begin{bmatrix} 2.0 & 1.0 & 1.8 & 0.3 & 0.2 & 0.1 \\\\ 0.1 & 0.2 & 0.3 & 2.1 & 2.0 & 1.9 \\end{bmatrix} \\\\ \\\\ & = \\begin{bmatrix} 3.8 & 3.61 & 3.42 & 0.57 & 0.38 & 0.19 \\\\ 4.01 & 3.82 & 3.63 & 0.81 & 0.6 & 0.39 \\\\ 5.1 & 4.95 & 4.8 & 2.85 & 2.5 & 2.15 \\\\ 0.39 & 0.57 & 0.75 & 4.02 & 3.82 & 3.62 \\\\ 0.61 & 0.8 & 0.99 & 4.47 & 4.24 & 4.01 \\\\ 0.15 & 0.3 & 0.45 & 3.15 & 3 & 2.85 \\\\ \\end{bmatrix} \\\\ \\\\ & =\\begin{bmatrix} {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_1^\\top @ {\\boldsymbol b}_6 \\\\ {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_2^\\top @ {\\boldsymbol b}_6 \\\\ {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_3^\\top @ {\\boldsymbol b}_6 \\\\ {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_4^\\top @ {\\boldsymbol b}_6 \\\\ {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_5^\\top @ {\\boldsymbol b}_6 \\\\ {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_1 & {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_2 & {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_3 & {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_4 & {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_5 & {\\boldsymbol a}_6^\\top @ {\\boldsymbol b}_6 \\\\ \\end{bmatrix}\\end{align*}\\)\n\nA.T\n\ntensor([[1.9000, 0.0000],\n        [2.0000, 0.1000],\n        [2.5000, 1.0000],\n        [0.1000, 1.9000],\n        [0.2000, 2.1000],\n        [0.0000, 1.5000]])\n\n\n\nA.T@B\n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\na1.T@b1, a2.T@b2, a3.T@b1\n\n(array([[3.8]]), array([[3.82]]), array([[5.1]]))\n\n\n\nA.T@B \n\narray([[3.8 , 3.61, 3.42, 0.57, 0.38, 0.19],\n       [4.01, 3.82, 3.63, 0.81, 0.6 , 0.39],\n       [5.1 , 4.95, 4.8 , 2.85, 2.5 , 2.15],\n       [0.39, 0.57, 0.75, 4.02, 3.82, 3.62],\n       [0.61, 0.8 , 0.99, 4.47, 4.24, 4.01],\n       [0.15, 0.3 , 0.45, 3.15, 3.  , 2.85]])\n\n\n\ndf_view\n\n\n\n\n\n\n\n\n영식\n영철\n영호\n광수\n상철\n영수\n\n\n\n\n옥순\n3.9\n4.1\nNaN\n0.5\n0.3\nNaN\n\n\n영자\n4.5\nNaN\n3.7\n0.5\nNaN\n0.2\n\n\n정숙\nNaN\n4.9\n4.7\nNaN\n1.2\n1.3\n\n\n영숙\n0.6\n0.2\nNaN\n4.1\n4.3\nNaN\n\n\n순자\n0.7\n0.9\nNaN\n4.2\nNaN\n3.9\n\n\n현숙\nNaN\n0.2\n0.3\nNaN\n3.5\n3.4\n\n\n\n\n\n\n\n\ndf = pd.DataFrame([(f,m,df_view.loc[f,m]) for f in df_view.index for m in df_view.columns if not np.isnan(df_view.loc[f,m])])\ndf.columns = ['X1','X2','y']\ndf\n\n\n\n\n\n\n\n\nX1\nX2\ny\n\n\n\n\n0\n옥순\n영식\n3.9\n\n\n1\n옥순\n영철\n4.1\n\n\n2\n옥순\n광수\n0.5\n\n\n3\n옥순\n상철\n0.3\n\n\n4\n영자\n영식\n4.5\n\n\n5\n영자\n영호\n3.7\n\n\n6\n영자\n광수\n0.5\n\n\n7\n영자\n영수\n0.2\n\n\n8\n정숙\n영철\n4.9\n\n\n9\n정숙\n영호\n4.7\n\n\n10\n정숙\n상철\n1.2\n\n\n11\n정숙\n영수\n1.3\n\n\n12\n영숙\n영식\n0.6\n\n\n13\n영숙\n영철\n0.2\n\n\n14\n영숙\n광수\n4.1\n\n\n15\n영숙\n상철\n4.3\n\n\n16\n순자\n영식\n0.7\n\n\n17\n순자\n영철\n0.9\n\n\n18\n순자\n광수\n4.2\n\n\n19\n순자\n영수\n3.9\n\n\n20\n현숙\n영철\n0.2\n\n\n21\n현숙\n영호\n0.3\n\n\n22\n현숙\n상철\n3.5\n\n\n23\n현숙\n영수\n3.4\n\n\n\n\n\n\n\n\nmapp1 = {k[1]:k[0] for k in enumerate(df.X1.unique())}\nmapp2 = {k[1]:k[0] for k in enumerate(df.X2.unique())}\nmapp1,mapp2\n\n({'옥순': 0, '영자': 1, '정숙': 2, '영숙': 3, '순자': 4, '현숙': 5},\n {'영식': 0, '영철': 1, '광수': 2, '상철': 3, '영호': 4, '영수': 5})\n\n\n\nX1 = torch.tensor(list(map(lambda name: mapp1[name], df.X1)))\nX2 = torch.tensor(list(map(lambda name: mapp2[name], df.X2)))\nX1_onehot = torch.nn.functional.one_hot(X1).float()\nX2_onehot = torch.nn.functional.one_hot(X2).float()\ny = torch.tensor(df.y).float()\n\n\nX1,X2,y\n\n(tensor([0, 0, 0, 0, 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5]),\n tensor([0, 1, 2, 3, 0, 4, 2, 5, 1, 4, 3, 5, 0, 1, 2, 3, 0, 1, 2, 5, 1, 4, 3, 5]),\n tensor([3.9000, 4.1000, 0.5000, 0.3000, 4.5000, 3.7000, 0.5000, 0.2000, 4.9000,\n         4.7000, 1.2000, 1.3000, 0.6000, 0.2000, 4.1000, 4.3000, 0.7000, 0.9000,\n         4.2000, 3.9000, 0.2000, 0.3000, 3.5000, 3.4000]))\n\n\n\nX1_ebdd\n\ntensor([[1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [1., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.],\n        [0., 0., 0., 0., 0., 1.]])\n\n\n\ne1 = torch.nn.Embedding(6,2)\nl1 = torch.nn.Linear(in_features=6,out_features=2) \n\n\nebdd(X1),l1(X1_onehot)\n\n(tensor([[ 2.6026,  0.4667],\n         [ 2.6026,  0.4667],\n         [ 2.6026,  0.4667],\n         [ 2.6026,  0.4667],\n         [ 0.1359, -0.1735],\n         [ 0.1359, -0.1735],\n         [ 0.1359, -0.1735],\n         [ 0.1359, -0.1735],\n         [-1.0644, -0.2754],\n         [-1.0644, -0.2754],\n         [-1.0644, -0.2754],\n         [-1.0644, -0.2754],\n         [-1.0586,  0.3923],\n         [-1.0586,  0.3923],\n         [-1.0586,  0.3923],\n         [-1.0586,  0.3923],\n         [-0.4783, -1.7533],\n         [-0.4783, -1.7533],\n         [-0.4783, -1.7533],\n         [-0.4783, -1.7533],\n         [ 0.6503, -0.0975],\n         [ 0.6503, -0.0975],\n         [ 0.6503, -0.0975],\n         [ 0.6503, -0.0975]], grad_fn=&lt;EmbeddingBackward0&gt;),\n tensor([[-0.0844,  0.3446],\n         [-0.0844,  0.3446],\n         [-0.0844,  0.3446],\n         [-0.0844,  0.3446],\n         [-0.1052, -0.0718],\n         [-0.1052, -0.0718],\n         [-0.1052, -0.0718],\n         [-0.1052, -0.0718],\n         [-0.0119,  0.2076],\n         [-0.0119,  0.2076],\n         [-0.0119,  0.2076],\n         [-0.0119,  0.2076],\n         [-0.2060,  0.1455],\n         [-0.2060,  0.1455],\n         [-0.2060,  0.1455],\n         [-0.2060,  0.1455],\n         [-0.0590, -0.1849],\n         [-0.0590, -0.1849],\n         [-0.0590, -0.1849],\n         [-0.0590, -0.1849],\n         [ 0.0080,  0.1759],\n         [ 0.0080,  0.1759],\n         [ 0.0080,  0.1759],\n         [ 0.0080,  0.1759]], grad_fn=&lt;AddmmBackward0&gt;))\n\n\n\nli"
  }
]