{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 11wk-1: 추천시스템 (2) – Embedding 레이어, 사용자정의 네트워크,\n",
        "\n",
        "NN-based 추천시스템\n",
        "\n",
        "최규빈  \n",
        "2024-05-14\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/11wk-1.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "9afbc99d-5241-4422-8213-15ed5e3d3e7e"
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-xl7f2bcPTKMVCe3kHM380M&si=5SO7pni3fXX4kK-4 >}}"
      ],
      "id": "14dd1448-f6d9-4e15-a364-e0c5f4a69148"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. Imports"
      ],
      "id": "ff3267ed-582c-464b-8fb3-25ba00a3f30f"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "4dab14d4-fa0a-4be1-a9eb-3f25a4ed1150"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. `torch.nn.Embedding`\n",
        "\n",
        "## A. 임베딩레이어\n",
        "\n",
        "`-` 모티브: `torch.nn.functional.one_hot` + `torch.nn.Linear` 를 매번\n",
        "쓰는건 너무 귀찮지 않어?\n",
        "\n",
        "-   ${\\boldsymbol x}= \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\Longrightarrow {\\bf E}= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}$\n",
        "\n",
        "-   $\\text{linr}({\\bf E})= \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}$\n",
        "\n",
        "`-` `torch.nn.functional.one_hot` + `torch.nn.Linear` 를 함께처리해주는\n",
        "레이어 `torch.nn.Embedding` 존재\n",
        "\n",
        "-   $\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\end{bmatrix} = \\begin{bmatrix} -0.2002 \\\\ -0.4890 \\\\ 0.2081 \\\\ -0.2002 \\\\ -0.4890 \\end{bmatrix}$\n",
        "\n",
        "-   우리가 이전에 구현했던 코드 “onehot + linr” 와 “ebdd”는 정확하게\n",
        "    동일한 동작을 수행함.\n",
        "\n",
        "`-` 결론: 아래의 두개의 코드는 같다.\n",
        "\n",
        "``` python\n",
        "X = torch.tensor([0,1,2,0,1])\n",
        "\n",
        "## 코드1 \n",
        "linr = torch.nn.Linear(3,1) \n",
        "linr(torch.nn.functional.one_hot(X))\n",
        "\n",
        "## 코드2 \n",
        "ebdd = torch.nn.Embedding(3,1)\n",
        "ebdd(X) \n",
        "```\n",
        "\n",
        "`# 의문`: 그냥 원핫인코딩없이 바로 선형변환하면 안되나? (= 꼭\n",
        "임베딩레이어를 써야하나?)\n",
        "\n",
        "-   $\\text{linr}({\\bf X}) = \\begin{bmatrix} 0 \\\\ 1 \\\\ 2 \\\\ 0 \\\\ 1 \\end{bmatrix} \\times (-0.3467) + (-0.8470)=\\begin{bmatrix} -0.8470 \\\\ -1.1937 \\\\ -1.5404 \\\\ -0.8470 \\\\ -1.1937 \\end{bmatrix}$\n",
        "\n",
        "-   $\\text{ebdd}({\\boldsymbol x})= \\text{linr}\\big(\\text{onehot}({\\boldsymbol x})\\big) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 1 \\\\ 1 & 0 & 0 \\\\ 0 & 1 & 0 \\end{bmatrix}\\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\end{bmatrix} = \\begin{bmatrix} -0.8178 \\\\ -0.7052 \\\\ -0.5843 \\\\ -0.8178 \\\\ -0.7052 \\end{bmatrix}$\n",
        "\n",
        "`-` 데이터를 읽으며 해석: 사실상 0,1,2에 대한 의미는\n",
        "“옥순”,“영숙”,“하니” 같은 자료였고, 임베딩의 결과는\n",
        "“옥순”,“영숙”,“하니”가 가지는 어떠한 특징이었음 (예를들면 매력같은).\n",
        "데이터를 상상하며 위의 결과를 다시 해석해보자.\n",
        "\n",
        "**옥순이 가지는 어떠한 특징 (-0.8470 혹은 -0.8178) 을 바꾸고 싶다면?**\n",
        "\n",
        "-   `ebdd`의 경우: `ebdd.weigth`에 있는 -0.8178 이라는 숫자를 조정하면\n",
        "    된다. 이 조정은 옥순의 특징만 바꾸며 영숙과 하니의 특징은 바꾸지\n",
        "    않는다. (개별조정이 쉬움)\n",
        "-   `linr`의 경우: `linr.weight`에 있는 -0.3467 혹은 `linr.bias`에 있는\n",
        "    -0.8470 을 조정하면 되는데, 이를 조정하면 옥순의 특징을 바꿈과\n",
        "    동시에 영숙/하니의 특징까지 같이 바뀌게 된다. (개별조정이 어려움)\n",
        "\n",
        "**만약에 출연자가 1000명이라면??**\n",
        "\n",
        "-   `linr`의 경우: 1000명의 특징을 단 2개의 파라메터로 조정해야한다.\n",
        "    (그리고 한명의 특징을 바꾸면 999명의 특징이 같이 바뀐다, 개별조정은\n",
        "    애초에 가능하지 않음.)\n",
        "-   `ebdd`의 경우: 1000개의 특징을 조정할 수 있는 1000개의 파라메터를\n",
        "    확보할 수 있게 된다.\n",
        "\n",
        "`-` 결론: ebdd가 더 파라메터 미세조정을 통하여 특징을 학습하기 용이하다.\n",
        "(독립적으로 특징값을 줄 수 있으니까!)\n",
        "\n",
        "> 만약에 문자열이 “최우수(A)”, “우수(B)”, “보통(C)”, “미흡(D)”,\n",
        "> “매우미흡(F)” 이었다면 특징을 뽑아낼때 linr 가 더 적절했겠죠?\n",
        "\n",
        "## B. MF-based 추천시스템 재설계"
      ],
      "id": "cb557370-8daf-48e5-80f8-8504862e9930"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\n",
        "df_view"
      ],
      "id": "32312f78-6890-4878-b22c-372df4797dd7"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\n",
        "w = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n",
        "m = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\n",
        "X1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \n",
        "X2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \n",
        "y = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector"
      ],
      "id": "1a5017f3-f863-483a-a894-c63f960aa739"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 4. 사용자정의 네트워크\n",
        "\n",
        "## A. 사용자정의 네트워크 사용법\n",
        "\n",
        "`# 예비학습1`: net(x)와 사실 net.forward(x)는 같다.\n",
        "\n",
        "그래서 net.forward를 재정의하면 net(x)의 기능을 재정의 할 수 있다.\n",
        "\n",
        "`#`\n",
        "\n",
        "`# 예비학습2`: `torch.nn.Module`을 상속받아서 네트워크를 만들면 (=\n",
        "“`class XXX(torch.nn.Module):`” 와 같은 방식으로 클래스를 선언하면)\n",
        "약속된 아키텍처를 가진 네트워크를 찍어내는 함수를 만들 수 있다.\n",
        "\n",
        "(예시1)"
      ],
      "id": "07f8ec01-88b9-4eaf-8edb-7886e959b795"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Mynet1(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        self.a1 = torch.nn.Sigmoid()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n",
        "    def forward(self,x):\n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        return yhat"
      ],
      "id": "982c2476-cedc-4719-9564-81cfbcacb7d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제\n",
        "\n",
        "``` python\n",
        "net = Mynet1()\n",
        "```\n",
        "\n",
        "는 아래와 같은 효과를 가진다.\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n",
        "    torch.nn.Sigmoid(),\n",
        "    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n",
        ")\n",
        "```\n",
        "\n",
        "(예시2)"
      ],
      "id": "5a0be3c2-9d64-4882-9e8d-069f8d2d2dec"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Mynet2(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.l1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        self.a1 = torch.nn.ReLU()\n",
        "        self.l2 = torch.nn.Linear(in_features=1,out_features=1,bias=False)\n",
        "    def forward(self,x):\n",
        "        yhat = self.l2(self.a1(self.l1(x)))\n",
        "        return yhat"
      ],
      "id": "f7e575f5-5738-4dac-a2a8-1e1c9b63eab0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "이제\n",
        "\n",
        "``` python\n",
        "net = Mynet2()\n",
        "```\n",
        "\n",
        "는 아래와 같은 효과를 가진다.\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=1,bias=True),\n",
        "    torch.nn.RuLU(),\n",
        "    torch.nn.Linear(in_features=1,out_features=1,bias=False)\n",
        ")\n",
        "```\n",
        "\n",
        "***클래스에 대한 이해가 부족한 학생을 위한 암기방법***\n",
        "\n",
        "**step1:** 아래와 코드를 복사하여 틀을 만든다. (이건 무조건 고정임, XXXX\n",
        "자리는 원하는 이름을 넣는다)\n",
        "\n",
        "``` python\n",
        "class XXXX(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n",
        "        \n",
        "        ## 정의 끝\n",
        "    def forward(self,X):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        \n",
        "        ## 정의 끝\n",
        "        return yhat\n",
        "```\n",
        "\n",
        "-   net(X)에 사용하는 X임, yhat은 net.forward(X) 함수의 리턴값임\n",
        "-   사실, X/yhat은 다른 변수로 써도 무방하나 (예를들면 input/output\n",
        "    이라든지, netin/netout 이라든지) 설명의 편의상 X와 yhat을 고정한다.\n",
        "\n",
        "**step2:** `def __init__(self):`에 yhat을 구하기 위해 필요한 재료를\n",
        "레이어를 정의하고 이름을 붙인다. 이름은 항상 `self.xxx` 와 같은 식으로\n",
        "정의한다.\n",
        "\n",
        "``` python\n",
        "class XXXX(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n",
        "        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        self.xxx2 = torch.nn.Sigmoid()\n",
        "        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        ## 정의 끝\n",
        "    def forward(self,X):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        \n",
        "        ## 정의 끝\n",
        "        return yhat\n",
        "```\n",
        "\n",
        "**step3:** `def forward:`에 “X –\\> yhat” 으로 가는 과정을 묘사한 코드를\n",
        "작성하고 yhat을 리턴하도록 한다.\n",
        "\n",
        "``` python\n",
        "class XXXX(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        ## 우리가 yhat을 구할때 사용할 레이어를 정의 \n",
        "        self.xxx1 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        self.xxx2 = torch.nn.Sigmoid()\n",
        "        self.xxx3 = torch.nn.Linear(in_features=1,out_features=1,bias=True)\n",
        "        ## 정의 끝\n",
        "    def forward(self,X):\n",
        "        ## yhat을 어떻게 구할것인지 정의 \n",
        "        u = self.xxx1(X) \n",
        "        v = self.xxx2(u)\n",
        "        yhat = self.xxx3(v) \n",
        "        ## 정의 끝\n",
        "        return yhat\n",
        "```\n",
        "\n",
        "`#`\n",
        "\n",
        "`# 실습`: 사용자정의 네트워크를 사용하여 아래의 자료를 학습해보자."
      ],
      "id": "bebae7fc-4c3c-4c03-b382-c47fe101aea9"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(43052)\n",
        "x,_ = torch.randn(100).sort()\n",
        "x = x.reshape(-1,1)\n",
        "ϵ = torch.randn(100).reshape(-1,1)*0.5\n",
        "y = 2.5+ 4*x + ϵ"
      ],
      "id": "1c4cdc0a-f1b7-42c3-9035-f071ca50b756"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(풀이)\n",
        "\n",
        "`#`\n",
        "\n",
        "## B. MF-based 추천시스템 재설계\n",
        "\n",
        "아래의 자료를 활용하여 추천시스템을 설계하고자한다."
      ],
      "id": "b4836251-5116-44f9-a146-ac7f6a924f39"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\n",
        "df_view"
      ],
      "id": "23143b68-f0fb-4392-84c3-51c18749603e"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\n",
        "w = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n",
        "m = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\n",
        "X1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \n",
        "X2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \n",
        "y = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector"
      ],
      "id": "c8453f26-93a6-4b60-9ed5-73cdf85a01d1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "사용자정의 네트워크를 이용하여 MF-based 추천시스템을 설계하라.\n",
        "\n",
        "(풀이1) – `net(X1,X2)`\n",
        "\n",
        "(풀이2) – `net(X)`\n",
        "\n",
        "# 5. NN-based 추천시스템\n",
        "\n",
        "## A. NN-based 방식\n",
        "\n",
        "아래의 자료를 활용하여 추천시스템을 설계하고자한다."
      ],
      "id": "68c552d9-107a-4177-b40d-149cc6d6d557"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_view = pd.read_csv('https://raw.githubusercontent.com/guebin/DL2024/main/posts/solo.csv',index_col=0)\n",
        "df_view"
      ],
      "id": "1351ee6f-0b65-4f43-94d2-00afabfc4601"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "df_train = df_view.stack().reset_index().set_axis(['W','M','y'],axis=1)\n",
        "w = {'옥순(IN)':0, '영자(IN)':1, '정숙(IS)':2, '영숙(IS)':3, '순자(EN)':4, '현숙(EN)':5, '서연(ES)':6, '보람(ES)':7, '하니(I)':8}\n",
        "m = {'영식(IN)':0, '영철(IN)':1, '영호(IS)':2, '광수(IS)':3, '상철(EN)':4, '영수(EN)':5, '규빈(ES)':6, '다호(ES)':7}\n",
        "X1 = torch.tensor(df_train['W'].map(w)) # length-n int vector \n",
        "X2 = torch.tensor(df_train['M'].map(m)) # length-n int vector \n",
        "y = torch.tensor(df_train['y']).float().reshape(-1,1) # (n,1) float vector"
      ],
      "id": "2d522a56-bcf5-45f0-8c10-342e14a7002f"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**소망**: NN-based 모델로 만들어 보고싶다.\n",
        "\n",
        "(풀이1) – 실패\n",
        "\n",
        "(풀이2) – 에라 모르겠다 깊은신경망..\n",
        "\n",
        "(영자-다호), (보람-다호), (하니-영호) 를 예측해보자.\n",
        "\n",
        "## B. NCF (He et al. 2017)\n",
        "\n",
        "![](https://github.com/guebin/DL2024/blob/main/posts/NCF.png?raw=true)\n",
        "\n",
        "He, Xiangnan, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, and\n",
        "Tat-Seng Chua. 2017. “Neural Collaborative Filtering.” In *Proceedings\n",
        "of the 26th International Conference on World Wide Web*, 173–82."
      ],
      "id": "34da997a-47e9-4a30-8529-d5deec1a365b"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  }
}