{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13wk-1: 강화학습 (1) – bandit\n",
        "\n",
        "최규빈  \n",
        "2024-05-29\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "dfecd882-f443-4d66-a825-9a8af8320421"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp >}}"
      ],
      "id": "4685c071-46e9-4bcb-84a7-ece876eb4654"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. 환경셋팅 ($\\star\\star\\star$)\n",
        "\n",
        "`-` 설치 (코랩)\n",
        "\n",
        "``` python\n",
        "!pip install -q swig\n",
        "!pip install gymnasium\n",
        "!pip install gymnasium[box2d]\n",
        "```\n",
        "\n",
        "# 3. Imports"
      ],
      "id": "37e4b1eb-8252-4deb-9620-ab7891e29cd5"
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "da124c05-12c5-4e50-b7c2-c7156427cc82"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ref: <https://gymnasium.farama.org/index.html>\n",
        "\n",
        "# 4. 강화학습 Intro\n",
        "\n",
        "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
        "학습하는 과업\n",
        "\n",
        "`-` 딥마인드: breakout $\\to$ 알파고\n",
        "\n",
        "-   <https://www.youtube.com/watch?v=TmPfTpjtdgg>\n",
        "\n",
        "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?)\n",
        "\n",
        "# 5. Game1: `Bandit` 게임\n",
        "\n",
        "## A. 게임설명 및 원시코드\n",
        "\n",
        "`-` 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을\n",
        "누르면 100의 보상을 준다고 가정\n",
        "\n",
        "`-` 처음에 어떤 행동을 해야 하는가? —\\> ??? 처음에는 아는게 없음 —\\>\n",
        "일단 “아무거나” 눌러보자.\n",
        "\n",
        "`-` 버튼을 아무거나 누르는 함수를 구현해보자."
      ],
      "id": "1e30648d-a34a-48f6-a2e4-e9afc5990bf6"
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = ['button0', 'button1'] \n",
        "action = np.random.choice(action_space)\n",
        "action"
      ],
      "id": "cd4a7dbb-f420-479c-a420-4097bb2bad59"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 보상을 주는 함수를 구현해보자."
      ],
      "id": "2f24259b-be7c-4612-86c0-8af2af7178fc"
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "if action == 'button0': # button0을 눌렀다면 \n",
        "    reward = 1 \n",
        "else: # button1을 눌렀다면 \n",
        "    reward = 100 "
      ],
      "id": "61b66eff-ec7c-4884-9e55-0a61279495a8"
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "reward"
      ],
      "id": "d81e4baa-7bb5-4dfd-a786-488ac021a364"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자."
      ],
      "id": "11c9ccc4-d1bc-4dcb-bb17-6c3f24c81ab7"
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button0 1\n",
            "button0 1\n",
            "button1 100\n",
            "button0 1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = np.random.choice(action_space)\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else: \n",
        "        reward = 100     \n",
        "    print(action,reward) "
      ],
      "id": "d1e676d0-b3b8-427d-ace9-a887ff371c9e"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
        "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
        "상황이구나?\n",
        "\n",
        "-   여기에서 $\\to$의 과정을 체계화 시킨 학문이 강화학습"
      ],
      "id": "e5127d0e-09e6-41fb-847f-93fdd4707039"
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100\n",
            "button1 100"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    action = action_space[1]\n",
        "    if action == 'button0': \n",
        "        reward = 1 \n",
        "    else: \n",
        "        reward = 100     \n",
        "    print(action,reward) "
      ],
      "id": "84bb28cb-bae0-4364-b208-43f88a1e8690"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   게임 클리어\n",
        "\n",
        "`-` 강화학습: 환경을 이해 $\\to$ 행동을 결정\n",
        "\n",
        "***위의 과정이 잘 되었다는 의미로 사용하는 문장들***\n",
        "\n",
        "-   강화학습이 성공적으로 잘 되었다.\n",
        "-   에이전트가 환경의 과제를 완료했다.\n",
        "-   에이전트가 환경에서 성공적으로 학습했다.\n",
        "-   에이전트가 올바른 행동을 학습했다.\n",
        "-   게임 클리어 (비공식)\n",
        "\n",
        "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다.\n",
        "\n",
        "-   첫 생각: `button1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
        "-   두번째 생각: 아니지? 우연히 누를수도 있잖아?\n",
        "-   게임클리어조건: 최근 20번의 보상이 1900점 이상이면 게임이 클리어\n",
        "    되었다고 생각하자.[1]\n",
        "\n",
        "`-` 무지한자 – 게임을 클리어할 수 없다.\n",
        "\n",
        "[1] `button1`을 눌러야 하는건 맞지만 20번에 한번정도의 실수는 눈감아\n",
        "주는 조건"
      ],
      "id": "11695e48-a2a4-4228-814d-fad7d0ccd866"
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
            "n_try = 2   action= 0   reward= 1   reward20= 101   \n",
            "n_try = 3   action= 1   reward= 100 reward20= 201   \n",
            "n_try = 4   action= 0   reward= 1   reward20= 202   \n",
            "n_try = 5   action= 1   reward= 100 reward20= 302   \n",
            "n_try = 6   action= 1   reward= 100 reward20= 402   \n",
            "n_try = 7   action= 1   reward= 100 reward20= 502   \n",
            "n_try = 8   action= 1   reward= 100 reward20= 602   \n",
            "n_try = 9   action= 1   reward= 100 reward20= 702   \n",
            "n_try = 10  action= 1   reward= 100 reward20= 802   \n",
            "n_try = 11  action= 1   reward= 100 reward20= 902   \n",
            "n_try = 12  action= 1   reward= 100 reward20= 1002  \n",
            "n_try = 13  action= 0   reward= 1   reward20= 1003  \n",
            "n_try = 14  action= 0   reward= 1   reward20= 1004  \n",
            "n_try = 15  action= 0   reward= 1   reward20= 1005  \n",
            "n_try = 16  action= 1   reward= 100 reward20= 1105  \n",
            "n_try = 17  action= 1   reward= 100 reward20= 1205  \n",
            "n_try = 18  action= 0   reward= 1   reward20= 1206  \n",
            "n_try = 19  action= 0   reward= 1   reward20= 1207  \n",
            "n_try = 20  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 21  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 22  action= 0   reward= 1   reward20= 1307  \n",
            "n_try = 23  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 24  action= 0   reward= 1   reward20= 1307  \n",
            "n_try = 25  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 26  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 27  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 28  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 29  action= 1   reward= 100 reward20= 1109  \n",
            "n_try = 30  action= 1   reward= 100 reward20= 1109  \n",
            "n_try = 31  action= 0   reward= 1   reward20= 1010  \n",
            "n_try = 32  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 33  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 34  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 35  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 36  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 37  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 38  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 39  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 40  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 41  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 42  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 43  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 44  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 45  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 46  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 47  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 48  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 49  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 50  action= 0   reward= 1   reward20= 812   "
          ]
        }
      ],
      "source": [
        "action_space = [0,1]\n",
        "rewards = [] \n",
        "for t in range(50): # 10000번을 해도 못깸 \n",
        "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else: \n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {action}\\t\"\n",
        "        f\"reward= {reward}\\t\"\n",
        "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "88406414-89f3-44bc-bdd7-bc1b43788f74"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 깨달은자 – 게임클리어"
      ],
      "id": "ab14e8cf-06d7-4fcb-8490-b2f8c13cc706"
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
            "n_try = 2   action= 1   reward= 100 reward20= 200   \n",
            "n_try = 3   action= 1   reward= 100 reward20= 300   \n",
            "n_try = 4   action= 1   reward= 100 reward20= 400   \n",
            "n_try = 5   action= 1   reward= 100 reward20= 500   \n",
            "n_try = 6   action= 1   reward= 100 reward20= 600   \n",
            "n_try = 7   action= 1   reward= 100 reward20= 700   \n",
            "n_try = 8   action= 1   reward= 100 reward20= 800   \n",
            "n_try = 9   action= 1   reward= 100 reward20= 900   \n",
            "n_try = 10  action= 1   reward= 100 reward20= 1000  \n",
            "n_try = 11  action= 1   reward= 100 reward20= 1100  \n",
            "n_try = 12  action= 1   reward= 100 reward20= 1200  \n",
            "n_try = 13  action= 1   reward= 100 reward20= 1300  \n",
            "n_try = 14  action= 1   reward= 100 reward20= 1400  \n",
            "n_try = 15  action= 1   reward= 100 reward20= 1500  \n",
            "n_try = 16  action= 1   reward= 100 reward20= 1600  \n",
            "n_try = 17  action= 1   reward= 100 reward20= 1700  \n",
            "n_try = 18  action= 1   reward= 100 reward20= 1800  \n",
            "n_try = 19  action= 1   reward= 100 reward20= 1900  "
          ]
        }
      ],
      "source": [
        "action_space = [0,1]\n",
        "rewards = [] \n",
        "for t in range(50): # 10000번을 해도 못깸 \n",
        "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
        "    action = 1\n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else: \n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {action}\\t\"\n",
        "        f\"reward= {reward}\\t\"\n",
        "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "a2f7b8d7-ba44-4bc7-987d-bd2660890203"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## B. 수정1: `action_space`의 수정"
      ],
      "id": "4ef0719f-9f15-435e-928e-963c9c63dad7"
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action_space = gym.spaces.Discrete(2)\n",
        "action_space"
      ],
      "id": "ef224ee2-c37f-46cc-aeac-3ba69e84e798"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 좋은점1: sample"
      ],
      "id": "fc3cd2f5-ce84-4d2e-97c5-810e875e0214"
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "1\n",
            "1"
          ]
        }
      ],
      "source": [
        "for _ in range(10):\n",
        "    print(action_space.sample())"
      ],
      "id": "38ffbc03-4b50-4064-8e3c-07f2728afed4"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 좋은점2: in"
      ],
      "id": "76f00a34-0d2b-4554-ac7c-dd21489ff5ac"
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "0 in action_space # 유효한 액션을 검사 -- 0은 유효한 액션"
      ],
      "id": "8b0b6d5c-7ceb-48d0-8d30-e83cadbd9d19"
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "1 in action_space # 유효한 액션을 검사 -- 1은 유효한 액션 "
      ],
      "id": "6921440d-1559-4820-9e09-e0804f961ca2"
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "2 in action_space # 유효한 액션을 검사 -- 2는 유효하지 않은 액션 "
      ],
      "id": "ce09141e-9a78-4946-8020-09340e26d8f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 코드 1차수정"
      ],
      "id": "b036e9c2-a82d-416d-993d-97475dec4aed"
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 0   reward= 1   reward20= 1 \n",
            "n_try = 2   action= 1   reward= 100 reward20= 101   \n",
            "n_try = 3   action= 0   reward= 1   reward20= 102   \n",
            "n_try = 4   action= 0   reward= 1   reward20= 103   \n",
            "n_try = 5   action= 0   reward= 1   reward20= 104   \n",
            "n_try = 6   action= 1   reward= 100 reward20= 204   \n",
            "n_try = 7   action= 1   reward= 100 reward20= 304   \n",
            "n_try = 8   action= 0   reward= 1   reward20= 305   \n",
            "n_try = 9   action= 0   reward= 1   reward20= 306   \n",
            "n_try = 10  action= 1   reward= 100 reward20= 406   \n",
            "n_try = 11  action= 1   reward= 100 reward20= 506   \n",
            "n_try = 12  action= 1   reward= 100 reward20= 606   \n",
            "n_try = 13  action= 1   reward= 100 reward20= 706   \n",
            "n_try = 14  action= 1   reward= 100 reward20= 806   \n",
            "n_try = 15  action= 0   reward= 1   reward20= 807   \n",
            "n_try = 16  action= 1   reward= 100 reward20= 907   \n",
            "n_try = 17  action= 0   reward= 1   reward20= 908   \n",
            "n_try = 18  action= 1   reward= 100 reward20= 1008  \n",
            "n_try = 19  action= 1   reward= 100 reward20= 1108  \n",
            "n_try = 20  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 21  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 22  action= 1   reward= 100 reward20= 1109  \n",
            "n_try = 23  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 24  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 25  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 26  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 27  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 28  action= 1   reward= 100 reward20= 1307  \n",
            "n_try = 29  action= 0   reward= 1   reward20= 1307  \n",
            "n_try = 30  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 31  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 32  action= 1   reward= 100 reward20= 1109  \n",
            "n_try = 33  action= 0   reward= 1   reward20= 1010  \n",
            "n_try = 34  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 35  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 36  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 37  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 38  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 39  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 40  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 41  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 42  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 43  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 44  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 45  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 46  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 47  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 48  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 49  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 50  action= 0   reward= 1   reward20= 911   "
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(2) \n",
        "rewards = [] \n",
        "for t in range(50): \n",
        "    action = action_space.sample()\n",
        "    #action = 1\n",
        "    if action == 0: \n",
        "        reward = 1 \n",
        "        rewards.append(reward)\n",
        "    else: \n",
        "        reward = 100\n",
        "        rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {action}\\t\"\n",
        "        f\"reward= {reward}\\t\"\n",
        "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "46b2ed36-1c39-40f6-9d71-47e7d6ef191d"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## C. 수정2: `Env` 클래스구현\n",
        "\n",
        "`-` env 클래스 선언"
      ],
      "id": "eb399e50-f43a-4e4a-92de-1a4c18fc5e98"
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Bandit: \n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            return 1 \n",
        "        else: \n",
        "            return 100 "
      ],
      "id": "c6091a16-b766-4546-aa94-877ed2653c52"
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
            "n_try = 2   action= 1   reward= 100 reward20= 200   \n",
            "n_try = 3   action= 1   reward= 100 reward20= 300   \n",
            "n_try = 4   action= 1   reward= 100 reward20= 400   \n",
            "n_try = 5   action= 1   reward= 100 reward20= 500   \n",
            "n_try = 6   action= 1   reward= 100 reward20= 600   \n",
            "n_try = 7   action= 1   reward= 100 reward20= 700   \n",
            "n_try = 8   action= 1   reward= 100 reward20= 800   \n",
            "n_try = 9   action= 1   reward= 100 reward20= 900   \n",
            "n_try = 10  action= 1   reward= 100 reward20= 1000  \n",
            "n_try = 11  action= 1   reward= 100 reward20= 1100  \n",
            "n_try = 12  action= 1   reward= 100 reward20= 1200  \n",
            "n_try = 13  action= 1   reward= 100 reward20= 1300  \n",
            "n_try = 14  action= 1   reward= 100 reward20= 1400  \n",
            "n_try = 15  action= 1   reward= 100 reward20= 1500  \n",
            "n_try = 16  action= 1   reward= 100 reward20= 1600  \n",
            "n_try = 17  action= 1   reward= 100 reward20= 1700  \n",
            "n_try = 18  action= 1   reward= 100 reward20= 1800  \n",
            "n_try = 19  action= 1   reward= 100 reward20= 1900  "
          ]
        }
      ],
      "source": [
        "action_space = gym.spaces.Discrete(2) \n",
        "env = Bandit()\n",
        "rewards = []\n",
        "for t in range(50): \n",
        "    #action = action_space.sample()\n",
        "    action = 1\n",
        "    reward = env.step(action)\n",
        "    rewards.append(reward)\n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {action}\\t\"\n",
        "        f\"reward= {reward}\\t\"\n",
        "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
        "    )\n",
        "    if np.sum(rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "28fb2c07-c995-4270-8f44-352b16fa9ca0"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## D. 수정3: `Agent` 클래스 구현 (랜덤행동)\n",
        "\n",
        "`-` Agent 클래스를 만들자. (액션을 하고, 환경에서 받은 reward를 간직)"
      ],
      "id": "7888e92e-55b6-48e5-a252-4588c72a5b7b"
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2) \n",
        "        self.action = None \n",
        "        self.reward = None \n",
        "        self.actions = [] \n",
        "        self.rewards = []\n",
        "    def act(self):\n",
        "        self.action = self.action_space.sample() # 무지한자 \n",
        "        #self.action = 1 # 깨달은 자\n",
        "    def save_experience(self):\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)"
      ],
      "id": "0e5d87ae-8fe3-417d-848a-f49786c2b2ed"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "— 대충 아래와 같은 느낌으로 코드가 돌아가요 —\n",
        "\n",
        "**시점0**: init"
      ],
      "id": "27b3be70-cf51-42b0-b1d0-14e07f08ec07"
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "env = Bandit()\n",
        "agent = Agent() "
      ],
      "id": "6ee01a47-2ecc-41c9-9344-419f06f89d09"
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "43397ed8-1846-4db8-85e5-feab67bb12f1"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점1**: agent \\>\\> env"
      ],
      "id": "ff9578ab-3c97-4693-acf0-fa753b523cee"
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.act()"
      ],
      "id": "94b910e3-9d0d-4e32-bfe4-1ea5bc7a537b"
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.action, agent.reward"
      ],
      "id": "88ca0c67-6c67-461b-adad-5781c23e366a"
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "env.agent_action = agent.action"
      ],
      "id": "390746fe-70f2-42ff-97e7-02872bf725fe"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**시점2**: agent \\<\\< env"
      ],
      "id": "e846a8d7-ebe5-43a5-ac9d-ed336f859020"
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.reward = env.step(env.agent_action)"
      ],
      "id": "0c06f08a-96f0-454f-bb0e-76f3b80650a0"
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.action, agent.reward, env.agent_action"
      ],
      "id": "92121832-fc74-40ca-885b-1b7ebbc0b2ef"
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.actions,agent.rewards"
      ],
      "id": "5de5658f-352b-4080-a452-c7b9ceb32181"
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.save_experience()"
      ],
      "id": "5e3ea513-38ff-42a0-b298-c2b17347e30c"
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.actions,agent.rewards"
      ],
      "id": "89f2ead3-14ff-4db7-91b7-e7444900a2ae"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "– 전체코드 –"
      ],
      "id": "6e718508-00bc-46c8-88d9-8b995199fee3"
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 1   reward= 100 reward20= 100   \n",
            "n_try = 2   action= 0   reward= 1   reward20= 101   \n",
            "n_try = 3   action= 1   reward= 100 reward20= 201   \n",
            "n_try = 4   action= 0   reward= 1   reward20= 202   \n",
            "n_try = 5   action= 1   reward= 100 reward20= 302   \n",
            "n_try = 6   action= 0   reward= 1   reward20= 303   \n",
            "n_try = 7   action= 0   reward= 1   reward20= 304   \n",
            "n_try = 8   action= 1   reward= 100 reward20= 404   \n",
            "n_try = 9   action= 1   reward= 100 reward20= 504   \n",
            "n_try = 10  action= 1   reward= 100 reward20= 604   \n",
            "n_try = 11  action= 1   reward= 100 reward20= 704   \n",
            "n_try = 12  action= 1   reward= 100 reward20= 804   \n",
            "n_try = 13  action= 0   reward= 1   reward20= 805   \n",
            "n_try = 14  action= 0   reward= 1   reward20= 806   \n",
            "n_try = 15  action= 1   reward= 100 reward20= 906   \n",
            "n_try = 16  action= 1   reward= 100 reward20= 1006  \n",
            "n_try = 17  action= 0   reward= 1   reward20= 1007  \n",
            "n_try = 18  action= 0   reward= 1   reward20= 1008  \n",
            "n_try = 19  action= 1   reward= 100 reward20= 1108  \n",
            "n_try = 20  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 21  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 22  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 23  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 24  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 25  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 26  action= 1   reward= 100 reward20= 1208  \n",
            "n_try = 27  action= 0   reward= 1   reward20= 1208  \n",
            "n_try = 28  action= 0   reward= 1   reward20= 1109  \n",
            "n_try = 29  action= 1   reward= 100 reward20= 1109  \n",
            "n_try = 30  action= 0   reward= 1   reward20= 1010  \n",
            "n_try = 31  action= 1   reward= 100 reward20= 1010  \n",
            "n_try = 32  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 33  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 34  action= 0   reward= 1   reward20= 911   \n",
            "n_try = 35  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 36  action= 0   reward= 1   reward20= 713   \n",
            "n_try = 37  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 38  action= 1   reward= 100 reward20= 911   \n",
            "n_try = 39  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 40  action= 0   reward= 1   reward20= 713   \n",
            "n_try = 41  action= 0   reward= 1   reward20= 713   \n",
            "n_try = 42  action= 1   reward= 100 reward20= 713   \n",
            "n_try = 43  action= 1   reward= 100 reward20= 713   \n",
            "n_try = 44  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 45  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 46  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 47  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 48  action= 0   reward= 1   reward20= 812   \n",
            "n_try = 49  action= 1   reward= 100 reward20= 812   \n",
            "n_try = 50  action= 0   reward= 1   reward20= 812   "
          ]
        }
      ],
      "source": [
        "env = Bandit() \n",
        "agent = Agent()\n",
        "for t in range(50): \n",
        "    ## 1. main 코드 \n",
        "    # step1: agent >> env \n",
        "    agent.act() \n",
        "    env.agent_action = agent.action\n",
        "    # step2: agent << env \n",
        "    agent.reward = env.step(env.agent_action)\n",
        "    agent.save_experience() \n",
        "\n",
        "    ## 2. 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {agent.action}\\t\"\n",
        "        f\"reward= {agent.reward}\\t\"\n",
        "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "94d5f2d2-b38f-472c-97b1-a64c58f68455"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## E. 수정4: `Agent.learn()` 구현\n",
        "\n",
        "`-` Game1에 대한 생각:\n",
        "\n",
        "-   사실 강화학습은 “환경을 이해 $\\to$ 행동을 결정” 의 과정에서 $\\to$의\n",
        "    과정을 수식화 한 것이다.\n",
        "-   그런데 지금까지 했던 코드는 환경(env)를 이해하는 순간 에이전트가\n",
        "    최적의 행동(action)[1]을 직관적으로 결정하였으므로 기계가 스스로\n",
        "    학습을 했다고 볼 수 없다.\n",
        "\n",
        "`-` 지금까지의 코드 복습\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   Env 클래스의 선언\n",
        "    -   Agent 클래스의 선언\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하여 게임을 진행\n",
        "    -   메인코드: (1) agent $\\to$ env (2) agent $\\leftarrow$ env\n",
        "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
        "\n",
        "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
        "`button1`을 눌러야 한다는 생각을 했으면 좋겠음.\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   Env 클래스의 선언\n",
        "    -   **Agent 클래스의 선언** // \\<—- `학습의 과정이 포함되어야 한다`,\n",
        "        `act함수의 수정`, `learn함수의 추가`\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하여 게임을 진행\n",
        "    -   **메인코드** (1) agent $\\to$ env (2) agent $\\leftarrow$ env //\n",
        "        \\<—- `agent가 데이터를 분석하고 학습하는 과정이 추가`\n",
        "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
        "\n",
        "`-` 에이전트가 학습을 어떻게 하는가? 아래와 같이 버튼을 누르도록 한다면\n",
        "\n",
        "-   버튼0을 누를 확률: $\\frac{q_0}{q_0+q_1}$\n",
        "-   버튼1을 누를 확률: $\\frac{q_1}{q_0+q_1}$\n",
        "\n",
        "시간이 지날수록 버튼1을 주로 누를 것이다.\n",
        "\n",
        "`-` 걱정: $t=0$ 이면 어쩌지? $t=1$이면 어쩌지?… $\\to$ 해결책:\n",
        "일정시간동안 랜덤액션을 하면서 데이터를 쌓고 그 뒤에 $q_0,q_1$을 계산\n",
        "\n",
        "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n",
        "\n",
        "[1] `button1`을 누른다"
      ],
      "id": "302408d9-6d8a-407f-bd3b-e62923ae897c"
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.actions = [0,1,1,0,1,0,0] \n",
        "agent.rewards = [1,101,102,1,99,1,1.2] \n",
        "actions = np.array(agent.actions)\n",
        "rewards = np.array(agent.rewards)"
      ],
      "id": "f725954b-d1fa-47e9-ab79-46ec3a53eef2"
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "q0 = rewards[actions == 0].mean()\n",
        "q1 = rewards[actions == 1].mean()"
      ],
      "id": "2ca4712f-f522-431c-b71d-816820b5f6b2"
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "agent.q = np.array([q0,q1]) \n",
        "agent.q"
      ],
      "id": "0f400b80-ff55-4b0c-bb7c-6bf4eded24f6"
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "prob = agent.q / agent.q.sum()\n",
        "prob "
      ],
      "id": "3d52e620-b8ed-42de-a1a1-7d5961ccbccb"
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "action = np.random.choice([0,1], p= agent.q / agent.q.sum())\n",
        "action"
      ],
      "id": "3ef3f7fe-29a4-473b-bfac-3bb00c45b045"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 최종코드정리"
      ],
      "id": "2f5be442-f480-43cb-a407-b4d8ac872edd"
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "class Bandit: \n",
        "    def step(self, action):\n",
        "        if action == 0:\n",
        "            return 1 \n",
        "        else: \n",
        "            return 100 \n",
        "class Agent:\n",
        "    def __init__(self):\n",
        "        self.action_space = gym.spaces.Discrete(2) \n",
        "        self.action = None \n",
        "        self.reward = None \n",
        "        self.actions = [] \n",
        "        self.rewards = []\n",
        "        self.q = np.array([0,0]) \n",
        "        self.n_experience = 0 \n",
        "    def act(self):\n",
        "        if self.n_experience<30: \n",
        "            self.action = self.action_space.sample() \n",
        "        else: \n",
        "            self.action = np.random.choice([0,1], p= self.q / self.q.sum())\n",
        "    def save_experience(self):\n",
        "        self.actions.append(self.action)\n",
        "        self.rewards.append(self.reward)\n",
        "        self.n_experience += 1 \n",
        "    def learn(self):\n",
        "        if self.n_experience<30: \n",
        "            pass \n",
        "        else: \n",
        "            actions = np.array(self.actions)\n",
        "            rewards = np.array(self.rewards)\n",
        "            q0 = rewards[actions == 0].mean()\n",
        "            q1 = rewards[actions == 1].mean()\n",
        "            self.q = np.array([q0,q1]) "
      ],
      "id": "a218caa5-b032-4e57-ab22-cca6b2c8ab02"
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "n_try = 1   action= 0   reward= 1   reward20= 1 q = [0 0]\n",
            "n_try = 2   action= 0   reward= 1   reward20= 2 q = [0 0]\n",
            "n_try = 3   action= 1   reward= 100 reward20= 102   q = [0 0]\n",
            "n_try = 4   action= 0   reward= 1   reward20= 103   q = [0 0]\n",
            "n_try = 5   action= 1   reward= 100 reward20= 203   q = [0 0]\n",
            "n_try = 6   action= 1   reward= 100 reward20= 303   q = [0 0]\n",
            "n_try = 7   action= 0   reward= 1   reward20= 304   q = [0 0]\n",
            "n_try = 8   action= 0   reward= 1   reward20= 305   q = [0 0]\n",
            "n_try = 9   action= 0   reward= 1   reward20= 306   q = [0 0]\n",
            "n_try = 10  action= 0   reward= 1   reward20= 307   q = [0 0]\n",
            "n_try = 11  action= 0   reward= 1   reward20= 308   q = [0 0]\n",
            "n_try = 12  action= 1   reward= 100 reward20= 408   q = [0 0]\n",
            "n_try = 13  action= 1   reward= 100 reward20= 508   q = [0 0]\n",
            "n_try = 14  action= 0   reward= 1   reward20= 509   q = [0 0]\n",
            "n_try = 15  action= 1   reward= 100 reward20= 609   q = [0 0]\n",
            "n_try = 16  action= 1   reward= 100 reward20= 709   q = [0 0]\n",
            "n_try = 17  action= 1   reward= 100 reward20= 809   q = [0 0]\n",
            "n_try = 18  action= 0   reward= 1   reward20= 810   q = [0 0]\n",
            "n_try = 19  action= 0   reward= 1   reward20= 811   q = [0 0]\n",
            "n_try = 20  action= 0   reward= 1   reward20= 812   q = [0 0]\n",
            "n_try = 21  action= 0   reward= 1   reward20= 812   q = [0 0]\n",
            "n_try = 22  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
            "n_try = 23  action= 0   reward= 1   reward20= 812   q = [0 0]\n",
            "n_try = 24  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
            "n_try = 25  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
            "n_try = 26  action= 1   reward= 100 reward20= 911   q = [0 0]\n",
            "n_try = 27  action= 1   reward= 100 reward20= 1010  q = [0 0]\n",
            "n_try = 28  action= 0   reward= 1   reward20= 1010  q = [0 0]\n",
            "n_try = 29  action= 1   reward= 100 reward20= 1109  q = [0 0]\n",
            "n_try = 30  action= 0   reward= 1   reward20= 1109  q = [  1. 100.]\n",
            "n_try = 31  action= 1   reward= 100 reward20= 1208  q = [  1. 100.]\n",
            "n_try = 32  action= 1   reward= 100 reward20= 1208  q = [  1. 100.]\n",
            "n_try = 33  action= 1   reward= 100 reward20= 1208  q = [  1. 100.]\n",
            "n_try = 34  action= 1   reward= 100 reward20= 1307  q = [  1. 100.]\n",
            "n_try = 35  action= 1   reward= 100 reward20= 1307  q = [  1. 100.]\n",
            "n_try = 36  action= 1   reward= 100 reward20= 1307  q = [  1. 100.]\n",
            "n_try = 37  action= 1   reward= 100 reward20= 1307  q = [  1. 100.]\n",
            "n_try = 38  action= 1   reward= 100 reward20= 1406  q = [  1. 100.]\n",
            "n_try = 39  action= 1   reward= 100 reward20= 1505  q = [  1. 100.]\n",
            "n_try = 40  action= 1   reward= 100 reward20= 1604  q = [  1. 100.]\n",
            "n_try = 41  action= 1   reward= 100 reward20= 1703  q = [  1. 100.]\n",
            "n_try = 42  action= 1   reward= 100 reward20= 1703  q = [  1. 100.]\n",
            "n_try = 43  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
            "n_try = 44  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
            "n_try = 45  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
            "n_try = 46  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
            "n_try = 47  action= 1   reward= 100 reward20= 1802  q = [  1. 100.]\n",
            "n_try = 48  action= 1   reward= 100 reward20= 1901  q = [  1. 100.]"
          ]
        }
      ],
      "source": [
        "env = Bandit() \n",
        "agent = Agent()\n",
        "for t in range(50): \n",
        "    ## 1. main 코드 \n",
        "    # step1: agent >> env \n",
        "    agent.act() \n",
        "    env.agent_action = agent.action\n",
        "    # step2: agent << env \n",
        "    agent.reward = env.step(env.agent_action)\n",
        "    agent.save_experience() \n",
        "    # step3: learn \n",
        "    agent.learn()\n",
        "    ## 2. 비본질적 코드 \n",
        "    print(\n",
        "        f\"n_try = {t+1}\\t\"\n",
        "        f\"action= {agent.action}\\t\"\n",
        "        f\"reward= {agent.reward}\\t\"\n",
        "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
        "        f\"q = {agent.q}\"\n",
        "    )\n",
        "    if np.sum(agent.rewards[-20:])>=1900:\n",
        "        break "
      ],
      "id": "23269b00-b8b6-4e57-89b2-963594874899"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  }
}