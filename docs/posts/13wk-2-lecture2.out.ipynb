{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 13wk-1: 강화학습 (1) – bandit\n",
        "\n",
        "최규빈  \n",
        "2024-05-29\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>\n",
        "\n",
        "# 1. 강의영상"
      ],
      "id": "91f74fa6-34e5-43e1-a1a8-1e72adb00b6e"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp >}}"
      ],
      "id": "4685c071-46e9-4bcb-84a7-ece876eb4654"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2. 환경셋팅 ($\\star\\star\\star$)\n",
        "\n",
        "`-` 설치 (코랩)\n",
        "\n",
        "``` python\n",
        "!pip install -q swig\n",
        "!pip install gymnasium\n",
        "!pip install gymnasium[box2d]\n",
        "```\n",
        "\n",
        "# 3. Imports"
      ],
      "id": "87df86c2-f52f-46c5-b9ab-780afd146b83"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "tags": []
      },
      "outputs": [],
      "source": [
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "id": "da124c05-12c5-4e50-b7c2-c7156427cc82"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   ref: <https://gymnasium.farama.org/index.html>\n",
        "\n",
        "# 4. 강화학습 Intro\n",
        "\n",
        "`-` 강화학습(대충설명): 어떠한 “(게임)환경”이 있을때 거기서 “뭘 할지”를\n",
        "학습하는 과업\n",
        "\n",
        "`-` 딥마인드: breakout $\\to$ 알파고\n",
        "\n",
        "-   <https://www.youtube.com/watch?v=TmPfTpjtdgg>\n",
        "\n",
        "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?)\n",
        "\n",
        "# 5. Game1: `Bandit` 게임\n",
        "\n",
        "## A. 게임설명 및 원시코드\n",
        "\n",
        "`-` 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을\n",
        "누르면 100의 보상을 준다고 가정\n",
        "\n",
        "`-` 처음에 어떤 행동을 해야 하는가? —\\> ??? 처음에는 아는게 없음 —\\>\n",
        "일단 “아무거나” 눌러보자.\n",
        "\n",
        "`-` 버튼을 아무거나 누르는 함수를 구현해보자."
      ],
      "id": "49fd6f51-cfb8-4613-9694-1af00c462380"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "action_space = ['b0','b1']\n",
        "action = np.random.choice(action_space)\n",
        "action"
      ],
      "id": "55124f7a-19ec-4a7b-87c4-1d02b2b3d9df"
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "`-` 보상을 주는 함수를 구현해보자.\n",
        "\n",
        "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자.\n",
        "\n",
        "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을\n",
        "받는 “환경”이구나? $\\to$ `button1`을 누르는 “동작”을 해야하는\n",
        "상황이구나?\n",
        "\n",
        "-   여기에서 “$\\to$”의 과정을 체계화 시킨 학문이 강화학습\n",
        "\n",
        "-   게임 클리어\n",
        "\n",
        "`-` 강화학습: 환경을 이해 $\\to$ 행동을 결정\n",
        "\n",
        "***위의 과정이 잘 되었다는 의미로 사용하는 문장들***\n",
        "\n",
        "-   강화학습이 성공적으로 잘 되었다.\n",
        "-   에이전트가 환경의 과제를 완료했다.\n",
        "-   에이전트가 환경에서 성공적으로 학습했다.\n",
        "-   에이전트가 올바른 행동을 학습했다.\n",
        "-   게임 클리어 (비공식)\n",
        "\n",
        "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다.\n",
        "\n",
        "-   첫 생각: `button1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
        "-   두번째 생각: 아니지? 우연히 누를수도 있잖아?\n",
        "-   게임클리어조건: 최근 20번의 보상이 1900점 이상이면 게임이 클리어\n",
        "    되었다고 생각하자.[1]\n",
        "\n",
        "`-` 무지한자 – 게임을 클리어할 수 없다.\n",
        "\n",
        "`-` 깨달은자 – 게임클리어\n",
        "\n",
        "## B. 수정1: `action_space` 수정\n",
        "\n",
        "`-` 좋은점1: sample\n",
        "\n",
        "`-` 좋은점2: in\n",
        "\n",
        "`-` 코드 1차수정\n",
        "\n",
        "## C. 수정2: `Env` 구현\n",
        "\n",
        "`-` env 클래스 선언\n",
        "\n",
        "## D. 수정3: `Agent` 구현 (인간지능)\n",
        "\n",
        "`-` Agent 클래스를 만들자. (액션을 하고, 환경에서 받은 reward를 간직)\n",
        "\n",
        "— 대충 아래와 같은 느낌으로 코드가 돌아가요 —\n",
        "\n",
        "**시점0**: init\n",
        "\n",
        "**시점1**: agent \\>\\> env\n",
        "\n",
        "**시점2**: agent \\<\\< env\n",
        "\n",
        "– 전체코드 –\n",
        "\n",
        "## E. 수정4: `Agent` 구현 (인공지능)\n",
        "\n",
        "`-` Game1에 대한 생각:\n",
        "\n",
        "-   사실 강화학습은 “환경을 이해 $\\to$ 행동을 결정” 의 과정에서 $\\to$의\n",
        "    과정을 수식화 한 것이다.\n",
        "-   그런데 지금까지 했던 코드는 환경(env)를 이해하는 순간 에이전트가\n",
        "    최적의 행동(action)[2]을 직관적으로 결정하였으므로 기계가 스스로\n",
        "    학습을 했다고 볼 수 없다.\n",
        "\n",
        "`-` 지금까지의 코드 복습\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   Env 클래스의 선언\n",
        "    -   Agent 클래스의 선언\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하여 게임을 진행\n",
        "    -   메인코드: (1) agent $\\to$ env (2) agent $\\leftarrow$ env\n",
        "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
        "\n",
        "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로\n",
        "`button1`을 눌러야 한다는 생각을 했으면 좋겠음.\n",
        "\n",
        "1.  클래스를 선언하는 부분\n",
        "    -   Env 클래스의 선언\n",
        "    -   **Agent 클래스의 선언** // \\<—- `학습의 과정이 포함되어야 한다`,\n",
        "        `act함수의 수정`, `learn함수의 추가`\n",
        "2.  환경과 에이전트를 인스턴스화 (초기화)\n",
        "3.  for loop를 반복하여 게임을 진행\n",
        "    -   **메인코드** (1) agent $\\to$ env (2) agent $\\leftarrow$ env //\n",
        "        \\<—- `agent가 데이터를 분석하고 학습하는 과정이 추가`\n",
        "    -   비본질적코드: 학습과정을 display, 학습의 종료조건체크\n",
        "\n",
        "`-` 에이전트가 학습을 어떻게 하는가? 아래와 같이 버튼을 누르도록 한다면\n",
        "\n",
        "-   버튼0을 누를 확률: $\\frac{q_0}{q_0+q_1}$\n",
        "-   버튼1을 누를 확률: $\\frac{q_1}{q_0+q_1}$\n",
        "\n",
        "시간이 지날수록 버튼1을 주로 누를 것이다.\n",
        "\n",
        "`-` 걱정: $t=0$ 이면 어쩌지? $t=1$이면 어쩌지?… $\\to$ 해결책:\n",
        "일정시간동안 랜덤액션을 하면서 데이터를 쌓고 그 뒤에 $q_0,q_1$을 계산\n",
        "\n",
        "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드\n",
        "\n",
        "`-` 최종코드정리\n",
        "\n",
        "[1] `button1`을 눌러야 하는건 맞지만 20번에 한번정도의 실수는 눈감아\n",
        "주는 조건\n",
        "\n",
        "[2] `button1`을 누른다"
      ],
      "id": "337e6c09-0450-41b5-b2c4-3ab274ece8f6"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  }
}