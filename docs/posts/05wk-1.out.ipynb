{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 05wk-1: 깊은신경망 (4) –\n",
        "\n",
        "최규빈  \n",
        "2024-04-01\n",
        "\n",
        "# A1. 자잘한 용어 정리 ($\\star$)\n",
        "\n",
        "## A. 지도학습\n",
        "\n",
        "`-` 우리가 수업에서 다루는 데이터는 주로 아래와 같은 느낌이다.\n",
        "\n",
        "1.  데이터는 $(X,y)$의 형태로 정리되어 있다.\n",
        "\n",
        "2.  $y$는 우리가 관심이 있는 변수이다. 즉 우리는 $y$를 적절하게 추정하는\n",
        "    것에 관심이 있다.\n",
        "\n",
        "3.  $X$는 $y$를 추정하기 위해 필요한 정보이다.\n",
        "\n",
        "|  $X$ = 설명변수 = 독립변수   | $y$ = 반응변수 = 종속변수  |     비고     |     순서     |           예시           |\n",
        "|:-------------:|:-------------:|:-------------:|:-------------:|:-------------:|\n",
        "|            이미지            |          카테고리          | 합성곱신경망 |   상관없음   |  개/고양이 이미지 구분   |\n",
        "|         유저,아이템          |            평점            |  추천시스템  |   상관없음   |    넷플릭스 영화추천     |\n",
        "|     과거~오늘까지의주가      |          내일주가          |  순환신경망  | 순서상관있음 |         주가예측         |\n",
        "| 처음 $m$개의 단어(혹은 문장) | 이후 1개의 단어(혹은 문장) |  순환신경망  | 순서상관있음 |     챗봇, 텍스트생성     |\n",
        "| 처음 $m$개의 단어(혹은 문장) |          카테고리          |  순환신경망  | 순서상관있음 | 영화리뷰 텍스트 감정분류 |\n",
        "\n",
        "`-` 이러한 문제상황, 즉 $(X,y)$가 주어졌을때 $X \\to y$를 추정하는 문제를\n",
        "supervised learning 이라한다.\n",
        "\n",
        "## B. DNN, ANN, MLP\n",
        "\n",
        "`-` DNN 은 깊은 신경망, ANN 은 인공신경망, MLP 는 다층퍼셉트론이라\n",
        "번역된다.\n",
        "\n",
        "`-` 아래의 네트워크는 ANN이라 볼 수 있다. 하지만 MLP, DNN 이라 볼 수는\n",
        "없다.\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=1),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "```\n",
        "\n",
        "`-` 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 2개 있으므로\n",
        "MLP라고 볼 수 있다. DNN 이라 보기는 애매하다. (그래서 이걸\n",
        "얕은신경망(shallow network)이라고 표현하기도 합니다)\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=1),\n",
        "    torch.nn.Sigmoid()\n",
        ")\n",
        "```\n",
        "\n",
        "`-` 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 7개 있으므로\n",
        "MLP라고 볼 수 있다. 이 정도면 깊어보이니까 DNN 이라 주장할 수\n",
        "있어보인다.\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=2),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=2,out_features=1),\n",
        "    torch.nn.Sigmoid(),    \n",
        ")\n",
        "```\n",
        "\n",
        "`-` 아래의 네트워크는 ANN이라 볼 수 있다. 또한 레이어가 3개 있으므로\n",
        "MLP라고 볼 수 있다. 이건 DNN이라고 봐야하나? 깊다기 보다는 넓은\n",
        "신경망인데…\n",
        "\n",
        "``` python\n",
        "net = torch.nn.Sequential(\n",
        "    torch.nn.Linear(in_features=1,out_features=1048576),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=1048576,out_features=1048576),\n",
        "    torch.nn.ReLU(),\n",
        "    torch.nn.Linear(in_features=1048576,out_features=1),\n",
        "    torch.nn.Sigmoid(),    \n",
        ")\n",
        "```\n",
        "\n",
        "`-` 야매개념: 요즘은 거의 ANN $\\approx$ MLP $\\approx$ DNN 의 느낌으로\n",
        "쓴다.\n",
        "\n",
        "-   어지간한 모형은 다 ANN이라 우길 수 있다. 회귀분석도, 로지스틱분석도\n",
        "    마음먹으면 ANN으로 우길 수 있다. 그래서 ANN을 썼다라는건 뭘 썼는지\n",
        "    모르겟다는 말이랑 같다. 이런 이유로 사람들은 거의 MLP를 쓴 경우에\n",
        "    ANN을 썼다고 하고, 회귀모형을 쓴 경우에는 굳이 ANN을 썼다고 표현하지\n",
        "    않는다.\n",
        "-   MLP과 DNN은 구분이 모호하다. 하나이상의 은닉층만 포함하고 있으면\n",
        "    MLP라고 부를 수 있다. 적은 노드수를 유지하면서 은닉층을 여러개 쓰면\n",
        "    깊은신경망이라고 하고, 많은 노드를 사용하면서 은닉층을 얇게, 그리고\n",
        "    노드를 많이 쓰면 넓은신경망이라고 한다. 얼마나 깊을때 DNN으로 부를지\n",
        "    명확한 합의가 되어있지 않다. (3층-MLP부터 DNN으로 부르는 방식이\n",
        "    지지를 얻는듯. 그렇지만 4층-MLP 부터 DNN으로 부르는 사람도 존재함.)\n",
        "-   이러한 이유로 거의 ANN, MLP, DNN은 비슷한 뉘앙스로 사용된다.\n",
        "\n",
        "## C 학습이란?\n",
        "\n",
        "`-` 학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한\n",
        "“규칙” 혹은 “원리”를 찾는 것이다.\n",
        "\n",
        "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한\n",
        "    “맵핑”을 찾는 것이다.\n",
        "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한\n",
        "    “함수”을 찾는 것이다. 즉 $y\\approx f(X)$가 되도록 만드는 $f$를 잘\n",
        "    찾는 것이다. (이 경우 “함수를 추정한다”라고 표현)\n",
        "-   학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는 어떠한\n",
        "    “모델” 혹은 “모형”을 찾는 것이다. 즉 $y\\approx model(X)$가 되도록\n",
        "    만드는 $model$을 잘 찾는 것이다. (이 경우 “모형을 학습시킨다”라고\n",
        "    표현)\n",
        "-   **학습이란 주어진 자료 $(X,y)$를 잘 분석하여 $X$에서 $y$로 가는\n",
        "    어떠한 “네트워크”을 찾는 것이다. 즉 $y\\approx net(X)$가 되도록\n",
        "    만드는 $net$을 잘 찾는 것이다. (이 경우 “네트워크를 학습시킨다”라고\n",
        "    표현)**\n",
        "\n",
        "`-` prediction이란 학습과정에서 찾은 “규칙” 혹은 “원리”를 $X$에 적용하여\n",
        "$\\hat{y}$을 구하는 과정이다. 학습과정에서 찾은 규칙 혹은 원리는\n",
        "$f$,$model$,$net$ 으로 생각가능한데 이에 따르면 아래가 성립한다.\n",
        "\n",
        "-   $\\hat{y} = f(X)$\n",
        "-   $\\hat{y} = model(X)$\n",
        "-   $\\hat{y} = net(X)$\n",
        "\n",
        "## D. $\\hat{y}$를 부르는 다양한 이름\n",
        "\n",
        "`-` $\\hat{y}$는 $X$가 주어진 자료에 있는 값인지 아니면 새로운 값 인지에\n",
        "따라 지칭하는 이름이 미묘하게 다르다.\n",
        "\n",
        "1.  $X \\in data$: $\\hat{y}=net(X)$ 는 predicted value, fitted value 라고\n",
        "    부른다.\n",
        "\n",
        "2.  $X \\notin data$: $\\hat{y}=net(X)$ 는 predicted value, predicted\n",
        "    value with new data 라고 부른다.\n",
        "\n",
        "`-` 경우1은 “$loss$ = $y$ 와 $\\hat{y}$ 의 차이” 를 정의할 수 있으나\n",
        "경우2는 그렇지 않다.\n",
        "\n",
        "## E. 다양한 코드들\n",
        "\n",
        "`-` 파이썬 코드..\n",
        "\n",
        "``` python\n",
        "#Python\n",
        "predictor.fit(X,y) # autogluon 에서 \"학습\"을 의미하는 과정\n",
        "model.fit(X,y) # sklearn 에서 \"학습\"을 의미하는 과정\n",
        "learner.learn() # fastai 에서 \"학습\"을 의미하는 과정\n",
        "learner.fine_tune(1) # fastai 에서 \"부분학습\"을 의미하는 과정\n",
        "learner.predict(cat1) # fastai 에서 \"예측\"을 의미하는 과정 \n",
        "model.fit(x, y, batch_size=32, epochs=10) # keras에서 \"학습\"을 의미하는 과정\n",
        "model.predict(test_img) # keras에서 \"예측\"을 의미하는 과정 \n",
        "```\n",
        "\n",
        "`-` R 코드..\n",
        "\n",
        "``` r\n",
        "# R\n",
        "ols <- lm(y~x) # 선형회귀분석에서 학습을 의미하는 함수\n",
        "ols$fitted.values # 선형회귀분석에서 yhat을 출력 \n",
        "predict(ols, newdata=test) # 선형회귀분석에서 test에 대한 예측값을 출력하는 함수\n",
        "ols$coef # 선형회귀분석에서 weight를 확인하는 방법\n",
        "```\n",
        "\n",
        "# A2. 참고자료들\n",
        "\n",
        "`-` 케라스/텐서플로우: <https://guebin.github.io/STBDA2022/>\n",
        "\n",
        "`-` 상속:\n",
        "<https://guebin.github.io/PP2023/posts/03_Class/2023-06-12-15wk-1.html>\n",
        "\n",
        "`-` sklearn/autogluon: <https://guebin.github.io/MP2023/>\n",
        "\n",
        "`-` 리눅스관련: <https://guebin.github.io/DSTBX2024/> – 자료 부실함..\n",
        "강의영상 없는것 많음.."
      ],
      "id": "97278b12-7e2e-4e4a-8ebe-5e638411a48d"
    }
  ],
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3 (ipykernel)",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "codemirror_mode": {
        "name": "ipython",
        "version": "3"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  }
}