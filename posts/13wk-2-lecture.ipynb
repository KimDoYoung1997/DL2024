{
 "cells": [
  {
   "cell_type": "raw",
   "id": "855d203d-e1fd-40dc-9c2c-e90e8380f06e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"13wk-1: 강화학습 (1) -- Bandit\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/29/2024\"\n",
    "draft: true\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c13712-1185-4386-90e7-3e23c62be398",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d11f9-7f12-401a-82da-e4b2e568dde6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4685c071-46e9-4bcb-84a7-ece876eb4654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5c5b0-94a7-4a3d-bb6c-1623909505e1",
   "metadata": {},
   "source": [
    "# 2. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da124c05-12c5-4e50-b7c2-c7156427cc82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de1a84-3d65-40d2-a1ee-3f5213791081",
   "metadata": {},
   "source": [
    "# 3. 강화학습 Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0f4e9-06d3-412a-9bd9-79399e11414f",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 \"(게임)환경\"이 있을때 거기서 \"뭘 할지\"를 학습하는 과업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eab2ee-e9e4-4032-8344-a72188f96b27",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고 \n",
    "\n",
    "- <https://www.youtube.com/watch?v=TmPfTpjtdgg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047016d4-087a-4087-8440-072610804ec2",
   "metadata": {},
   "source": [
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79839a6-f30a-4a3c-baf9-aa3ccc8797e5",
   "metadata": {},
   "source": [
    "# 4. Game1: `Bandit` 게임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b366221-0891-4c37-8e73-bd1622cd0a0d",
   "metadata": {},
   "source": [
    "## A. 게임설명 및 원시코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b629176-ac93-4d67-8c4c-ce616e8709f0",
   "metadata": {},
   "source": [
    "`-` 문제설명: 두 개의 버튼이 있다. `버튼0`을 누르면 1의 보상을, `버튼1`을 누르면 10의 보상을 준다고 가정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0db51-86d9-45c1-925b-23561fe9d0d0",
   "metadata": {},
   "source": [
    "`-` 처음에 어떤 행동을 해야 하는가?\n",
    "\n",
    "- 처음에는 아는게 없음\n",
    "- 일단 \"아무거나\" 눌러보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d02dba-7da9-48b9-8371-18ceea6de043",
   "metadata": {},
   "source": [
    "`-` 버튼을 아무거나 누르는 코드를 작성해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d3310f1-1f64-464e-8d7a-f10fda5ac8a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6cce19f2-b173-4af0-ac97-d6f5f3ea6987",
   "metadata": {},
   "source": [
    "> `action_space` 와 `action` 이라는 용어를 기억할 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58ae92-18be-4d72-9be9-6bed4ac5d7ef",
   "metadata": {},
   "source": [
    "`-` 버튼을 누른 행위에 따른 보상을 구현하자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4df5ca-80ae-488d-b156-3f89f865e5ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "60ad8d94-ce00-44a2-b64c-25ca1ad1bc91",
   "metadata": {},
   "source": [
    "> `reward`라는 용어를 기억할 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2653f6-e9b0-4aff-b52e-a3e2cc34414a",
   "metadata": {},
   "source": [
    "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5d69d3-b3f9-4ef3-a450-2a659a3acc0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2033e58-a603-4583-94da-b0f884ae2d26",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a666665-184a-4dc9-822a-1c993a2e3c78",
   "metadata": {},
   "source": [
    "`-` 깨달았음: `버튼0`을 누르면 1점을 받고, `버튼1`을 누르면 10점을 받는 \"환경(environment)\"이구나? $\\to$ `버튼1`을 누르는 \"동작(=action)\"을 해야하는 상황이구나? \n",
    "\n",
    "- 여기에서 $\\to$의 과정을 체계화 시킨 학문이 강화학습 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a6794d-15d2-48e0-b44d-8ee12b664e00",
   "metadata": {},
   "source": [
    "> `environment`라는 용어를 기억할 것 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "490cdb80-7d34-4b5e-944a-8b77d56cd669",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0658333b-ac00-4bf9-9d30-2b20448998c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "00d1129a-5d3e-47f7-b3b8-d90631494289",
   "metadata": {},
   "source": [
    "- 게임 클리어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdee96-6c0e-4e26-8551-d76ce1629188",
   "metadata": {},
   "source": [
    "`-` 강화학습: 환경(environment)을 이해 $\\to$ 에이전트(agent)가 행동(action)을 결정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fcf0472-6529-4462-acd8-1f1ffadef928",
   "metadata": {
    "tags": []
   },
   "source": [
    "> `agent`라는 용어를 기억할 것 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2f276-9417-4a55-9ca2-016dbf1bc921",
   "metadata": {},
   "source": [
    "***위의 과정이 잘 되었다는 의미로 사용하는 문장들*** \n",
    "\n",
    "- 강화학습이 성공적으로 잘 되었다. \n",
    "- 에이전트가 환경의 과제를 완료했다. \n",
    "- 에이전트가 환경에서 성공적으로 학습했다. \n",
    "- 에이전트가 올바른 행동을 학습했다. \n",
    "- 게임 클리어 (비공식) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947330d-217b-4ae6-90f2-bdc44cf60d49",
   "metadata": {},
   "source": [
    "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다. \n",
    "\n",
    "- 첫 생각: `버튼1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
    "- 두번째 생각: 아니지? 우연히 누를수도 있잖아?\n",
    "- 게임클리어조건: (1) 20번은 그냥 진행 (2) 최근 20번의 보상의 평균이 95점 이상이면 게임이 클리어 되었다고 생각하자.^[`버튼1`을 눌러야 하는건 맞지만 몇번의 실수는 눈감아 주자는 의미]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6dc80-305e-4fb7-a6e2-817a49e7db52",
   "metadata": {},
   "source": [
    "`-` 원시코드1: 환경을 이해하지 못한 에이전트 -- 게임을 클리어할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42891a56-8fc9-4a26-873e-8ad83000415f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c81a0d-b637-498e-9b9e-60f165349078",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7f2f62e-2057-447e-99da-9ffffd21b510",
   "metadata": {},
   "source": [
    "`-` 원시코드2: 환경을 깨달은 에이전트 -- 게임클리어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca2f857-efa5-4246-b527-f814c6a15695",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e26d0587-2534-4a2f-8da0-7612fdf17cac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3fd4cff1-c6d8-4ae2-b8c0-8fb1422485f0",
   "metadata": {},
   "source": [
    "## B. 수정1: `Env` 구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf810ba-a4dc-407f-93c6-54d9784b5109",
   "metadata": {},
   "source": [
    "`-` `Bandit` 클래스 선언 + `.step()` 구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b10aa-1577-4438-8878-d93414e0592b",
   "metadata": {},
   "source": [
    "## C. 수정2: `Agent` 구현 (인간지능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59e2be6-7b34-4e33-a877-4878765247d6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a452a393-8bc4-4c1a-827c-a429155a1ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10343b7-fb36-479e-aca1-61a94cc045e9",
   "metadata": {},
   "source": [
    "`-` Agent 클래스 설계\n",
    "\n",
    "- 액션을 하고, 본인의 행동과 환경에서 받은 reward를 기억 \n",
    "- `.act()`함수와 `.save_experience()`함수 구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ec5202-0160-41a2-8a94-3b535b2daef7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d40f628b-4875-4c60-9c1a-27333c1778f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a993f656-12f6-47a3-bc8c-b3e15d147c45",
   "metadata": {},
   "source": [
    "--- 대충 아래와 같은 느낌으로 코드가 돌아가요 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9c806-87eb-4892-b38c-8c7229ad7ee6",
   "metadata": {},
   "source": [
    "**시점0**: init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "6ee01a47-2ecc-41c9-9344-419f06f89d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = Bandit()\n",
    "agent = Agent() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "43397ed8-1846-4db8-85e5-feab67bb12f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75799c0a-2ee2-4229-8ee3-6d259c430355",
   "metadata": {},
   "source": [
    "**시점1**: agent >> env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "94b910e3-9d0d-4e32-bfe4-1ea5bc7a537b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "88ca0c67-6c67-461b-adad-5781c23e366a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "390746fe-70f2-42ff-97e7-02872bf725fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.agent_action = agent.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32765dfd-7627-4fca-b565-a290855b1991",
   "metadata": {},
   "source": [
    "**시점2**: agent << env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0c06f08a-96f0-454f-bb0e-76f3b80650a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.reward = env.step(env.agent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "92121832-fc74-40ca-885b-1b7ebbc0b2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 10, 1)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, env.agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "5de5658f-352b-4080-a452-c7b9ceb32181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "5e3ea513-38ff-42a0-b298-c2b17347e30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "89f2ead3-14ff-4db7-91b7-e7444900a2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [10])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae975d1-5725-41f0-b063-3d57fb6f91df",
   "metadata": {},
   "source": [
    "-- 전체코드 -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044b34f2-70a7-4004-aae0-3324e2930ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61ed75c8-a92b-4359-b317-534df5ab9924",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9b17361b-9b5c-461a-b6a3-574c8e1c904b",
   "metadata": {},
   "source": [
    "## D. 수정3: `Agent` 구현 (인공지능)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e84973-7e84-44f0-b0c0-a86889a39205",
   "metadata": {},
   "source": [
    "`-` 지금까지 풀이의 한계\n",
    "\n",
    "- 사실 강화학습은 \"환경을 이해 $\\to$ 행동을 결정\" 의 과정에서 \"$\\to$\"의 과정을 수식화 한 것이다.\n",
    "- 그런데 지금까지 했던 코드는 환경(environment)를 이해하는 순간 에이전트(agent)가 최적의 행동(action)^[`버튼1`을 누른다]을 **\"직관적으로\"** 결정하였으므로 기계가 스스로 학습을 했다고 볼 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369c83bb-8afd-44ef-875c-972a8019934d",
   "metadata": {},
   "source": [
    "`-` 에이전트가 데이터를 보고 스스로 학습할 수 있도록 설계 -- 부제: `agent.learn()`을 설계하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a98672-9ef6-4625-b108-3f19e53d3821",
   "metadata": {},
   "source": [
    "1. 데이터를 모아서 `q_table` 를 만든다. `q_table`은 아래와 같은 내용을 포함한다. \n",
    "\n",
    "|행동|보상(추정값)|\n",
    "|:--:|:--:|\n",
    "|버튼0 ($=a_0$)|1 ($=q_0$)|\n",
    "|버튼1 ($=a_1$)|100 ($=q_1$)|"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8bed72-386d-47e9-b7ac-caced2e56eb7",
   "metadata": {},
   "source": [
    "2. `q_table`을 바탕으로 적절한 정책(=`policy`)을 설정한다. \n",
    "\n",
    "- 이 예제에서는 버튼0과 버튼1을 각각 $\\big(\\frac{q_0}{q_0+q_1},\\frac{q_1}{q_0+q_1}\\big)$ 의 확률로 선택하는 \"정책\"을 이용하면 충분할 듯 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3acdd922-7ab3-42d2-8efc-b923bc581d5f",
   "metadata": {},
   "source": [
    "> 여기에서 `q_table`, `policy`라는 용어를 기억하세요."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8fb01-71c0-47f6-9484-eea924f03ccf",
   "metadata": {},
   "source": [
    "`-` `q_table`을 계산하는 코드 예시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f725954b-d1fa-47e9-ab79-46ec3a53eef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.actions = [0, 1, 1,  0, 1,   0, 0] \n",
    "agent.rewards = [1, 9, 10, 1, 9.5, 1, 1.2] \n",
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4647d67a-5086-4f46-a388-65724312b3d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f867a6-3e0a-40a2-a950-4dc5b67c5f6b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cc4d00-61c9-4cf1-b92c-ea70e3a1bed4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8209e84e-49e3-47c1-939d-f0ab723b33cf",
   "metadata": {},
   "source": [
    "`-` 최종코드정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fef197-6ec6-45a3-8292-1d4f7dcaa3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245e7f6d-2587-4d4d-aedb-9231e9df6696",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
