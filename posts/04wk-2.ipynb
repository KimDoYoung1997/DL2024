{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d6d385e4-f274-4321-b545-24c6b36c4aa0",
   "metadata": {
    "id": "87b5cded-346b-4915-acf5-b5ec93a5207d"
   },
   "source": [
    "---\n",
    "title: \"04wk-2: 깊은 신경망 (3) -- 오버피팅, 드랍아웃, 신경망의 표현\"\n",
    "author: \"최규빈\"\n",
    "date: \"03/27/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b528a9c-75ec-4828-a716-963c44a58759",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/04wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3339a3ba-ff9a-4e08-9e7f-3cf6f509e776",
   "metadata": {
    "id": "4d47a7c9",
    "tags": []
   },
   "source": [
    "# 1. 강의영상"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90500e55-2113-4325-bfc6-ce153ed961aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "{{<video https://youtu.be/playlist?list=PLQqh36zP38-wHAizLm_MYaUweataauffD&si=U5TXo5UgkRGc6a-F >}}"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4a562be7",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "!pip install opencv-python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2af706c7-9f98-4d4f-8608-7c9c0185c2c0",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a4b6bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyrealsense2 as rs\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad61b644",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No device connected",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m cfg\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mcolor, \u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mbgr8, \u001b[38;5;241m30\u001b[39m)\n\u001b[1;32m      5\u001b[0m cfg\u001b[38;5;241m.\u001b[39menable_stream(rs\u001b[38;5;241m.\u001b[39mstream\u001b[38;5;241m.\u001b[39mdepth, \u001b[38;5;241m640\u001b[39m,\u001b[38;5;241m480\u001b[39m, rs\u001b[38;5;241m.\u001b[39mformat\u001b[38;5;241m.\u001b[39mz16, \u001b[38;5;241m30\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m \u001b[43mpipe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m     10\u001b[0m     frame \u001b[38;5;241m=\u001b[39m pipe\u001b[38;5;241m.\u001b[39mwait_for_frames()\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No device connected"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "pipe = rs.pipeline()\n",
    "cfg  = rs.config()\n",
    "\n",
    "cfg.enable_stream(rs.stream.color, 640,480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640,480, rs.format.z16, 30)\n",
    "\n",
    "pipe.start(cfg)\n",
    "\n",
    "while True:\n",
    "    frame = pipe.wait_for_frames()\n",
    "    depth_frame = frame.get_depth_frame()\n",
    "    color_frame = frame.get_color_frame()\n",
    "\n",
    "    depth_image = np.asanyarray(depth_frame.get_data())\n",
    "    color_image = np.asanyarray(color_frame.get_data())\n",
    "    depth_cm = cv2.applyColorMap(cv2.convertScaleAbs(depth_image,\n",
    "                                     alpha = 0.5), cv2.COLORMAP_JET)\n",
    "\n",
    "    gray_image = cv2.cvtColor(color_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    cv2.imshow('rgb', color_image)\n",
    "    cv2.imshow('depth', depth_cm)\n",
    "\n",
    "    if cv2.waitKey(1) == ord('q'):\n",
    "        break\n",
    "\n",
    "pipe.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca96da50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "failed to set power state",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 22\u001b[0m\n\u001b[1;32m     19\u001b[0m             \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevice connected:\u001b[39m\u001b[38;5;124m'\u001b[39m, dev\u001b[38;5;241m.\u001b[39mget_info(rs\u001b[38;5;241m.\u001b[39mcamera_info\u001b[38;5;241m.\u001b[39mname), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSerial:\u001b[39m\u001b[38;5;124m'\u001b[39m, dev\u001b[38;5;241m.\u001b[39mget_info(rs\u001b[38;5;241m.\u001b[39mcamera_info\u001b[38;5;241m.\u001b[39mserial_number))\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# List connected devices\u001b[39;00m\n\u001b[0;32m---> 22\u001b[0m \u001b[43mlist_devices\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Try to start the pipeline\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m, in \u001b[0;36mlist_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo device connected\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 18\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dev \u001b[38;5;129;01min\u001b[39;00m ctx\u001b[38;5;241m.\u001b[39mdevices:\n\u001b[1;32m     19\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDevice connected:\u001b[39m\u001b[38;5;124m'\u001b[39m, dev\u001b[38;5;241m.\u001b[39mget_info(rs\u001b[38;5;241m.\u001b[39mcamera_info\u001b[38;5;241m.\u001b[39mname), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSerial:\u001b[39m\u001b[38;5;124m'\u001b[39m, dev\u001b[38;5;241m.\u001b[39mget_info(rs\u001b[38;5;241m.\u001b[39mcamera_info\u001b[38;5;241m.\u001b[39mserial_number))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: failed to set power state"
     ]
    }
   ],
   "source": [
    "import pyrealsense2 as rs\n",
    "\n",
    "# Create a pipeline\n",
    "pipe = rs.pipeline()\n",
    "cfg = rs.config()\n",
    "\n",
    "# Enable the streams\n",
    "cfg.enable_stream(rs.stream.color, 640, 480, rs.format.bgr8, 30)\n",
    "cfg.enable_stream(rs.stream.depth, 640, 480, rs.format.z16, 30)\n",
    "\n",
    "# Function to list connected devices\n",
    "def list_devices():\n",
    "    print(\"111\")\n",
    "    ctx = rs.context()\n",
    "    if len(ctx.devices) == 0:\n",
    "        print(\"No device connected\")\n",
    "    else:\n",
    "        for dev in ctx.devices:\n",
    "            print('Device connected:', dev.get_info(rs.camera_info.name), 'Serial:', dev.get_info(rs.camera_info.serial_number))\n",
    "\n",
    "# List connected devices\n",
    "list_devices()\n",
    "\n",
    "# Try to start the pipeline\n",
    "try:\n",
    "    pipe.start(cfg)\n",
    "    print(\"Pipeline started successfully\")\n",
    "except Exception as e:\n",
    "    print(e)\n",
    "\n",
    "# Add your frame processing code here\n",
    "# while (True):\n",
    "#     frame = pipe.wait_for_frames()\n",
    "#     depth_frame = frame.get_depth_frame()\n",
    "#     color_frame = frame.get_color_frame()\n",
    "#     if not depth_frame or not color_frame:\n",
    "#         continue\n",
    "#     # Process frames here\n",
    "\n",
    "# Stop the pipeline\n",
    "pipe.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ec9ed-a822-4953-9c16-3ce8db61f117",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ece4e56-9216-4772-b65e-c806efc9f106",
   "metadata": {},
   "source": [
    "# 3. 오버피팅 (시벤코정리의 이면)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41366622-fed0-41f3-9ab0-d3252d15ca3d",
   "metadata": {},
   "source": [
    "## A. 오버피팅"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "089b896d-4757-400d-afb2-3e62c1a985ec",
   "metadata": {},
   "source": [
    "`-` 오버피팅이란? \n",
    "\n",
    "- 위키: In mathematical modeling, overfitting is \"the production of an analysis that corresponds too closely or exactly to a particular set of data, and may therefore fail to fit to additional data or predict future observations reliably\". \n",
    "- 제 개념: 데이터를 \"데이터 = 언더라잉 + 오차\"라고 생각할때 우리가 데이터로부터 적합할 것은 언더라잉인데 오차항을 적합하고 있는 현상. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ab8ace-6a64-4ac3-a67e-4663b18d63a3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## B. 오버피팅 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5ea4c7-13dd-4201-ad50-a1ea95348a8f",
   "metadata": {},
   "source": [
    "`-` $m$이 매우 클때 아래의 네트워크 거의 무엇이든 맞출 수 있다고 보면 된다. \n",
    "\n",
    "- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{h}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}$ \n",
    "- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}$\n",
    "- $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,m)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,m)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\hat{\\boldsymbol y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ac8351-1c60-4ef2-a441-4a2f2da6cbf4",
   "metadata": {},
   "source": [
    "`-` 그런데 종종 맞추지 말아야 할 것들도 맞춘다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561762fd-2ec6-4b05-90f7-5b5b178de42a",
   "metadata": {},
   "source": [
    "model: $y_i = (0\\times x_i) + \\epsilon_i$, where $\\epsilon_i \\sim N(0,0.01^2)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95a1c122-c384-40b0-a18e-301935166d74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(5) \n",
    "x = torch.linspace(0,1,100).reshape(100,1)\n",
    "y = torch.randn(100).reshape(100,1)*0.01\n",
    "plt.plot(x,y,'--o',alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d22ad4d-07f8-410b-8de5-8ccbea44c6ad",
   "metadata": {},
   "source": [
    "- y는 그냥 정규분포에서 생성한 오차이므로 $X \\to y$ 로 향하는 규칙따위는 없음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2d989-4087-49a4-bb4b-ef173f8ecd19",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1) \n",
    "net=torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=512,out_features=1)) \n",
    "optimizr= torch.optim.Adam(net.parameters())\n",
    "loss_fn= torch.nn.MSELoss()\n",
    "\n",
    "for epoc in range(1000): \n",
    "    ## 1 \n",
    "    yhat=net(x) \n",
    "    ## 2 \n",
    "    loss=loss_fn(yhat,y) \n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    net.zero_grad() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9d8d96-aba2-49d1-a879-600b7c17700f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'--o',alpha=0.5)\n",
    "plt.plot(x,net(x).data,'--')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740bc40d-6ca3-4e01-9c2d-16d822c1030d",
   "metadata": {},
   "source": [
    "- 우리는 데이터를 랜덤에서 뽑았는데, 데이터의 추세를 따라간다 $\\to$ 오버피팅 (underlying이 아니라 오차항을 따라가고 있음) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48cbbe4e-91ae-4511-811f-2b7da0f9e542",
   "metadata": {},
   "source": [
    "## C. 오버피팅이라는 뚜렷한 증거! (train / test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c85fae7-aebb-4013-998f-ad7b06936a44",
   "metadata": {},
   "source": [
    "`-` 데이터의 분리하여 보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8dbcdf-332c-427a-8a2c-483ac15f3f52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(5) \n",
    "x_all = torch.linspace(0,1,100).reshape(100,1)\n",
    "y_all = torch.randn(100).reshape(100,1)*0.01\n",
    "x = x_all[:80] \n",
    "y = y_all[:80]\n",
    "xx = x_all[80:]\n",
    "yy = y_all[80:]\n",
    "plt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\n",
    "plt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953b0d33-4234-48b9-addd-8447266bc4e9",
   "metadata": {},
   "source": [
    "`-` train만 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc72fa1-f495-4dd5-8f2e-7b408801ec2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1) \n",
    "net=torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=512), \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=512,out_features=1)) \n",
    "optimizr= torch.optim.Adam(net.parameters())\n",
    "loss_fn= torch.nn.MSELoss()\n",
    "\n",
    "for epoc in range(1000): \n",
    "    ## 1 \n",
    "    yhat = net(x) \n",
    "    ## 2 \n",
    "    loss=loss_fn(yhat,y) \n",
    "    ## 3 \n",
    "    loss.backward()\n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4db9b-bd3e-4798-8655-1e308dd75e50",
   "metadata": {},
   "source": [
    "`-` training data로 학습한 net를 training data 에 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb12c9b8-03a8-42fd-9701-83af71e362f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\n",
    "plt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\n",
    "plt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc086b-ead9-4697-bff3-4d830f0fc213",
   "metadata": {},
   "source": [
    "- train에서는 잘 맞추는듯이 보인다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e8cd3d-2f2a-4033-a669-258370a3505e",
   "metadata": {},
   "source": [
    "`-` training data로 학습한 net를 test data 에 적용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff22a89-e680-4d75-a306-f1b7b8687f77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'--o',label=\"training data (open)\",alpha=0.3)\n",
    "plt.plot(xx,yy,'--o',label=\"test data (hidden)\",alpha=0.3)\n",
    "plt.plot(x,net(x).data,label=\"fitted values, predicted values\",color=\"C0\")\n",
    "plt.plot(xx,net(xx).data,label=\"predicted values, predicted values with new data\",color=\"C1\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d28d8ef-cc32-4b9b-9d11-30c9c0c2bc4e",
   "metadata": {},
   "source": [
    "- train은 그럭저럭 따라가지만 test에서는 엉망이다. $\\to$ overfit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2546b9df-89b3-4ffc-853d-dcf105874865",
   "metadata": {},
   "source": [
    "## D. 시벤코정리의 올바른 이해"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1c93a0-6fb1-467f-baaf-6d323e9e6eb9",
   "metadata": {
    "tags": []
   },
   "source": [
    "::: {.callout-note}\n",
    "### 시벤코정리의 항변(?) [@cybenko1989approximation]\n",
    "\n",
    "하나의 은닉층을 가지는 아래와 같은 꼴의 네트워크 $net: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}$는\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(p,???),\n",
    "    torch.nn.Sigmoid(), ## <-- 여기에 렐루를 써도 된다. \n",
    "    torch.nn.Linear(???,q)\n",
    ")\n",
    "```\n",
    "\n",
    "모든 continuous mapping \n",
    "\n",
    "$$f: {\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}$$ \n",
    "\n",
    "를 원하는 정확도로 \"근사\"시킬 수 있다 (즉 마음만 먹으면 loss를 0에 가깝도록 만들 수 있다는 의다) 쉽게 말하면 ${\\bf X} \\to {\\bf y}$ 인 어떠한 복잡한 규칙라도 하나의 은닉층을 가진 심층신경망(DNN)이 원하는 정확도로 근사시킨다는 의미이다. **그렇지만 이러한 규칙이 네크워크가 학습하지 못했던 자료 (처음 보는 자료, unseen data)** ${\\bf XX}_{m \\times p}$, ${\\bf yy}_{m \\times p}$ **에 대하여서도 올바르게 적용된다라는 보장은 없다**. 즉 \n",
    "\n",
    "$${\\bf X}_{n \\times p} \\to {\\bf y}_{n\\times q}$$ \n",
    "\n",
    "를 원하는 정확도로 근사시킨 네트워크라고 할지라도 \n",
    "\n",
    "$${\\bf XX}_{m \\times p} \\to {\\bf yy}_{m\\times q}$$ \n",
    "\n",
    "는 엉터리로 나올 수 있다. 시벤코는 넓은 신경망이 가지는 표현력의 한계를 수학적으로 밝혔을 뿐이다. 넓은 신경망이 우수한 신경망^[여기에서 우수하다는 말은 여러의미가 있어요, 오버피팅이 없는 신경망이라든가, 경제적인 신경망이라든가..]이라는 주장을 한적은 없다.\n",
    ":::\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a39e09f-5880-4571-9ab1-5f1fa9529349",
   "metadata": {},
   "source": [
    "# 4. 드랍아웃"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56004273-6118-44ad-b999-e535e6bc4aa9",
   "metadata": {},
   "source": [
    "## A. 오버피팅의 해결 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71333e58-fa88-47b5-bea5-2b3ae5497ea3",
   "metadata": {},
   "source": [
    "`-` 오버피팅의 해결책: 드랍아웃 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2769a57e-23d5-4f2a-bbf3-21ea0250382e",
   "metadata": {},
   "source": [
    "`-` 데이터 -- 재활용 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b90fa-6cac-4b63-adbd-4d177f07890a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(5) \n",
    "x_all = torch.linspace(0,1,100).reshape(100,1)\n",
    "y_all = torch.randn(100).reshape(100,1)*0.01\n",
    "x = x_all[:80] \n",
    "y = y_all[:80]\n",
    "xx = x_all[80:]\n",
    "yy = y_all[80:]\n",
    "plt.plot(x,y,'--o',label=\"training (open)\",alpha=0.7)\n",
    "plt.plot(xx,yy,'--o',label=\"test (hidden)\",alpha=0.3)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e47296e-96f3-4fa9-9163-63ba572a7ea1",
   "metadata": {},
   "source": [
    "`-` 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ca250a4-c15a-43ac-b35f-e21848c9d30f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(1) \n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=512),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Dropout(0.8),\n",
    "    torch.nn.Linear(in_features=512,out_features=1)\n",
    ")\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimizr = torch.optim.Adam(net.parameters())\n",
    "\n",
    "for epoc in range(1000):\n",
    "    ## 1 \n",
    "    yhat = net(x)\n",
    "    ## 2 \n",
    "    loss = loss_fn(net(x),y) \n",
    "    ## 3 \n",
    "    loss.backward() \n",
    "    ## 4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59da7d4-740e-410a-a70f-e94caea7d9b0",
   "metadata": {
    "tags": []
   },
   "source": [
    "`-` 결과시각화 (잘못된 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b010ea-be22-45e8-81fe-b4f5b7329241",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'o')\n",
    "plt.plot(xx,yy,'o')\n",
    "plt.plot(x,net(x).data,'--',color='C0') \n",
    "plt.title(f\"net.training = {net.training}\",fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d494066a-5f91-4a24-bc6c-c38fe4557b63",
   "metadata": {},
   "source": [
    "- `net`에 드랍아웃이 포함되어 있다면, `net.training  == True` 일때 결과가 엉망으로 나옴. \n",
    "- 왜??"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f608706c-e1a7-4c43-8aef-305c8ea4929a",
   "metadata": {},
   "source": [
    "`-` 결과시각화 (올바른 사용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cea284a7-700e-4200-af30-7c9aa63d9924",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ae3d1b-fa01-43ef-96d5-dc173286d723",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net.eval()\n",
    "net.training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c99bfd-218c-450b-b0a3-285a4e2d4936",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(x,y,'o')\n",
    "plt.plot(xx,yy,'o')\n",
    "plt.plot(x,net(x).data,'--',color='C0') \n",
    "plt.plot(xx,net(xx).data,'--',color='C1') \n",
    "plt.title(f\"net.training = {net.training}\",fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d1f6a8-dbf0-4f63-8850-895f770c283c",
   "metadata": {},
   "source": [
    "- 이게 제대로 된 결과시각화임!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62c2177-53b7-4bb2-a076-4bd0d3debb22",
   "metadata": {},
   "source": [
    "## B. 드랍아웃 레이어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe9ac8-afcb-45c5-ad6b-17c6914fb335",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "u = torch.randn(20).reshape(10,2)\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9c9601-cc3f-4610-a10f-cab102a06fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "d = torch.nn.Dropout(0.9)\n",
    "d(u)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f604116-e012-490e-9d9b-cc88bf84de21",
   "metadata": {},
   "source": [
    "- 90%의 드랍아웃: 드랍아웃층의 입력 중 임의로 90%를 골라서 결과를 0으로 만든다. + 그리고 0이 되지않고 살아남은 값들은 10배 만큼 값이 커진다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25053ba3-f20c-4c43-9b85-f69554f7a0a3",
   "metadata": {},
   "source": [
    "`-` 드랍아웃레이어 정리 \n",
    "\n",
    "- 구조: 입력 -> 드랍아웃레이어 -> 출력 \n",
    "- 역할: (1) 입력의 일부를 임의로 0으로 만드는 역할 (2) 0이 안된것들은 스칼라배하여 드랍아웃을 통과한 모든 숫자들의 총합이 일정하게 되도록 조정 \n",
    "- 효과: 오버피팅을 억제하는 효과가 있음 (왜??) <-- 이거 너무 시간이 없어서 대충 설명했는데요.. 잘 이해가 안되시면 [2023-기계학습활용-11wk-43](https://guebin.github.io/MP2023/posts/11wk-43.html), [2023-기계학습활용-12wk-44](https://guebin.github.io/MP2023/posts/12wk-44.html) 참고하시면 될 겁니다. 그래도 이해가 안되면 일단은 외우세요. (진짜 궁금하시면 따로 물어보세요.. 제가 이걸 설명할 시간이 없을것 같아요.. 죄송합니다)\n",
    "- 의미: each iteration (each epoch x) 마다 학습에 참여하는 노드가 랜덤으로 결정됨.\n",
    "- 느낌: 모든 노드가 골고루 학습가능 + 한 두개의 특화된 능력치가 개발되기 보다 평균적인 능력치가 전반적으로 개선됨 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "723853b0-9959-4cd3-ba8e-c51d6a8301a5",
   "metadata": {},
   "source": [
    "> 오버피팅을 잡는 방법은 드랍아웃만 있는게 아니다.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fca086-b613-41c4-9d2a-4b8ab1a7e5f4",
   "metadata": {},
   "source": [
    "`-` ReLU + dropout의 특이한 성질 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73410f92-b1d5-42a6-af4b-865c89a768f0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def my_dropout(x):\n",
    "    x[:5,[0]] = torch.zeros(5).reshape(-1,1)\n",
    "    x[5:,[1]] = torch.zeros(5).reshape(-1,1)\n",
    "    return 2*x\n",
    "\n",
    "relu = torch.nn.ReLU()\n",
    "sig = torch.nn.Sigmoid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c232c6-d754-44c7-a2df-354aa15d121e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "relu(my_dropout(u)), my_dropout(relu(u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac542eb-2aab-4aff-8747-2f01d3e790c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sig(my_dropout(u)), my_dropout(sig(u))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec42438-1101-4bc5-aec7-b23a78661afe",
   "metadata": {},
   "source": [
    "> 드랍아웃은 히든레이어사이, 즉 활성화 함수 바로 뒤에 오는게 맞음. 그렇지만 ReLU의 경우 활성화 함수 직전에 취하기도 함. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68ddd552-8fd7-4701-b484-520b41da7768",
   "metadata": {},
   "source": [
    "# 5. 신경망의 표현 (${\\boldsymbol x} \\to \\hat{\\boldsymbol y}$ 로 가는 과정을 그림으로 표현)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f56b7cf-34a0-40e7-8423-e64e354b22cf",
   "metadata": {},
   "source": [
    "## 예제1: $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(1)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(1)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b724f53-ad56-4131-a451-2977735f164b",
   "metadata": {},
   "source": [
    "`-` 모든 observation과 가중치를 명시한 버전 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066e5daf-209f-4e87-aeb0-01a5ef133efc",
   "metadata": {},
   "source": [
    "**(표현1)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7d3176-c0e5-43ad-a4f2-519950787395",
   "metadata": {
    "tags": []
   },
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-4-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a8586e-ce5a-4e43-bc34-8d7e5a6cca47",
   "metadata": {},
   "source": [
    "- 단점: 똑같은 그림의 반복이 너무 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f320f16-70d9-4963-aa3d-01c6fcd4b7f2",
   "metadata": {},
   "source": [
    "`-` observation 반복을 생략한 버전들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7dfec5-cd7f-446f-856c-9f081344afb5",
   "metadata": {},
   "source": [
    "**(표현2)** 모든 $i$에 대하여 아래의 그림을 반복한다고 하면 (표현1)과 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3da51c9-c6e3-40a0-b65c-cc1d45bc8534",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-5-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da79f19b-da15-4efd-9687-053ad5801ff6",
   "metadata": {},
   "source": [
    "**(표현3)** 그런데 (표현2)에서 아래와 같이 $x_i$, $y_i$ 대신에 간단히 $x$, $y$로 쓰는 경우도 많음"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1ba6fd-c108-4e25-8acb-ab3c5ae613c1",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-6-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e2b8c5-8279-4d17-a18e-83823be53472",
   "metadata": {},
   "source": [
    "`-` 1을 생략한 버전들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0f17d1-38a6-4963-9aa0-039c7df21c85",
   "metadata": {},
   "source": [
    "**(표현4)** bais=False 대신에 bias=True를 주면 1을 생략할 수 있음 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd79a6aa-642c-4f87-b74a-f04327ed295d",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-7-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6313d04a-ef56-46b2-8e88-720fa9cb5c5b",
   "metadata": {},
   "source": [
    "**(표현4의 수정)** $\\hat{w}_1$대신에 $\\hat{w}$를 쓰는 것이 더 자연스러움 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfbef8a-b5c9-4164-9b82-ed459a491c7f",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-8-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0568fa-28d7-4857-b3c4-e8c1649d09e1",
   "metadata": {},
   "source": [
    "**(표현5)** 선형변환의 결과는 아래와 같이 $u$로 표현하기도 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8768e47d-3a07-400d-bca5-211cad5f1c4f",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-9-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59dd0fe8-3090-431b-b9ae-699cd60150a3",
   "metadata": {},
   "source": [
    "> 다이어그램은 그리는 사람의 취향에 따라 그리는 방법이 조금씩 다릅니다. 즉 교재마다 달라요. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d629d404-95cb-45d6-9abf-b072bc100df8",
   "metadata": {},
   "source": [
    "## 예제2: $\\underset{(n,1)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\overset{l_2}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}} =\\underset{(n,1)}{\\hat{\\boldsymbol y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc052d5-8e62-4040-a778-99ebc18adc8d",
   "metadata": {},
   "source": [
    "**참고: 코드로 표현**\n",
    "\n",
    "```Python\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=1,out_features=2),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=2,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "636b6ac1-da3d-4771-99d8-25be1852674b",
   "metadata": {},
   "source": [
    "`-` 이해를 위해서 03kw-2에서 다루었던 아래의 상황을 고려하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608d6bc2-cdc2-4704-87da-298eb261adb2",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2024/posts/03wk-2_files/figure-html/cell-11-output-1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834996ca-ab49-400b-958f-da9186c6fb03",
   "metadata": {},
   "source": [
    "**(강의노트의 표현)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dae5cb1-6c7a-4ca0-a9ee-293710bb7308",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-10-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba6f085-ace3-4f51-8a5f-ecb8093aa62b",
   "metadata": {},
   "source": [
    "**(좀 더 일반화된 표현)** 상황을 일반화하면 아래와 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5203a000-38c0-4063-8b1d-cf65c04fe206",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-11-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49757ec8-fece-42ad-9b1f-c2eabfe12672",
   "metadata": {},
   "source": [
    "`*` Layer의 개념: ${\\bf X}$에서 $\\hat{\\boldsymbol y}$로 가는 과정은 \"선형변환+비선형변환\"이 반복되는 구조이다. \"선형변환+비선형변환\"을 하나의 세트로 보면 아래와 같이 표현할 수 있다. \n",
    "\n",
    "- $\\underset{(n,1)}{\\bf X}  \\overset{l_1}{\\to} \\left( \\underset{(n,2)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,2)}{\\boldsymbol v^{(1)}} \\right) \\overset{l_2}{\\to} \\left(\\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}\\right), \\quad  \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{net({\\bf X})}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4b2877-8d3d-482c-a22f-2db95b09e642",
   "metadata": {},
   "source": [
    "이것을 다이어그램으로 표현한다면 아래와 같다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5d4c6-6299-4dfd-85f0-36044426a841",
   "metadata": {},
   "source": [
    "**(선형+비선형을 하나의 Layer로 묶은 표현)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246bbc13-e056-4682-ad4a-c1bb23c1aef2",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-12-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a886087-1631-4968-bcc8-889f50adcd9c",
   "metadata": {},
   "source": [
    "***Layer를 세는 방법***\n",
    "\n",
    "- 제 방식: 학습가능한 파라메터가 몇층으로 있는지... <-- 이것만 기억하세여\n",
    "- 일부 교재 설명: 입력층은 계산하지 않음, activation layer는 계산하지 않음. <-- 무시하세요.. 이러면 헷갈립니다.. \n",
    "- 위의 예제의 경우 `number of layer = 2` 이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5b5f85-8722-40e9-9ab2-2e94d313ef4e",
   "metadata": {},
   "source": [
    "***Hidden Layer의 수를 세는 방법*** \n",
    "\n",
    "- 제 방식: `Hidden Layer의 수 = Layer의 수 -1` <-- 이걸 기억하세여..  \n",
    "- 일부 교재 설명: `Layer의 수 = Hidden Layer의 수 + 출력층의 수 = Hidden Layer의 수 + 1` <-- 기억하지 마세여 \n",
    "- 위의 예제의 경우 `number of hidden layer = 1` 이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028301eb-ec4a-4d94-86da-dec8b2379c7b",
   "metadata": {
    "tags": []
   },
   "source": [
    "::: {.callout-important}\n",
    "무조건 학습가능한 파라메터가 몇겹으로 있는지만 판단하세요. 딴거 아무것도 생각하지마세여\n",
    "\n",
    "```Python\n",
    "## 예시1 -- 2층 (히든레이어는 1층)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    ")\n",
    "```\n",
    "\n",
    "```Python\n",
    "## 예시2 -- 2층 (히든레이어는 1층)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.Sigmoid(),\n",
    ")\n",
    "```\n",
    "\n",
    "```Python\n",
    "## 예시3 -- 1층 (히든레이어는 없음!!)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    ") \n",
    "```\n",
    "\n",
    "```Python\n",
    "## 예시4 -- 1층 (히든레이어는 없음!!)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.Sigmoid()\n",
    ") \n",
    "```\n",
    "\n",
    "```Python\n",
    "## 예시5 -- 3층 (히든레이어는 2층)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.Sigmoid()\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.Sigmoid()\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층    \n",
    ") \n",
    "```\n",
    "\n",
    "```Python\n",
    "## 예시6 -- 3층 (히든레이어는 2층)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.ReLU()\n",
    "    torch.nn.Dropout(??)\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.ReLU()\n",
    "    torch.nn.Dropout(??)\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층  \n",
    "    torch.nn.Sigmoid()\n",
    ") \n",
    "```\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c93f06-2a53-46b5-bf86-7df852c6f90d",
   "metadata": {
    "tags": []
   },
   "source": [
    "::: {.callout-important}\n",
    "\n",
    "문헌에 따라서 레이어를 세는 개념이 제가 설명한 방식과 다른경우가 있습니다. 제가 설명한 방식보다 1씩 더해서 셉니다. 즉 아래의 경우 레이어를 3개로 카운트합니다. \n",
    "```Python\n",
    "## 예시1 -- 문헌에 따라 3층으로 세는 경우가 있음 (히든레이어는 1층)\n",
    "torch.nn.Sequential(\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(??,??), ## <-- 학습해야할 가중치가 있는 층\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "```\n",
    "예를 들어 [여기](https://en.wikipedia.org/wiki/Multilayer_perceptron#Layers)에서는 위의 경우 레이어는 3개라고 설명하고 있습니다. 이러한 카운팅은 **\"무시\"하세요. 제가 설명한 방식이 맞아요.** [이 링크](https://en.wikipedia.org/wiki/Multilayer_perceptron#Layers) 잘못(?) 나와있는 이유는 아래와 같습니다. \n",
    "\n",
    "`-` 진짜 예전에 MLP를 소개할 초창기에서는 위의 경우 Layer를 3개로 셌음. [@rosenblatt1962principles]\n",
    "\n",
    "`-` 그런데 요즘은 그렇게 안셈.. (그리고 애초에 MLP라는 용어도 잘 안쓰죠..)\n",
    "\n",
    "참고로 히든레이어의 수는 예전방식이나 지금방식이나 동일하게 카운트하므로 히든레이어만 세면 혼돈이 없습니다. \n",
    "\n",
    ":::"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527c8202-5c4a-40d4-a81d-23072c6ccac4",
   "metadata": {},
   "source": [
    "`*` node의 개념: $u\\to v$로 가는 쌍을 간단히 노드라는 개념을 이용하여 나타낼 수 있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56a6e7e-769e-4fa8-a259-b3ba18e80f5b",
   "metadata": {},
   "source": [
    "**(노드의 개념이 포함된 그림)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1a4e10-72c6-4606-a49d-df8ffe87dc26",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-13-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c2d185-ed7a-4374-8cff-4181bb9ad8d8",
   "metadata": {},
   "source": [
    "여기에서 `node의 숫자 = feature의 숫자`와 같이 이해할 수 있다. 즉 아래와 같이 이해할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca339b0e-0b0a-40b5-99d2-f39fef6d2034",
   "metadata": {},
   "source": [
    "**(\"number of nodes = number of features\"로 이해한 그림)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e15576-7902-443e-a6eb-99a0447c8ec9",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-14-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a78987d-8859-4791-8818-db4b85b1d77a",
   "metadata": {},
   "source": [
    "> 다이어그램의 표현방식은 교재마다 달라서 모든 예시를 달달 외울 필요는 없습니다. 다만 임의의 다이어그램을 보고 대응하는 네트워크를 pytorch로 구현하는 능력은 매우 중요합니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f612b662-ee5b-4612-ab90-c6c4bab8b000",
   "metadata": {},
   "source": [
    "## 예제3: $\\underset{(n,784)}{\\bf X} \\overset{l_1}{\\to} \\underset{(n,32)}{\\boldsymbol u^{(1)}} \\overset{relu}{\\to} \\underset{(n,32)}{\\boldsymbol v^{(1)}} \\overset{l_1}{\\to} \\underset{(n,1)}{\\boldsymbol u^{(2)}} \\overset{sig}{\\to} \\underset{(n,1)}{\\boldsymbol v^{(2)}}=\\underset{(n,1)}{\\hat{\\boldsymbol y}}$  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1502a477-c447-4ab7-8b0b-670d7642ef50",
   "metadata": {},
   "source": [
    "**(다이어그램표현)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a029422-8dde-409c-b3ab-e4e3037e25dd",
   "metadata": {},
   "source": [
    "![](https://guebin.github.io/DL2022/posts/II.%20DNN/2022-10-11-6wk-2_files/figure-html/cell-15-output-1.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ad4267c-1e70-4a67-a2c1-b6d9ac42c47b",
   "metadata": {},
   "source": [
    "- Layer0,1,2 대신에 Input Layer, Hidden Layer, Output Layer로 표현함 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49fef3b-df81-40ac-b711-d5c7143d1c17",
   "metadata": {},
   "source": [
    "`-` 위의 다이어그램에 대응하는 코드\n",
    "\n",
    "```Python\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=28*28*1,out_features=32),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=32,out_features=1),\n",
    "    torch.nn.Sigmoid() \n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b476c-9e78-40a9-b10c-3a22e16e15bd",
   "metadata": {},
   "source": [
    "# 6. 숙제 -- 나 혼자 내고 나 혼자 품.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436f0e05-a788-4fff-a63e-a511a622c496",
   "metadata": {},
   "source": [
    "아래의 아키텍처를 가지는 네트워크를 파이토치코드로 선언하라. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379f44e3-2b02-4cfe-97c1-c6730d726d52",
   "metadata": {},
   "source": [
    "![출처: <https://aws.amazon.com/ko/what-is/deep-learning/>](https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2017/10/06/intro-gluon-1.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f40a02f-d997-40fa-b751-4971e01b85b6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(784,128),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(128,64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64,10),\n",
    "    #torch.nn.Softmax()\n",
    ")\n",
    "loss_fn = torch.nn.CrossEntropyLoss() # <- 이 로스에 torch.nn.Softmax() 가 사실 포함되어있음.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
