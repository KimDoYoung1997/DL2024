{
 "cells": [
  {
   "cell_type": "raw",
   "id": "855d203d-e1fd-40dc-9c2c-e90e8380f06e",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"13wk-1: 강화학습 (1) -- bandit\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/29/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c13712-1185-4386-90e7-3e23c62be398",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/13wk-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0d11f9-7f12-401a-82da-e4b2e568dde6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4685c071-46e9-4bcb-84a7-ece876eb4654",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#{{<video https://youtu.be/playlist?list=PLQqh36zP38-zoOHd7w3N5q9Jc5P34Ux8X&si=MdJTHM3a27MCAssp >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963beba8-d0a6-487b-bc61-2bfa3d05b255",
   "metadata": {},
   "source": [
    "# 2. 환경셋팅 ($\\star\\star\\star$)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb23742-65c3-4c4c-88c1-94a0aa048bd1",
   "metadata": {},
   "source": [
    "`-` 설치 (코랩)\n",
    "\n",
    "```Python\n",
    "!pip install -q swig\n",
    "!pip install gymnasium\n",
    "!pip install gymnasium[box2d]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc5c5b0-94a7-4a3d-bb6c-1623909505e1",
   "metadata": {},
   "source": [
    "# 3. Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "da124c05-12c5-4e50-b7c2-c7156427cc82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae27afc5-05fd-48ec-9059-29a4523ef47c",
   "metadata": {},
   "source": [
    "- ref: <https://gymnasium.farama.org/index.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69de1a84-3d65-40d2-a1ee-3f5213791081",
   "metadata": {},
   "source": [
    "# 4. 강화학습 Intro "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e0f4e9-06d3-412a-9bd9-79399e11414f",
   "metadata": {},
   "source": [
    "`-` 강화학습(대충설명): 어떠한 \"(게임)환경\"이 있을때 거기서 \"뭘 할지\"를 학습하는 과업"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eab2ee-e9e4-4032-8344-a72188f96b27",
   "metadata": {},
   "source": [
    "`-` 딥마인드: breakout $\\to$ 알파고 \n",
    "\n",
    "- <https://www.youtube.com/watch?v=TmPfTpjtdgg>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047016d4-087a-4087-8440-072610804ec2",
   "metadata": {},
   "source": [
    "`-` 강화학습 미래? (이거 잘하면 먹고 살 수 있을까?) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a79839a6-f30a-4a3c-baf9-aa3ccc8797e5",
   "metadata": {},
   "source": [
    "# 5. Game1: `Bandit` 게임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b366221-0891-4c37-8e73-bd1622cd0a0d",
   "metadata": {},
   "source": [
    "## A. 게임설명 및 원시코드"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b629176-ac93-4d67-8c4c-ce616e8709f0",
   "metadata": {},
   "source": [
    "`-` 문제설명: 두 개의 버튼이 있다. 버튼0을 누르면 1의 보상을, 버튼1을 누르면 100의 보상을 준다고 가정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f0db51-86d9-45c1-925b-23561fe9d0d0",
   "metadata": {},
   "source": [
    "`-` 처음에 어떤 행동을 해야 하는가? ---> ??? 처음에는 아는게 없음 ---> 일단 \"아무거나\" 눌러보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d02dba-7da9-48b9-8371-18ceea6de043",
   "metadata": {},
   "source": [
    "`-` 버튼을 아무거나 누르는 함수를 구현해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cd4a7dbb-f420-479c-a420-4097bb2bad59",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'button1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = ['button0', 'button1'] \n",
    "action = np.random.choice(action_space)\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b58ae92-18be-4d72-9be9-6bed4ac5d7ef",
   "metadata": {},
   "source": [
    "`-` 보상을 주는 함수를 구현해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "61b66eff-ec7c-4884-9e55-0a61279495a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if action == 'button0': # button0을 눌렀다면 \n",
    "    reward = 1 \n",
    "else: # button1을 눌렀다면 \n",
    "    reward = 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d81e4baa-7bb5-4dfd-a786-488ac021a364",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2653f6-e9b0-4aff-b52e-a3e2cc34414a",
   "metadata": {},
   "source": [
    "`-` 아무버튼이나 10번정도 눌러보면서 데이터를 쌓아보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1e676d0-b3b8-427d-ace9-a887ff371c9e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button0 1\n",
      "button0 1\n",
      "button1 100\n",
      "button0 1\n",
      "button0 1\n",
      "button1 100\n",
      "button0 1\n",
      "button0 1\n",
      "button1 100\n",
      "button0 1\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = np.random.choice(action_space)\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else: \n",
    "        reward = 100     \n",
    "    print(action,reward) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821cb259-4d6d-468b-8dc7-d61154be7ecd",
   "metadata": {},
   "source": [
    "`-` 깨달았음: `button0`을 누르면 1점을 받고, `button1`을 누르면 100점을 받는 \"환경\"이구나? $\\to$ `button1`을 누르는 \"동작\"을 해야하는 상황이구나? \n",
    "\n",
    "- 여기에서 $\\to$의 과정을 체계화 시킨 학문이 강화학습 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "84bb28cb-bae0-4364-b208-43f88a1e8690",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n",
      "button1 100\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    action = action_space[1]\n",
    "    if action == 'button0': \n",
    "        reward = 1 \n",
    "    else: \n",
    "        reward = 100     \n",
    "    print(action,reward) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d1129a-5d3e-47f7-b3b8-d90631494289",
   "metadata": {},
   "source": [
    "- 게임 클리어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cdee96-6c0e-4e26-8551-d76ce1629188",
   "metadata": {},
   "source": [
    "`-` 강화학습: 환경을 이해 $\\to$ 행동을 결정 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df2f276-9417-4a55-9ca2-016dbf1bc921",
   "metadata": {},
   "source": [
    "***위의 과정이 잘 되었다는 의미로 사용하는 문장들*** \n",
    "\n",
    "- 강화학습이 성공적으로 잘 되었다. \n",
    "- 에이전트가 환경의 과제를 완료했다. \n",
    "- 에이전트가 환경에서 성공적으로 학습했다. \n",
    "- 에이전트가 올바른 행동을 학습했다. \n",
    "- 게임 클리어 (비공식) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6947330d-217b-4ae6-90f2-bdc44cf60d49",
   "metadata": {},
   "source": [
    "`-` 게임이 클리어 되었다는 것을 의미하는 지표를 정하고 싶다. \n",
    "\n",
    "- 첫 생각: `button1`을 누르는 순간 게임클리어로 보면 되지 않나?\n",
    "- 두번째 생각: 아니지? 우연히 누를수도 있잖아?\n",
    "- 게임클리어조건: 최근 20번의 보상이 1900점 이상이면 게임이 클리어 되었다고 생각하자.^[`button1`을 눌러야 하는건 맞지만 20번에 한번정도의 실수는 눈감아 주는 조건]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f6dc80-305e-4fb7-a6e2-817a49e7db52",
   "metadata": {},
   "source": [
    "`-` 무지한자 -- 게임을 클리어할 수 없다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "88406414-89f3-44bc-bdd7-bc1b43788f74",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 1\treward= 100\treward20= 100\t\n",
      "n_try = 2\taction= 0\treward= 1\treward20= 101\t\n",
      "n_try = 3\taction= 1\treward= 100\treward20= 201\t\n",
      "n_try = 4\taction= 0\treward= 1\treward20= 202\t\n",
      "n_try = 5\taction= 1\treward= 100\treward20= 302\t\n",
      "n_try = 6\taction= 1\treward= 100\treward20= 402\t\n",
      "n_try = 7\taction= 1\treward= 100\treward20= 502\t\n",
      "n_try = 8\taction= 1\treward= 100\treward20= 602\t\n",
      "n_try = 9\taction= 1\treward= 100\treward20= 702\t\n",
      "n_try = 10\taction= 1\treward= 100\treward20= 802\t\n",
      "n_try = 11\taction= 1\treward= 100\treward20= 902\t\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 1002\t\n",
      "n_try = 13\taction= 0\treward= 1\treward20= 1003\t\n",
      "n_try = 14\taction= 0\treward= 1\treward20= 1004\t\n",
      "n_try = 15\taction= 0\treward= 1\treward20= 1005\t\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 1105\t\n",
      "n_try = 17\taction= 1\treward= 100\treward20= 1205\t\n",
      "n_try = 18\taction= 0\treward= 1\treward20= 1206\t\n",
      "n_try = 19\taction= 0\treward= 1\treward20= 1207\t\n",
      "n_try = 20\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 21\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 22\taction= 0\treward= 1\treward20= 1307\t\n",
      "n_try = 23\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 24\taction= 0\treward= 1\treward20= 1307\t\n",
      "n_try = 25\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 26\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 27\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 28\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 29\taction= 1\treward= 100\treward20= 1109\t\n",
      "n_try = 30\taction= 1\treward= 100\treward20= 1109\t\n",
      "n_try = 31\taction= 0\treward= 1\treward20= 1010\t\n",
      "n_try = 32\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 33\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 34\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 35\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 36\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 37\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 38\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 39\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 40\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 41\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 42\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 43\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 44\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 45\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 46\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 47\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 48\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 49\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 50\taction= 0\treward= 1\treward20= 812\t\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "rewards = [] \n",
    "for t in range(50): # 10000번을 해도 못깸 \n",
    "    action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f2f62e-2057-447e-99da-9ffffd21b510",
   "metadata": {},
   "source": [
    "`-` 깨달은자 -- 게임클리어 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a2f7b8d7-ba44-4bc7-987d-bd2660890203",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 1\treward= 100\treward20= 100\t\n",
      "n_try = 2\taction= 1\treward= 100\treward20= 200\t\n",
      "n_try = 3\taction= 1\treward= 100\treward20= 300\t\n",
      "n_try = 4\taction= 1\treward= 100\treward20= 400\t\n",
      "n_try = 5\taction= 1\treward= 100\treward20= 500\t\n",
      "n_try = 6\taction= 1\treward= 100\treward20= 600\t\n",
      "n_try = 7\taction= 1\treward= 100\treward20= 700\t\n",
      "n_try = 8\taction= 1\treward= 100\treward20= 800\t\n",
      "n_try = 9\taction= 1\treward= 100\treward20= 900\t\n",
      "n_try = 10\taction= 1\treward= 100\treward20= 1000\t\n",
      "n_try = 11\taction= 1\treward= 100\treward20= 1100\t\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 1200\t\n",
      "n_try = 13\taction= 1\treward= 100\treward20= 1300\t\n",
      "n_try = 14\taction= 1\treward= 100\treward20= 1400\t\n",
      "n_try = 15\taction= 1\treward= 100\treward20= 1500\t\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 1600\t\n",
      "n_try = 17\taction= 1\treward= 100\treward20= 1700\t\n",
      "n_try = 18\taction= 1\treward= 100\treward20= 1800\t\n",
      "n_try = 19\taction= 1\treward= 100\treward20= 1900\t\n"
     ]
    }
   ],
   "source": [
    "action_space = [0,1]\n",
    "rewards = [] \n",
    "for t in range(50): # 10000번을 해도 못깸 \n",
    "    #action = np.random.choice(action_space) # 무지한자의 행동 (찍어) \n",
    "    action = 1\n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e7aff0-5d87-4f25-8ffe-ec9a5547e975",
   "metadata": {},
   "source": [
    "## B. 수정1: `action_space`의 수정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ef224ee2-c37f-46cc-aeac-3ba69e84e798",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Discrete(2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2)\n",
    "action_space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cecaec-3717-4d73-8d8f-9adce9c3ce84",
   "metadata": {},
   "source": [
    "`-` 좋은점1: sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "38ffbc03-4b50-4064-8e3c-07f2728afed4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(action_space.sample())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1852f9bb-0584-4239-aa08-38d6cf2821ff",
   "metadata": {},
   "source": [
    "`-` 좋은점2: in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8b0b6d5c-7ceb-48d0-8d30-e83cadbd9d19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 in action_space # 유효한 액션을 검사 -- 0은 유효한 액션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6921440d-1559-4820-9e09-e0804f961ca2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 in action_space # 유효한 액션을 검사 -- 1은 유효한 액션 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ce09141e-9a78-4946-8020-09340e26d8f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 in action_space # 유효한 액션을 검사 -- 2는 유효하지 않은 액션 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e9288c-40e4-4641-8e00-44bc4cd277d9",
   "metadata": {},
   "source": [
    "`-` 코드 1차수정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "46b2ed36-1c39-40f6-9d71-47e7d6ef191d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 0\treward= 1\treward20= 1\t\n",
      "n_try = 2\taction= 1\treward= 100\treward20= 101\t\n",
      "n_try = 3\taction= 0\treward= 1\treward20= 102\t\n",
      "n_try = 4\taction= 0\treward= 1\treward20= 103\t\n",
      "n_try = 5\taction= 0\treward= 1\treward20= 104\t\n",
      "n_try = 6\taction= 1\treward= 100\treward20= 204\t\n",
      "n_try = 7\taction= 1\treward= 100\treward20= 304\t\n",
      "n_try = 8\taction= 0\treward= 1\treward20= 305\t\n",
      "n_try = 9\taction= 0\treward= 1\treward20= 306\t\n",
      "n_try = 10\taction= 1\treward= 100\treward20= 406\t\n",
      "n_try = 11\taction= 1\treward= 100\treward20= 506\t\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 606\t\n",
      "n_try = 13\taction= 1\treward= 100\treward20= 706\t\n",
      "n_try = 14\taction= 1\treward= 100\treward20= 806\t\n",
      "n_try = 15\taction= 0\treward= 1\treward20= 807\t\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 907\t\n",
      "n_try = 17\taction= 0\treward= 1\treward20= 908\t\n",
      "n_try = 18\taction= 1\treward= 100\treward20= 1008\t\n",
      "n_try = 19\taction= 1\treward= 100\treward20= 1108\t\n",
      "n_try = 20\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 21\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 22\taction= 1\treward= 100\treward20= 1109\t\n",
      "n_try = 23\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 24\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 25\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 26\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 27\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 28\taction= 1\treward= 100\treward20= 1307\t\n",
      "n_try = 29\taction= 0\treward= 1\treward20= 1307\t\n",
      "n_try = 30\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 31\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 32\taction= 1\treward= 100\treward20= 1109\t\n",
      "n_try = 33\taction= 0\treward= 1\treward20= 1010\t\n",
      "n_try = 34\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 35\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 36\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 37\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 38\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 39\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 40\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 41\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 42\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 43\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 44\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 45\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 46\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 47\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 48\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 49\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 50\taction= 0\treward= 1\treward20= 911\t\n"
     ]
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2) \n",
    "rewards = [] \n",
    "for t in range(50): \n",
    "    action = action_space.sample()\n",
    "    #action = 1\n",
    "    if action == 0: \n",
    "        reward = 1 \n",
    "        rewards.append(reward)\n",
    "    else: \n",
    "        reward = 100\n",
    "        rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd4cff1-c6d8-4ae2-b8c0-8fb1422485f0",
   "metadata": {},
   "source": [
    "## C. 수정2: `Env` 클래스구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaf810ba-a4dc-407f-93c6-54d9784b5109",
   "metadata": {},
   "source": [
    "`-` env 클래스 선언 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c6091a16-b766-4546-aa94-877ed2653c52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Bandit: \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 100 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "28fb2c07-c995-4270-8f44-352b16fa9ca0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 1\treward= 100\treward20= 100\t\n",
      "n_try = 2\taction= 1\treward= 100\treward20= 200\t\n",
      "n_try = 3\taction= 1\treward= 100\treward20= 300\t\n",
      "n_try = 4\taction= 1\treward= 100\treward20= 400\t\n",
      "n_try = 5\taction= 1\treward= 100\treward20= 500\t\n",
      "n_try = 6\taction= 1\treward= 100\treward20= 600\t\n",
      "n_try = 7\taction= 1\treward= 100\treward20= 700\t\n",
      "n_try = 8\taction= 1\treward= 100\treward20= 800\t\n",
      "n_try = 9\taction= 1\treward= 100\treward20= 900\t\n",
      "n_try = 10\taction= 1\treward= 100\treward20= 1000\t\n",
      "n_try = 11\taction= 1\treward= 100\treward20= 1100\t\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 1200\t\n",
      "n_try = 13\taction= 1\treward= 100\treward20= 1300\t\n",
      "n_try = 14\taction= 1\treward= 100\treward20= 1400\t\n",
      "n_try = 15\taction= 1\treward= 100\treward20= 1500\t\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 1600\t\n",
      "n_try = 17\taction= 1\treward= 100\treward20= 1700\t\n",
      "n_try = 18\taction= 1\treward= 100\treward20= 1800\t\n",
      "n_try = 19\taction= 1\treward= 100\treward20= 1900\t\n"
     ]
    }
   ],
   "source": [
    "action_space = gym.spaces.Discrete(2) \n",
    "env = Bandit()\n",
    "rewards = []\n",
    "for t in range(50): \n",
    "    #action = action_space.sample()\n",
    "    action = 1\n",
    "    reward = env.step(action)\n",
    "    rewards.append(reward)\n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {action}\\t\"\n",
    "        f\"reward= {reward}\\t\"\n",
    "        f\"reward20= {sum(rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124b10aa-1577-4438-8878-d93414e0592b",
   "metadata": {},
   "source": [
    "## D. 수정3: `Agent` 클래스 구현 (랜덤행동)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10343b7-fb36-479e-aca1-61a94cc045e9",
   "metadata": {},
   "source": [
    "`-` Agent 클래스를 만들자. (액션을 하고, 환경에서 받은 reward를 간직) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e5d87ae-8fe3-417d-848a-f49786c2b2ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2) \n",
    "        self.action = None \n",
    "        self.reward = None \n",
    "        self.actions = [] \n",
    "        self.rewards = []\n",
    "    def act(self):\n",
    "        self.action = self.action_space.sample() # 무지한자 \n",
    "        #self.action = 1 # 깨달은 자\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a993f656-12f6-47a3-bc8c-b3e15d147c45",
   "metadata": {},
   "source": [
    "--- 대충 아래와 같은 느낌으로 코드가 돌아가요 ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea9c806-87eb-4892-b38c-8c7229ad7ee6",
   "metadata": {},
   "source": [
    "**시점0**: init "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6ee01a47-2ecc-41c9-9344-419f06f89d09",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env = Bandit()\n",
    "agent = Agent() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "43397ed8-1846-4db8-85e5-feab67bb12f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75799c0a-2ee2-4229-8ee3-6d259c430355",
   "metadata": {},
   "source": [
    "**시점1**: agent >> env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "94b910e3-9d0d-4e32-bfe4-1ea5bc7a537b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.act()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "88ca0c67-6c67-461b-adad-5781c23e366a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, None)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "390746fe-70f2-42ff-97e7-02872bf725fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env.agent_action = agent.action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32765dfd-7627-4fca-b565-a290855b1991",
   "metadata": {},
   "source": [
    "**시점2**: agent << env "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0c06f08a-96f0-454f-bb0e-76f3b80650a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.reward = env.step(env.agent_action)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "92121832-fc74-40ca-885b-1b7ebbc0b2ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 100, 1)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.action, agent.reward, env.agent_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5de5658f-352b-4080-a452-c7b9ceb32181",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([], [])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5e3ea513-38ff-42a0-b298-c2b17347e30c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.save_experience()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "89f2ead3-14ff-4db7-91b7-e7444900a2ae",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1], [100])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.actions,agent.rewards"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae975d1-5725-41f0-b063-3d57fb6f91df",
   "metadata": {},
   "source": [
    "-- 전체코드 -- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94d5f2d2-b38f-472c-97b1-a64c58f68455",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 1\treward= 100\treward20= 100\t\n",
      "n_try = 2\taction= 0\treward= 1\treward20= 101\t\n",
      "n_try = 3\taction= 1\treward= 100\treward20= 201\t\n",
      "n_try = 4\taction= 0\treward= 1\treward20= 202\t\n",
      "n_try = 5\taction= 1\treward= 100\treward20= 302\t\n",
      "n_try = 6\taction= 0\treward= 1\treward20= 303\t\n",
      "n_try = 7\taction= 0\treward= 1\treward20= 304\t\n",
      "n_try = 8\taction= 1\treward= 100\treward20= 404\t\n",
      "n_try = 9\taction= 1\treward= 100\treward20= 504\t\n",
      "n_try = 10\taction= 1\treward= 100\treward20= 604\t\n",
      "n_try = 11\taction= 1\treward= 100\treward20= 704\t\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 804\t\n",
      "n_try = 13\taction= 0\treward= 1\treward20= 805\t\n",
      "n_try = 14\taction= 0\treward= 1\treward20= 806\t\n",
      "n_try = 15\taction= 1\treward= 100\treward20= 906\t\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 1006\t\n",
      "n_try = 17\taction= 0\treward= 1\treward20= 1007\t\n",
      "n_try = 18\taction= 0\treward= 1\treward20= 1008\t\n",
      "n_try = 19\taction= 1\treward= 100\treward20= 1108\t\n",
      "n_try = 20\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 21\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 22\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 23\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 24\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 25\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 26\taction= 1\treward= 100\treward20= 1208\t\n",
      "n_try = 27\taction= 0\treward= 1\treward20= 1208\t\n",
      "n_try = 28\taction= 0\treward= 1\treward20= 1109\t\n",
      "n_try = 29\taction= 1\treward= 100\treward20= 1109\t\n",
      "n_try = 30\taction= 0\treward= 1\treward20= 1010\t\n",
      "n_try = 31\taction= 1\treward= 100\treward20= 1010\t\n",
      "n_try = 32\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 33\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 34\taction= 0\treward= 1\treward20= 911\t\n",
      "n_try = 35\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 36\taction= 0\treward= 1\treward20= 713\t\n",
      "n_try = 37\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 38\taction= 1\treward= 100\treward20= 911\t\n",
      "n_try = 39\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 40\taction= 0\treward= 1\treward20= 713\t\n",
      "n_try = 41\taction= 0\treward= 1\treward20= 713\t\n",
      "n_try = 42\taction= 1\treward= 100\treward20= 713\t\n",
      "n_try = 43\taction= 1\treward= 100\treward20= 713\t\n",
      "n_try = 44\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 45\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 46\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 47\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 48\taction= 0\treward= 1\treward20= 812\t\n",
      "n_try = 49\taction= 1\treward= 100\treward20= 812\t\n",
      "n_try = 50\taction= 0\treward= 1\treward20= 812\t\n"
     ]
    }
   ],
   "source": [
    "env = Bandit() \n",
    "agent = Agent()\n",
    "for t in range(50): \n",
    "    ## 1. main 코드 \n",
    "    # step1: agent >> env \n",
    "    agent.act() \n",
    "    env.agent_action = agent.action\n",
    "    # step2: agent << env \n",
    "    agent.reward = env.step(env.agent_action)\n",
    "    agent.save_experience() \n",
    "\n",
    "    ## 2. 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {agent.action}\\t\"\n",
    "        f\"reward= {agent.reward}\\t\"\n",
    "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>=1900:\n",
    "        break "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b17361b-9b5c-461a-b6a3-574c8e1c904b",
   "metadata": {},
   "source": [
    "## E. 수정4: `Agent.learn()` 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e84973-7e84-44f0-b0c0-a86889a39205",
   "metadata": {},
   "source": [
    "`-` Game1에 대한 생각: \n",
    "\n",
    "- 사실 강화학습은 \"환경을 이해 $\\to$ 행동을 결정\" 의 과정에서 $\\to$의 과정을 수식화 한 것이다.\n",
    "- 그런데 지금까지 했던 코드는 환경(env)를 이해하는 순간 에이전트가 최적의 행동(action)^[`button1`을 누른다]을 직관적으로 결정하였으므로 기계가 스스로 학습을 했다고 볼 수 없다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b280e541-17f2-4fdf-8b65-3141fb2b3811",
   "metadata": {},
   "source": [
    "`-` 지금까지의 코드 복습 \n",
    "\n",
    "1. 클래스를 선언하는 부분\n",
    "    - Env 클래스의 선언\n",
    "    - Agent 클래스의 선언\n",
    "2. 환경과 에이전트를 인스턴스화 (초기화)\n",
    "3. for loop를 반복하여 게임을 진행\n",
    "   - 메인코드: (1) agent $\\to$ env (2) agent $\\leftarrow$ env \n",
    "   - 비본질적코드: 학습과정을 display, 학습의 종료조건체크 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ab98c0-997e-4f9a-a040-6721b05ce9c6",
   "metadata": {},
   "source": [
    "`-` 앞으로 구성할 코드의 형태: 에이전트가 데이터를 보고 스스로 `button1`을 눌러야 한다는 생각을 했으면 좋겠음. \n",
    "\n",
    "1. 클래스를 선언하는 부분\n",
    "    - Env 클래스의 선언\n",
    "    - **Agent 클래스의 선언** // <---- `학습의 과정이 포함되어야 한다`, `act함수의 수정`, `learn함수의 추가` \n",
    "2. 환경과 에이전트를 인스턴스화 (초기화)\n",
    "3. for loop를 반복하여 게임을 진행\n",
    "   - **메인코드** (1) agent $\\to$ env (2) agent $\\leftarrow$ env // <---- `agent가 데이터를 분석하고 학습하는 과정이 추가`\n",
    "   - 비본질적코드: 학습과정을 display, 학습의 종료조건체크 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f1c123-5c8c-4660-9465-316bf75990f4",
   "metadata": {},
   "source": [
    "`-` 에이전트가 학습을 어떻게 하는가? 아래와 같이 버튼을 누르도록 한다면 \n",
    "\n",
    "- 버튼0을 누를 확률: $\\frac{q_0}{q_0+q_1}$\n",
    "- 버튼1을 누를 확률: $\\frac{q_1}{q_0+q_1}$\n",
    "\n",
    "시간이 지날수록 버튼1을 주로 누를 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c812320-4aca-4a7a-8690-5a5ae021d25a",
   "metadata": {},
   "source": [
    "`-` 걱정: $t=0$ 이면 어쩌지? $t=1$이면 어쩌지?... $\\to$ 해결책: 일정시간동안 랜덤액션을 하면서 데이터를 쌓고 그 뒤에 $q_0,q_1$을 계산 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52f8fb01-71c0-47f6-9484-eea924f03ccf",
   "metadata": {},
   "source": [
    "`-` 쌓은 데이터를 바탕으로 환경을 이해하고 action을 뽑는 코드 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f725954b-d1fa-47e9-ab79-46ec3a53eef2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "agent.actions = [0,1,1,0,1,0,0] \n",
    "agent.rewards = [1,101,102,1,99,1,1.2] \n",
    "actions = np.array(agent.actions)\n",
    "rewards = np.array(agent.rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2ca4712f-f522-431c-b71d-816820b5f6b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "q0 = rewards[actions == 0].mean()\n",
    "q1 = rewards[actions == 1].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0f400b80-ff55-4b0c-bb7c-6bf4eded24f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.05      , 100.66666667])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.q = np.array([q0,q1]) \n",
    "agent.q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "3d52e620-b8ed-42de-a1a1-7d5961ccbccb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01032279, 0.98967721])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob = agent.q / agent.q.sum()\n",
    "prob "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3ef3f7fe-29a4-473b-bfac-3bb00c45b045",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action = np.random.choice([0,1], p= agent.q / agent.q.sum())\n",
    "action"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8209e84e-49e3-47c1-939d-f0ab723b33cf",
   "metadata": {},
   "source": [
    "`-` 최종코드정리 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a218caa5-b032-4e57-ab22-cca6b2c8ab02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Bandit: \n",
    "    def step(self, action):\n",
    "        if action == 0:\n",
    "            return 1 \n",
    "        else: \n",
    "            return 100 \n",
    "class Agent:\n",
    "    def __init__(self):\n",
    "        self.action_space = gym.spaces.Discrete(2) \n",
    "        self.action = None \n",
    "        self.reward = None \n",
    "        self.actions = [] \n",
    "        self.rewards = []\n",
    "        self.q = np.array([0,0]) \n",
    "        self.n_experience = 0 \n",
    "    def act(self):\n",
    "        if self.n_experience<30: \n",
    "            self.action = self.action_space.sample() \n",
    "        else: \n",
    "            self.action = np.random.choice([0,1], p= self.q / self.q.sum())\n",
    "    def save_experience(self):\n",
    "        self.actions.append(self.action)\n",
    "        self.rewards.append(self.reward)\n",
    "        self.n_experience += 1 \n",
    "    def learn(self):\n",
    "        if self.n_experience<30: \n",
    "            pass \n",
    "        else: \n",
    "            actions = np.array(self.actions)\n",
    "            rewards = np.array(self.rewards)\n",
    "            q0 = rewards[actions == 0].mean()\n",
    "            q1 = rewards[actions == 1].mean()\n",
    "            self.q = np.array([q0,q1]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23269b00-b8b6-4e57-89b2-963594874899",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_try = 1\taction= 0\treward= 1\treward20= 1\tq = [0 0]\n",
      "n_try = 2\taction= 0\treward= 1\treward20= 2\tq = [0 0]\n",
      "n_try = 3\taction= 1\treward= 100\treward20= 102\tq = [0 0]\n",
      "n_try = 4\taction= 0\treward= 1\treward20= 103\tq = [0 0]\n",
      "n_try = 5\taction= 1\treward= 100\treward20= 203\tq = [0 0]\n",
      "n_try = 6\taction= 1\treward= 100\treward20= 303\tq = [0 0]\n",
      "n_try = 7\taction= 0\treward= 1\treward20= 304\tq = [0 0]\n",
      "n_try = 8\taction= 0\treward= 1\treward20= 305\tq = [0 0]\n",
      "n_try = 9\taction= 0\treward= 1\treward20= 306\tq = [0 0]\n",
      "n_try = 10\taction= 0\treward= 1\treward20= 307\tq = [0 0]\n",
      "n_try = 11\taction= 0\treward= 1\treward20= 308\tq = [0 0]\n",
      "n_try = 12\taction= 1\treward= 100\treward20= 408\tq = [0 0]\n",
      "n_try = 13\taction= 1\treward= 100\treward20= 508\tq = [0 0]\n",
      "n_try = 14\taction= 0\treward= 1\treward20= 509\tq = [0 0]\n",
      "n_try = 15\taction= 1\treward= 100\treward20= 609\tq = [0 0]\n",
      "n_try = 16\taction= 1\treward= 100\treward20= 709\tq = [0 0]\n",
      "n_try = 17\taction= 1\treward= 100\treward20= 809\tq = [0 0]\n",
      "n_try = 18\taction= 0\treward= 1\treward20= 810\tq = [0 0]\n",
      "n_try = 19\taction= 0\treward= 1\treward20= 811\tq = [0 0]\n",
      "n_try = 20\taction= 0\treward= 1\treward20= 812\tq = [0 0]\n",
      "n_try = 21\taction= 0\treward= 1\treward20= 812\tq = [0 0]\n",
      "n_try = 22\taction= 1\treward= 100\treward20= 911\tq = [0 0]\n",
      "n_try = 23\taction= 0\treward= 1\treward20= 812\tq = [0 0]\n",
      "n_try = 24\taction= 1\treward= 100\treward20= 911\tq = [0 0]\n",
      "n_try = 25\taction= 1\treward= 100\treward20= 911\tq = [0 0]\n",
      "n_try = 26\taction= 1\treward= 100\treward20= 911\tq = [0 0]\n",
      "n_try = 27\taction= 1\treward= 100\treward20= 1010\tq = [0 0]\n",
      "n_try = 28\taction= 0\treward= 1\treward20= 1010\tq = [0 0]\n",
      "n_try = 29\taction= 1\treward= 100\treward20= 1109\tq = [0 0]\n",
      "n_try = 30\taction= 0\treward= 1\treward20= 1109\tq = [  1. 100.]\n",
      "n_try = 31\taction= 1\treward= 100\treward20= 1208\tq = [  1. 100.]\n",
      "n_try = 32\taction= 1\treward= 100\treward20= 1208\tq = [  1. 100.]\n",
      "n_try = 33\taction= 1\treward= 100\treward20= 1208\tq = [  1. 100.]\n",
      "n_try = 34\taction= 1\treward= 100\treward20= 1307\tq = [  1. 100.]\n",
      "n_try = 35\taction= 1\treward= 100\treward20= 1307\tq = [  1. 100.]\n",
      "n_try = 36\taction= 1\treward= 100\treward20= 1307\tq = [  1. 100.]\n",
      "n_try = 37\taction= 1\treward= 100\treward20= 1307\tq = [  1. 100.]\n",
      "n_try = 38\taction= 1\treward= 100\treward20= 1406\tq = [  1. 100.]\n",
      "n_try = 39\taction= 1\treward= 100\treward20= 1505\tq = [  1. 100.]\n",
      "n_try = 40\taction= 1\treward= 100\treward20= 1604\tq = [  1. 100.]\n",
      "n_try = 41\taction= 1\treward= 100\treward20= 1703\tq = [  1. 100.]\n",
      "n_try = 42\taction= 1\treward= 100\treward20= 1703\tq = [  1. 100.]\n",
      "n_try = 43\taction= 1\treward= 100\treward20= 1802\tq = [  1. 100.]\n",
      "n_try = 44\taction= 1\treward= 100\treward20= 1802\tq = [  1. 100.]\n",
      "n_try = 45\taction= 1\treward= 100\treward20= 1802\tq = [  1. 100.]\n",
      "n_try = 46\taction= 1\treward= 100\treward20= 1802\tq = [  1. 100.]\n",
      "n_try = 47\taction= 1\treward= 100\treward20= 1802\tq = [  1. 100.]\n",
      "n_try = 48\taction= 1\treward= 100\treward20= 1901\tq = [  1. 100.]\n"
     ]
    }
   ],
   "source": [
    "env = Bandit() \n",
    "agent = Agent()\n",
    "for t in range(50): \n",
    "    ## 1. main 코드 \n",
    "    # step1: agent >> env \n",
    "    agent.act() \n",
    "    env.agent_action = agent.action\n",
    "    # step2: agent << env \n",
    "    agent.reward = env.step(env.agent_action)\n",
    "    agent.save_experience() \n",
    "    # step3: learn \n",
    "    agent.learn()\n",
    "    ## 2. 비본질적 코드 \n",
    "    print(\n",
    "        f\"n_try = {t+1}\\t\"\n",
    "        f\"action= {agent.action}\\t\"\n",
    "        f\"reward= {agent.reward}\\t\"\n",
    "        f\"reward20= {sum(agent.rewards[-20:])}\\t\"\n",
    "        f\"q = {agent.q}\"\n",
    "    )\n",
    "    if np.sum(agent.rewards[-20:])>=1900:\n",
    "        break "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
