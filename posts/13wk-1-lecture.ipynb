{
 "cells": [
  {
   "cell_type": "raw",
   "id": "fc790e4e-de4b-44f0-bb7e-dfca30d357db",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"13wk-1: 순환신경망 (4)\"\n",
    "author: \"최규빈\"\n",
    "date: \"05/27/2024\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f4d5cc-191f-4302-b12b-3fd45659bfb1",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2296a38c-2ff6-4fd7-b15f-61f71672a07d",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 2. Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b9d91c0-5d8b-419c-8bd1-900b958ab38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94b48461-2be7-4dc9-9c8b-6538bf629cc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "soft = torch.nn.Softmax(dim=1)\n",
    "sig = torch.nn.Sigmoid()\n",
    "tanh = torch.nn.Tanh()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fd9cf8-368a-4d0d-9606-21d2e80cbe45",
   "metadata": {},
   "source": [
    "# 3. Data -- `abcabC`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01e05d7e-833a-400f-80ac-68b24310ab6a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'b', 'c', 'a', 'b', 'C', 'a', 'b', 'c', 'a']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = list('abcabC')*50\n",
    "txt[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b4937931-a9f2-4efa-95c2-39bed26cd779",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  a  b\n",
       "1  b  c\n",
       "2  c  a\n",
       "3  a  b\n",
       "4  b  C"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.DataFrame({'x':txt[:-1], 'y':txt[1:]})\n",
    "df_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8bc9363-4c7f-41dd-b5d4-c1537937979f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = torch.tensor(df_train.x.map({'a':0,'b':1,'c':2,'C':3}))\n",
    "y = torch.tensor(df_train.y.map({'a':0,'b':1,'c':2,'C':3}))\n",
    "X = torch.nn.functional.one_hot(x).float()\n",
    "y = torch.nn.functional.one_hot(y).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4be7666f-d970-4cc5-85b1-0a9e2b6c23e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1, 3,\n",
       "        0, 1, 2, 0, 1, 3, 0, 1, 2, 0, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e36548-c90c-4b5a-a917-4bbabec65fb5",
   "metadata": {},
   "source": [
    "## A. `torch.nn.LSTMCell` vs 직접구현 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da2fd203-7767-421d-9498-a19a47a54a10",
   "metadata": {},
   "source": [
    "### ***t=0 $\\to$ t=1***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c0ee60-6dd1-40f4-b818-216942e170ec",
   "metadata": {},
   "source": [
    "`-` `lstmcell`을 이용하여 $t=0 \\to t=1$을 구현해보자. (결과비교용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "d4cf1d70-d8f1-4efe-adf9-c2e1461f2a4c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "lstmcell = torch.nn.LSTMCell(4,2)\n",
    "cook = torch.nn.Linear(2,4)\n",
    "#--#\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1)\n",
    "#--#\n",
    "L = len(X)\n",
    "for epoc in range(1):\n",
    "    # step1~2\n",
    "    ht,ct = torch.zeros(2),torch.zeros(2)\n",
    "    loss = 0 \n",
    "    for t in range(1):\n",
    "        Xt,yt = X[t],y[t]\n",
    "        ht,ct = lstmcell(Xt,(ht,ct))\n",
    "        netout_t = cook(ht)  # 원래는 ot 로 썼는데, 여기서는 기호가 겹쳐서..\n",
    "        loss = loss + loss_fn(netout_t,yt)\n",
    "    loss = loss/L \n",
    "    # step3\n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e9f8b90c-3a07-46ce-8aa7-375520e8fac1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1067, 0.1069], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.1734, 0.2688], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht,ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d3c501d-3e12-4375-a97a-0393ab892e0a",
   "metadata": {},
   "source": [
    "- 이런결과를 어떻게 만드는걸까? \n",
    "- <https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a159de01-85da-486b-aed1-9e39002efac2",
   "metadata": {},
   "source": [
    "`-` 직접계산 (ifgo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b1054f6a-ca97-4cb7-8231-6e4c57ebfd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "lstmcell = torch.nn.LSTMCell(4,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "c1243742-be10-4f86-b6e8-0ce06d073775",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0053, -0.2723, -0.0628, -0.6755,  0.2795,  0.2568, -0.1140, -0.4452],\n",
      "        [ 0.3793,  0.1896,  0.1871, -0.4683,  0.4243,  0.5872,  0.0748, -0.1790],\n",
      "        [-0.5820, -0.0140, -0.2137, -0.2915, -0.4794, -0.1455,  0.6403, -0.2756],\n",
      "        [-0.5204,  0.5607, -0.1390,  0.0262, -0.3079,  0.5291, -0.6560,  0.6109]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "Parameter containing:\n",
      "tensor([-0.3136, -0.0255,  0.4522,  0.7030,  0.2806,  0.0955,  0.4741, -0.4163],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(lstmcell.weight_ih.T)\n",
    "print(lstmcell.bias_ih)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b976df17-bcc8-46f8-b121-4c9f1aa145c7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.4583, -0.4940, -0.4128,  0.3155,  0.0372,  0.1196, -0.5109,  0.4461],\n",
      "        [-0.3255, -0.6622,  0.6078,  0.3427, -0.3625, -0.6602, -0.3645,  0.4146]],\n",
      "       grad_fn=<PermuteBackward0>)\n",
      "Parameter containing:\n",
      "tensor([ 0.1318, -0.5482, -0.4901, -0.3653,  0.3199,  0.2844, -0.4189,  0.2136],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "print(lstmcell.weight_hh.T)\n",
    "print(lstmcell.bias_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "98dacd3b-ed84-4762-be20-4a472ca31ac2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Wih02 = lstmcell.weight_ih.T[:,0:2] # (4,2)\n",
    "Wih24 = lstmcell.weight_ih.T[:,2:4] # (4,2)\n",
    "Wih46 = lstmcell.weight_ih.T[:,4:6] # (4,2)\n",
    "Wih68 = lstmcell.weight_ih.T[:,6:8] # (4,2)\n",
    "#--#\n",
    "Whh02 = lstmcell.weight_hh.T[:,0:2] # (2,2)\n",
    "Whh24 = lstmcell.weight_hh.T[:,2:4] # (2,2)\n",
    "Whh46 = lstmcell.weight_hh.T[:,4:6] # (2,2)\n",
    "Whh68 = lstmcell.weight_hh.T[:,6:8] # (2,2) \n",
    "#--#\n",
    "bih02 = lstmcell.bias_ih[0:2] \n",
    "bih24 = lstmcell.bias_ih[2:4] \n",
    "bih46 = lstmcell.bias_ih[4:6] \n",
    "bih68 = lstmcell.bias_ih[6:8]\n",
    "#--#\n",
    "bhh02 = lstmcell.bias_hh[0:2] \n",
    "bhh24 = lstmcell.bias_hh[2:4] \n",
    "bhh46 = lstmcell.bias_hh[4:6] \n",
    "bhh68 = lstmcell.bias_hh[6:8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "580dbe8d-65c3-4fb0-8874-2e510bb4dd26",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ht = torch.zeros(2)\n",
    "ct = torch.zeros(2)\n",
    "#--#\n",
    "it = sig((Xt@Wih02 + bih02) + (ht@Whh02 + bhh02))\n",
    "ft = sig((Xt@Wih24 + bih24) + (ht@Whh24 + bhh24))\n",
    "gt = tanh((Xt@Wih46 + bih46) + (ht@Whh46 + bhh46))\n",
    "ot = sig((Xt@Wih68 + bih68) + (ht@Whh68 + bhh68))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8e534810-3dd8-4a35-a114-1bb700e632d9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4534, 0.3003], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.4749, 0.4163], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7065, 0.5627], grad_fn=<TanhBackward0>),\n",
       " tensor([0.4853, 0.3435], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "it,ft,gt,ot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea78947e-d331-486d-989b-744e964274ee",
   "metadata": {},
   "source": [
    "그런데 아래와 같이 계산할수도 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f6a981bb-c0f5-46de-90de-30cb0191e433",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "i = (Xt@Wih02 + bih02) + (ht@Whh02 + bhh02)\n",
    "f = (Xt@Wih24 + bih24) + (ht@Whh24 + bhh24)\n",
    "g = (Xt@Wih46 + bih46) + (ht@Whh46 + bhh46)\n",
    "o = (Xt@Wih68 + bih68) + (ht@Whh68 + bhh68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4ea6298a-f9b8-4731-ba06-07c645128cdc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1871, -0.8461, -0.1006, -0.3379,  0.8801,  0.6367, -0.0587, -0.6479],\n",
       "       grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([i,f,g,o],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "d701c1d3-bc69-4b08-b5a3-e477c0fe8f19",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1871, -0.8461, -0.1006, -0.3379,  0.8801,  0.6367, -0.0587, -0.6479],\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ifgo = Xt@ lstmcell.weight_ih.T + lstmcell.bias_ih + ht@ lstmcell.weight_hh.T + lstmcell.bias_hh\n",
    "ifgo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "aeaf54c5-1747-4aa6-920f-e9606b847d3e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.4534, 0.3003], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.4749, 0.4163], grad_fn=<SigmoidBackward0>),\n",
       " tensor([0.7065, 0.5627], grad_fn=<TanhBackward0>),\n",
       " tensor([0.4853, 0.3435], grad_fn=<SigmoidBackward0>))"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig(ifgo[0:2]), sig(ifgo[2:4]), tanh(ifgo[4:6]), sig(ifgo[6:8])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57100e52-10f9-4ad2-8b4a-64a4e54a433f",
   "metadata": {},
   "source": [
    "`-` 직접계산 (ch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "6821aeae-bb47-4bc1-b856-c3bbcf4e1945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ht = torch.zeros(2)\n",
    "ct = torch.zeros(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "11dcca4e-c6d4-4d71-b93e-0efb84a64644",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ct = it*gt + ft*ct\n",
    "ht = ot*tanh(ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "95585404-9c46-4dfa-a11a-4c05e47c4a86",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.1503, 0.0575], grad_fn=<MulBackward0>),\n",
       " tensor([0.3203, 0.1689], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht,ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6d5c0f-0e9d-4ebe-979a-59b49fe3a871",
   "metadata": {},
   "source": [
    "### `#` ***t=0 $\\to$ t=L***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1199572b-7923-432a-a556-cc7e05cce1cf",
   "metadata": {},
   "source": [
    "`-` `lstmcell`을 이용하여 구현해보자. (결과비교용)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "12df1e95-28ff-4070-89d7-80d6fb5a60b9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "lstmcell = torch.nn.LSTMCell(4,2)\n",
    "cook = torch.nn.Linear(2,4)\n",
    "#--#\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1)\n",
    "#--#\n",
    "L = len(X)\n",
    "for epoc in range(1):\n",
    "    # step1~2\n",
    "    ht,ct = torch.zeros(2),torch.zeros(2)\n",
    "    loss = 0 \n",
    "    for t in range(L):\n",
    "        Xt,yt = X[t],y[t]\n",
    "        ht,ct = lstmcell(Xt,(ht,ct))\n",
    "        netout_t = cook(ht) \n",
    "        loss = loss + loss_fn(netout_t,yt)\n",
    "    loss = loss/L \n",
    "    # step3\n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c73ed40b-b72c-43c9-8fa2-d908e01f9bd1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0533, 0.2075], grad_fn=<SqueezeBackward1>),\n",
       " tensor([0.1218, 0.5590], grad_fn=<SqueezeBackward1>))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht,ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfb2cbb-97b4-4568-a573-53e7f9db9cc9",
   "metadata": {},
   "source": [
    "`-` 직접구현 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2e5add57-c622-4b27-b8f0-18d7db9edde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "lstmcell = torch.nn.LSTMCell(4,2)\n",
    "cook = torch.nn.Linear(2,4)\n",
    "#--#\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizr = torch.optim.Adam(list(lstmcell.parameters())+list(cook.parameters()),lr=0.1)\n",
    "#--#\n",
    "L = len(X)\n",
    "for epoc in range(1):\n",
    "    # step1~2\n",
    "    ht,ct = torch.zeros(2),torch.zeros(2)\n",
    "    loss = 0 \n",
    "    for t in range(L):\n",
    "        Xt,yt = X[t],y[t]\n",
    "        ifgo = Xt@lstmcell.weight_ih.T + lstmcell.bias_ih +\\\n",
    "                ht@lstmcell.weight_hh.T + lstmcell.bias_hh\n",
    "        it,ft,gt,ot = sig(ifgo[0:2]), sig(ifgo[2:4]), tanh(ifgo[4:6]), sig(ifgo[6:8])\n",
    "        ct = it*gt + ft*ct\n",
    "        ht = ot*tanh(ct)\n",
    "        netout_t = cook(ht) \n",
    "        loss = loss + loss_fn(netout_t,yt)\n",
    "    loss = loss/L \n",
    "    # step3\n",
    "    loss.backward()\n",
    "    # step4 \n",
    "    optimizr.step()\n",
    "    optimizr.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "64621670-9a1f-49e5-8125-e7cfea4c9d84",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.0533, 0.2075], grad_fn=<MulBackward0>),\n",
       " tensor([0.1218, 0.5590], grad_fn=<AddBackward0>))"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht,ct"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ad34b2-4bdd-4e5f-ae09-7a23056bdce4",
   "metadata": {},
   "source": [
    "## C. `torch.nn.LSTM`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d13cac-068e-4f41-80c6-afb1643ed4d8",
   "metadata": {},
   "source": [
    "# 5. LSTM은 왜 강한가? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9062512-23a7-4a91-9f90-dd57aeaef2e7",
   "metadata": {},
   "source": [
    "## A. 적합 및 시각화 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f853c185-887f-44d0-9b58-59d8c46d6e2f",
   "metadata": {},
   "source": [
    "`-` 적합"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42b2ed4-3e96-4380-8300-57255b9ff37d",
   "metadata": {},
   "source": [
    "`-` 시각화 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a2a0db-0a9a-4e95-8f34-f1310f01b9aa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.axvline(x=3.5,color=\"lime\")\n",
    "# plt.xticks(\n",
    "#     ticks=range(mat.shape[-1]),\n",
    "#     labels=[r\"$g_0$\",r\"$g_1$\",r\"$h_0$\",r\"$h_1$\",\n",
    "#             r\"$P_a$\",r\"$P_b$\",r\"$P_c$\",r\"$P_C$\"]\n",
    "# )\n",
    "# plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e7c3454-dc7d-40ad-ac7f-127874016c83",
   "metadata": {},
   "source": [
    "## B. 시각화1: $({\\boldsymbol g}_t, {\\boldsymbol c}_{t-1}) \\to {\\boldsymbol c}_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21930975-d835-4198-a750-4fca0254614c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fig,ax = plt.subplots(1,3,figsize=(10,10))\n",
    "# ax[0].matshow(mat1,cmap='bwr',vmin=-1,vmax=1);\n",
    "# ax[0].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[0].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[0].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf g}_t$',r'${\\bf i}_t$',r'${\\bf g}_t \\odot {\\bf i}_t$']);\n",
    "# ax[1].matshow(mat2,cmap='bwr',vmin=-1,vmax=1);\n",
    "# ax[1].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[1].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[1].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf c}_{t-1}$',r'${\\bf f}_t$',r'${\\bf c}_{t-1} \\odot {\\bf f}_t$']);\n",
    "# ax[2].matshow(mat3,cmap='bwr',vmin=-1,vmax=1);\n",
    "# ax[2].axvline(x=1.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[2].axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# ax[2].set_xticks(ticks= [0.5,2.5,4.5],labels=[r'${\\bf g}_t \\odot {\\bf i}_t$',r'${\\bf c}_{t-1} \\odot {\\bf f}_t$',r'${\\bf c}_t$']);\n",
    "# fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc8b5f5-c135-4503-afa1-7b61a8bb92bd",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol g}_t$ 특징: 보통 -1,1 중 하나의 값을 가지도록 학습되어 있다. (마치 RNN의 hidden node처럼!) \n",
    "\n",
    "- $\\boldsymbol{g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg}+ {\\boldsymbol b}_{ig}+{\\boldsymbol b}_{hg})$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a91ff6-b0e0-4989-9231-9b4849845e95",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol c}_t$ 특징: ${\\boldsymbol g}_t$와 매우 비슷하지만 약간 다른값을 가진다. 그래서 ${\\boldsymbol g}_t$와는 달리 \n",
    "-1,1 이외의 값도 종종 등장. \n",
    "\n",
    "- ${\\boldsymbol c}_t$의 값은 이론상 제한이 없음. (꼭 -1,1 사이에 있지 않음)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efcad76-6ef5-4a06-ae6c-6134dff311f6",
   "metadata": {},
   "source": [
    "## C. 시각화2: ${\\boldsymbol g}_t \\to {\\boldsymbol h}_{t}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd867a54-e1df-43c8-8a58-1152acea1f52",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plt.xticks([0.5,2.5,4.5,6.5,8.5],[r'${\\bf g}_t$',r'${\\bf c}_t$',r'${\\bf o}_t$',r'${\\bf o}_t \\odot {\\bf c}_t$',r'${\\bf h}_t$']);\n",
    "# plt.axvline(x=1.5,color=\"lime\",linewidth=3)\n",
    "# plt.axvline(x=3.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# plt.axvline(x=5.5,linestyle=\"dashed\",color=\"lime\")\n",
    "# plt.axvline(x=7.5,color=\"lime\",linewidth=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cde257-370d-42fe-bd5f-548a09b863b5",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol h}_t$ 특징: (1) ${\\boldsymbol c}_t$에서 원하는 것만 선택적으로 특징으로 삼은 느낌. (2) $c_t$보다 훨씬 값을 다양하게 가진다. ($\\odot$ 의 효과 )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8210864-19de-4395-92bb-d79309896e0d",
   "metadata": {},
   "source": [
    "## D. LSTM의 알고리즘 리뷰 I (수식위주)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4f48f14-ecde-4a67-b72c-c1ed7f973892",
   "metadata": {},
   "source": [
    "**(step1)** calculate ${\\tt ifgo}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cb9aff-c50b-47ba-bdce-407b845e4296",
   "metadata": {},
   "source": [
    "${\\tt ifgo} = {\\boldsymbol x}_t  \\big[{\\bf W}_{ii} | {\\bf W}_{if}| {\\bf W}_{ig} |{\\bf W}_{io}\\big] + {\\boldsymbol h}_{t-1}  \\big[ {\\bf W}_{hi}|{\\bf W}_{hf} |{\\bf W}_{hg} | {\\bf W}_{ho} \\big] + bias$\n",
    "\n",
    "$=\\big[{\\boldsymbol x}_t{\\bf W}_{ii} + {\\boldsymbol h}_{t-1}{\\bf W}_{hi} ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{if}+ {\\boldsymbol h}_{t-1}{\\bf W}_{hf}~ \\big|~ {\\boldsymbol x}_t{\\bf W}_{ig} + {\\boldsymbol h}_{t-1}{\\bf W}_{hg}  ~\\big|~ {\\boldsymbol x}_t{\\bf W}_{io} + {\\boldsymbol h}_{t-1}{\\bf W}_{ho} \\big] + bias$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e08b45-dbff-4be9-a9a5-c09f0a745d83",
   "metadata": {},
   "source": [
    "참고: 위의 수식은 아래코드에 해당하는 부분\n",
    "\n",
    "```Python\n",
    "ifgo = xt @ lstm_cell.weight_ih.T +\\\n",
    "       ht @ lstm_cell.weight_hh.T +\\\n",
    "       lstm_cell.bias_ih + lstm_cell.bias_hh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c9ab21-3f65-4953-8d70-d4ec6f9dc711",
   "metadata": {},
   "source": [
    "**(step2)** decompose ${\\tt ifgo}$ and get ${\\boldsymbol i}_t$, ${\\boldsymbol f}_t$, ${\\boldsymbol g}_t$, ${\\boldsymbol o}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76f2f44-148c-4adb-9272-a52c4e8f4a2a",
   "metadata": {},
   "source": [
    "${\\boldsymbol i}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{ii} + {\\boldsymbol h}_{t-1} {\\bf W}_{hi} +bias )$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc75e3d-78f2-44a4-81ba-6f1c22c0b845",
   "metadata": {},
   "source": [
    "${\\boldsymbol f}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{if} + {\\boldsymbol h}_{t-1} {\\bf W}_{hf} +bias )$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6847818-3906-413a-8ae7-ff9aa2b7a7c1",
   "metadata": {},
   "source": [
    "${\\boldsymbol g}_t = \\tanh({\\boldsymbol x}_t {\\bf W}_{ig} + {\\boldsymbol h}_{t-1} {\\bf W}_{hg} +bias )$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f352ad9-059b-48e4-bae8-cae4dd54adde",
   "metadata": {},
   "source": [
    "${\\boldsymbol o}_t = \\sigma({\\boldsymbol x}_t {\\bf W}_{io} + {\\boldsymbol h}_{t-1} {\\bf W}_{ho} +bias )$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a990af3-459a-4b40-a545-422c159ad4d9",
   "metadata": {},
   "source": [
    "**(step3)** calculate ${\\boldsymbol c}_t$ and ${\\boldsymbol h}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227a768b-86de-4f8c-8b07-73b3dca4f321",
   "metadata": {},
   "source": [
    "${\\boldsymbol c}_t = {\\boldsymbol i}_t \\odot {\\boldsymbol g}_t+ {\\boldsymbol f}_t \\odot {\\boldsymbol c}_{t-1}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc230aac-7778-4561-a0f3-4e59a1a4e99b",
   "metadata": {},
   "source": [
    "${\\boldsymbol h}_t = \\tanh({\\boldsymbol o}_t \\odot {\\boldsymbol c}_t)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa9dd69-f94b-4354-b408-2f2b0933193d",
   "metadata": {},
   "source": [
    "## E. LSTM의 알고리즘 리뷰 II (느낌위주)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12160ed4-5f29-4ae2-a382-635ced02a50a",
   "metadata": {},
   "source": [
    "- 이해 및 암기를 돕기위해서 비유적으로 설명한 챕터입니다.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f6e5f8-4710-4ee0-ab88-31195edb0f99",
   "metadata": {},
   "source": [
    "`-` 느낌: RNN이 콩물에서 간장을 한번에 숙성시키는 방법이라면 LSTM은 콩물에서 간장을 단계를 나누어 숙성하는 느낌이다. \n",
    "\n",
    "- RNN: ${\\boldsymbol x}_t \\overset{{\\boldsymbol h}_{t-1}}{\\longrightarrow} {\\boldsymbol h}_t$\n",
    "- LSTM: ${\\boldsymbol x}_t \\overset{{\\boldsymbol h}_{t-1}}{\\longrightarrow} {\\boldsymbol g}_t \\overset{{\\boldsymbol c}_{t-1}}{\\longrightarrow} \\Big({\\boldsymbol c}_t \\to {\\boldsymbol h}_t \\Big)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afc8944-23e6-4848-a715-be6bcab000ad",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol g}_t$에 대하여\n",
    "\n",
    "- 과거와 현재의 결합 (선형변환): ${\\boldsymbol x}_t$와 ${\\boldsymbol h}_{t-1}$를 ${\\bf W}_{ig}, {\\bf W}_{hg}$를 이용해 선형결합\n",
    "- 숙성(비선형변환): $\\tanh$\n",
    "- 느낌: RNN에서 간장을 만들던 그 수식에서 $h_t$를 $g_t$로 바꾼것 그래서 RNN의 간장과 비슷하다고 생각하면 된다. \n",
    "- 노트: RNN의 간장은 한계를 가지고 있는데 그 한계를 극복하기 위해 만든 것이 ${\\boldsymbol c}_t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2af51c-24c6-44b5-9b41-a2a02c720323",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol c}_t$에 대하여\n",
    "\n",
    "- 과거와 현재의 결합 (선형변환): ${\\boldsymbol g}_{t}$와 ${\\boldsymbol c}_{t-1}$를 요소별로 선택하고 더하는 과정 \n",
    "- 숙성 (비선형변환): 없음. \n",
    "- 느낌: 과거와 현재의 정보중 유리한것만 기억하여 선택적으로 결합함. 이때 결합방식에 대한 노하우는 ${\\tt input-gate}$, ${\\tt forget-gate}$ 에 있으며 그러한 결합의 결과가 ${\\boldsymbol c}_t$에 있음. 이 ${\\boldsymbol c}_t$에 대한 정보는 그대로 \"냉동보관(?)\"되어 다음세대로 내려옴.\n",
    "- 비고: ${\\boldsymbol c}_t$는 사실상 LSTM 알고리즘의 꽃이라 할 수 있음. LSTM은 long short term memory의 약자임. 기존의 RNN은 장기기억을 활용함에 약점이 있는데 LSTM은 단기기억/장기기억 모두 잘 활용함. LSTM이 장기기억을 잘 활용하는 비법은 바로 ${\\boldsymbol c}_t$에 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374c473a-dfbf-4da1-a51a-b4f7fc693621",
   "metadata": {},
   "source": [
    "`-` ${\\boldsymbol h}_t$에 대하여\n",
    "\n",
    "- 과거와 현재의 결합 (선형변환): 없음 \n",
    "- 숙성 (비선형변환): $\\tanh({\\boldsymbol c}_t)$를 요소별로 선택하여 숙성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055886ba-80e5-4ed1-ad18-ed31bbf53236",
   "metadata": {},
   "source": [
    "> RNN은 기억할 과거정보가 ${\\boldsymbol h}_{t-1}$ 하나이지만 LSTM은 ${\\boldsymbol c}_{t-1}$, ${\\boldsymbol h}_{t-1}$ 2개이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a83203f-ce76-40b6-8027-755672aca419",
   "metadata": {},
   "source": [
    "## F. LSTM이 강한이유 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd901a3f-391e-4077-af16-ba97d1909121",
   "metadata": {},
   "source": [
    "`-` 답변1: LSTM이 장기기억에 유리함. 그 이유는 input, forget, output gate 들이 장기기억을 위한 역할을 하기 때문. \n",
    "\n",
    "- 비판: 아키텍처에 대한 이론적 근거는 없음. 장기기억을 위하여 꼭 LSTM같은 구조일 필요는 없음. (게이트는 꼭3개이어야 하는지?)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b4cca1e-ecba-461f-b27e-8381848bfa2c",
   "metadata": {},
   "source": [
    "`-` 답변2: 아키텍처상으로 LSTM은 RNN을 포함함. 그래서 이론적으로 LSTM의 성능이 RNN보다 떨어질 이유는 없음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f6644c-c52d-4db4-af94-51aba33d3a11",
   "metadata": {},
   "source": [
    "`-` 답변3: 저는 사실 아까 살펴본 아래의 이유로 이해하고 있습니다. \n",
    "\n",
    "- 실험적으로 살펴보니 LSTM이 RNN보다 장기기억에 유리했음.\n",
    "- 그 이유: RNN은 ${\\boldsymbol h}_t$의 값이 -1 혹은 1로 결정되는 경우가 많았음. 그러나 경우에 따라서는 ${\\boldsymbol h}_t$이 -1~1의 값을 가지는 것이 문맥적 뉘앙스를 포착하기에는 유리한데 LSTM이 이러한 방식으로 학습되는 경우가 많았음. \n",
    "- 왜 LSTM의 ${\\boldsymbol h}_t$은 -1,1 이외의 값을 쉽게 가질 수 있는가? $\\odot$ 때문에.. 즉 게이트때문에.."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ca1adf-19c7-4a16-a147-17da3b968f00",
   "metadata": {},
   "source": [
    "# 6. Ref "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e917c7b2-76de-4bb1-8399-5045c798cbec",
   "metadata": {},
   "source": [
    "`-` 참고자료들 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8734514-f2a7-4ccc-a46c-57d321fef918",
   "metadata": {},
   "source": [
    "- <https://colah.github.io/posts/2015-08-Understanding-LSTMs/>\n",
    "- <https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html>\n",
    "- <https://arxiv.org/abs/1402.1128>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
