{
 "cells": [
  {
   "cell_type": "raw",
   "id": "9c91760c-0490-4bbd-a907-f67f3abb9fb2",
   "metadata": {
    "tags": []
   },
   "source": [
    "---\n",
    "title: \"08wk-1,2: 생성모형 -- Generative Adversarial Network (GAN)\"\n",
    "author: \"최규빈\"\n",
    "date: \"04/22/2024\"\n",
    "categories:\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b13452ba-0daf-4e48-ae96-6c2b94316491",
   "metadata": {
    "id": "e67ab8e0"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/guebin/DL2024/blob/main/posts/08wk-1-2.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" style=\"text-align: left\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b6c0ff-0060-496d-b9dc-20f843d2a7eb",
   "metadata": {},
   "source": [
    "# 1. 강의영상 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577ba98a-adbd-414d-b4f4-fa104ba5f92e",
   "metadata": {
    "tags": []
   },
   "source": [
    "{{<video https://youtu.be/playlist?list=PLQqh36zP38-xfh-AQQI0B_GONOjgj9DCi&si=uWImDc1bYBoNqCB_ >}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78c28f9b-64a4-4979-9eab-dbf88f2f7f89",
   "metadata": {},
   "source": [
    "# 2. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f622828-1f15-4ee0-a2fd-680c24d412ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "import fastai.vision.all \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b10e9-8a60-4b7c-b0b3-9473659eaf70",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 3. GAN [@goodfellow2014generative] intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf632713-7419-4a65-9fef-74ea6fb71370",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 저자: 이안굿펠로우 \n",
    "\n",
    "- 천재임 \n",
    "- 지도교수가 요수아 벤지오 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc84280c-e32f-41ab-9365-b586b7b7490e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 저는 아래의 논문 읽고 소름돋았어요.. \n",
    "\n",
    "- https://arxiv.org/abs/1406.2661 (2021-09, 38751회 인용.. $\\to$ 2022-09, 48978회 인용.. $\\to$ 2024-03, 66609 인용..)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052bd17f-125d-4fea-84a9-02ddc8e133f8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 최근 10년간 머신러닝 분야에서 가장 혁신적인 아이디어이다. (얀르쿤, 2014년 시점..) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e1cb52-376d-4b3a-af31-cfe29a540b67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 무슨내용? 생성모형 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1afad5-4598-480f-85e5-808d19bdac24",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## A. 생성모형이란? (쉬운 설명)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf4e02c-8f3f-46a7-98d9-03f9e1768e38",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 만들수 없다면 이해하지 못한 것이다, 리처드 파인만 (천재 물리학자) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49bb7fa-c917-4011-a9e2-4f13fe117b49",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 사진속에 들어있는 동물이 개인지 고양이인지 맞출수 있는 기계와 개와 고양이를 그릴수 있는 기계중 어떤것이 더 시각적보에 대한 이해가 깊다고 볼 수 있는가? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab319f4-7392-4ae3-8e55-c72939ae847f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 진정으로 인공지능이 이미지자료를 이해했다면, 이미지를 만들수도 있어야 한다. $\\to$ 이미지를 생성하는 모형을 만들어보자 $\\to$ 성공 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd481c59-5d4c-46b7-b429-df16f1abddd8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/1/1f/Woman_1.jpg){width=70%}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2771aca-477a-4277-9650-a9f575d02da5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## B. GAN의 응용분야"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52074c49-e433-4c85-9de1-cc8d19989dd9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 내가 찍은 사진이 피카소의 화풍으로 표현된다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f171dd8-53cd-496e-8262-19e82147cd21",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 퀸의 라이브에이드가 4k로 나온다면?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1443a32f-8f45-47c9-9da9-62c10a5972b2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 1920년대 서울의 모습이 칼라로 복원된다면? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e800b9c7-a4cf-4a4c-aab4-51b6383b1117",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 딥페이크: 유명인의 가짜 포르노, 가짜뉴스, 협박(거짓기소) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ad6b94-282c-48ca-8502-9da318c20825",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 거북이의 커버.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50b335a-c1c0-4a35-ae01-ef524170947c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 너무 많아요....."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1bc26b-4092-4096-aec1-a17a8111e784",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## C. 생성모형이란? 통계학과 버전의 설명 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a1ce1e-c105-4d31-9c34-e7097ff076f0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> 제한된 정보만으로 어떤 문제를 풀 때, 그 과정에서 원래의 문제보다 일반적인 문제를 풀지 말고 (=문제를 괜히 어렵게 만들어서 풀지 말고), 가능한 원래의 문제를 직접 풀어야한다. 배프닉 (SVM 창시자) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f474310-9e9b-4d85-9fab-2fa1754dc741",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 이미지 $\\boldsymbol{X}$ 가 주어졌을 경우 라벨을 $y$ 라고 하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab2872e-adf0-4b5f-b012-a4c5f8da1966",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 이미지를 보고 라벨을 맞추는 일은 $p(y| \\boldsymbol{X})$에 관심이 있다. -- 판별모형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0feb467c-c1eb-4144-97e6-2cb5d5a75498",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 이미지를 생성하는 일은 $p(\\boldsymbol{X},y)$에 관심이 있는것이다. -- 생성모형"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39678e4-fa4c-47ea-b787-553f7a0b5088",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 데이터의 생성확률 $p(\\boldsymbol{X},y)$을 알면 클래스의 사후확률 $p(y|\\boldsymbol{X})$를 알 수 있음. (아래의 수식 참고) 하지만 역은 불가능 \n",
    "\n",
    "$$p(y|{\\boldsymbol X}) = \\frac{p({\\boldsymbol X},y)}{p({\\boldsymbol X})} = \\frac{p({\\boldsymbol X},y)}{\\sum_{y}p({\\boldsymbol X},y)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48237f-740a-4e4a-914e-3105f9f18e3a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- 즉 이미지를 생성하는일은 분류문제보다 더 어려운 일이라 해석가능 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31989e8e-a39a-4349-b141-e2de4d2c8c7b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 따라서 배프닉의 원리에 의하면 일반적인 분류문제를 해결할때 \"판별모형이 생성모형보다 더 바람직한 접근법\"이라 할 수 있음. 즉 개와 고양이를 구분할 때, 그려진 개와 고양이 사진을 잘 구분하면 되는 것이지 굳이 개와 고양이를 그릴줄 알아야하는건 아니라는 의미. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8a46dc-c085-4a8e-aa89-13933ae2d823",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "`-` 예전에는 머신러닝의 응용분야가 \"분류/회귀\"에 한정된 느낌이었는데 요즘은 생성모형도 인기있음. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f001b9-042e-4de4-91ca-c8ef911c91fc",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## D. GAN의 원리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea6f56f-c919-407d-80a7-85f1d1b6de30",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` GAN은 생성모형 중 하나임 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679d836f-9cdc-498b-b3f4-b0b5f0c4ee17",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` GAN의 원리는 경찰과 위조지폐범이 서로 선의의(?) 경쟁을 통하여 서로 발전하는 모형으로 설명할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0446fc09-05d8-4372-bf16-2a5108a62557",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> The generative model can be thought of as analogous to a team of fakers,\n",
    "trying to produce fake currency and use it without detection, while the discriminative model is\n",
    "analogous to the police, trying to detect the counterfeit currency. Competition in this game drives\n",
    "both teams to improve their methods until the counterfeits are indistiguishable from the genuine\n",
    "articles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "311fa6ef-e096-497d-8e7e-871051f673f2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 서로 적대적인(adversarial) 네트워크(network)를 동시에 학습시켜 가짜이미지를 만든다(generate) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef826614-e5a0-4e91-b51b-5423f13bf726",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 무식한 상황극.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe7c1a7-8726-4d80-9770-ee683dbd70a4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- 위조범: 가짜돈을 만들어서 부자가 되어야지! (가짜돈을 그림) \n",
    "- 경찰: (위조범이 만든 돈을 보고) 이건 가짜다! \n",
    "- 위조범: 걸렸군.. 더 정교하게 만들어야지.. \n",
    "- 경찰: 이건 진짠가?... --> 상사에게 혼남. 그것도 구분못하냐고 --> (판별능력 업그레이드) --> 이건 가짜다!! \n",
    "- 위조범: 더 정교하게 만들자.. \n",
    "- 경찰: 더 판별능력을 업그레이드 하자! \n",
    "- 반복.. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649d8e98-0935-4e00-8605-1f09d4d0bc0e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`-` 굉장히 우수한 경찰조차도 진짜와 가짜를 구분하지 못할때(=진짜 이미지를 0.5의 확률로만 진짜라고 말할때 = 가짜 이미지를 0.5의 확률로만 가짜라고 말할때) 학습을 멈춘다. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64432128-6ac3-4b51-be41-835cc28ab843",
   "metadata": {
    "tags": []
   },
   "source": [
    "# 4. GAN의 구현"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f64e9ba-265c-48fe-80be-93afd1c59587",
   "metadata": {},
   "source": [
    "## A. Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce06afe-ad52-41bb-82ce-6184c8a714c9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/home/myuser/.fastai/data/mnist_png')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = fastai.data.external.untar_data(fastai.data.external.URLs.MNIST)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "891fca54-9896-45a0-a66d-3037a3a831e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6131, 1, 28, 28])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_real = torch.stack([torchvision.io.read_image(str(l)) for l in (path/'training/3').ls()],axis=0)/255\n",
    "X_real.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86de9668-5aca-4737-af82-184aaa8a4e27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x76edfd2db6d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f7474-02e8-4211-8cfd-91776d9c623d",
   "metadata": {},
   "source": [
    "## B. 페이커 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6c8da25-f617-46dc-8198-53ae9ea836f1",
   "metadata": {},
   "source": [
    "> \"net_faker: noise $\\to$ 가짜이미지\" 를 만들자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40574235-6806-4e97-841c-5b974cd0f3a0",
   "metadata": {},
   "source": [
    "`-` 네트워크의 입력: (n,??) 인 랜덤으로 뽑은 숫자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72cb20b6-fcda-42a0-a5df-6b4544200377",
   "metadata": {},
   "source": [
    "`-` 네트워크의 출력: (n,1,28,28)의 텐서 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129f9915-26e0-4716-896d-a4c382194e0b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.randn(1,4) # 이게 들어온다고 상상하자. 하나의 observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b617e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Reshape2828(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5186df22",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 2 required positional arguments: 'in_features' and 'out_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m net_faker \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSequential(\n\u001b[1;32m      2\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m      3\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[1;32m      4\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m64\u001b[39m,\u001b[38;5;241m64\u001b[39m),\n\u001b[1;32m      5\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mReLU(),\n\u001b[0;32m----> 6\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLinear\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m      7\u001b[0m     torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mSigmoid()\n\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 2 required positional arguments: 'in_features' and 'out_features'"
     ]
    }
   ],
   "source": [
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(4,64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64,64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(64,784),\n",
    "    torch.nn.Sigmoid(),\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3381a416",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9394ee7d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6326f11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7feb28e-432f-4b2e-9a9b-f35529a5b1c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Reshape2828(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "    def forward(self,X):\n",
    "        return X.reshape(-1,1,28,28) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "441bb7d0-4fdb-469f-9b77-4e5aa0fdaba1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -> (n,64) \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -> (n,64)   \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -> (n,784) \n",
    "    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n",
    "    Reshape2828()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5580ac62-1319-48bf-9340-01adc92afcd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_faker(torch.randn(1,4)).shape # 가짜이미지!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fae8804-015b-4d71-afa2-76442e181774",
   "metadata": {},
   "source": [
    "## C. 경찰 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e13759d-132e-4405-a6b6-f17ab442cc13",
   "metadata": {},
   "source": [
    "> net_police: 진짜이미지 $\\to$ 0 // 가짜이미지 $\\to$ 1 와 같은 네트워크를 설계하자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28eb7a1a-a1e8-4898-b0e1-b8e9d7c7e670",
   "metadata": {},
   "source": [
    "`-` 네트워크의 입력: (n,1,28,28) 인 이미지 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dada3a59-55f1-410d-9d3e-fb11e3166101",
   "metadata": {},
   "source": [
    "`-` 네트워크의 출력: 0,1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec6eca9-78a4-4a6c-9214-b4e3b5e19288",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784,out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cff0644-90a9-43c0-9ee7-936b7d89d8a5",
   "metadata": {},
   "source": [
    "## D. 바보경찰, 바보페이커"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df735ee5-32f2-4d2b-9be7-1f62a17ea6be",
   "metadata": {},
   "source": [
    "> 스토리를 전개해볼까? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5609b4ec-4d45-4aba-a18a-751dcb7e75e2",
   "metadata": {},
   "source": [
    "`-` 경찰네트워크가 가짜이미지를 봤을때 어떤 판단을 하는지, 진짜 이미지를 봤을떄 어떤 판단을 하는지 살펴보자. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a9c1f5-d930-472d-b636-6bb6b3559eda",
   "metadata": {},
   "source": [
    "***<경찰이 진짜이미지를 봤다면>***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7f86e0-3128-4972-8f89-9a3a37478a78",
   "metadata": {},
   "source": [
    "`-` 진짜이미지 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8dea27-2d63-477e-b4b2-d4412cc1139d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_real[0].reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d64cedf-7833-4645-af60-a340f0dc9d73",
   "metadata": {},
   "source": [
    "`-` 진짜 이미지를 경찰한테 한장 줘볼까? $\\to$ yhat이 나올텐데, 이 값이 0이어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7390b7a2-0712-4c19-81c5-9186f847d55d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_real = net_police(X_real[[0]]) # 이 값이 0이어야 하는데..\n",
    "yhat_real"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af9161a-c816-49b9-8e4f-dfea7ac73493",
   "metadata": {},
   "source": [
    "- 진짜 이미지가 입력으로 왔으므로 `yhat_real` $\\approx$ `0` 이어야 함\n",
    "- 그런데 0과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0855a36-d03f-4e54-8687-c18f3dc33f55",
   "metadata": {},
   "source": [
    "***<경찰이 가짜이미지를 봤다면>***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce80265c-1661-4eae-8af5-d261689adcc1",
   "metadata": {},
   "source": [
    "`-` 가짜이미지 -- 데이터셋이 있는게 아니고 net_faker가 생성해야하는 데이터 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b529a779-e18e-4cc8-a8fb-33e234161034",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Noise = torch.randn(1,4)\n",
    "Noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810e572d-9e08-4748-a68e-364153a11938",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_faker(Noise).shape # 페이커가 만든 가짜 이미지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f27f7e-1dee-425f-b9c1-d0372a9b6e77",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccac23a4-30e1-4607-b0e6-a35bdaea69d7",
   "metadata": {},
   "source": [
    "- 누가봐도 가짜이미지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a9b8df6-08f5-4c15-acf5-c480a6a91d82",
   "metadata": {},
   "source": [
    "`-` 가짜 이미지를 경찰한테 한장 줘볼까? $\\to$ yhat이 나올텐데, 이 값이 1이어야 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d018efd-49f3-4491-a204-1f93b41fd6c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_fake = net_police(net_faker(Noise).data) # 이 값이 1이어야 하는데..\n",
    "yhat_fake"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d48e88a6-bd27-4c70-830a-72e51a9c3851",
   "metadata": {},
   "source": [
    "- 가짜 이미지가 입력으로 왔으므로 `yhat_fake` $\\approx$ `1` 이어야 함\n",
    "- 그런데 1과 거리가 멀어보임. (=배운것이 없는 무능한 경찰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48701c33-831a-41a6-8255-a4224c21fa4e",
   "metadata": {},
   "source": [
    "`-` 페이커의 무능함 (왼쪽 이미지를 가짜이미라고 만들어 놓았음) + 경찰의 무능함 (왼쪽과 오른쪽을 보고 뭐가 진짜인지도 모름)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4207b17b-77a1-4514-b3c9-73a1064d139e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(net_faker(Noise).data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\n",
    "ax[1].imshow(X_real[[0]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39df3054-25e8-4f8c-ae2e-42e3c80d7eeb",
   "metadata": {},
   "source": [
    "## E. 똑똑해진 경찰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0464e239-fd21-479b-9104-54e57d0dfe87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca2c258-34c1-405c-8170-e35f970e5fb5",
   "metadata": {},
   "source": [
    "`-` 데이터 정리 \n",
    "\n",
    "- 원래 $n=6131$개의 이미지 자료가 있음. 이를 ${\\bf X}_{real}$ 라고 하자. 따라서 ${\\bf X}_{real}$ 의 차원은 (6131,1,28,28). \n",
    "- 위조범이 만든 가짜자료를 원래 자료와 같은 숫자인 6131개 만듦. 이 가짜자료를 ${\\bf X}_{fake}$ 라고 하자. 따라서 ${\\bf X}_{fake}$ 의 차원은 (6131,1,28,28). \n",
    "- 진짜자료는 0, 가짜자료는 1으로 라벨링. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfedf23-b6ec-4bc2-baa7-c1716a627627",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Noise = torch.randn(6131,4)     # n = 6131\n",
    "X_fake = net_faker(Noise).data\n",
    "y_real = torch.tensor([0]*6131).reshape(-1,1).float()   # real\n",
    "y_fake = torch.tensor([1]*6131).reshape(-1,1).float()   # fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dce045",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_real.shape , y_fake.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc6490",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fake.shape , X_real.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbaf9924-6d33-4321-9d62-cc344510823b",
   "metadata": {},
   "source": [
    "`-` step1: X_real, X_fake를 보고 각가 yhat_real, yhat_fake를 만드는 과정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b57d56-7e6d-486b-aeb7-d98b4cdb8bc0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_real = net_police(X_real)\n",
    "yhat_fake = net_police(X_fake)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94fe68ad-666f-4cd5-9f4b-f4b1c7b6ee0e",
   "metadata": {},
   "source": [
    "`-` step2: 손실을 계산 -- 경찰의 미덕은 (1) 가짜이미지를 가짜라고 하고 (yhat_fake $\\approx$ y_fake) (2) 진짜이미지를 진짜라고 해야한다. (yhat_real $\\approx$ y_real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631023f4-4a9c-4284-9788-4204065ddaa3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "bce = torch.nn.BCELoss()\n",
    "loss_police = bce(yhat_fake,y_fake) + bce(yhat_real,y_real)\n",
    "loss_police"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9631ed-4316-46b9-897a-e618ad9f6149",
   "metadata": {},
   "source": [
    "`-` step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4efa266-0721-40c2-85d8-78ced44d5873",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "##\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784,out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters())\n",
    "# Noise = torch.randn(6131,4) \n",
    "\n",
    "##\n",
    "for epoc in range(50):\n",
    "    Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise).data\n",
    "    ## step1 \n",
    "    yhat_real = net_police(X_real)  # 0이길 바람\n",
    "    yhat_fake = net_police(X_fake)  # 1이길 바람\n",
    "    ## step2\n",
    "    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n",
    "    ## step3 \n",
    "    loss_police.backward()\n",
    "    ## step4 \n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa3777b-4e9e-44f7-86b8-12c74055050a",
   "metadata": {},
   "source": [
    "`-` 훈련된 경찰의 성능을 살펴보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d50c334-f5ab-43b6-ba27-1520d27ff07a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_police(X_real) # 거의 0으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a58343-0e34-4624-b5fa-3b5120a84249",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_police(X_fake) # 거의 1로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333ddfa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "net_police2 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784,out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police2.parameters())\n",
    "Noise = torch.randn(6131,4) \n",
    "\n",
    "##\n",
    "for epoc in range(50):\n",
    "    # Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise).data\n",
    "    ## step1 \n",
    "    yhat_real = net_police2(X_real)  # 0이길 바람\n",
    "    yhat_fake = net_police2(X_fake)  # 1이길 바람\n",
    "    ## step2\n",
    "    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n",
    "    ## step3 \n",
    "    loss_police.backward()\n",
    "    ## step4 \n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc6539fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_police2(X_real) # 거의 0으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d4aeb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_police2(X_fake) # 거의 1로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c41944",
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "net_police3 = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784,out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police3.parameters())\n",
    "# Noise = torch.randn(6131,4) \n",
    "##\n",
    "for epoc in range(50):\n",
    "    # torch.manual_seed(5)\n",
    "    Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise).data\n",
    "    ## step1 \n",
    "    yhat_real = net_police3(X_real)  # 0이길 바람\n",
    "    yhat_fake = net_police3(X_fake)  # 1이길 바람\n",
    "    ## step2\n",
    "    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n",
    "    ## step3 \n",
    "    loss_police.backward()\n",
    "    ## step4 \n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988ed80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_police3(X_real) # 거의 0으로!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b944f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "net_police3(X_fake) # 거의 1로!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "134f6b37-4bb0-45b6-afe1-efb60bce8666",
   "metadata": {},
   "source": [
    "`-` 꽤 우수한 경찰이 되었음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f00013-439e-4f03-b8d1-e7af75f616d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,2)\n",
    "ax[0].imshow(X_fake[[-1]].data.reshape(28,28),cmap=\"gray\"); ax[0].set_title(\"fake\")\n",
    "ax[1].imshow(X_real[[-1]].reshape(28,28),cmap=\"gray\"); ax[1].set_title(\"real\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b548e1be-c70c-4817-b81e-27c13ab37415",
   "metadata": {},
   "source": [
    "## F. 더 똑똑해지는 페이커"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0242a957-b812-460d-8ee9-4bd1225cb8de",
   "metadata": {},
   "source": [
    "`-` step1: Noise $\\to$ X_fake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c11b5e0-2844-46d8-815b-d39f68c195a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "Noise = torch.randn(6131,4)\n",
    "X_fake = net_faker(Noise) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d619fecd-a594-4c5d-b12d-0cb1ae3a535a",
   "metadata": {},
   "source": [
    "`-` step2: 손실함수 -- 페이커의 미덕은 (잘 훈련된) 경찰이 가짜이미지를 진짜라고 판단하는 것. 즉 `yhat_fake` $\\approx$ `y_real` 이어야 페이커의 실력이 우수하다고 볼 수 있음. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded32ace-c36c-4c3e-a82e-107ec746bb6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yhat_fake = net_police(X_fake) \n",
    "loss_faker = bce(yhat_fake,y_real) ## 가짜이미지를 보고 잘 훈련된 경찰조차 진짜이미지라고 깜빡 속으면 위조범의 실력이 좋은 것임"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ae0af3-a0b3-4e30-bd11-67ac2013297e",
   "metadata": {},
   "source": [
    "`-` step3~4는 별로 특별한게 없음. 그래서 바로 epoch을 진행시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71129701-5022-4a79-8448-c2744e85c9d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -> (n,64) \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -> (n,64)   \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -> (n,784) \n",
    "    torch.nn.Sigmoid(), # 출력을 0~1로 눌러주는 역할.. -- 저는 이 레이어가 일종의 문화충격이었어요.. (시그모이드를 이렇게 쓴다고??)\n",
    "    Reshape2828()\n",
    ")\n",
    "#bce = torch.nn.BCELoss()\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters())\n",
    "#--#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0811cd56-b380-428d-860f-65ed893019fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoc in range(10):\n",
    "    # step1\n",
    "    Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise) \n",
    "    # step2\n",
    "    yhat_fake = net_police(X_fake) \n",
    "    loss_faker = bce(yhat_fake,y_real)\n",
    "    # step3 \n",
    "    loss_faker.backward()\n",
    "    # step4 \n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7f9364-b5d8-41a8-8566-53ebad467453",
   "metadata": {},
   "source": [
    "`-` 위조범의 실력향상을 감상해보자. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70408f5-be17-4957-83b8-51e1144aa5a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,5,figsize=(10,4))\n",
    "k = 0 \n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n",
    "        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n",
    "        k = k+1 \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87735657-7b6f-4138-8f01-39c8378b70ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "((yhat_fake > 0.5) == 0).float().mean() # 경찰이 가짜이미지를 진짜라고 생각한 비율 = 페이커가 사기에 성공한 비율"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72339c95-84c9-428d-afd0-fdb396d1b332",
   "metadata": {},
   "source": [
    "## G. 경쟁학습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97bd651d-b03f-4f1e-bf39-e06a24565d4f",
   "metadata": {},
   "source": [
    "> 두 적대적인 네트워크를 경쟁시키자!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82987ccd-4000-478e-978d-0819fbb3eff2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(43052)\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784,out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30,out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ")\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64), # (n,4) -> (n,64) \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64), # (n,64) -> (n,64)   \n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784), # (n,64) -> (n,784) \n",
    "    torch.nn.Sigmoid(), \n",
    "    Reshape2828()\n",
    ")\n",
    "bce = torch.nn.BCELoss()\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(),lr=0.001,betas=(0.5,0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(),lr=0.0002,betas=(0.5,0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a13b02e-d9ae-46dc-9558-78432453abca",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoc in range(1000):\n",
    "    # net_police 을 훈련\n",
    "    Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise).data # net_faker에 대한 미분꼬리표는 여기선 필요없으므로 .data 만을 이용\n",
    "    ## step1 \n",
    "    yhat_real = net_police(X_real)\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    ## step2 \n",
    "    loss_police = bce(yhat_real,y_real) + bce(yhat_fake,y_fake)\n",
    "    ## step3 \n",
    "    loss_police.backward()\n",
    "    ## step4 \n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()\n",
    "    # net_faker 를 훈련\n",
    "    ## step1 \n",
    "    Noise = torch.randn(6131,4) \n",
    "    X_fake = net_faker(Noise)\n",
    "    ## step2 \n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_faker = bce(yhat_fake,y_real) \n",
    "    ## step3\n",
    "    loss_faker.backward()\n",
    "    ## step4 \n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ed6e8c-342c-42a5-9a91-f2867ad4505f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(2,5,figsize=(10,4))\n",
    "k = 0 \n",
    "for i in range(2):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(X_fake[k].reshape(28,28).data,cmap=\"gray\")\n",
    "        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n",
    "        k = k+1 \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c6ff981",
   "metadata": {},
   "source": [
    "CUDA 사용하여 학습 30000회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942c87a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CUDA 사용 가능한지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 임의의 시드 설정\n",
    "torch.manual_seed(43052)\n",
    "\n",
    "# 모델 정의\n",
    "class Reshape2828(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 28, 28)  # (n, 784) -> (n, 28, 28)\n",
    "\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784, out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784),\n",
    "    torch.nn.Sigmoid(),\n",
    "    Reshape2828()\n",
    ").to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41a6988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수와 옵티마이저\n",
    "bce = torch.nn.BCELoss().to(device)\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "for epoc in range(30000):\n",
    "    # net_police 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device) \n",
    "    X_fake = net_faker(Noise).detach()  # .detach() 사용하여 불필요한 그래디언트 추적 방지\n",
    "    yhat_real = net_police(X_real.to(device))\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_police = bce(yhat_real, y_real.to(device)) + bce(yhat_fake, y_fake.to(device))\n",
    "    loss_police.backward()\n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()\n",
    "\n",
    "    # net_faker 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device)\n",
    "    X_fake = net_faker(Noise)\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_faker = bce(yhat_fake, y_real.to(device))\n",
    "    loss_faker.backward()\n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af699d7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,5,figsize=(10,4))\n",
    "k = 0 \n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(X_fake[k].to(\"cpu\").reshape(28,28).data,cmap=\"gray\")\n",
    "        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n",
    "        k = k+1 \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a437c46",
   "metadata": {},
   "source": [
    "CUDA 사용하여 학습 10000회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e80e53a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CUDA 사용 가능한지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 임의의 시드 설정\n",
    "torch.manual_seed(43052)\n",
    "\n",
    "# 모델 정의\n",
    "class Reshape2828(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 28, 28)  # (n, 784) -> (n, 28, 28)\n",
    "\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784, out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784),\n",
    "    torch.nn.Sigmoid(),\n",
    "    Reshape2828()\n",
    ").to(device)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f77af6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 손실 함수와 옵티마이저\n",
    "bce = torch.nn.BCELoss().to(device)\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(), lr=0.0002, betas=(0.5, 0.999))\n",
    "\n",
    "for epoc in range(10000):\n",
    "    # net_police 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device) \n",
    "    X_fake = net_faker(Noise).detach()  # .detach() 사용하여 불필요한 그래디언트 추적 방지\n",
    "    yhat_real = net_police(X_real.to(device))\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_police = bce(yhat_real, y_real.to(device)) + bce(yhat_fake, y_fake.to(device))\n",
    "    loss_police.backward()\n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()\n",
    "\n",
    "    # net_faker 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device)\n",
    "    X_fake = net_faker(Noise)\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_faker = bce(yhat_fake, y_real.to(device))\n",
    "    loss_faker.backward()\n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec25a3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,5,figsize=(10,4))\n",
    "k = 0 \n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(X_fake[k].to(\"cpu\").reshape(28,28).data,cmap=\"gray\")\n",
    "        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n",
    "        k = k+1 \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0296711",
   "metadata": {},
   "source": [
    "CUDA 사용하여 학습 1000회"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd94f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# CUDA 사용 가능한지 확인\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "# 임의의 시드 설정\n",
    "torch.manual_seed(43052)\n",
    "\n",
    "# 모델 정의\n",
    "class Reshape2828(torch.nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, 28, 28)  # (n, 784) -> (n, 28, 28)\n",
    "\n",
    "net_police = torch.nn.Sequential(\n",
    "    torch.nn.Flatten(),\n",
    "    torch.nn.Linear(in_features=784, out_features=30),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=30, out_features=1),\n",
    "    torch.nn.Sigmoid()\n",
    ").to(device)\n",
    "\n",
    "net_faker = torch.nn.Sequential(\n",
    "    torch.nn.Linear(in_features=4, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=64),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(in_features=64, out_features=784),\n",
    "    torch.nn.Sigmoid(),\n",
    "    Reshape2828()\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# 손실 함수와 옵티마이저\n",
    "bce = torch.nn.BCELoss().to(device)\n",
    "optimizr_police = torch.optim.Adam(net_police.parameters(), lr=0.001, betas=(0.5, 0.999))\n",
    "optimizr_faker = torch.optim.Adam(net_faker.parameters(), lr=0.0002, betas=(0.5, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5251eb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoc in range(100):\n",
    "    # net_police 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device) \n",
    "    X_fake = net_faker(Noise).detach()  # .detach() 사용하여 불필요한 그래디언트 추적 방지\n",
    "    yhat_real = net_police(X_real.to(device))\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_police = bce(yhat_real, y_real.to(device)) + bce(yhat_fake, y_fake.to(device))\n",
    "    loss_police.backward()\n",
    "    optimizr_police.step()\n",
    "    optimizr_police.zero_grad()\n",
    "\n",
    "    # net_faker 훈련\n",
    "    Noise = torch.randn(6131, 4).to(device)\n",
    "    X_fake = net_faker(Noise)\n",
    "    yhat_fake = net_police(X_fake)\n",
    "    loss_faker = bce(yhat_fake, y_real.to(device))\n",
    "    loss_faker.backward()\n",
    "    optimizr_faker.step()\n",
    "    optimizr_faker.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b96328",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(3,5,figsize=(10,10))\n",
    "k = 0 \n",
    "for i in range(3):\n",
    "    for j in range(5):\n",
    "        ax[i][j].imshow(X_fake[k].to(\"cpu\").reshape(28,28).data,cmap=\"gray\")\n",
    "        ax[i][j].set_title(f\"police hat = {yhat_fake[k].item():.4f}\")\n",
    "        k = k+1 \n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15273d5-5b0e-4d03-95b1-0ed6adce48c1",
   "metadata": {},
   "source": [
    "# 5. 초기 GAN의 한계점 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db174dad-0f9e-43e0-a690-4950e8255d96",
   "metadata": {},
   "source": [
    "`-` 두 네트워크의 균형이 매우 중요함 -- 균형이 깨지는 순간 학습은 실패함"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2614cf01-f54e-4074-96e4-b1f209e4d51a",
   "metadata": {},
   "source": [
    "`-` 생성되는 이미지의 다양성이 부족한 경우가 발생함. (mode collapse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
